arch/alpha/Kconfig.debug:	tristate "Kernel FP software completion" if DEBUG_KERNEL && !SMP
arch/alpha/kernel/core_t2.c: * lowering IPL during completion processing in pci_read_config_byte()
arch/alpha/kernel/err_marvel.c:	printk("%s      Split Completion Error:\n"	
arch/alpha/kernel/err_marvel.c:		sprintf(message, "Normal completion");
arch/alpha/kernel/err_marvel.c:		"Memory Read Multiple / Split Completion",
arch/alpha/kernel/err_marvel.c:		printk("%s    Unexpected Split Completion\n",
arch/alpha/kernel/err_marvel.c:		printk("%s    IO7 Split Completion Timeout expired\n",
arch/alpha/kernel/err_marvel.c:			printk("%s    Split Completion Response with "
arch/alpha/kernel/err_marvel.c:		printk("%s    IO7 Received Split Completion Error message\n",
arch/alpha/kernel/err_marvel.c:		printk("%s    Discarded split completion\n", err_print_prefix);
arch/alpha/kernel/err_marvel.c:	 * completion transaction. The symptom is an ERROR_RESPONSE 
arch/alpha/kernel/err_titan.c:		printk("%s    Delayed-Completion Retry Timeout\n", 
arch/alpha/kernel/traps.c:		/* Software-completion summary bit is set, so try to
arch/alpha/math-emu/math.c:MODULE_DESCRIPTION("FP Software completion module");
arch/arc/include/asm/barrier.h: *  - DSYNC provides DMB+completion_of_cache_bpu_maintenance_ops hence not needed
arch/arm/Kconfig:	bool "ARM errata: Interrupted ICIALLUIS may prevent completion of broadcasted operation"
arch/arm/Kconfig:	  completion of a following broadcasted operation if the second
arch/arm/boot/dts/ti/keystone/keystone-k2e-netcp.dtsi:			tx-completion-queue = <530>;
arch/arm/boot/dts/ti/keystone/keystone-k2e-netcp.dtsi:			tx-completion-queue = <531>;
arch/arm/boot/dts/ti/keystone/keystone-k2g-netcp.dtsi:			tx-completion-queue = <78>;
arch/arm/boot/dts/ti/keystone/keystone-k2hk-netcp.dtsi:			tx-completion-queue = <8706>;
arch/arm/boot/dts/ti/keystone/keystone-k2hk-netcp.dtsi:			tx-completion-queue = <8707>;
arch/arm/boot/dts/ti/keystone/keystone-k2l-netcp.dtsi:			tx-completion-queue = <530>;
arch/arm/boot/dts/ti/keystone/keystone-k2l-netcp.dtsi:			tx-completion-queue = <531>;
arch/arm/common/bL_switcher.c:	struct completion inbound_alive;
arch/arm/common/bL_switcher.c:	init_completion(&inbound_alive);
arch/arm/common/bL_switcher.c:	ipi_nr = register_ipi_completion(&inbound_alive, this_cpu);
arch/arm/common/bL_switcher.c:	wait_for_completion(&inbound_alive);
arch/arm/common/bL_switcher.c:	struct completion started;
arch/arm/common/bL_switcher.c:	bL_switch_completion_handler completer;
arch/arm/common/bL_switcher.c:	bL_switch_completion_handler completer;
arch/arm/common/bL_switcher.c: *      with completion notification via a callback
arch/arm/common/bL_switcher.c: * @completer: switch completion callback.  if non-NULL,
arch/arm/common/bL_switcher.c: *	@completer(@completer_cookie) will be called on completion of
arch/arm/common/bL_switcher.c:			 bL_switch_completion_handler completer,
arch/arm/common/bL_switcher.c:		init_completion(&t->started);
arch/arm/common/bL_switcher.c:		init_completion(&t->started);
arch/arm/common/bL_switcher.c:			wait_for_completion(&t->started);
arch/arm/include/asm/bL_switcher.h:typedef void (*bL_switch_completion_handler)(void *cookie);
arch/arm/include/asm/bL_switcher.h:			 bL_switch_completion_handler completer,
arch/arm/include/asm/smp.h:extern int register_ipi_completion(struct completion *completion, int cpu);
arch/arm/kernel/head.S: *  r13 = *virtual* address to jump to upon completion
arch/arm/kernel/head.S: *  r13 = *virtual* address to jump to upon completion
arch/arm/kernel/head.S: * other registers depend on the function called upon completion
arch/arm/kernel/smp.c:#include <linux/completion.h>
arch/arm/kernel/smp.c:	IPI_COMPLETION,
arch/arm/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/arm/kernel/smp.c:		wait_for_completion_timeout(&cpu_running,
arch/arm/kernel/smp.c:	 * before the completion to ensure that data is safely written out
arch/arm/kernel/smp.c:	 * Ensure that the cache lines associated with that completion are
arch/arm/kernel/smp.c:	 * powering down, to ensure that the completion is visible to the
arch/arm/kernel/smp.c:	[IPI_COMPLETION]	= "completion interrupts",
arch/arm/kernel/smp.c:static DEFINE_PER_CPU(struct completion *, cpu_completion);
arch/arm/kernel/smp.c:int register_ipi_completion(struct completion *completion, int cpu)
arch/arm/kernel/smp.c:	per_cpu(cpu_completion, cpu) = completion;
arch/arm/kernel/smp.c:	return IPI_COMPLETION;
arch/arm/kernel/smp.c:	complete(per_cpu(cpu_completion, cpu));
arch/arm/kernel/smp.c:	case IPI_COMPLETION:
arch/arm/lib/copy_template.S: * Abort preamble and completion macros.
arch/arm/mach-bcm/platsmp-brcmstb.c: * cannot use traditional completion structures or spinlocks as they rely on
arch/arm/mach-davinci/sleep.S:	/* Check for DDR2 clock disable completion; */
arch/arm/mach-rpc/ecard.c:#include <linux/completion.h>
arch/arm/mach-rpc/ecard.c:	struct completion *complete;
arch/arm/mach-rpc/ecard.c:	DECLARE_COMPLETION_ONSTACK(completion);
arch/arm/mach-rpc/ecard.c:	req->complete = &completion;
arch/arm/mach-rpc/ecard.c:	wait_for_completion(&completion);
arch/arm/mach-ux500/pm.c:	/* Wait a few cycles for the gic mask completion */
arch/arm/mach-versatile/spc.c:	struct completion done;
arch/arm/mach-versatile/spc.c:static int ve_spc_waitforcompletion(int req_type)
arch/arm/mach-versatile/spc.c:	int ret = wait_for_completion_interruptible_timeout(
arch/arm/mach-versatile/spc.c:	init_completion(&info->done);
arch/arm/mach-versatile/spc.c:	ret = ve_spc_waitforcompletion(req_type);
arch/arm/mach-versatile/spc.c:	init_completion(&info->done);
arch/arm/mach-versatile/spc.c:	ret = ve_spc_waitforcompletion(SPC_SYS_CFG);
arch/arm/mach-versatile/spc.c:	init_completion(&info->done);
arch/arm/mm/cache-feroceon-l2.c: * The cache range operations stall the CPU pipeline until completion.
arch/arm/mm/cache-feroceon-l2.c:	 * until completion.
arch/arm/mm/cache-l2x0.c:	 * until completion.
arch/arm/mm/cache-uniphier.c:#define    UNIPHIER_SSCOQM_CE			BIT(15)	/* notify completion */
arch/arm/mm/dma-mapping.c: * before transfers and delay cache invalidation until transfer completion.
arch/arm/mm/proc-xsc3.S:	sub	pc, \lr, \rd, LSR #32		@ wait for completion and
arch/arm/mm/proc-xscale.S:	mov	\rd, \rd			@ wait for completion
arch/arm/mm/proc-xscale.S:	sub	pc, \lr, \rd, LSR #32		@ wait for completion and
arch/arm64/Kconfig:	bool "Cortex-A55: Completion of affected memory accesses might not be guaranteed by completion of a TLBI (rare)"
arch/arm64/Kconfig:	bool "Cortex-A510: Completion of affected memory accesses might not be guaranteed by completion of a TLBI (rare)"
arch/arm64/include/asm/assembler.h:	 * run to completion as quickly as we can. The preempt_count field will
arch/arm64/include/asm/tlbflush.h: * completion at the end in arch_tlbbatch_flush(). Since we've already issued
arch/arm64/kernel/smp.c:#include <linux/completion.h>
arch/arm64/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/arm64/kernel/smp.c:	wait_for_completion_timeout(&cpu_running,
arch/arm64/kvm/hyp/nvhe/tlb.c:	 * We have to ensure completion of the invalidation at Stage-2,
arch/arm64/kvm/hyp/nvhe/tlb.c:	 * We have to ensure completion of the invalidation at Stage-2,
arch/arm64/kvm/hyp/vhe/tlb.c:	 * We have to ensure completion of the invalidation at Stage-2,
arch/arm64/kvm/hyp/vhe/tlb.c:	 * We have to ensure completion of the invalidation at Stage-2,
arch/csky/include/asm/barrier.h: * sync:        completion barrier, all sync.xx instructions
arch/loongarch/include/asm/barrier.h: * Bit4: ordering or completion (0: completion, 1: ordering)
arch/loongarch/kernel/process.c:#include <linux/completion.h>
arch/loongarch/kernel/smp.c:static DECLARE_COMPLETION(cpu_starting);
arch/loongarch/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/loongarch/kernel/smp.c:	if (!wait_for_completion_timeout(&cpu_starting,
arch/loongarch/kernel/smp.c:	wait_for_completion(&cpu_running);
arch/m68k/fpsp040/bindec.S:	frestore (%a7)+		|restore frame to fpu for completion
arch/m68k/fpsp040/bugfix.S:| This code is entered only on completion of the handling of an
arch/m68k/fpsp040/bugfix.S:| the code sequence to allow completion.  We will jump to
arch/m68k/fpsp040/bugfix.S:| the code sequence to allow completion.  fpsp_fmt_error causes
arch/m68k/include/asm/mcfdma.h:#define	MCFDMA_DCR_INT	        0x8000		/* Enable completion irq */
arch/m68k/include/asm/mcfdma.h:#define MCFDMA_DIR_ASCEN     0x0800 /* Address Sequence Complete (Completion) interrupt enable */
arch/m68k/include/asm/mcfdma.h:#define MCFDMA_DIR_ASC       0x0008 /* Address Sequence Complete (DMA Completion) */
arch/m68k/kernel/entry.S: *  6/05/00 RZ:	 addedd writeback completion after return from sighandler
arch/mips/include/asm/atomic.h:	 * completion barrier at 2: above, which is needed due to the	\
arch/mips/include/asm/barrier.h: * a completion barrier immediately preceding the LL instruction. Therefore we
arch/mips/include/asm/cmpxchg.h:	 * contains a completion barrier prior to the LL, so we don't	\
arch/mips/include/asm/cmpxchg.h:	 * contains a completion barrier prior to the LL, so we don't	\
arch/mips/include/asm/cmpxchg.h:	 * contains a completion barrier after the SC, so we don't	\
arch/mips/include/asm/kvm_host.h:	/* Resume PC after MMIO completion */
arch/mips/include/asm/mach-au1x00/au1xxx_dbdma.h:	u32	dscr_stat;		/* completion status */
arch/mips/include/asm/mach-au1x00/au1xxx_dbdma.h: * meaningful name.  The 'callback' is called during DMA completion
arch/mips/include/asm/octeon/cvmx-pow.h: * Waits for a tag switch to complete by polling the completion bit.
arch/mips/include/asm/octeon/cvmx-pow.h: * Completion for the tag switch must be checked for separately.  This
arch/mips/include/asm/octeon/cvmx-pow.h: * Completion for the tag switch must be checked for separately.  This
arch/mips/include/asm/octeon/cvmx-pow.h: * Completion for the tag switch must be checked for separately.  This
arch/mips/include/asm/octeon/cvmx-pow.h: * Completion for the tag switch must be checked for separately.  This
arch/mips/include/asm/octeon/cvmx-pow.h: * so completion should not be waited for.
arch/mips/include/asm/octeon/cvmx-pow.h: * so completion should not be waited for.
arch/mips/include/asm/octeon/cvmx-pow.h: * immediately, so completion must not be waited for.  This function does NOT
arch/mips/include/asm/octeon/cvmx-pow.h: * immediately, so completion must not be waited for.  This function does NOT
arch/mips/include/asm/sync.h: *   1) Completion barriers, which ensure that a memory operation has actually
arch/mips/include/asm/sync.h: * Ordering barriers can be more efficient than completion barriers, since:
arch/mips/include/asm/sync.h: *      other coherent CPUs will observe their completion before they observe
arch/mips/include/asm/sync.h: * A full completion barrier; all memory accesses appearing prior to this sync
arch/mips/include/asm/sync.h: * For now we use a full completion barrier to implement all sync types, until
arch/mips/include/uapi/asm/siginfo.h:#define SI_ASYNCIO	-2	/* sent by AIO completion */
arch/mips/kernel/mips-cm.c:	[0x14] = "Coherent Completion Sync",
arch/mips/kernel/relocate.c:	/* Completion barrier */
arch/mips/kernel/smp.c:static DECLARE_COMPLETION(cpu_starting);
arch/mips/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/mips/kernel/smp.c:	if (!wait_for_completion_timeout(&cpu_starting,
arch/mips/kernel/smp.c:	wait_for_completion(&cpu_running);
arch/mips/mm/page.c:	 * reliable way to delay completion detection.
arch/mips/mm/page.c:	 * reliable way to delay completion detection.
arch/mips/pci/ops-tx4927.c:	/* wait write cycle completion before checking error status */
arch/mips/pci/pcie-octeon.c:	 * Load completion relaxed ordering (NPEI_CTL_PORTn[WAITL_COM]).
arch/mips/pci/pcie-octeon.c:	 * Load completion relaxed ordering (NPEI_CTL_PORTn[WAITL_COM])
arch/openrisc/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/openrisc/kernel/smp.c:	if (!wait_for_completion_timeout(&cpu_running,
arch/parisc/kernel/perf_asm.S:	ssm     0,0                     ; dummy op to ensure completion
arch/parisc/kernel/perf_asm.S:	ssm     0,0                     ; dummy op to ensure completion
arch/powerpc/include/asm/dbdma.h:	__le16 res_count;	/* residual count after completion */
arch/powerpc/include/asm/icswx.h:/* Chapter 6.5.8 Coprocessor-Completion Block (CCB) */
arch/powerpc/include/asm/icswx.h:#define CCB_CM0_ALL_COMPLETIONS	(0x0)
arch/powerpc/include/asm/icswx.h:struct coprocessor_completion_block {
arch/powerpc/include/asm/icswx.h:	struct coprocessor_completion_block ccb;
arch/powerpc/include/asm/opal-api.h:#define OPAL_ASYNC_COMPLETION	-15
arch/powerpc/include/asm/opal-api.h:#define OPAL_GET_COMPLETION_TOKEN_STATUS	21 /* obsolete */
arch/powerpc/include/asm/opal-api.h:#define OPAL_CHECK_ASYNC_COMPLETION		86
arch/powerpc/include/asm/opal.h:int64_t opal_check_completion(uint64_t buffer, uint64_t size, uint64_t token);
arch/powerpc/include/asm/ps3gpu.h:#define L1GPU_FB_BLIT_WAIT_FOR_COMPLETION	(1ULL << 32)
arch/powerpc/include/asm/ps3stor.h:	struct completion done;
arch/powerpc/include/asm/reg_booke.h:#define DBSR_IC		0x08000000	/* Instruction Completion */
arch/powerpc/include/asm/reg_booke.h:#define DBCR0_ICMP	0x08000000	/* Instruction Completion */
arch/powerpc/include/asm/smu.h: * Completion helper. Pass it to smu_queue_simple or as 'done'
arch/powerpc/include/asm/smu.h: * completion passed in the "misc" argument
arch/powerpc/include/asm/smu.h: * Synchronous helpers. Will spin-wait for completion of a command
arch/powerpc/include/asm/smu.h: * For now, no polling interface is provided so you have to use completion
arch/powerpc/kernel/eeh_event.c:static DECLARE_COMPLETION(eeh_eventlist_event);
arch/powerpc/kernel/eeh_event.c:		if (wait_for_completion_interruptible(&eeh_eventlist_event))
arch/powerpc/kernel/traps.c:		/* Disable instruction completion */
arch/powerpc/kernel/traps.c:		/* Clear the instruction completion event */
arch/powerpc/kvm/book3s_hv_builtin.c: *	2 Passthrough that needs completion in the host
arch/powerpc/kvm/book3s_hv_rmhandlers.S:	 *   2 Passthrough that needs completion in the host
arch/powerpc/lib/sstep.c:		 *   Successful completion for an instruction means that the
arch/powerpc/perf/power7-events-list.h:EVENT(PM_FLUSH_COMPLETION,                    0x30012)
arch/powerpc/platforms/book3s/vas-api.c: * documentation for exact copy/paste usage and completion / error
arch/powerpc/platforms/cell/spufs/sched.c:#include <linux/completion.h>
arch/powerpc/platforms/cell/spufs/switch.c:	/* Stop SPE execution and wait for completion. */
arch/powerpc/platforms/cell/spufs/switch.c:	/* Initiate isolate exit request and wait for completion. */
arch/powerpc/platforms/powermac/low_i2c.c:#include <linux/completion.h>
arch/powerpc/platforms/powermac/low_i2c.c:	struct completion	complete;
arch/powerpc/platforms/powermac/low_i2c.c:		/* Clear completion */
arch/powerpc/platforms/powermac/low_i2c.c:		reinit_completion(&host->complete);
arch/powerpc/platforms/powermac/low_i2c.c:	/* Wait for completion */
arch/powerpc/platforms/powermac/low_i2c.c:		wait_for_completion(&host->complete);
arch/powerpc/platforms/powermac/low_i2c.c:	init_completion(&host->complete);
arch/powerpc/platforms/powermac/low_i2c.c:	struct completion comp;
arch/powerpc/platforms/powermac/low_i2c.c:	init_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:		reinit_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:		wait_for_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:		reinit_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:		wait_for_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:	struct completion comp;
arch/powerpc/platforms/powermac/low_i2c.c:	init_completion(&comp);
arch/powerpc/platforms/powermac/low_i2c.c:	wait_for_completion(&comp);
arch/powerpc/platforms/powermac/nvram.c:#include <linux/completion.h>
arch/powerpc/platforms/powermac/nvram.c:		complete((struct completion *)req->arg);
arch/powerpc/platforms/powermac/nvram.c:	DECLARE_COMPLETION_ONSTACK(req_complete);
arch/powerpc/platforms/powermac/nvram.c:		wait_for_completion(&req_complete);
arch/powerpc/platforms/powermac/nvram.c:	DECLARE_COMPLETION_ONSTACK(req_complete);
arch/powerpc/platforms/powermac/nvram.c:		wait_for_completion(&req_complete);
arch/powerpc/platforms/powernv/opal-async.c: * PowerNV OPAL asynchronous completion interfaces
arch/powerpc/platforms/powernv/opal-async.c: * OPAL_ASYNC_COMPLETION you MUST call one of opal_async_wait_response() or
arch/powerpc/platforms/powernv/opal-async.c:	 * function that if the opal call returns OPAL_ASYNC_COMPLETION to
arch/powerpc/platforms/powernv/opal-call.c:OPAL_CALL(opal_check_completion,		OPAL_CHECK_ASYNC_COMPLETION);
arch/powerpc/platforms/powernv/opal-powercap.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-powercap.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-psr.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-psr.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-sensor-groups.c:	if (ret == OPAL_ASYNC_COMPLETION) {
arch/powerpc/platforms/powernv/opal-sensor-groups.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-sensor.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-sensor.c:	case OPAL_ASYNC_COMPLETION:
arch/powerpc/platforms/powernv/opal-sysparam.c:	if (ret != OPAL_ASYNC_COMPLETION) {
arch/powerpc/platforms/powernv/opal-sysparam.c:	if (ret != OPAL_ASYNC_COMPLETION) {
arch/powerpc/platforms/powernv/opal.c:	/* Initialise OPAL asynchronous completion interface */
arch/powerpc/platforms/powernv/opal.c:	case OPAL_ASYNC_COMPLETION:	return -EINPROGRESS;
arch/powerpc/platforms/powernv/pci.c:	} else if (rc != OPAL_ASYNC_COMPLETION) {
arch/powerpc/platforms/pseries/eeh_pseries.c:		 * completion from platform.
arch/powerpc/platforms/pseries/mobility.c:#include <linux/completion.h>
arch/powerpc/platforms/pseries/vas.h:	u32 complete_irq;	/* Completion interrupt */
arch/powerpc/platforms/pseries/vio.c: * Upon completion sizes of the reserve and excess pools are calculated.
arch/powerpc/sysdev/fsl_pci.h:	__be32	pex_otb_cpl_tor;	/* 0x.00c - PCIE Outbound completion timeout register */
arch/powerpc/sysdev/pmi.c:#include <linux/completion.h>
arch/powerpc/sysdev/pmi.c:	struct completion	*completion;
arch/powerpc/sysdev/pmi.c:	if (type & PMI_ACK && !data->completion) {
arch/powerpc/sysdev/pmi.c:	if (data->completion && !(type & PMI_ACK)) {
arch/powerpc/sysdev/pmi.c:		complete(data->completion);
arch/powerpc/sysdev/pmi.c:	DECLARE_COMPLETION_ONSTACK(completion);
arch/powerpc/sysdev/pmi.c:	data->completion = &completion;
arch/powerpc/sysdev/pmi.c:	pr_debug("pmi_send_message: wait for completion\n");
arch/powerpc/sysdev/pmi.c:	wait_for_completion_interruptible_timeout(data->completion,
arch/powerpc/sysdev/pmi.c:	data->completion = NULL;
arch/riscv/kernel/smpboot.c:static DECLARE_COMPLETION(cpu_running);
arch/riscv/kernel/smpboot.c:		wait_for_completion_timeout(&cpu_running,
arch/s390/include/asm/ap.h:		"	brc	2,0b\n"       /* handle partial completion */
arch/s390/include/asm/ccwdev.h:/* Allow for i/o completion notification after primary interrupt status. */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n"	  /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n"	  /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n" /* handle partial completion */
arch/s390/include/asm/cpacf.h:		"	brc	1,0b\n"	/* handle partial completion */
arch/s390/include/asm/gmap.h: * completion, 0 is returned.
arch/s390/kernel/perf_cpum_cf_events.c:CPUMF_EVENT_ATTR(cf_z16, NNPA_COMPLETIONS, 0x010c);
arch/s390/kernel/perf_cpum_cf_events.c:	CPUMF_EVENT_PTR(cf_z16, NNPA_COMPLETIONS),
arch/s390/kernel/uv.c:	 * and if the UVC returned busy or partial completion, we return
arch/s390/kernel/uv.c:		 * completion, this is just a useless check, but it is safe.
arch/s390/kvm/interrupt.c:			kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/kvm-s390.c:	kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/kvm-s390.c:	kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/kvm-s390.c:			kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/kvm-s390.c:	kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/kvm-s390.c:	 * but we still want check_async_completion to cleanup
arch/s390/kvm/kvm-s390.c:	kvm_check_async_pf_completion(vcpu);
arch/s390/kvm/kvm-s390.c:			kvm_clear_async_pf_completion_queue(vcpu);
arch/s390/kvm/pv.c: * Completes the dumping operation and writes the completion data to
arch/s390/kvm/pv.c: *  -ENOMEM if allocating the completion buffer fails
arch/s390/lib/test_unwind.c:#include <linux/completion.h>
arch/s390/lib/test_unwind.c:	struct completion task_ready;
arch/s390/lib/test_unwind.c:	init_completion(&u->task_ready);
arch/s390/lib/test_unwind.c:	wait_for_completion(&u->task_ready);
arch/s390/lib/test_unwind.c:	init_completion(&u->task_ready);
arch/s390/lib/test_unwind.c:	wait_for_completion(&u->task_ready);
arch/s390/mm/pfault.c: * Of course we have a lot of additional fun with the completion interrupt (->
arch/s390/mm/pfault.c:	 * Get the external interruption subcode & pfault initial/completion
arch/s390/mm/pfault.c:			 * Initial interrupt was faster than the completion
arch/s390/mm/pfault.c:			 * Completion interrupt was faster than initial
arch/s390/mm/pfault.c:			 * If the task is not running, ignore the completion
arch/s390/mm/pfault.c:			 * completion interrupts.
arch/s390/mm/pfault.c:			 * Completion interrupt was faster than the initial
arch/s390/mm/pfault.c:			 * Initial interrupt arrived before completion
arch/sh/drivers/dma/dma-api.c:void dma_wait_for_completion(unsigned int chan)
arch/sh/drivers/dma/dma-api.c:EXPORT_SYMBOL(dma_wait_for_completion);
arch/sh/drivers/dma/dma-g2.c:	 * bit 1 - if set, generate a hardware event on transfer completion
arch/sh/drivers/dma/dma-pvr2.c:		dma_wait_for_completion(PVR2_CASCADE_CHAN);
arch/sh/drivers/pci/pcie-sh7786.c:	/* Set the completion timer timeout to the maximum 32ms. */
arch/sh/include/asm/dma.h:	 * wait_queue used in dma_wait_for_completion.
arch/sh/include/asm/dma.h:extern void dma_wait_for_completion(unsigned int chan);
arch/sh/kernel/cpu/sh4/sq.c:	/* Wait for completion */
arch/sh/kernel/hw_breakpoint.c:		 * Reset the condition match flag to denote completion of
arch/sparc/include/asm/backoff.h: * completion of the compare-and-swap instruction.  Heavily
arch/sparc/include/asm/estate.h: * 3) As the result of store merge completion, writeback, or copyout will
arch/sparc/include/asm/hypervisor.h: * boundary.  On successful completion, the specified CPU will be in
arch/sparc/include/asm/hypervisor.h: * running state.  On completion, it will be in the stopped state.  It
arch/sparc/include/asm/hypervisor.h: * Upon successful completion, control will be returned to the given
arch/sparc/include/asm/hypervisor.h: * ARG0:	real address of CCB completion area
arch/sparc/include/asm/hypervisor.h: * ARG0:	real address of CCB completion area
arch/sparc/include/asm/hypervisor.h: * and the completion of the configuration operation.  It should be noted
arch/sparc/include/asm/hypervisor.h: * completion and return HV_EOK, or return an error code.
arch/sparc/include/asm/vio.h:#include <linux/completion.h>
arch/sparc/include/asm/vio.h:struct vio_completion {
arch/sparc/include/asm/vio.h:	struct completion	com;
arch/sparc/include/asm/vio.h:	struct vio_completion	*cmp;
arch/sparc/include/uapi/asm/oradax.h:	__u16 ca_offset;	/* offset into mmapped completion area */
arch/sparc/include/uapi/asm/perfctr.h:#define  US3_FM_PIPE_COMPLETION	0x00014000
arch/sparc/kernel/hvcalls.S:	/* %o0: completion area ra for the ccb to get info
arch/sparc/kernel/hvcalls.S:	/* %o0: completion area ra for the ccb to kill
arch/sparc/kernel/iommu.c:		/* Ensure completion of previous PIO writes. */
arch/sparc/kernel/pci_fire.c:	 * completion register.
arch/sparc/kernel/pci_schizo.c:	 * completion register.
arch/sparc/kernel/sbus.c:	 * in order to ensure write completion.
arch/sparc/kernel/smp_64.c:	/* Now, poll for completion. */
arch/um/drivers/port_kern.c:#include <linux/completion.h>
arch/um/drivers/port_kern.c:	struct completion done;
arch/um/drivers/port_kern.c:	init_completion(&port->done);
arch/um/drivers/port_kern.c:		if (wait_for_completion_interruptible(&port->done))
arch/um/drivers/random.c:static DECLARE_COMPLETION(have_data);
arch/um/drivers/random.c:			ret = wait_for_completion_killable(&have_data);
arch/um/drivers/xterm_kern.c:#include <linux/completion.h>
arch/um/drivers/xterm_kern.c:	struct completion ready;
arch/um/drivers/xterm_kern.c:	init_completion(&data->ready);
arch/um/drivers/xterm_kern.c:	wait_for_completion(&data->ready);
arch/x86/coco/tdx/tdcall.S: * On successful completion, return the hypercall error code.
arch/x86/include/asm/amd-ibs.h:		__u64	comp_to_ret_ctr:16,	/* 0-15: op completion to retire count */
arch/x86/include/asm/kvm_host.h:enum exit_fastpath_completion {
arch/x86/include/asm/kvm_host.h:typedef enum exit_fastpath_completion fastpath_t;
arch/x86/include/asm/kvm_host.h:	enum exit_fastpath_completion (*vcpu_run)(struct kvm_vcpu *vcpu,
arch/x86/include/asm/kvm_host.h:		enum exit_fastpath_completion exit_fastpath);
arch/x86/kernel/cpu/resctrl/internal.h: *			completion
arch/x86/kernel/cpu/resctrl/pseudo_lock.c: * Return: 0. Waiter on waitqueue will be woken on completion.
arch/x86/kernel/cpu/resctrl/pseudo_lock.c: * Return: 0. Waiter on waitqueue will be woken on completion.
arch/x86/kernel/cpu/sgx/ioctl.c:	/* Set only after completion, as encl->lock has not been taken. */
arch/x86/kernel/cpuid.c:#include <linux/completion.h>
arch/x86/kernel/cpuid.c:	struct completion done;
arch/x86/kernel/cpuid.c:	init_completion(&cmd.done);
arch/x86/kernel/cpuid.c:		wait_for_completion(&cmd.done);
arch/x86/kernel/cpuid.c:		reinit_completion(&cmd.done);
arch/x86/kernel/hw_breakpoint.c:		 * Reset the 'i'th TRAP bit in dr6 to denote completion of
arch/x86/kernel/kgdb.c:	 * denote completion of processing
arch/x86/kernel/kvm.c:			 * Recheck for async #PF completion before enqueueing
arch/x86/kernel/smp.c:		 * Don't wait longer than a second for IPI completion. The
arch/x86/kvm/svm/nested.c:	 * If we are here following the completion of a VMRUN that
arch/x86/kvm/svm/svm.c:	svm->awaiting_iret_completion = false;
arch/x86/kvm/svm/svm.c:	svm->awaiting_iret_completion = true;
arch/x86/kvm/svm/svm.c:		if (!svm->awaiting_iret_completion)
arch/x86/kvm/svm/svm.c:	 * If we've made progress since setting awaiting_iret_completion, we've
arch/x86/kvm/svm/svm.c:	if (svm->awaiting_iret_completion &&
arch/x86/kvm/svm/svm.c:		svm->awaiting_iret_completion = false;
arch/x86/kvm/svm/svm.h:	bool awaiting_iret_completion;
arch/x86/kvm/svm/svm.h:	 * Set when KVM is awaiting IRET completion and needs to inject NMIs as
arch/x86/kvm/x86.c:		kvm_clear_async_pf_completion_queue(vcpu);
arch/x86/kvm/x86.c:			      int (*completion)(struct kvm_vcpu *vcpu),
arch/x86/kvm/x86.c:	vcpu->arch.complete_userspace_io = completion;
arch/x86/kvm/x86.c:		kvm_clear_async_pf_completion_queue(vcpu);
arch/x86/kvm/x86.c:			kvm_check_async_pf_completion(vcpu);
arch/x86/kvm/x86.c:		/* stat is incremented on completion. */
arch/x86/kvm/x86.c:			kvm_check_async_pf_completion(vcpu);
arch/x86/kvm/x86.c:	kvm_clear_async_pf_completion_queue(vcpu);
arch/x86/kvm/x86.c:		kvm_clear_async_pf_completion_queue(vcpu);
arch/x86/lib/msr-smp.c:#include <linux/completion.h>
arch/x86/lib/msr-smp.c:struct msr_info_completion {
arch/x86/lib/msr-smp.c:	struct completion	done;
arch/x86/lib/msr-smp.c:	struct msr_info_completion *rv = info;
arch/x86/lib/msr-smp.c:	struct msr_info_completion rv;
arch/x86/lib/msr-smp.c:	init_completion(&rv.done);
arch/x86/lib/msr-smp.c:		wait_for_completion(&rv.done);
arch/x86/math-emu/README:emulate each FPU instruction to completion without interruption.
arch/x86/mm/kmmio.c:			 * denote completion of processing
arch/x86/virt/vmx/tdx/seamcall.S: * fails, or the completion status of the SEAMCALL leaf function.
arch/x86/virt/vmx/tdx/seamcall.S: * fails, or the completion status of the SEAMCALL leaf function.
arch/x86/virt/vmx/tdx/seamcall.S: * fails, or the completion status of the SEAMCALL leaf function.
arch/xtensa/kernel/smp.c:static DECLARE_COMPLETION(cpu_running);
arch/xtensa/kernel/smp.c:	init_completion(&cpu_running);
arch/xtensa/kernel/smp.c:		wait_for_completion_timeout(&cpu_running,
block/bfq-cgroup.c:void bfqg_stats_update_completion(struct bfq_group *bfqg, u64 start_time_ns,
block/bfq-cgroup.c:void bfqg_stats_update_completion(struct bfq_group *bfqg, u64 start_time_ns,
block/bfq-iosched.c:	 * the ideal completion time to be guaranteed to bfqq's I/O.
block/bfq-iosched.c:	 * some request completion.
block/bfq-iosched.c: * still being served by the drive, and may receive new I/O on the completion
block/bfq-iosched.c:	    now_ns - bfqd->last_completion >= 4 * NSEC_PER_MSEC ||
block/bfq-iosched.c:	 * If a new request completion has occurred after last
block/bfq-iosched.c:	 * extend the observation interval to the last completion.
block/bfq-iosched.c:		      bfqd->last_completion - bfqd->first_dispatch);
block/bfq-iosched.c: * (plus, when useful, request completion times), to estimate what is
block/bfq-iosched.c:	 * completion event in bfq_completed_request()). Go to
block/bfq-iosched.c:	 *   request dispatch or completion
block/bfq-iosched.c:		now_ns - bfqd->last_completion < BFQ_MIN_TT)
block/bfq-iosched.c: * completion. In fact, requests have still to be guaranteed their
block/bfq-iosched.c: * If there are groups with requests waiting for completion
block/bfq-iosched.c: * for completion, then only conditions (i-a) and (i-b) are actually
block/bfq-iosched.c: * there are no groups with requests waiting for completion, then, to
block/bfq-iosched.c: * whether all the queues with requests waiting for completion also
block/bfq-iosched.c: * requests waiting for completion happen to be
block/bfq-iosched.c:			 * process still waiting for completion, then
block/bfq-iosched.c:			 * still waiting for the completion of some of
block/bfq-iosched.c:			 * for request completions, or blocking for
block/bfq-iosched.c: * The next function is invoked on the completion of the last request of a
block/bfq-iosched.c:		 * requests, then we have to wait for the completion
block/bfq-iosched.c: * just checked on request arrivals and completions, as well as on
block/bfq-iosched.c:	 * for a new request, or has requests waiting for a completion and
block/bfq-iosched.c:	 * may idle after their completion, then keep it anyway.
block/bfq-iosched.c: * contribute to the execution/completion of that common application
block/bfq-iosched.c:	delta_us = div_u64(now_ns - bfqd->last_completion, NSEC_PER_USEC);
block/bfq-iosched.c:	 * to the maximum request size recorded, this completion latency
block/bfq-iosched.c:	 *   request dispatch or completion
block/bfq-iosched.c:	bfqd->last_completion = now_ns;
block/bfq-iosched.c:			 * completion event that causes bfqq->dispatch
block/bfq-iosched.c:	 * path that handles the completion of a request of bfqq, and,
block/bfq-iosched.c:	/* update complete, not waiting for any request completion any longer */
block/bfq-iosched.c:		bfqg_stats_update_completion(bfqq_group(bfqq),
block/bfq-iosched.h:	/* completion time of the last request */
block/bfq-iosched.h:	/* Number of consecutive pairs of request completion and
block/bfq-iosched.h:	 * completion, but the next request arrives within an idle
block/bfq-iosched.h:	 * has at least one request waiting for completion. Note that
block/bfq-iosched.h:	 * completion.
block/bfq-iosched.h:	 * entity remains with no request waiting for completion,
block/bfq-iosched.h:	 * with no request waiting for completion.
block/bfq-iosched.h:	/* number of requests dispatched and waiting for completion */
block/bfq-iosched.h:	 * number of requests dispatched and waiting for completion
block/bfq-iosched.h:	/* time of last request completion (ns) */
block/bfq-iosched.h:	u64 last_completion;
block/bfq-iosched.h:void bfqg_stats_update_completion(struct bfq_group *bfqg, u64 start_time_ns,
block/bio-integrity.c:		 * in it for completion handling
block/bio-integrity.c: * bio_integrity_verify_fn - Integrity I/O completion worker
block/bio-integrity.c: * __bio_integrity_endio - Integrity I/O completion function
block/bio-integrity.c: * Description: Completion for integrity I/O
block/bio-integrity.c: * Normally I/O completion is done in interrupt context.  However,
block/bio-integrity.c: * in process context.	This function postpones completion
block/bio.c: * bio_chain - chain bio completions
block/bio.c: * map them into the kernel. On IO completion, the caller should put those
block/bio.c: * on IO completion. If it isn't, then pages should be released.
block/bio.c:	DECLARE_COMPLETION_ONSTACK_MAP(done,
block/bio.c:	DECLARE_COMPLETION_ONSTACK_MAP(done,
block/bio.c:	if (bio->bi_bdev && bio_flagged(bio, BIO_TRACE_COMPLETION)) {
block/bio.c:		bio_clear_flag(bio, BIO_TRACE_COMPLETION);
block/bio.c:	if (bio_flagged(bio, BIO_TRACE_COMPLETION))
block/bio.c:		bio_set_flag(split, BIO_TRACE_COMPLETION);
block/blk-cgroup.c: *    to the completion of writeback associated with the blkcg.  This lets us
block/blk-core.c:#include <linux/completion.h>
block/blk-core.c:	if (!bio_flagged(bio, BIO_TRACE_COMPLETION)) {
block/blk-core.c:		 * completion as well.
block/blk-core.c:		bio_set_flag(bio, BIO_TRACE_COMPLETION);
block/blk-core.c: * completion, is delivered asynchronously through the ->bi_end_io() callback
block/blk-core.c: * bio_poll - poll for BIO completions
block/blk-core.c: * Poll for completions on queue associated with the bio. Returns number of
block/blk-flush.c: * completion.
block/blk-flush.c: * complete.  The first completion updates the contained bio but doesn't
block/blk-flush.c:	 * After flush data completion, @rq->bio is %NULL but we need to
block/blk-flush.c: * completion and trigger the next step.
block/blk-flush.c:		 * flush data request completion path.  Restore @rq for
block/blk-flush.c:		 * normal completion and end it.
block/blk-flush.c:	/* account completion of the flush request */
block/blk-flush.c:		 * Initialize the flush fields and completion handler to trigger
block/blk-iocost.c: * completion latencies.
block/blk-iocost.c: * control quality.  For a better control quality, completion latency QoS
block/blk-iocost.c: * if N'th percentile completion latency rises above the set point.
block/blk-iocost.c: * The completion latency requirements are a function of both the
block/blk-iocost.c:	 * `vtime_done` is the same but progressed on completion rather
block/blk-iocost.c:		 * high-latency completions appearing as idle.
block/blk-iocost.c:	 * called before policy activation completion, can't assume that the
block/blk-iolatency.c: * total_time += min_lat_nsec - actual_io_completion
block/blk-iolatency.c: * the in-flight counts by disabling accounting in the completion path while IOs
block/blk-map.c: *    the I/O completion may have changed rq->bio.
block/blk-mq-sched.c: * its queue by itself in its completion handler, so we don't need to
block/blk-mq-sched.c: * its queue by itself in its completion handler, so we don't need to
block/blk-mq-tag.c:		 * as running the queue may also have found completions.
block/blk-mq-tag.c: * completions have finished.
block/blk-mq.c:		laptop_io_completion(q->disk->bdi);
block/blk-mq.c:static void blk_account_io_completion(struct request *req, unsigned int bytes)
block/blk-mq.c: * Fully end IO on a request. Does not support partial completions, or
block/blk-mq.c:	blk_account_io_completion(req, total_bytes);
block/blk-mq.c:		/* Completion has already been traced */
block/blk-mq.c:		bio_clear_flag(bio, BIO_TRACE_COMPLETION);
block/blk-mq.c:	blk_account_io_completion(req, nr_bytes);
block/blk-mq.c:			 * Partial zone append completions cannot be supported
block/blk-mq.c:		/* Completion has already been traced */
block/blk-mq.c:		bio_clear_flag(bio, BIO_TRACE_COMPLETION);
block/blk-mq.c:	 * Account IO completion.  flush_rq isn't accounted as a
block/blk-mq.c:	 * normal IO on queueing nor completion.  Accounting the
block/blk-mq.c:	 * it's pointless to redirect the completion.
block/blk-mq.c: *    for execution.  Don't wait for completion.
block/blk-mq.c:	struct completion done;
block/blk-mq.c:static void blk_rq_poll_completion(struct request *rq, struct completion *wait)
block/blk-mq.c:	} while (!completion_done(wait));
block/blk-mq.c: *    for execution and wait for completion.
block/blk-mq.c:		.done = COMPLETION_INITIALIZER_ONSTACK(wait.done),
block/blk-mq.c:		blk_rq_poll_completion(rq, &wait.done);
block/blk-mq.c:	 * completion, since the timeout code would not be able to
block/blk-stat.h: * @timer is active, that queue's request completion latencies are sorted into
block/blk-wbt.c: * Called on completion of a request. Note that it's also called when
block/blk-wbt.c:	 * flag the latency as exceeded. wbt works off completion latencies,
block/blk-wbt.c:	 * monitoring window AND we didn't see any other completions in that
block/blk-zoned.c:	 * Completions of BIOs with blk_zone_write_plug_bio_endio() may
block/blk-zoned.c:	 * happen after handling a request completion with
block/blk-zoned.c:	 * completions are seen. Check by looking at the zone write plug
block/blk-zoned.c:		 * Check that a BIO completion or a zone reset or finish
block/blk-zoned.c:	 * Make sure that a BIO completion or another zone reset or finish
block/blk-zoned.c:	 * Indicate that completion of this request needs to be handled with
block/blk-zoned.c:		 * so that we can restore its operation code on completion.
block/blk-zoned.c:	 * the responsibility of the user to first wait for the completion of
block/blk-zoned.c:	 * completion of the flush sequence will go through the regular BIO
block/blk-zoned.c:	 * completion, which will handle zone write plugging.
block/blk.h:static inline void blk_wait_io(struct completion *done)
block/blk.h:		while (!wait_for_completion_io_timeout(done, timeout))
block/blk.h:		wait_for_completion_io(done);
block/blk.h:	 * For write BIOs to zoned devices, signal the completion of the BIO so
block/bsg-lib.c: * bsg_job_done - completion routine for bsg requests
block/fops.c:	/* avoid the need for a I/O completion work item */
block/genhd.c:	lockdep_init_map(&disk->lockdep_map, "(bio completion)", lkclass, 0);
block/t10-pi.c:	 * and completion, so use the copy created during submission here.
crypto/af_alg.c: * @data: async request completion data
crypto/af_alg.c: * This handler cleans up the struct af_alg_async_req upon completion of the
crypto/ahash.c:static int ahash_save_req(struct ahash_request *req, crypto_completion_t cplt,
crypto/algapi.c:	complete_all(&test->completion);
crypto/algboss.c:#include <linux/completion.h>
crypto/algboss.c:	complete_all(&param->larval->completion);
crypto/algif_aead.c: * After the completion of the crypto operation, the RX SGL and the cipher
crypto/algif_skcipher.c: * After the completion of the crypto operation, the RX SGL and the cipher
crypto/api.c:#include <linux/completion.h>
crypto/api.c:	init_completion(&larval->completion);
crypto/api.c:	complete_all(&larval->completion);
crypto/api.c:	time_left = wait_for_completion_killable_timeout(
crypto/api.c:		&larval->completion, 60 * HZ);
crypto/api.c:	complete(&wait->completion);
crypto/async_tx/async_memcpy.c: * @submit: submission / completion modifiers
crypto/async_tx/async_pq.c: * @submit: submission/completion modifiers
crypto/async_tx/async_pq.c: * @submit: submission / completion modifiers
crypto/async_tx/async_raid6_recov.c: * @submit: submission/completion modifiers
crypto/async_tx/async_raid6_recov.c: * @submit: submission/completion modifiers
crypto/async_tx/async_tx.c:	 * otherwise poll for completion
crypto/async_tx/async_tx.c: * @submit: submission and completion parameters
crypto/async_tx/async_tx.c:		 * otherwise poll for completion
crypto/async_tx/async_xor.c: * @submit: submission / completion modifiers
crypto/async_tx/async_xor.c: * @submit: submission / completion modifiers
crypto/async_tx/async_xor.c: * @submit: submission / completion modifiers
crypto/async_tx/async_xor.c: * @submit: submission / completion modifiers
crypto/async_tx/raid6test.c:	struct completion *cmp = param;
crypto/async_tx/raid6test.c:	struct completion cmp;
crypto/async_tx/raid6test.c:	init_completion(&cmp);
crypto/async_tx/raid6test.c:	if (wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000)) == 0)
crypto/async_tx/raid6test.c:	struct completion cmp;
crypto/async_tx/raid6test.c:	init_completion(&cmp);
crypto/async_tx/raid6test.c:	if (wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000)) == 0) {
crypto/cryptd.c:	crypto_completion_t complete;
crypto/cryptd.c:				     crypto_completion_t complete)
crypto/cryptd.c:				   crypto_completion_t compl)
crypto/cryptd.c:				crypto_completion_t compl)
crypto/cryptd.c:				 crypto_completion_t complete)
crypto/cryptd.c:			      crypto_completion_t compl)
crypto/cryptd.c:				    crypto_completion_t compl)
crypto/crypto_engine.c:	 * We'll need it on completion (crypto_finalize_request).
crypto/echainiv.c:	crypto_completion_t compl;
crypto/gcm.c:			   crypto_completion_t compl,
crypto/gcm.c:			   crypto_completion_t compl, u32 flags)
crypto/internal.h:#include <linux/completion.h>
crypto/internal.h:	struct completion completion;
crypto/seqiv.c:	crypto_completion_t compl;
crypto/seqiv.c:	crypto_completion_t compl;
crypto/xts.c:			  crypto_completion_t compl)
Documentation/ABI/stable/firewire-cdev:		    outbound asynchronous transaction completion or isochronous
Documentation/ABI/stable/firewire-cdev:		    buffer completion, and unsolicited events such as bus resets,
Documentation/ABI/stable/sysfs-block:		In this mode, the CPU will repeatedly ask for completions
Documentation/ABI/stable/sysfs-block:		completions to the cpu "group" that originally submitted the
Documentation/ABI/stable/sysfs-block:		completion processing setting this option to '2' forces the
Documentation/ABI/stable/sysfs-block:		completion to run on the requesting cpu (bypassing the "group"
Documentation/ABI/stable/sysfs-class-infiniband:		cq_per_vf:	(RO) Completion queue per virtual function
Documentation/ABI/stable/sysfs-driver-dma-idxd:Description:	Show the number of Completion Record (CR) faults this application
Documentation/ABI/stable/sysfs-driver-dma-idxd:Description:	Show the number of Completion Record (CR) faults failures that this
Documentation/ABI/stable/sysfs-driver-ib_srp:		  MSI-X completion vector of the first RDMA channel. Some
Documentation/ABI/stable/sysfs-driver-ib_srp:		  spread the SRP completion workload over multiple CPU's.
Documentation/ABI/stable/sysfs-driver-ib_srp:Description:	Completion vector used for the first RDMA channel.
Documentation/ABI/testing/debugfs-hisi-hpre:		QM task completion.
Documentation/ABI/testing/debugfs-hisi-sec:		QM task completion.
Documentation/ABI/testing/debugfs-hisi-zip:		QM task completion.
Documentation/ABI/testing/sysfs-bus-cxl:		upon completion of a sanitize operation.
Documentation/ABI/testing/sysfs-bus-event_source-devices-hisi_ptt:Description:	(RW) Controls the weight of Tx completion TLPs, which influence
Documentation/ABI/testing/sysfs-bus-event_source-devices-hisi_ptt:		the proportion of outbound completion TLPs on the PCIe link.
Documentation/ABI/testing/sysfs-bus-nfit:		completion timeout. Since the platform does not know whether the
Documentation/ABI/testing/sysfs-bus-pci-devices-aer_stats:		    Completion Timeout 0
Documentation/ABI/testing/sysfs-bus-pci-devices-aer_stats:		    Unexpected Completion 0
Documentation/ABI/testing/sysfs-bus-pci-devices-aer_stats:		    Completion Timeout 0
Documentation/ABI/testing/sysfs-bus-pci-devices-aer_stats:		    Unexpected Completion 0
Documentation/ABI/testing/sysfs-class-firmware:		sequence will signal the completion of the firmware write and
Documentation/ABI/testing/sysfs-class-net-queues:		Tx completion stall detection threshold in ms. Kernel will
Documentation/ABI/testing/sysfs-class-net-queues:		Number of detected Tx completion stalls.
Documentation/ABI/testing/sysfs-class-net-queues:		Longest detected Tx completion stall. Write 0 to clear.
Documentation/ABI/testing/sysfs-driver-w1_therm:                2  Enable poll for conversion completion. Generate read cycles
Documentation/PCI/boot-interrupts.rst:run to completion; otherwise some handlers will end up in stack overflows
Documentation/PCI/pci-error-recovery.rst:will be platform-dependent. Upon completion of slot reset, the
Documentation/PCI/pci.rst:call this "Write Posting" because the write completion is "posted" to
Documentation/RCU/Design/Data-Structures/Data-Structures.rst:detects the completion of an RCU grace period by noticing that the value
Documentation/RCU/Design/Expedited-Grace-Periods/Expedited-Grace-Periods.rst:period also drove it to completion. This straightforward approach had
Documentation/RCU/Design/Memory-Ordering/Tree-RCU-Memory-Ordering.rst:``wait_for_completion()`` in the ``synchronize_rcu()`` code path.
Documentation/RCU/Design/Memory-Ordering/Tree-RCU-Memory-Ordering.rst:| ``wait_for_completion()``!!!                                          |
Documentation/RCU/Design/Requirements/Requirements.rst:RCU's grace-period guarantee allows updaters to wait for the completion
Documentation/RCU/Design/Requirements/Requirements.rst:that waits, directly or indirectly, on completion of an invocation of
Documentation/RCU/Design/Requirements/Requirements.rst:But what if the updater must wait for the completion of code to be
Documentation/RCU/Design/Requirements/Requirements.rst:In theory, delaying grace-period completion and callback invocation is
Documentation/RCU/Design/Requirements/Requirements.rst:to ensure timely completion of grace periods and timely invocation of
Documentation/RCU/Design/Requirements/Requirements.rst:RCU takes the following steps to encourage timely completion of grace
Documentation/RCU/Design/Requirements/Requirements.rst:   completion numbers, rather than waiting for the ``RCU_SOFTIRQ``
Documentation/RCU/Design/Requirements/Requirements.rst:starting grace periods and more aggressively forcing completion of
Documentation/RCU/Design/Requirements/Requirements.rst:   the completion of a future SRCU grace period and ensures
Documentation/RCU/listRCU.rst:object in question will remain in existence until after the completion
Documentation/RCU/rcubarrier.rst:  6    init_completion(&rcu_barrier_completion);
Documentation/RCU/rcubarrier.rst: 10      complete(&rcu_barrier_completion);
Documentation/RCU/rcubarrier.rst: 11    wait_for_completion(&rcu_barrier_completion);
Documentation/RCU/rcubarrier.rst:global completion and counters at a time, which are initialized on lines
Documentation/RCU/rcubarrier.rst:the completion, which prevents line 11 from blocking.  Either way,
Documentation/RCU/rcubarrier.rst:line 11 then waits (if needed) for the completion.
Documentation/RCU/rcubarrier.rst:rcu_barrier_cpu_count variable and finalizes the completion when it
Documentation/RCU/rcubarrier.rst:  4      complete(&rcu_barrier_completion);
Documentation/RCU/rcubarrier.rst:	11's wait_for_completion() would return immediately, failing to
Documentation/RCU/whatisRCU.rst:	the data element, in order to wait for the completion of all
Documentation/RCU/whatisRCU.rst:	function that will be invoked after the completion of all RCU
Documentation/RCU/whatisRCU.rst:"toy" implementation would restore the affinity upon completion rather
Documentation/accel/qaic/aic100.rst:	* Bit(4) is the completion code flag, and indicates that the DMA Bridge
Documentation/accel/qaic/aic100.rst:	u16 completion_code;
Documentation/accel/qaic/aic100.rst:completion_code
Documentation/accounting/delay-accounting.rst:b) completion of synchronous block I/O initiated by the task
Documentation/admin-guide/blockdev/drbd/disk-states-8.dot:	Consistent -> Failed           [ label = "io completion error" ]
Documentation/admin-guide/blockdev/drbd/disk-states-8.dot:	Outdated   -> Failed           [ label = "io completion error" ]
Documentation/admin-guide/blockdev/drbd/disk-states-8.dot:	UpToDate   -> Failed           [ label = "io completion error" ]
Documentation/admin-guide/blockdev/drbd/disk-states-8.dot:	Inconsistent -> Failed         [ label = "io completion error" ]
Documentation/admin-guide/cgroup-v1/blkio-controller.rst:	  Total amount of time between request dispatch and request completion
Documentation/admin-guide/cgroup-v2.rst:	the device saturated if the 95th percentile of read completion
Documentation/admin-guide/device-mapper/dm-io.rst:Callers of the asynchronous I/O services must include the name of a completion
Documentation/admin-guide/device-mapper/kcopyd.rst:to one or more other block-devices, with an asynchronous completion
Documentation/admin-guide/device-mapper/kcopyd.rst:completion callback routine, and a pointer to some context data for the copy::
Documentation/admin-guide/device-mapper/kcopyd.rst:When the copy completes, kcopyd will call the user's completion routine,
Documentation/admin-guide/device-mapper/log-writes.rst:We log things in order of completion once we are sure the write is no longer in
Documentation/admin-guide/device-mapper/thin-provisioning.rst:completion may have already been acknowledged to upper IO layers
Documentation/admin-guide/device-mapper/vdo.rst:		completing a bio calls an arbitrary completion function
Documentation/admin-guide/device-mapper/vdo.rst:		completion is slow. The default is 1.
Documentation/admin-guide/iostats.rst:    This field is incremented at each I/O start, I/O completion, I/O
Documentation/admin-guide/iostats.rst:    I/O completion time and the backlog that may be accumulating.
Documentation/admin-guide/iostats.rst:of queuing for partitions, and at completion for whole disks.  This is
Documentation/admin-guide/kernel-parameters.txt:				  bit-3 : ACS P2P Completion Redirect
Documentation/admin-guide/laptops/thinkpad-acpi.rst:0x6032		Thermal Control command set completion  (DYTC, Windows)
Documentation/admin-guide/mm/numa_memory_policy.rst:on completion of the policy installation.
Documentation/admin-guide/xfs.rst:	completion when there are persistent errors, and it may prevent the
Documentation/admin-guide/xfs.rst:	there is a successful completion of the operation.
Documentation/arch/arm/stm32/stm32-dma-mdma-chaining.rst:  transfer or the period completion.
Documentation/arch/powerpc/cxlflash.rst:    completion events. This file descriptor is intentionally installed by
Documentation/arch/powerpc/cxlflash.rst:    maximum transfer size of 256K imposed. Note that partial read completions
Documentation/arch/powerpc/eeh-pci-error-recovery.rst:connectivity due to a poorly seated card), and PCI-X split-completion
Documentation/arch/powerpc/ultravisor.rst:    Secure the virtual machine. On successful completion, return
Documentation/arch/s390/cds.rst:they are presenting I/O completion a unified way : I/O interruptions. Every
Documentation/arch/s390/cds.rst:      0  successful completion or request successfully initiated
Documentation/arch/s390/cds.rst:interrupt will be presented to indicate I/O completion as the I/O request was
Documentation/arch/s390/cds.rst:never started, even though ccw_device_start() returned with successful completion.
Documentation/arch/s390/cds.rst:successful completion for all overlapping ccw_device_start() requests that have
Documentation/arch/s390/cds.rst:-ENOTCONN   there is no I/O request pending for completion
Documentation/arch/s390/vfio-ccw.rst:defined access method and they are presenting I/O completion a unified
Documentation/arch/s390/vfio-ccw.rst:until interrupted. The I/O completion result is received by the
Documentation/arch/s390/vfio-ccw.rst:- I/O completion will be signaled to the host with I/O interruptions.
Documentation/arch/s390/vfio-ccw.rst:  space to retrieve. To notify user space an I/O completion, it offers
Documentation/arch/s390/vfio-ccw.rst:  notify the user space program the I/O completion in an asynchronous
Documentation/arch/s390/vfio-ccw.rst:    Setup event notifier and handler to handle I/O completion.
Documentation/arch/sparc/oradax/dax-hv-api.txt:        of the submitted operations reported through a Completion Area linked to each CCB. Each CCB has a
Documentation/arch/sparc/oradax/dax-hv-api.txt:        separate Completion Area and, unless execution order is specifically restricted through the use of serial-
Documentation/arch/sparc/oradax/dax-hv-api.txt:        conditional flags, the execution order of submitted CCBs is arbitrary. Likewise, the time to completion
Documentation/arch/sparc/oradax/dax-hv-api.txt:[1:0]          Completion area address type
Documentation/arch/sparc/oradax/dax-hv-api.txt:with the Serial flag set. CCBs marked solely with the Serial flag will execute upon the completion of the
Documentation/arch/sparc/oradax/dax-hv-api.txt:previous Serial CCB, regardless of the completion status of that CCB. The Conditional flag allows CCBs
Documentation/arch/sparc/oradax/dax-hv-api.txt:execute in parallel based on the completion of another CCB.
Documentation/arch/sparc/oradax/dax-hv-api.txt:          error in the completion area.
Documentation/arch/sparc/oradax/dax-hv-api.txt:        The return value of the CCB completion area is invalid. The “number of elements processed” field in the
Documentation/arch/sparc/oradax/dax-hv-api.txt:        CCB completion area will be valid.
Documentation/arch/sparc/oradax/dax-hv-api.txt:                         uint64_t completion;
Documentation/arch/sparc/oradax/dax-hv-api.txt:8        8      Completion
Documentation/arch/sparc/oradax/dax-hv-api.txt:                             completion word. If 0, the lower bits of this completion word
Documentation/arch/sparc/oradax/dax-hv-api.txt:                [58:6]       Completion area address bits [58:6]. Address type is
Documentation/arch/sparc/oradax/dax-hv-api.txt:                [5:0]        Virtual device interrupt number for completion interrupt, if
Documentation/arch/sparc/oradax/dax-hv-api.txt:The return value of the CCB completion area contains the number of input elements found which match
Documentation/arch/sparc/oradax/dax-hv-api.txt:field in the CCB completion area will be valid, indicating the number of input elements processed.
Documentation/arch/sparc/oradax/dax-hv-api.txt:                uint64_t         completion;
Documentation/arch/sparc/oradax/dax-hv-api.txt:8        8      Completion (same fields as Section 36.2.1.2, “Extract command”)
Documentation/arch/sparc/oradax/dax-hv-api.txt:        The return value of the CCB completion area contains the number of bits set in the output bit vector,
Documentation/arch/sparc/oradax/dax-hv-api.txt:        completion area will be valid, indicating the number of input elements processed.
Documentation/arch/sparc/oradax/dax-hv-api.txt:                        uint64_t completion;
Documentation/arch/sparc/oradax/dax-hv-api.txt:8        8      Completion (same fields as Section 36.2.1.2, “Extract command”
Documentation/arch/sparc/oradax/dax-hv-api.txt:        The return value of the CCB completion area contains the number of bits set in the input bit vector. The
Documentation/arch/sparc/oradax/dax-hv-api.txt:        "number of elements processed" field in the CCB completion area will be valid, indicating the number
Documentation/arch/sparc/oradax/dax-hv-api.txt:                         uint64_t completion;
Documentation/arch/sparc/oradax/dax-hv-api.txt:        8              8               Completion (same fields as Section 36.2.1.2, “Extract command”
Documentation/arch/sparc/oradax/dax-hv-api.txt:        by the virtual machine, simply updates the completion area with its execution status. The CCB may have
Documentation/arch/sparc/oradax/dax-hv-api.txt:        The return value of the CCB completion area is invalid for these CCBs. The “number of elements
Documentation/arch/sparc/oradax/dax-hv-api.txt:                        uint64_t completion;
Documentation/arch/sparc/oradax/dax-hv-api.txt:       8             8             Completion (same fields as Section 36.2.1.2, “Extract command”
Documentation/arch/sparc/oradax/dax-hv-api.txt:36.2.2. CCB Completion Area
Documentation/arch/sparc/oradax/dax-hv-api.txt:       All CCB commands use a common 128-byte Completion Area format, which can be specified by the
Documentation/arch/sparc/oradax/dax-hv-api.txt:                struct completion_area {
Documentation/arch/sparc/oradax/dax-hv-api.txt:       The Completion Area must be a 128-byte aligned memory location. The exact layout can be described
Documentation/arch/sparc/oradax/dax-hv-api.txt:The CCB completion area should be treated as read-only by guest software. The CCB execution status
Documentation/arch/sparc/oradax/dax-hv-api.txt:               completion area instead. Some CCBs may have been enqueued prior to the
Documentation/arch/sparc/oradax/dax-hv-api.txt:       by the 64-byte aligned real address of the CCBs completion area.
Documentation/arch/sparc/oradax/dax-hv-api.txt:          EINVAL                    The CCB completion area contents are not valid.
Documentation/arch/sparc/oradax/dax-hv-api.txt:         the 64-byte aligned real address of the CCBs completion area.
Documentation/arch/sparc/oradax/dax-hv-api.txt:                                            it, and the completion area will never be updated. The same CCB may
Documentation/arch/sparc/oradax/dax-hv-api.txt:                                            is no longer active in the virtual machine. The CCB completion area
Documentation/arch/sparc/oradax/dax-hv-api.txt:                                             to the completion area.
Documentation/arch/sparc/oradax/dax-hv-api.txt:         If the pipeline target CCB is killed but the pipeline source CCB was skipped, the completion area of the
Documentation/arch/sparc/oradax/dax-hv-api.txt:         If the pipeline source CCB is killed, the pipeline target CCB's completion status may read (1,0) "Success".
Documentation/arch/sparc/oradax/dax-hv-api.txt:          EINVAL                     The CCB completion area contents are not valid.
Documentation/arch/sparc/oradax/oracle-dax.rst:pointer to a "completion area", which is a 128 byte memory block that
Documentation/arch/sparc/oradax/oracle-dax.rst:interrupt is generated upon completion; the completion area must be
Documentation/arch/sparc/oradax/oracle-dax.rst:processor until the completion status has been updated by the
Documentation/arch/sparc/oradax/oracle-dax.rst:completion of a request and resumption of execution of the requesting
Documentation/arch/sparc/oradax/oracle-dax.rst:call, and gets results (if any) via read(). The completion areas are
Documentation/arch/sparc/oradax/oracle-dax.rst:requests. The completion area buffer is also allocated, and this is
Documentation/arch/sparc/oradax/oracle-dax.rst:large enough to contain the completion areas for many concurrent
Documentation/arch/sparc/oradax/oracle-dax.rst:requests. Since no interrupt is generated upon the completion of a
Documentation/arch/sparc/oradax/oracle-dax.rst:completion area to use, and may be set via lseek() or using the
Documentation/arch/sparc/oradax/oracle-dax.rst:The mmap() function provides access to the completion area allocated
Documentation/arch/sparc/oradax/oracle-dax.rst:in the driver.  Note that the completion area is not writeable by the
Documentation/arch/sparc/oradax/oracle-dax.rst:Completion of a Request
Documentation/arch/sparc/oradax/oracle-dax.rst:The first byte in each completion area is the command status which is
Documentation/arch/sparc/oradax/oracle-dax.rst:transaction completes. Thus the latency between transaction completion
Documentation/arch/sparc/oradax/oracle-dax.rst: - call mmap() to get the completion area address
Documentation/arch/sparc/oradax/oracle-dax.rst: - call munmap() for completion area
Documentation/arch/sparc/oradax/oracle-dax.rst:for the completion area, output buffer, and various inputs::
Documentation/arch/sparc/oradax/oracle-dax.rst:       u64   completion;
Documentation/arch/sparc/oradax/oracle-dax.rst:both; the only difference is in preparation of the completion area. An
Documentation/arch/sparc/oradax/oracle-dax.rst:Next, the completion area must be mapped::
Documentation/arch/sparc/oradax/oracle-dax.rst:      completion_area = mmap(NULL, DAX_MMAP_LEN, PROT_READ, MAP_SHARED, fd, 0);
Documentation/arch/sparc/oradax/oracle-dax.rst:	ccb->completion = 0;    /* Completion area address, to be filled in by driver */
Documentation/arch/sparc/oradax/oracle-dax.rst:After a successful submission of the CCB, the completion area may be
Documentation/arch/sparc/oradax/oracle-dax.rst:the contents of the completion area can be found in section 36.2.2 of
Documentation/arch/sparc/oradax/oracle-dax.rst:				     : "r"  (completion_area));
Documentation/arch/sparc/oradax/oracle-dax.rst:A completion area status of 1 indicates successful completion of the
Documentation/arch/sparc/oradax/oracle-dax.rst:	if (completion_area[0] != 1) {	/* section 36.2.2, 1 = command ran and succeeded */
Documentation/arch/sparc/oradax/oracle-dax.rst:		/* completion_area[0] contains the completion status */
Documentation/arch/sparc/oradax/oracle-dax.rst:		/* completion_area[1] contains an error code, see 36.2.2 */
Documentation/arch/sparc/oradax/oracle-dax.rst:After the completion area has been processed, the driver must be
Documentation/arch/sparc/oradax/oracle-dax.rst:completion area, closing the dax device, freeing memory etc.
Documentation/arch/sparc/oradax/oracle-dax.rst:of the completion area. Unlike user applications which mmap the
Documentation/arch/sparc/oradax/oracle-dax.rst:completion area allocated by the driver, kernel code must allocate its
Documentation/arch/sparc/oradax/oracle-dax.rst:own memory to use for the completion area, and this address and its
Documentation/arch/sparc/oradax/oracle-dax.rst:	        (3L << 32);     /* completion area address type = primary virtual */
Documentation/arch/sparc/oradax/oracle-dax.rst:	ccb->completion = (unsigned long) completion_area;   /* Completion area address */
Documentation/arch/sparc/oradax/oracle-dax.rst:After the submission, the completion area polling code is identical to
Documentation/arch/sparc/oradax/oracle-dax.rst:				     : "r"  (completion_area));
Documentation/arch/sparc/oradax/oracle-dax.rst:	if (completion_area[0] != 1) {	/* section 36.2.2, 1 = command ran and succeeded */
Documentation/arch/sparc/oradax/oracle-dax.rst:		/* completion_area[0] contains the completion status */
Documentation/arch/sparc/oradax/oracle-dax.rst:		/* completion_area[1] contains an error code, see 36.2.2 */
Documentation/arch/sparc/oradax/oracle-dax.rst:completion status indicates success.
Documentation/arch/x86/intel_txt.rst:executed between system reset through the completion of the kernel
Documentation/arch/x86/sva.rst:performed, virtual addresses of all parameters, virtual address of a completion
Documentation/arch/x86/sva.rst:submitting work and processing completions.
Documentation/arch/x86/sva.rst:aspects are mediated via the slow path. The work submission and completion
Documentation/block/bfq-iosched.rst:completion hooks---is, e.g., 1.9 us on an Intel Core i7-2760QM@2.40GHz
Documentation/block/blk-mq.rst:        the order of completion of requests. This must be handled by
Documentation/block/blk-mq.rst:Tag-based completion
Documentation/block/data-integrity.rst:    to be verified upon completion.
Documentation/block/data-integrity.rst:      Upon completion of a READ operation, the attached pages will
Documentation/block/data-integrity.rst:      integrity upon completion.
Documentation/block/inline-encryption.rst:For decryption, blk-crypto-fallback "wraps" the bio's completion callback
Documentation/block/inline-encryption.rst:successfully, blk-crypto-fallback restores the bio's original completion
Documentation/block/null_blk.rst:All of them have a completion queue for each core in the system.
Documentation/block/null_blk.rst:  The completion mode used for completing IOs to the block-layer.
Documentation/block/null_blk.rst:  2  Timer: Waits a specific period (completion_nsec) for each IO before
Documentation/block/null_blk.rst:     completion.
Documentation/block/null_blk.rst:completion_nsec=[ns]: Default: 10,000ns
Documentation/block/null_blk.rst:  Combined with irqmode=2 (timer). The time each completion event must wait.
Documentation/block/writeback_cache_control.rst:write back caches.  That means the devices signal I/O completion to the
Documentation/block/writeback_cache_control.rst:filesystem and will make sure that I/O completion for this request is only
Documentation/block/writeback_cache_control.rst:after the completion of the write request for bio submissions with the REQ_FUA
Documentation/core-api/workqueue.rst:and the bandwidth becomes dependent on completion latencies.
Documentation/crypto/architecture.rst:signal its completion. Before invoking a cipher operation, the caller
Documentation/crypto/architecture.rst:signal the completion of the cipher operation. Furthermore, the caller
Documentation/crypto/async-tx-api.rst:There are two methods for an application to learn about the completion
Documentation/crypto/async-tx-api.rst:   it polls for the completion of the operation.  It handles dependency
Documentation/crypto/async-tx-api.rst:2. Specify a completion callback.  The callback routine runs in tasklet
Documentation/crypto/async-tx-api.rst:   completion interrupt/callback at the end of the chain.
Documentation/crypto/async-tx-api.rst:2. Completion callback routines cannot submit new operations.  This
Documentation/crypto/async-tx-api.rst:	    struct completion cmp;
Documentation/crypto/async-tx-api.rst:	    init_completion(&cmp);
Documentation/crypto/async-tx-api.rst:	    wait_for_completion(&cmp);
Documentation/crypto/async-tx-api.rst:1. Completion callbacks are expected to happen in tasklet context
Documentation/dev-tools/kunit/architecture.rst:		  ``void kthread_complete_and_exit(struct completion *, long) __noreturn;``
Documentation/dev-tools/kunit/index.rst:completion, KUnit can run around 100 tests in less than 10 seconds.
Documentation/dev-tools/kunit/style.rst:tab-completion).
Documentation/devicetree/bindings/cache/socionext,uniphier-system-cache.yaml:      Interrupts can be used to notify the completion of cache operations.
Documentation/devicetree/bindings/cpu/idle-states.yaml:    to completion up to IDLE before anything else can happen.
Documentation/devicetree/bindings/crypto/hisilicon,hip07-sec.txt:  Interrupt 2N + 1 is the completion interrupt for queue N.
Documentation/devicetree/bindings/display/imx/nxp,imx8mq-dcss.yaml:      - description: Context loader completion and error interrupt
Documentation/devicetree/bindings/dma/apm-xgene-dma.txt:  are completion interrupts for each DMA channels.
Documentation/devicetree/bindings/dma/stm32/st,stm32-dma.yaml:              up to the removal of request and transfer completion
Documentation/devicetree/bindings/dma/stm32/st,stm32-dma.yaml:              by transfer completion. This must only be used on channels
Documentation/devicetree/bindings/dma/ti-edma.txt:              1. Transfer completion interrupt.
Documentation/devicetree/bindings/firmware/arm,scmi.yaml:      The interrupt that indicates message completion by the platform
Documentation/devicetree/bindings/firmware/arm,scmi.yaml:      The optional ("rx_reply") is for notifications completion interrupt,
Documentation/devicetree/bindings/iio/adc/adi,ad7173.yaml:          can be used to indicate the completion of a conversion.
Documentation/devicetree/bindings/infiniband/hisilicon-hns-roce.txt:- interrupts: should contain 32 completion event irq,1 async event irq
Documentation/devicetree/bindings/interconnect/qcom,bcm-voter.yaml:      Optional mask of which TCSs (Triggered Command Sets) wait for completion
Documentation/devicetree/bindings/interconnect/qcom,bcm-voter.yaml:      completion. The mask bits are available in the QCOM_ICC_TAG_* defines.
Documentation/devicetree/bindings/leds/leds-aw2013.yaml:      Used to report completion of operations (power up, LED breath effects).
Documentation/devicetree/bindings/mailbox/brcm,iproc-flexrm-mbox.txt:		The 2nd cell contains MSI completion threshold. This is the
Documentation/devicetree/bindings/mailbox/brcm,iproc-flexrm-mbox.txt:		number of completion messages for which FlexRM will inject
Documentation/devicetree/bindings/mailbox/brcm,iproc-flexrm-mbox.txt:		which FlexRM will wait to accumulate N completion messages
Documentation/devicetree/bindings/mailbox/brcm,iproc-flexrm-mbox.txt:		does not get required number of completion messages in time
Documentation/devicetree/bindings/mailbox/brcm,iproc-flexrm-mbox.txt:		to CPU provided at least one completion message is available.
Documentation/devicetree/bindings/mailbox/hisilicon,hi6220-mailbox.txt:			completion.
Documentation/devicetree/bindings/memory-controllers/mvebu-devbus.txt:                        drive the AD bus after the completion of a device read.
Documentation/devicetree/bindings/net/apm-xgene-enet.txt:  - Second is the Tx completion interrupt.
Documentation/devicetree/bindings/net/can/renesas,rcar-canfd.yaml:            - description: CAN0 transmit/receive FIFO receive completion interrupt
Documentation/devicetree/bindings/net/can/renesas,rcar-canfd.yaml:            - description: CAN1 transmit/receive FIFO receive completion interrupt
Documentation/devicetree/bindings/net/keystone-netcp.txt:- tx-completion-queue:	the navigator queue number where the descriptors are
Documentation/devicetree/bindings/net/keystone-netcp.txt:			recycled after Tx DMA completion.
Documentation/devicetree/bindings/net/keystone-netcp.txt:			tx-completion-queue = <8706>;
Documentation/devicetree/bindings/net/keystone-netcp.txt:			tx-completion-queue = <8707>;
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - description: interrupt event for ring wbm2host-tx-completions-ring3
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - description: interrupt event for ring wbm2host-tx-completions-ring2
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - description: interrupt event for ring wbm2host-tx-completions-ring1
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - const: wbm2host-tx-completions-ring3
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - const: wbm2host-tx-completions-ring2
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:            - const: wbm2host-tx-completions-ring1
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:                          "wbm2host-tx-completions-ring3",
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:                          "wbm2host-tx-completions-ring2",
Documentation/devicetree/bindings/net/wireless/qcom,ath11k.yaml:                          "wbm2host-tx-completions-ring1",
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:  - queue-count : number of delivery and completion queues in the controller
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:  - interrupts : For v1 hw: Interrupts for phys, completion queues, and fatal
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:			- Completion queue interrupts
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:		Completion queue interrupts : each completion queue has 1
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:		For v2 hw: Interrupts for phys, Sata, and completion queues;
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:			- Completion queue interrupts
Documentation/devicetree/bindings/scsi/hisilicon-sas.txt:		Completion queue interrupts : each completion queue has 1
Documentation/devicetree/bindings/spi/spi-pl022.yaml:    description: delay in ms following transfer completion before the
Documentation/devicetree/bindings/tpm/tpm-common.yaml:    description: indicates command completion
Documentation/driver-api/basics.rst:.. kernel-doc:: include/linux/completion.h
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    Select mode to be used to wait for completion of each compresses
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    with -EINPROGRESS.  The caller can then either poll for completion
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    for an interrupt signaling completion.  This latter mode is
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_einval_errors: 0
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_timeout_errors: 0
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_comp_buf_overflow_errors: 136
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_einval_errors: 0
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_timeout_errors: 0
Documentation/driver-api/crypto/iaa/iaa-crypto.rst:    total_completion_comp_buf_overflow_errors: 0
Documentation/driver-api/device-io.rst:calls, since only a few will indicate or depend on DMA completion.
Documentation/driver-api/device-io.rst:ensure posted write completion is to do a dummy read after a write as
Documentation/driver-api/dma-buf.rst:But memory allocations are not allowed to gate completion of DMA fences, which
Documentation/driver-api/dmaengine/client.rst:     Although the async_tx API specifies that completion callback
Documentation/driver-api/dmaengine/client.rst:    after their transfer completion callback has run for the descriptor.
Documentation/driver-api/dmaengine/client.rst:    If no completion callback has been defined for the transfer, then the
Documentation/driver-api/dmaengine/client.rst:    completed, then the client must use completion callback.
Documentation/driver-api/dmaengine/client.rst:      3. on transfer completion, use dmaengine_desc_get_metadata_ptr() to get
Documentation/driver-api/dmaengine/client.rst:     point when the completion callback returns if used).
Documentation/driver-api/dmaengine/client.rst:   On completion of each DMA operation, the next in queue is started and
Documentation/driver-api/dmaengine/client.rst:   completion callback routine for notification, if set.
Documentation/driver-api/dmaengine/client.rst:   completion of a specific DMA transaction.
Documentation/driver-api/dmaengine/dmatest.rst:To wait for test completion userspace can poll 'run' until it is false, or use
Documentation/driver-api/dmaengine/dmatest.rst:completion listing the number of tests executed, number that failed, and a
Documentation/driver-api/dmaengine/provider.rst:- DMA_COMPLETION_NO_ORDER
Documentation/driver-api/dmaengine/provider.rst:  - The device does not support in order completion.
Documentation/driver-api/dmaengine/provider.rst:    properly track the completion.
Documentation/driver-api/dmaengine/provider.rst:    On transfer completion the DMA driver must copy the metadata to the client
Documentation/driver-api/dmaengine/provider.rst:    provided metadata buffer before notifying the client about the completion.
Documentation/driver-api/dmaengine/provider.rst:    After the transfer completion, DMA drivers must not touch the metadata
Documentation/driver-api/dmaengine/provider.rst:  Note: since the client will ask for the metadata pointer in the completion
Documentation/driver-api/dmaengine/provider.rst:    completion and is completing the operation out of order.
Documentation/driver-api/dmaengine/provider.rst:  its completion.
Documentation/driver-api/dmaengine/pxa_dma.rst:d) Transfers completion updater
Documentation/driver-api/dmaengine/pxa_dma.rst:transfer being completed into the physical channel's completion mark.
Documentation/driver-api/dmaengine/pxa_dma.rst:e) Transfers completion, irq and tasklet
Documentation/driver-api/driver-model/binding.rst:Upon the successful completion of probe, the device is registered with
Documentation/driver-api/firewire.rst:   :functions: fw_iso_context_schedule_flush_completions
Documentation/driver-api/firmware/fw_upload.rst:sysfs file to signal completion. Echoing 0 to *loading* also triggers the
Documentation/driver-api/ipmi.rst:here) or the response.  Note that the completion code of a response is
Documentation/driver-api/libata.rst:    enum ata_completion_errors (*qc_prep) (struct ata_queued_cmd *qc);
Documentation/driver-api/libata.rst:    executed. qc currently has two mechanisms to notify completion. One
Documentation/driver-api/libata.rst:    is via ``qc->complete_fn()`` callback and the other is completion
Documentation/driver-api/libata.rst:    ``qc->complete_fn()`` callback is used for completion notification. ATA
Documentation/driver-api/libata.rst:    issued. Device will raise interrupt on completion.
Documentation/driver-api/libata.rst:   callback is not zero. Completion is short circuited and
Documentation/driver-api/libata.rst:timeout and ATAPI error completion. This function will check if a qc is active
Documentation/driver-api/libata.rst:not deallocated. The purpose of this half-completion is to use the qc as
Documentation/driver-api/libata.rst:-  DRQ on command completion.
Documentation/driver-api/libata.rst:during command execution and on completion.
Documentation/driver-api/libata.rst:ABRT error during data transfer or on completion
Documentation/driver-api/libata.rst:    on error completion is indeterminate, so we cannot assume that
Documentation/driver-api/libata.rst:-  Controller-specific error completion with error information
Documentation/driver-api/libata.rst:Late completion
Documentation/driver-api/mailbox.rst:		struct completion c;
Documentation/driver-api/mailbox.rst:		init_completion(&dc_async->c);
Documentation/driver-api/mailbox.rst:		wait_for_completion(&dc_async->c);
Documentation/driver-api/md/raid5-cache.rst:In write-through mode, MD reports IO completion to upper layer (usually
Documentation/driver-api/md/raid5-cache.rst:In write-back mode, MD reports IO completion to upper layer (usually
Documentation/driver-api/md/raid5-cache.rst:In write-back mode, MD writes IO data to the log and reports IO completion. The
Documentation/driver-api/mmc/mmc-async-req.rst:for completion of that request and starts the new one and returns. It
Documentation/driver-api/nfc/nfc-hci.rst:HCI command, setup a local wait queue on stack, and wait_event() for completion.
Documentation/driver-api/nfc/nfc-hci.rst:waiting command execution. Response processing involves invoking the completion
Documentation/driver-api/nfc/nfc-hci.rst:The completion callback will then wake the syscall context.
Documentation/driver-api/nfc/nfc-hci.rst:  connection, the error is reported through the connect completion.
Documentation/driver-api/nvdimm/security.rst:The sysfs attribute "security" can be polled to wait on overwrite completion.
Documentation/driver-api/pm/devices.rst:might be able to treat DMA completion as a wakeup event (sometimes DMA can stay
Documentation/driver-api/rapidio/mport_cdev.rst:- Check/Wait for completion of asynchronous DMA data transfer
Documentation/driver-api/rapidio/mport_cdev.rst:      - DMA transfer completion timeout (in msec, default value 3000).
Documentation/driver-api/rapidio/mport_cdev.rst:        This parameter set a maximum completion wait time for SYNC mode DMA
Documentation/driver-api/rapidio/rapidio.rst:each agent waits for enumeration completion by the host for the configured wait
Documentation/driver-api/surface_aggregator/clients/cdev.rst:completion of the request, the call will write the response to the response
Documentation/driver-api/surface_aggregator/internal.rst:workqueue for event and asynchronous request completion, and also manages
Documentation/driver-api/surface_aggregator/internal.rst:completed and provides the status of this completion, i.e. zero on success
Documentation/driver-api/surface_aggregator/internal.rst:* ``SSH_PACKET_SF_LOCKED_BIT``: This bit is set when completion, either
Documentation/driver-api/surface_aggregator/internal.rst:the successful completion of a sequenced packet will always run on the
Documentation/driver-api/surface_aggregator/internal.rst:receiver thread (whereas any failure-indicating completion will run on the
Documentation/driver-api/surface_aggregator/internal.rst:completion will occur once the underlying packet has been successfully
Documentation/driver-api/surface_aggregator/internal.rst:completion callback). For a request with response, successful completion
Documentation/driver-api/surface_aggregator/internal.rst:* ``SSH_REQUEST_SF_LOCKED_BIT``: This bit is set when completion, either
Documentation/driver-api/surface_aggregator/internal.rst:Packet Completion Callback
Documentation/driver-api/surface_aggregator/internal.rst:The packet completion callback is executed once the underlying packet of a
Documentation/driver-api/surface_aggregator/internal.rst:request has been completed. In case of an error completion, the
Documentation/driver-api/surface_aggregator/internal.rst:On successful packet completion, further processing depends on the request.
Documentation/driver-api/surface_aggregator/internal.rst:delivery and registration via the (event) completion system (|ssam_cplt|).
Documentation/driver-api/surface_aggregator/internal.rst:completion workqueue. After an event has been received via the callback
Documentation/driver-api/surface_aggregator/internal.rst:(|ssam_event_queue|). From this event queue the completion work item of that
Documentation/driver-api/surface_aggregator/internal.rst:queue (running on the completion workqueue) will pick up the event and
Documentation/driver-api/usb/URB.rst:- Each URB has a completion handler, which is called after the action
Documentation/driver-api/usb/URB.rst:  context-pointer for passing information to the completion handler.
Documentation/driver-api/usb/URB.rst:  data to an endpoint while your driver handles completion of another.
Documentation/driver-api/usb/URB.rst:  // (IN) all urbs need completion routines
Documentation/driver-api/usb/URB.rst:	void *context;                  // context for completion routine
Documentation/driver-api/usb/URB.rst:	usb_complete_t complete;        // pointer to completion routine
Documentation/driver-api/usb/URB.rst:  // (OUT) status after each completion
Documentation/driver-api/usb/URB.rst:returned to you in a completion callback.  It will automatically be
Documentation/driver-api/usb/URB.rst:length, the completion handler, and its context. Take a look at the some
Documentation/driver-api/usb/URB.rst:never look at that value except in your completion callback.
Documentation/driver-api/usb/URB.rst:For isochronous endpoints, your completion handlers should (re)submit
Documentation/driver-api/usb/URB.rst:returns; you must still wait for the completion handler to be called.
Documentation/driver-api/usb/URB.rst:until after the URB has been returned and the completion handler
Documentation/driver-api/usb/URB.rst:that if the completion handler or anyone else tries to resubmit it
Documentation/driver-api/usb/URB.rst:time, and the completion handler may free the URB.  If this happens
Documentation/driver-api/usb/URB.rst:completion handler, the handler must not take any lock that is held
Documentation/driver-api/usb/URB.rst:by the completion handler.
Documentation/driver-api/usb/URB.rst:What about the completion handler?
Documentation/driver-api/usb/URB.rst:I.e., it gets the URB that caused the completion call. In the completion
Documentation/driver-api/usb/URB.rst:information to the completion handler.
Documentation/driver-api/usb/URB.rst:have transferred successfully before the completion was called.
Documentation/driver-api/usb/URB.rst:   NEVER SLEEP IN A COMPLETION HANDLER.
Documentation/driver-api/usb/URB.rst:In the current kernel, completion handlers run with local interrupts
Documentation/driver-api/usb/URB.rst:local IRQs are always disabled inside completion handlers.
Documentation/driver-api/usb/URB.rst:After completion, actual_length contains the actual transferred length and
Documentation/driver-api/usb/URB.rst:completion keeps (re)submitting a later URB, you'll get smooth ISO streaming
Documentation/driver-api/usb/URB.rst:restarted when they complete.  They end when the completion handler is
Documentation/driver-api/usb/URB.rst:your completion handler must resubmit it.
Documentation/driver-api/usb/anchors.rst:an URB is finished by (successful) completion. Thus disassociation
Documentation/driver-api/usb/callbacks.rst:structure and through the completion handler of URBs a driver submits.
Documentation/driver-api/usb/callbacks.rst:completion callback can be found in :ref:`usb-urb`.
Documentation/driver-api/usb/dwc3.rst:We can log and decode every Generic Command with its completion
Documentation/driver-api/usb/dwc3.rst:Endpoints commands can also be logged together with completion
Documentation/driver-api/usb/error-codes.rst:USB device drivers may only test urb status values in completion handlers.
Documentation/driver-api/usb/error-codes.rst:``URB_SHORT_NOT_OK`` flag is set.  Completion handlers for isochronous URBs
Documentation/driver-api/usb/power-management.rst:	such as an URB's completion handler, but when they return the
Documentation/driver-api/usb/power-management.rst:the I/O request routine and the URB completion handler; it should
Documentation/driver-api/usb/usb.rst:URB's completion callback handles the next step. All USB transfer types
Documentation/driver-api/usb/writing_usb_driver.rst::c:func:`usb_fill_bulk_urb` function, we point the urb's completion callback
Documentation/driver-api/usb/writing_usb_driver.rst:handle urb completion callback functions. We call the :c:func:`usb_bulk_msg`
Documentation/driver-api/xillybus.rst:partial completion is allowed.
Documentation/fb/fbcon.rst:garbled display, but the system still boots to completion.  If you are
Documentation/filesystems/autofs-mount-control.rst:request back to the daemon and waits for completion.
Documentation/filesystems/caching/backend-api.rst:wait for completion by calling::
Documentation/filesystems/caching/backend-api.rst:completion until all objects have been destroyed.  The following functions are
Documentation/filesystems/caching/netfs-api.rst:invalidations can be detected upon completion.
Documentation/filesystems/caching/netfs-api.rst:will be run on completion::
Documentation/filesystems/caching/netfs-api.rst:and the termination function will be called upon completion.  If not given, the
Documentation/filesystems/caching/netfs-api.rst:and term_func indicates an optional completion function, to which
Documentation/filesystems/caching/netfs-api.rst:the pages upon completion before calling term_func.
Documentation/filesystems/ext4/journal.rst:     - Block commit record. This block signifies the completion of a
Documentation/filesystems/gfs2-uevents.rst:The other CHANGE uevent is used to inform of the completion
Documentation/filesystems/iomap/design.rst:   or completion.
Documentation/filesystems/iomap/design.rst:     at I/O completion, such as file size updates from direct I/O.
Documentation/filesystems/iomap/operations.rst:    deferring the ioend completion to a workqueue to run metadata update
Documentation/filesystems/iomap/operations.rst:Pagecache Writeback Completion
Documentation/filesystems/iomap/operations.rst: * ``IOCB_HIPRI``: Poll for I/O completion instead of waiting for an
Documentation/filesystems/iomap/operations.rst: * ``IOCB_DIO_CALLER_COMP``: Try to run I/O completion from the caller's
Documentation/filesystems/iomap/operations.rst:completion, it should call ``__iomap_dio_rw``.
Documentation/filesystems/iomap/operations.rst:Filesystems that want to perform extra work after an I/O completion
Documentation/filesystems/journalling.rst:and wait on IO completion of fast commit buffers.
Documentation/filesystems/locking.rst:completion.
Documentation/filesystems/locking.rst:page, write I/O can be submitted and the write I/O completion handler must run
Documentation/filesystems/locking.rst:call this method upon the IO completion.
Documentation/filesystems/vfs.rst:	unlocked by the I/O completion handler.  The set of pages are
Documentation/filesystems/vfs.rst:	called when aio wants to poll for completions on HIPRI iocbs
Documentation/filesystems/virtiofs.rst:the request completion.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:completion, after which they are unpinned and can be written to disk. An object
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:checkpoint completion.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:checkpoint from initiation to checkpoint completion. A new context is initiated
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:completion callback. Log IO completion will call that callback, which can then
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:every checkpoint transaction completion. Unfortunately, if this space is not
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:as there is a 1:1 relationship with transaction commit and log item completion.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:completion relationship. Every time an object is relogged in the CIL it goes
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:through the commit process without a corresponding completion being registered.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:log item completion. The result of this is that pinning and unpinning of the
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:on transaction completion" model.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:insertion into the CIL, unpin on checkpoint completion". In other words, the
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:ensure completion of checkpoints.
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:(obtained through completion of a commit record write) while log force
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:	7. Transaction completion
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:	<item IO completion>
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:	8. Checkpoint completion
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:	<item IO completion>
Documentation/filesystems/xfs/xfs-delayed-logging-design.rst:committing of the log items to the log itself and the completion processing.
Documentation/filesystems/xfs/xfs-online-fsck-design.rst:exchange begins, it will always run to completion, even there are
Documentation/filesystems/xfs/xfs-online-fsck-design.rst:  operation fails to run to completion.
Documentation/filesystems/xfs/xfs-self-describing-metadata.rst:that it should see, and the IO completion process verifies that the metadata
Documentation/firmware-guide/acpi/apei/output_format.rst:        Poisoned TLP | Flow Control Protocol | Completion Timeout | \
Documentation/firmware-guide/acpi/apei/output_format.rst:        Completer Abort | Unexpected Completion | Receiver Overflow | \
Documentation/gpu/drm-vm-bind-async.rst:  a certain mode that disallows completion dma-fences.
Documentation/gpu/drm-vm-bind-async.rst:out-syncobjs and internally in KMD to signal bind completion,  any
Documentation/gpu/drm-vm-bind-async.rst:the bind completion using the memory out-fence as the signal condition
Documentation/gpu/drm-vm-bind-async.rst:	/** @num_syncs: amount of syncs to wait for or to signal on completion. */
Documentation/gpu/drm-vm-bind-locking.rst:* ``dma_fence``: A struct dma_fence that is similar to a struct completion
Documentation/gpu/rfc/i915_scheduler.rst:	* Remove in-order completion assumptions from DRM scheduler
Documentation/gpu/rfc/i915_vm_bind.h: * The returned output fence will be signaled after the completion of the
Documentation/gpu/rfc/i915_vm_bind.h:	 * Return operation completion fence as output.
Documentation/gpu/rfc/i915_vm_bind.h:	 * @fence: Timeline fence for bind completion signaling.
Documentation/gpu/rfc/i915_vm_bind.h:	 * @fence: Timeline fence for unbind completion signaling.
Documentation/gpu/rfc/i915_vm_bind.rst:signaling the completion of bind/unbind operation.
Documentation/gpu/rfc/i915_vm_bind.rst:worker (like upon bind completion). User can wait on a user fence with a new
Documentation/gpu/todo.rst:One issue with the helpers is that they require that drivers handle completion
Documentation/hid/intel-ish-hid.rst:Optionally the caller can register handler to get notification of completion.
Documentation/hwmon/lm90.rst:transaction completion, effectively doubling the register cache refresh time.
Documentation/infiniband/core_locking.rst:  simultaneously.  However, the ordering of the work completion
Documentation/infiniband/core_locking.rst:  allowed for a low-level driver to call a consumer's completion event
Documentation/infiniband/core_locking.rst:  completion event handlers for the same CQ are not called
Documentation/infiniband/core_locking.rst:  The context in which completion event and asynchronous event
Documentation/infiniband/ipoib.rst:  IPoIB doesn't use events for TX completion signaling so only RX
Documentation/infiniband/tag_matching.rst:processed by the sender. A completion send is received in the send_cq
Documentation/isdn/interface_capi.rst:	Completion must be signalled by a call to capi_ctr_ready().
Documentation/isdn/interface_capi.rst:	Completion must be signalled by a call to capi_ctr_down().
Documentation/livepatch/livepatch.rst:determine which tasks are blocking completion of a patching operation.
Documentation/locking/locktypes.rst:as mutexes and completions.
Documentation/locking/mutex-design.rst:[ This is in contrast with spin_unlock() [or completion_done()], which
Documentation/locking/mutex-design.rst:  lock implementation after spin_unlock()/completion_done() releases
Documentation/memory-barriers.txt:     memory barrier will be _complete_ by the completion of a memory barrier
Documentation/memory-barriers.txt:	   completion of all prior writes to memory either issued by, or
Documentation/memory-barriers.txt:	that waits for a completion response from the I/O peripheral before
Documentation/mhi/mhi.rst:Event rings: Used by the device to send completion and state transition messages
Documentation/mhi/mhi.rst:data transfer completion status, command completion status, and state changes
Documentation/mhi/mhi.rst:* Device generates a completion event for the processed TD by updating ED.
Documentation/mhi/mhi.rst:* Host wakes up and checks the event ring for completion event.
Documentation/misc-devices/ibmvmc.rst:Prior to completion of this initialization sequence, the device returns
Documentation/netlink/specs/handshake.yaml:      doc: Handler reports handshake completion
Documentation/netlink/specs/netdev.yaml:          the device has issued a DMA completion for the packet).
Documentation/networking/af_xdp.rst:UMEM also has two rings: the FILL ring and the COMPLETION ring. The
Documentation/networking/af_xdp.rst:COMPLETION ring, on the other hand, contains frame addr that the
Documentation/networking/af_xdp.rst:COMPLETION ring are addrs that were previously transmitted using the
Documentation/networking/af_xdp.rst:and the TX and COMPLETION rings are used for the TX path.
Documentation/networking/af_xdp.rst:reason that there is only one set of FILL and COMPLETION rings per
Documentation/networking/af_xdp.rst:There are a four different kind of rings: FILL, COMPLETION, RX and
Documentation/networking/af_xdp.rst:The UMEM uses two rings: FILL and COMPLETION. Each socket associated
Documentation/networking/af_xdp.rst:one FILL ring, one COMPLETION ring, four TX rings and four RX rings.
Documentation/networking/af_xdp.rst:XDP_UMEM_PGOFF_COMPLETION_RING).
Documentation/networking/af_xdp.rst:UMEM Completion Ring
Documentation/networking/af_xdp.rst:The COMPLETION Ring is used transfer ownership of UMEM frames from
Documentation/networking/af_xdp.rst:COMPLETION ring pairs. You have to create one of these pairs per
Documentation/networking/af_xdp.rst:COMPLETION ring as there is only on unique netdev,queue_id tuple that
Documentation/networking/af_xdp.rst:ring, or at least one of them, but no FILL or COMPLETION rings as the
Documentation/networking/af_xdp.rst:Note, that since there is only a single set of FILL and COMPLETION
Documentation/networking/af_xdp.rst:create one FILL ring and one COMPLETION ring for each unique
Documentation/networking/af_xdp.rst:COMPLETION ring for this socket. Then in the bind call, set he
Documentation/networking/af_xdp.rst:takes a reference to a FILL ring and a COMPLETION ring that will be
Documentation/networking/af_xdp.rst:XDP_{RX|TX|UMEM_FILL|UMEM_COMPLETION}_RING setsockopts
Documentation/networking/af_xdp.rst:FILL, and COMPLETION rings respectively should have. It is mandatory
Documentation/networking/af_xdp.rst:COMPLETION ring are mandatory as you need to have a UMEM tied to your
Documentation/networking/af_xdp.rst:FILL or COMPLETION rings created as the ones from the shared UMEM will
Documentation/networking/device_drivers/can/ctu/ctucanfd-driver.rst:-  Signal TX completion and errors to the network subsystem: ISR
Documentation/networking/device_drivers/can/ctu/ctucanfd-driver.rst:#. **TX completion**. When the device successfully finishes transmitting
Documentation/networking/device_drivers/ethernet/altera/altera_tse.rst:completion in the context of the interrupt handling chain by recycling
Documentation/networking/device_drivers/ethernet/altera/altera_tse.rst:completions until no more receive completions are available.
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:- Admin Queue (AQ) and Admin Completion Queue (ACQ)
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:- Create I/O completion queue
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:- Destroy I/O completion queue
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:SQ correspondingly). Each SQ has a completion queue (CQ) associated
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:- Cache miss rate on completion is reduced, particularly for data
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:  out-of-order Tx completions.
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:- When the ENA device finishes sending the packet, a completion
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:  completion descriptors generated by the ENA, with a single
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:  completion descriptor per completed packet.
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:  * ``req_id`` is retrieved from the completion descriptor. The ``tx_info`` of
Documentation/networking/device_drivers/ethernet/amazon/ena.rst:  * The function stops when the completion descriptors are completed or
Documentation/networking/device_drivers/ethernet/aquantia/atlantic.rst: 0x0400   transmit completion.
Documentation/networking/device_drivers/ethernet/aquantia/atlantic.rst: 0x0800   receive completion.
Documentation/networking/device_drivers/ethernet/chelsio/cxgb.rst:      chipset, you may experience the "133-Mhz Mode Split Completion Data
Documentation/networking/device_drivers/ethernet/chelsio/cxgb.rst:      can provide stale data via split completion cycles to a PCI-X card that
Documentation/networking/device_drivers/ethernet/chelsio/cxgb.rst:      section 56, "133-MHz Mode Split Completion Data Corruption" for more
Documentation/networking/device_drivers/ethernet/freescale/dpaa2/overview.rst:- IRQs: command completion
Documentation/networking/device_drivers/ethernet/google/gve.rst:- RX and TX completion queues, which receive descriptors from the device, use a
Documentation/networking/device_drivers/ethernet/google/gve.rst:- It's the driver's responsibility to ensure that the RX and TX completion
Documentation/networking/device_drivers/ethernet/google/gve.rst:- TX packets have a 16 bit completion_tag and RX buffers have a 16 bit
Documentation/networking/device_drivers/ethernet/google/gve.rst:  buffer_id. These will be returned on the TX completion and RX queues
Documentation/networking/device_drivers/ethernet/huawei/hinic.rst:Completion Event Queues(CEQs) - The completion Event Queues that describe IO
Documentation/networking/device_drivers/ethernet/huawei/hinic.rst:used to set the QPs addresses in HW. The commands completion events are
Documentation/networking/device_drivers/ethernet/huawei/hinic.rst:accumulated on the CEQ that is configured to receive the CMDQ completion events.
Documentation/networking/device_drivers/ethernet/intel/iavf.rst:- Descriptor write-back completion
Documentation/networking/device_drivers/ethernet/mellanox/mlx5/counters.rst:       completion queues on channel i.
Documentation/networking/device_drivers/ethernet/mellanox/mlx5/counters.rst:     - The number of hard interrupt events on the completion queues of channel i.
Documentation/networking/device_drivers/ethernet/mellanox/mlx5/counters.rst:     - The number of completions received on the CQ of the `XDP_TX` ring.
Documentation/networking/device_drivers/ethernet/mellanox/mlx5/counters.rst:     - The number of completions received for packets redirected to the
Documentation/networking/devlink/devlink-params.rst:     - Control the size of I/O completion EQs.
Documentation/networking/devlink/devlink-port.rst:For example, the number of netdevice channels and RDMA device completion
Documentation/networking/devlink/mlx5.rst:- tx error completion
Documentation/networking/devlink/mlx5.rst:    Report on error tx completion.
Documentation/networking/devlink/mlx5.rst:- rx completions with errors (reported by HW on interrupt context)
Documentation/networking/devlink/mlx5.rst:    Report on rx completion error.
Documentation/networking/devlink/mlx5.rst:- Diagnose rx queues' status and corresponding completion queue::
Documentation/networking/devlink/mlx5.rst:        number of times an EQ mapped to completion events was
Documentation/networking/driver.rst:be aborted. If necessary, poll or wait for completion of
Documentation/networking/driver.rst:Timely completions
Documentation/networking/ethtool-netlink.rst:``ETHTOOL_A_RINGS_CQE_SIZE`` specifies the completion queue event size.
Documentation/networking/ethtool-netlink.rst:Completion queue events (CQE) are the events posted by NIC to indicate the
Documentation/networking/ethtool-netlink.rst:completion status of a packet when the packet is sent (like send success or
Documentation/networking/ethtool-netlink.rst:completion queue size can be adjusted in the driver if CQE size is modified.
Documentation/networking/filter.rst:Interaction in bpf_dbg happens through a shell that also has auto-completion
Documentation/networking/msg_zerocopy.rst:it replaces per byte copy cost with page accounting and completion
Documentation/networking/msg_zerocopy.rst:previously passed buffer. It queues completion notifications on the
Documentation/networking/msg_zerocopy.rst:avoidance, and a contract that the kernel will queue a completion
Documentation/networking/msg_zerocopy.rst:In all these cases, the kernel returns a completion notification when
Documentation/networking/msg_zerocopy.rst:before the (copied) data is fully transmitted. A zerocopy completion
Documentation/networking/msg_zerocopy.rst:notification is not a transmit completion notification, therefore.
Documentation/networking/napi.rst:argument - drivers can process completions for any number of Tx
Documentation/networking/napi.rst:   skb Tx completions and no Rx or XDP packets.
Documentation/networking/rds.rst:    - looks at write completions
Documentation/networking/rds.rst:  prior to outgoing hash completion in rds_sendmsg() when the transport
Documentation/networking/rxrpc.rst: (#) An call may be aborted by either end at any time up to its completion.
Documentation/networking/scaling.rst:exclusively to a subset of CPUs, where the transmit completions for
Documentation/networking/scaling.rst:transmit queue). Secondly, cache miss rate on transmit completion is
Documentation/networking/scaling.rst:in keeping the CPU overhead low. Transmit completion work is locked into
Documentation/networking/scaling.rst:application cleans up the packets during the busy poll, transmit completion
Documentation/networking/scaling.rst:with the CPU that processes transmit completions for that queue
Documentation/networking/tls-handshake.rst:Completion" sesction below.
Documentation/networking/tls-handshake.rst:@sock has been canceled. The consumer's handshake completion callback
Documentation/networking/tls-handshake.rst:completion callback has already been invoked.
Documentation/networking/tls-handshake.rst:Handshake Completion
Documentation/networking/tls-handshake.rst:the consumer's handshake completion callback, provided in the @ta_done
Documentation/networking/tls-handshake.rst:Once the handshake completion callback function has been invoked, normal
Documentation/power/freezing-of-tasks.rst:on another.  For example, if kernel thread A waits for a completion (in the
Documentation/power/runtime_pm.rst:	foo_io_completion(struct foo_priv *foo, void *req)
Documentation/power/runtime_pm.rst:The important point is that after foo_io_completion() asks for an autosuspend,
Documentation/rust/quick-start.rst:be used with many editors to enable syntax highlighting, completion, go to
Documentation/scheduler/completion.rst:Completions - "wait for completion" barrier APIs
Documentation/scheduler/completion.rst:to have reached a point or a specific state, completions can provide a
Documentation/scheduler/completion.rst:Completions are a code synchronization mechanism which is preferable to any
Documentation/scheduler/completion.rst:you probably want to look into using one of the wait_for_completion*()
Documentation/scheduler/completion.rst:The advantage of using completions is that they have a well defined, focused
Documentation/scheduler/completion.rst:Completions are built on top of the waitqueue and wakeup infrastructure of
Documentation/scheduler/completion.rst:is reduced to a simple flag in 'struct completion', appropriately called "done".
Documentation/scheduler/completion.rst:As completions are scheduling related, the code can be found in
Documentation/scheduler/completion.rst:kernel/sched/completion.c.
Documentation/scheduler/completion.rst:There are three main parts to using completions:
Documentation/scheduler/completion.rst: - the initialization of the 'struct completion' synchronization object
Documentation/scheduler/completion.rst: - the waiting part through a call to one of the variants of wait_for_completion(),
Documentation/scheduler/completion.rst:There are also some helper functions for checking the state of completions.
Documentation/scheduler/completion.rst:to have marked a completion as 'done' before another thread checks whether
Documentation/scheduler/completion.rst:To use completions you need to #include <linux/completion.h> and
Documentation/scheduler/completion.rst:create a static or dynamic variable of type 'struct completion',
Documentation/scheduler/completion.rst:	struct completion {
Documentation/scheduler/completion.rst:the ->done completion flag for indicating whether it's completed or not.
Documentation/scheduler/completion.rst:Completions should be named to refer to the event that is being synchronized on.
Documentation/scheduler/completion.rst:	wait_for_completion(&early_console_added);
Documentation/scheduler/completion.rst:Good, intuitive naming (as always) helps code readability. Naming a completion
Documentation/scheduler/completion.rst:Initializing completions:
Documentation/scheduler/completion.rst:Dynamically allocated completion objects should preferably be embedded in data
Documentation/scheduler/completion.rst:variants of wait_for_completion(), as it must be assured that memory de-allocation
Documentation/scheduler/completion.rst:does not happen until all related activities (complete() or reinit_completion())
Documentation/scheduler/completion.rst:Initializing of dynamically allocated completion objects is done via a call to
Documentation/scheduler/completion.rst:init_completion()::
Documentation/scheduler/completion.rst:	init_completion(&dynamic_object->done);
Documentation/scheduler/completion.rst:The re-initialization function, reinit_completion(), simply resets the
Documentation/scheduler/completion.rst:wait_for_completion() calls going on in parallel.
Documentation/scheduler/completion.rst:Calling init_completion() on the same completion object twice is
Documentation/scheduler/completion.rst:enqueued tasks could get "lost" - use reinit_completion() in that case,
Documentation/scheduler/completion.rst:DECLARE_COMPLETION()::
Documentation/scheduler/completion.rst:	static DECLARE_COMPLETION(setup_done);
Documentation/scheduler/completion.rst:	DECLARE_COMPLETION(setup_done);
Documentation/scheduler/completion.rst:Note that in this case the completion is boot time (or module load time)
Documentation/scheduler/completion.rst:initialized to 'not done' and doesn't require an init_completion() call.
Documentation/scheduler/completion.rst:When a completion is declared as a local variable within a function,
Documentation/scheduler/completion.rst:then the initialization should always use DECLARE_COMPLETION_ONSTACK()
Documentation/scheduler/completion.rst:	DECLARE_COMPLETION_ONSTACK(setup_done)
Documentation/scheduler/completion.rst:Note that when using completion objects as local variables you must be
Documentation/scheduler/completion.rst:threads) have ceased and the completion object is completely unused.
Documentation/scheduler/completion.rst:from the wait_on_completion*() caller function will deallocate the function
Documentation/scheduler/completion.rst:If unsure, use dynamically allocated completion objects, preferably embedded
Documentation/scheduler/completion.rst:exceeds the life time of any helper threads using the completion object,
Documentation/scheduler/completion.rst:A naive DECLARE_COMPLETION() on the stack triggers a lockdep warning.
Documentation/scheduler/completion.rst:Waiting for completions:
Documentation/scheduler/completion.rst:calls wait_for_completion() on the initialized completion structure::
Documentation/scheduler/completion.rst:	void wait_for_completion(struct completion *done)
Documentation/scheduler/completion.rst:	struct completion setup_done;
Documentation/scheduler/completion.rst:	init_completion(&setup_done);
Documentation/scheduler/completion.rst:	wait_for_completion(&setup_done);	complete(&setup_done);
Documentation/scheduler/completion.rst:This is not implying any particular order between wait_for_completion() and
Documentation/scheduler/completion.rst:to wait_for_completion() then the waiting side simply will continue
Documentation/scheduler/completion.rst:completion is signaled by complete().
Documentation/scheduler/completion.rst:Note that wait_for_completion() is calling spin_lock_irq()/spin_unlock_irq(),
Documentation/scheduler/completion.rst:uninterruptible. wait_for_completion() and its variants are only safe
Documentation/scheduler/completion.rst:try_wait_for_completion() below for handling completion in atomic/interrupt
Documentation/scheduler/completion.rst:As all variants of wait_for_completion() can (obviously) block for a long
Documentation/scheduler/completion.rst:wait_for_completion*() variants available:
Documentation/scheduler/completion.rst:	if (!wait_for_completion_interruptible_timeout(...))
Documentation/scheduler/completion.rst:... would execute the same code path for successful completion and for the
Documentation/scheduler/completion.rst:	int wait_for_completion_interruptible(struct completion *done)
Documentation/scheduler/completion.rst:	unsigned long wait_for_completion_timeout(struct completion *done, unsigned long timeout)
Documentation/scheduler/completion.rst:	long wait_for_completion_interruptible_timeout(struct completion *done, unsigned long timeout)
Documentation/scheduler/completion.rst:otherwise it returns 0 if the completion timed out, or the remaining time in
Documentation/scheduler/completion.rst:jiffies if completion occurred.
Documentation/scheduler/completion.rst:or 0 if completion was achieved.  There is a _timeout variant as well::
Documentation/scheduler/completion.rst:	long wait_for_completion_killable(struct completion *done)
Documentation/scheduler/completion.rst:	long wait_for_completion_killable_timeout(struct completion *done, unsigned long timeout)
Documentation/scheduler/completion.rst:The _io variants wait_for_completion_io() behave the same as the non-_io
Documentation/scheduler/completion.rst:	void wait_for_completion_io(struct completion *done)
Documentation/scheduler/completion.rst:	unsigned long wait_for_completion_io_timeout(struct completion *done, unsigned long timeout)
Documentation/scheduler/completion.rst:Signaling completions:
Documentation/scheduler/completion.rst:	void complete(struct completion *done)
Documentation/scheduler/completion.rst:	void complete_all(struct completion *done)
Documentation/scheduler/completion.rst:The signaling will work as expected even if completions are signaled before
Documentation/scheduler/completion.rst:(decrementing) the done field of 'struct completion'. Waiting threads
Documentation/scheduler/completion.rst:particular 'struct completion' at any time - serialized through the wait
Documentation/scheduler/completion.rst:Signaling completion from IRQ context is fine as it will appropriately
Documentation/scheduler/completion.rst:try_wait_for_completion()/completion_done():
Documentation/scheduler/completion.rst:The try_wait_for_completion() function will not put the thread on the wait
Documentation/scheduler/completion.rst:else it consumes one posted completion and returns true::
Documentation/scheduler/completion.rst:	bool try_wait_for_completion(struct completion *done)
Documentation/scheduler/completion.rst:Finally, to check the state of a completion without changing it in any way,
Documentation/scheduler/completion.rst:call completion_done(), which returns false if there are no posted
Documentation/scheduler/completion.rst:completions that were not yet consumed by waiters (implying that there are
Documentation/scheduler/completion.rst:	bool completion_done(struct completion *done)
Documentation/scheduler/completion.rst:Both try_wait_for_completion() and completion_done() are safe to be called in
Documentation/scheduler/index.rst:    completion
Documentation/scheduler/schedutil.rst:XXX IO-wait: when the update is due to a task wakeup from IO-completion we
Documentation/scsi/ChangeLog.lpfc:	  find command in both TX and TX completion queues.  Return ERROR
Documentation/scsi/ChangeLog.lpfc:	  completion path.
Documentation/scsi/ChangeLog.lpfc:	  function into two routines to match the fast and slow completion
Documentation/scsi/ChangeLog.lpfc:	  semantics - ELS completions worked for the wrong reasons.  Also
Documentation/scsi/ChangeLog.lpfc:	* Defined default mailbox completion routine and removed code in
Documentation/scsi/ChangeLog.lpfc:	* Abort handler will try to wait for abort completion before
Documentation/scsi/ChangeLog.lpfc:	  returning.  Fixes some panics in iocb completion code path.
Documentation/scsi/ChangeLog.lpfc:	* Ignore more unexpected completions in lpfc_nportdisc.c.
Documentation/scsi/ChangeLog.lpfc:	  I/O completion path a little more, especially taking care of
Documentation/scsi/ChangeLog.lpfc:	  submission and completion path a little.
Documentation/scsi/ChangeLog.lpfc:	* In some of the els completion routines, after calling
Documentation/scsi/ChangeLog.lpfc:	* Correct Iocbq completion routine for 2.6 kernel case
Documentation/scsi/ChangeLog.megaraid:	> sd 0:1:0:0: Notifying upper driver of completion (result 0)
Documentation/scsi/ChangeLog.megaraid_sas:    1. Removed un-needed completion_lock spinlock calls.
Documentation/scsi/ChangeLog.megaraid_sas:	(reduced interrupt operation).  In this mode, IO completion
Documentation/scsi/ChangeLog.megaraid_sas:	driver schedules for cmd completion if there are pending cmds
Documentation/scsi/ChangeLog.megaraid_sas:	to prevent IO completion processing from being delayed
Documentation/scsi/ChangeLog.megaraid_sas:routine for max 3 minutes for all pending command completion. Now driver will
Documentation/scsi/ChangeLog.megaraid_sas:call completion routine every 5 seconds from the reset routine instead of
Documentation/scsi/ChangeLog.megaraid_sas:waiting for depending on cmd completion from isr path.
Documentation/scsi/ChangeLog.megaraid_sas:iv.	Tasklet added for cmd completion
Documentation/scsi/ChangeLog.sym53c8xx:	  handler is called for command completion, then clears INTF, scans 
Documentation/scsi/arcmsr_spec.rst:Completion of request::
Documentation/scsi/hpsa.rst:mode, each command completion requires an interrupt, while with "performant mode"
Documentation/scsi/hpsa.rst:command completions indicated by a single interrupt.
Documentation/scsi/hptiop.rst:register 0. An outbound message with the same value indicates the completion
Documentation/scsi/hptiop.rst:with the same value indicates the completion of message.
Documentation/scsi/ncr53c8xx.rst:The profiling information is updated upon completion of SCSI commands.
Documentation/scsi/ncr53c8xx.rst:	(time from SCSI status get to command completion call)
Documentation/scsi/ncr53c8xx.rst:and delay data transfers or status/completions, and (b) may just waste
Documentation/scsi/scsi_eh.rst:discussion.  The latter is used for completion and EH lists and unless
Documentation/scsi/scsi_eh.rst:For all non-EH commands, scsi_done() is the completion callback.  It
Documentation/scsi/scsi_eh.rst:	scsi_io_completion() to finish the I/O.
Documentation/scsi/scsi_eh.rst:	scsi_io_completion() then notifies the block layer on
Documentation/scsi/scsi_eh.rst:active as long as lower layers are concerned and completion could
Documentation/scsi/scsi_eh.rst:occur at any time.  Of course, all such completions are ignored as the
Documentation/scsi/scsi_eh.rst: 1. Error completion / time out
Documentation/scsi/scsi_eh.rst:On completion, the handler should have made lower layers forget about
Documentation/scsi/scsi_eh.rst: - On completion, each failed sdev must have forgotten about all
Documentation/scsi/scsi_eh.rst: - On completion, each failed sdev must be ready for new commands or
Documentation/scsi/scsi_mid_low_api.rst:  - queuecommand - queue scsi command, invoke 'done' on completion
Documentation/scsi/scsi_mid_low_api.rst:    *      queuecommand - queue scsi command, invoke scp->scsi_done on completion
Documentation/scsi/scsi_mid_low_api.rst:with the completion of a SCSI command" when a status of CHECK CONDITION
Documentation/spi/spi-summary.rst:completion callbacks.  There are also some simple synchronous wrappers
Documentation/spi/spi-summary.rst:    issued in any context (irq handler, task, etc) and completion
Documentation/target/tcmu-design.rst:	indicates out-of-order completion is supported.
Documentation/target/tcmu-design.rst:capable of handling out-of-order completions. In this case, userspace can
Documentation/timers/hrtimers.rst:  evil to guarantee the processing of actual timeout completions
Documentation/timers/hrtimers.rst:  (because most of the timeouts are deleted before completion), which
Documentation/trace/ftrace.rst:    8)     1824      16   wait_for_completion+0x1d/0x1f
Documentation/trace/hisi-ptt.rst:- qos_tx_cpl: weight of Tx completion TLPs
Documentation/trace/hisi-ptt.rst:of the completion packets on the link to enhance the performance as
Documentation/trace/hisi-ptt.rst:more completions are consumed.
Documentation/trace/hisi-ptt.rst:- 8'b00000100: completions (CPL)
Documentation/trace/hisi-ptt.rst:Inbound completions are classified into two types:
Documentation/trace/hisi-ptt.rst:- completion A (CPL A): completion of CHI/DMA/Native non-posted requests, except for CPL B
Documentation/trace/hisi-ptt.rst:- completion B (CPL B): completion of DMA remote2local and P2P non-posted requests
Documentation/trace/histogram.rst:  => wait_for_completion_killable+0x144/0x1f0
Documentation/trace/histogram.rst:         wait_for_completion+0x24/0x30
Documentation/trace/histogram.rst:         wait_for_completion_timeout+0x1d/0x30
Documentation/translations/it_IT/locking/locktypes.rst:completion.
Documentation/translations/zh_CN/scheduler/completion.rst::Original: Documentation/scheduler/completion.rst
Documentation/translations/zh_CN/scheduler/completion.rst:或一些古怪的msleep(1)循环来允许其它代码继续运行时，你可能想用wait_for_completion*()
Documentation/translations/zh_CN/scheduler/completion.rst:调用和completion()来代替。
Documentation/translations/zh_CN/scheduler/completion.rst:事件被简化为 ``struct completion`` 中的一个简单标志，被恰如其名地称为‘done’。
Documentation/translations/zh_CN/scheduler/completion.rst:由于完成与调度有关，代码可以在kernel/sched/completion.c中找到。
Documentation/translations/zh_CN/scheduler/completion.rst: - 'struct completion' 同步对象的初始化
Documentation/translations/zh_CN/scheduler/completion.rst: - 通过调用wait_for_completion()的一个变体来实现等待部分。
Documentation/translations/zh_CN/scheduler/completion.rst:要使用完成API，你需要#include <linux/completion.h>并创建一个静态或动态的
Documentation/translations/zh_CN/scheduler/completion.rst:``struct completion`` 类型的变量，它只有两个字段::
Documentation/translations/zh_CN/scheduler/completion.rst:	struct completion {
Documentation/translations/zh_CN/scheduler/completion.rst:	wait_for_completion(&early_console_added);
Documentation/translations/zh_CN/scheduler/completion.rst:在使用wait_for_completion()的_timeout()或_killable()/_interruptible()变体
Documentation/translations/zh_CN/scheduler/completion.rst:时应特别小心，因为必须保证在所有相关活动（complete()或reinit_completion()）发生
Documentation/translations/zh_CN/scheduler/completion.rst:动态分配的完成对象的初始化是通过调用init_completion()来完成的::
Documentation/translations/zh_CN/scheduler/completion.rst:	init_completion(&dynamic_object->done);
Documentation/translations/zh_CN/scheduler/completion.rst:重新初始化函数reinit_completion()，只是将->done字段重置为0（“not done”），而
Documentation/translations/zh_CN/scheduler/completion.rst:不触及等待队列。这个函数的调用者必须确保没有任何令人讨厌的wait_for_completion()
Documentation/translations/zh_CN/scheduler/completion.rst:在同一个完成对象上调用init_completion()两次很可能是一个bug，因为它将队列重新初始
Documentation/translations/zh_CN/scheduler/completion.rst:化为一个空队列，已排队的任务可能会“丢失”--在这种情况下使用reinit_completion()，但
Documentation/translations/zh_CN/scheduler/completion.rst:对于文件范围内的静态（或全局）声明，你可以使用 DECLARE_COMPLETION()::
Documentation/translations/zh_CN/scheduler/completion.rst:	static DECLARE_COMPLETION(setup_done);
Documentation/translations/zh_CN/scheduler/completion.rst:	DECLARE_COMPLETION(setup_done);
Documentation/translations/zh_CN/scheduler/completion.rst:init_completion()。
Documentation/translations/zh_CN/scheduler/completion.rst:DECLARE_COMPLETION_ONSTACK()来初始化，这不仅仅是为了让lockdep正确运行，也是明确表
Documentation/translations/zh_CN/scheduler/completion.rst:	DECLARE_COMPLETION_ONSTACK(setup_done)
Documentation/translations/zh_CN/scheduler/completion.rst:能仍在被其他线程使用 - 从wait_on_completion*()调用者函数的返回会取消分配函数栈，如
Documentation/translations/zh_CN/scheduler/completion.rst:在堆栈上单纯地调用DECLARE_COMPLETION()会触发一个lockdep警告。
Documentation/translations/zh_CN/scheduler/completion.rst:wait_for_completion()::
Documentation/translations/zh_CN/scheduler/completion.rst:	void wait_for_completion(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:	struct completion setup_done;
Documentation/translations/zh_CN/scheduler/completion.rst:	init_completion(&setup_done);
Documentation/translations/zh_CN/scheduler/completion.rst:	wait_for_completion(&setup_done);	complete(setup_done);
Documentation/translations/zh_CN/scheduler/completion.rst:这并不意味着调用wait_for_completion()和complete()有任何特定的时间顺序--如果调
Documentation/translations/zh_CN/scheduler/completion.rst:用complete()发生在调用wait_for_completion()之前，那么等待方将立即继续执行，因为
Documentation/translations/zh_CN/scheduler/completion.rst:注意，wait_for_completion()是在调用spin_lock_irq()/spin_unlock_irq()，所以
Documentation/translations/zh_CN/scheduler/completion.rst:默认行为是不带超时的等待，并将任务标记为“UNINTERRUPTIBLE”状态。wait_for_completion()
Documentation/translations/zh_CN/scheduler/completion.rst:try_wait_for_completion()。
Documentation/translations/zh_CN/scheduler/completion.rst:由于wait_for_completion()的所有变体都可能（很明显）阻塞很长时间，这取决于它们所等
Documentation/translations/zh_CN/scheduler/completion.rst:wait_for_completion*()可用的变体:
Documentation/translations/zh_CN/scheduler/completion.rst:	if (!wait_for_completion_interruptible_timeout(...))
Documentation/translations/zh_CN/scheduler/completion.rst:	int wait_for_completion_interruptible(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:	unsigned long wait_for_completion_timeout(struct completion *done, unsigned long timeout)
Documentation/translations/zh_CN/scheduler/completion.rst:	long wait_for_completion_interruptible_timeout(struct completion *done, unsigned long timeout)
Documentation/translations/zh_CN/scheduler/completion.rst:	long wait_for_completion_killable(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:	long wait_for_completion_killable_timeout(struct completion *done, unsigned long timeout)
Documentation/translations/zh_CN/scheduler/completion.rst:wait_for_completion_io()的_io变体的行为与非_io变体相同，只是将等待时间计为“IO等待”，
Documentation/translations/zh_CN/scheduler/completion.rst:	void wait_for_completion_io(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:	unsigned long wait_for_completion_io_timeout(struct completion *done, unsigned long timeout)
Documentation/translations/zh_CN/scheduler/completion.rst:	void complete(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:	void complete_all(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:“consuming”（递减）“struct completion” 的完成字段来实现的。等待的线程唤醒的顺序
Documentation/translations/zh_CN/scheduler/completion.rst:在任何时候，只能有一个线程在一个特定的 “struct completion”上调用 complete() 或
Documentation/translations/zh_CN/scheduler/completion.rst:try_wait_for_completion()/completion_done():
Documentation/translations/zh_CN/scheduler/completion.rst:try_wait_for_completion()函数不会将线程放在等待队列中，而是在需要排队（阻塞）线
Documentation/translations/zh_CN/scheduler/completion.rst:	bool try_wait_for_completion(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:最后，为了在不以任何方式改变完成的情况下检查完成的状态，可以调用completion_done()，
Documentation/translations/zh_CN/scheduler/completion.rst:	bool completion_done(struct completion *done)
Documentation/translations/zh_CN/scheduler/completion.rst:try_wait_for_completion()和completion_done()都可以在IRQ或原子上下文中安全调用。
Documentation/translations/zh_CN/scheduler/index.rst:    completion
Documentation/usb/dwc3.rst:  - dwc3_send_gadget_ep_cmd() will sleep in wait_for_completion_timeout()
Documentation/usb/dwc3.rst:      for command completion.
Documentation/usb/ehci.rst:to receive interrupts from the EHCI controller indicating completion
Documentation/usb/ehci.rst:I/O completion and the driver issuing the next request will take longer
Documentation/usb/raw-gadget.rst:until its completion. This is done deliberately to assist with coverage-guided
Documentation/usb/raw-gadget.rst:  Raw Gadget would not wait until the completion of each USB request.
Documentation/usb/usbmon.rst:  completion where the received data is sparse in the buffer, the length of
Documentation/userspace-api/ioctl/hdio.rst:	  written back into in_flags on completion.
Documentation/userspace-api/ioctl/hdio.rst:	  effect other than modifying in_flags on completion.
Documentation/userspace-api/iommufd.rst:   completion of this operation establishes the desired DMA ownership over the
Documentation/userspace-api/iommufd.rst:   new pagetable object and iommu_domain is created. Successful completion of
Documentation/userspace-api/media/mediactl/request-api.rst:of request completion are also available for reading.
Documentation/userspace-api/media/mediactl/request-api.rst:associated controls have been updated with the values at the time of completion.
Documentation/userspace-api/media/mediactl/request-api.rst:request file descriptor, query control values at the time of its completion via
Documentation/userspace-api/media/mediactl/request-api.rst:User-space can then dequeue buffers, wait for the request completion, query
Documentation/userspace-api/media/v4l/dev-decoder.rst:   completion, as described by the steps above, unless it aborts the process by
Documentation/userspace-api/media/v4l/dev-encoder.rst:   completion, as described by the steps above, unless it aborts the process by
Documentation/userspace-api/media/v4l/dmabuf.rst:buffer at any time between the completion of the DMA and this ioctl. The
Documentation/userspace-api/media/v4l/userp.rst:memory pages at any time between the completion of the DMA and this
Documentation/userspace-api/media/v4l/vidioc-decoder-cmd.rst:	to completion before this command can be invoked.  Any attempt to
Documentation/userspace-api/media/v4l/vidioc-encoder-cmd.rst:	to completion before this command can be invoked.  Any attempt to
Documentation/userspace-api/media/v4l/vidioc-g-ext-ctrls.rst:values of the controls at the time of request completion.
Documentation/virt/acrn/io-request.rst:   of the completion via hypercalls.
Documentation/virt/hyperv/vpci.rst:VMBus message, and then poll for the completion message. As
Documentation/virt/kvm/api.rst:where KVM queues elapsed i8254 ticks and monitors completion of interrupt from
Documentation/virt/kvm/api.rst::Returns: 0 on successful completion,
Documentation/virt/kvm/api.rst::Returns: 0 on successful completion,
Documentation/virt/kvm/api.rst:On successful completion, the pending HPT will become the guest's active
Documentation/virt/kvm/api.rst::Returns: 0 on successful completion,
Documentation/virt/kvm/api.rst::Returns: 0 on successful completion,
Documentation/virt/kvm/api.rst:    On success `conf_dump_finalize_len` bytes of completion data will be
Documentation/virt/kvm/api.rst:    stored to the `buff_addr`. The completion data contains a key
Documentation/virt/kvm/devices/s390_flic.rst:    async page faults are done. This is necessary to trigger a completion interrupt
Documentation/virt/kvm/s390/s390-diag.rst:Upon completion of the DIAGNOSE instruction, general register 2 contains
Documentation/virt/kvm/s390/s390-diag.rst:    After completion of the DIAGNOSE call, general register 2 may contain
Documentation/virt/kvm/s390/s390-pv.rst:make the guest pending for instruction completion of the intercepted
Documentation/virt/kvm/s390/s390-pv.rst:be a program exception or instruction completion.
Documentation/virt/kvm/x86/amd-memory-encryption.rst:After completion of the launch flow, the KVM_SEV_LAUNCH_FINISH command can be
Documentation/virt/kvm/x86/amd-memory-encryption.rst:After completion of the migration flow, the KVM_SEV_SEND_FINISH command can be
Documentation/virt/kvm/x86/amd-memory-encryption.rst:After completion of SEND_START, but before SEND_FINISH, the source VMM can issue the
Documentation/virt/kvm/x86/amd-memory-encryption.rst:After completion of the migration flow, the KVM_SEV_RECEIVE_FINISH command can be
Documentation/virt/kvm/x86/amd-memory-encryption.rst:After completion of the SNP guest launch flow, the KVM_SEV_SNP_LAUNCH_FINISH
Documentation/w1/masters/ds2490.rst:  show a successful completion, but the ds2490 status register would
Documentation/w1/slaves/w1_therm.rst:completion. Options 2, 3 can't be used in parasite power mode. To get back to
Documentation/w1/slaves/w1_therm.rst:conversion completion (normal power only) by generating read cycles on the bus
Documentation/w1/w1-netlink.rst:If command requires reply (like read command) it is sent on command completion.
drivers/accel/habanalabs/common/command_submission.c:static void job_wq_completion(struct work_struct *work);
drivers/accel/habanalabs/common/command_submission.c:	init_completion(&fence->completion);
drivers/accel/habanalabs/common/command_submission.c:bool cs_needs_completion(struct hl_cs *cs)
drivers/accel/habanalabs/common/command_submission.c:	 * get a completion, any non staged CS will always get a completion
drivers/accel/habanalabs/common/command_submission.c:	parser.completion = cs_needs_completion(job->cs);
drivers/accel/habanalabs/common/command_submission.c:	/* We decrement reference only for a CS that gets completion
drivers/accel/habanalabs/common/command_submission.c:	 * gets completion, hence its release function will be called from here.
drivers/accel/habanalabs/common/command_submission.c:	 * completion, their CS reference will be decremented by the
drivers/accel/habanalabs/common/command_submission.c:	if (cs_needs_completion(cs) &&
drivers/accel/habanalabs/common/command_submission.c:		/* In CS based completions, the timestamp is already available,
drivers/accel/habanalabs/common/command_submission.c:		if (hdev->asic_prop.completion_mode == HL_COMPLETION_MODE_JOB)
drivers/accel/habanalabs/common/command_submission.c:			cs->completion_timestamp = job->timestamp;
drivers/accel/habanalabs/common/command_submission.c: * the CS which get completion.
drivers/accel/habanalabs/common/command_submission.c:	/* Only the last CS in this staged submission will get a completion.
drivers/accel/habanalabs/common/command_submission.c:	 * Once we get a completion we will release the whole staged submission.
drivers/accel/habanalabs/common/command_submission.c: * This function decrements a CS reference (for a non completion CS)
drivers/accel/habanalabs/common/command_submission.c:	if (!cs_needs_completion(cs))
drivers/accel/habanalabs/common/command_submission.c:		struct multi_cs_completion *mcs_compl;
drivers/accel/habanalabs/common/command_submission.c:		mcs_compl = &hdev->multi_cs_completion[i];
drivers/accel/habanalabs/common/command_submission.c:				"multi-CS completion context %d still waiting when calling force completion\n",
drivers/accel/habanalabs/common/command_submission.c:		complete_all(&mcs_compl->completion);
drivers/accel/habanalabs/common/command_submission.c: * - a completed CS worked on stream master QID 4, multi CS completion
drivers/accel/habanalabs/common/command_submission.c: * - a completed CS worked on stream master QID 4, multi CS completion
drivers/accel/habanalabs/common/command_submission.c:	/* in case of multi CS check for completion only for the first CS */
drivers/accel/habanalabs/common/command_submission.c:		struct multi_cs_completion *mcs_compl;
drivers/accel/habanalabs/common/command_submission.c:		mcs_compl = &hdev->multi_cs_completion[i];
drivers/accel/habanalabs/common/command_submission.c:		 * 1. still waiting for completion
drivers/accel/habanalabs/common/command_submission.c:		 *    master with the stream masters in the completion
drivers/accel/habanalabs/common/command_submission.c:			complete_all(&mcs_compl->completion);
drivers/accel/habanalabs/common/command_submission.c:	/* In case CS completed without mcs completion initialized */
drivers/accel/habanalabs/common/command_submission.c:	/* Need to update CI for all queue jobs that does not get completion */
drivers/accel/habanalabs/common/command_submission.c:		/* the completion CS decrements reference for the entire
drivers/accel/habanalabs/common/command_submission.c:		cs->fence->timestamp = cs->completion_timestamp;
drivers/accel/habanalabs/common/command_submission.c:	complete_all(&cs->fence->completion);
drivers/accel/habanalabs/common/command_submission.c:	if (other && !completion_done(&other->completion)) {
drivers/accel/habanalabs/common/command_submission.c:		 * completed as it depends on future CS's for completion.
drivers/accel/habanalabs/common/command_submission.c:		/* flush all completions before iterating over the CS mirror list in
drivers/accel/habanalabs/common/command_submission.c:		for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/common/command_submission.c:		complete_all(&pend->fence.completion);
drivers/accel/habanalabs/common/command_submission.c:	 * user threads waiting for interrupt completion. We iterate the
drivers/accel/habanalabs/common/command_submission.c:		complete_all(&cs->fence->completion);
drivers/accel/habanalabs/common/command_submission.c:void hl_abort_waiting_for_cs_completions(struct hl_device *hdev)
drivers/accel/habanalabs/common/command_submission.c:static void job_wq_completion(struct work_struct *work)
drivers/accel/habanalabs/common/command_submission.c:static void cs_completion(struct work_struct *work)
drivers/accel/habanalabs/common/command_submission.c:		INIT_WORK(&job->finish_work, job_wq_completion);
drivers/accel/habanalabs/common/command_submission.c:		 * only for those JOBs we get completion
drivers/accel/habanalabs/common/command_submission.c:		if (cs_needs_completion(cs) &&
drivers/accel/habanalabs/common/command_submission.c:	 * not get a completion
drivers/accel/habanalabs/common/command_submission.c:	if (int_queues_only && cs_needs_completion(cs)) {
drivers/accel/habanalabs/common/command_submission.c:			"Reject CS %d.%llu since it contains only internal queues jobs and needs completion\n",
drivers/accel/habanalabs/common/command_submission.c:		INIT_WORK(&cs->finish_work, cs_completion);
drivers/accel/habanalabs/common/command_submission.c:	 * fence object for multi-CS completion
drivers/accel/habanalabs/common/command_submission.c:		/* Need to wait for restore completion before execution phase */
drivers/accel/habanalabs/common/command_submission.c:	/* increment refcount as for external queues we get completion */
drivers/accel/habanalabs/common/command_submission.c:		if (completion_done(&sig_fence->completion)) {
drivers/accel/habanalabs/common/command_submission.c:		INIT_WORK(&cs->finish_work, cs_completion);
drivers/accel/habanalabs/common/command_submission.c:	long completion_rc;
drivers/accel/habanalabs/common/command_submission.c:		completion_rc = 1;
drivers/accel/habanalabs/common/command_submission.c:		completion_rc = completion_done(&fence->completion);
drivers/accel/habanalabs/common/command_submission.c:		completion_rc =
drivers/accel/habanalabs/common/command_submission.c:			wait_for_completion_interruptible_timeout(
drivers/accel/habanalabs/common/command_submission.c:				&fence->completion, timeout);
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc > 0) {
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc == -ERESTARTSYS)
drivers/accel/habanalabs/common/command_submission.c:		rc = completion_rc;
drivers/accel/habanalabs/common/command_submission.c: * hl_cs_poll_fences - iterate CS fences to check for CS completion
drivers/accel/habanalabs/common/command_submission.c: * @mcs_compl: multi-CS completion structure
drivers/accel/habanalabs/common/command_submission.c: * completion_bitmap for each completed CS.
drivers/accel/habanalabs/common/command_submission.c: * array in the completion QID stream map to be used by CSs to perform
drivers/accel/habanalabs/common/command_submission.c: * completion to the multi-CS context.
drivers/accel/habanalabs/common/command_submission.c:static int hl_cs_poll_fences(struct multi_cs_data *mcs_data, struct multi_cs_completion *mcs_compl)
drivers/accel/habanalabs/common/command_submission.c:	 * re-initialize the completion here to handle 2 possible cases:
drivers/accel/habanalabs/common/command_submission.c:	 * 1. CS will complete the multi-CS prior clearing the completion. in which
drivers/accel/habanalabs/common/command_submission.c:	 *    case the fence iteration is guaranteed to catch the CS completion.
drivers/accel/habanalabs/common/command_submission.c:	 * 2. the completion will occur after re-init of the completion.
drivers/accel/habanalabs/common/command_submission.c:	 *    in which case we will wake up immediately in wait_for_completion.
drivers/accel/habanalabs/common/command_submission.c:	reinit_completion(&mcs_compl->completion);
drivers/accel/habanalabs/common/command_submission.c:		 * 1. for each fence set it's QID map in the multi-CS completion QID map. This way
drivers/accel/habanalabs/common/command_submission.c:		 *    that once completion is initialized, calling complete* and then wait on the
drivers/accel/habanalabs/common/command_submission.c:		 *    completion will cause it to return at once)
drivers/accel/habanalabs/common/command_submission.c:		 * 2. only after allowing multi-CS completion for the specific QID we check whether
drivers/accel/habanalabs/common/command_submission.c:		 *    the specific CS already completed (and thus the wait for completion part will
drivers/accel/habanalabs/common/command_submission.c:		 *    wake up the completion.
drivers/accel/habanalabs/common/command_submission.c:				complete_all(&mcs_compl->completion);
drivers/accel/habanalabs/common/command_submission.c:			mcs_data->completion_bitmap |= BIT(i);
drivers/accel/habanalabs/common/command_submission.c:			 * no need to consider its QID for mcs completion.
drivers/accel/habanalabs/common/command_submission.c:			mcs_data->completion_bitmap |= BIT(i);
drivers/accel/habanalabs/common/command_submission.c: * hl_wait_multi_cs_completion_init - init completion structure
drivers/accel/habanalabs/common/command_submission.c: * @return valid completion struct pointer on success, otherwise error pointer
drivers/accel/habanalabs/common/command_submission.c: * the function gets the first available completion (by marking it "used")
drivers/accel/habanalabs/common/command_submission.c:static struct multi_cs_completion *hl_wait_multi_cs_completion_init(struct hl_device *hdev)
drivers/accel/habanalabs/common/command_submission.c:	struct multi_cs_completion *mcs_compl;
drivers/accel/habanalabs/common/command_submission.c:	/* find free multi_cs completion structure */
drivers/accel/habanalabs/common/command_submission.c:		mcs_compl = &hdev->multi_cs_completion[i];
drivers/accel/habanalabs/common/command_submission.c:			 * init QID map to 0 to avoid completion by CSs. the actual QID map
drivers/accel/habanalabs/common/command_submission.c:		dev_err(hdev->dev, "no available multi-CS completion structure\n");
drivers/accel/habanalabs/common/command_submission.c: * hl_wait_multi_cs_completion_fini - return completion structure and set as
drivers/accel/habanalabs/common/command_submission.c: * @mcs_compl: pointer to the completion structure
drivers/accel/habanalabs/common/command_submission.c:static void hl_wait_multi_cs_completion_fini(
drivers/accel/habanalabs/common/command_submission.c:					struct multi_cs_completion *mcs_compl)
drivers/accel/habanalabs/common/command_submission.c:	 * free completion structure, do it under lock to be in-sync with the
drivers/accel/habanalabs/common/command_submission.c:	 * thread that signals completion
drivers/accel/habanalabs/common/command_submission.c: * hl_wait_multi_cs_completion - wait for first CS to complete
drivers/accel/habanalabs/common/command_submission.c:static int hl_wait_multi_cs_completion(struct multi_cs_data *mcs_data,
drivers/accel/habanalabs/common/command_submission.c:						struct multi_cs_completion *mcs_compl)
drivers/accel/habanalabs/common/command_submission.c:	long completion_rc;
drivers/accel/habanalabs/common/command_submission.c:	completion_rc = wait_for_completion_interruptible_timeout(&mcs_compl->completion,
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc > 0)
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc == -ERESTARTSYS)
drivers/accel/habanalabs/common/command_submission.c:		return completion_rc;
drivers/accel/habanalabs/common/command_submission.c:	mcs_data->wait_status = completion_rc;
drivers/accel/habanalabs/common/command_submission.c: * hl_multi_cs_completion_init - init array of multi-CS completion structures
drivers/accel/habanalabs/common/command_submission.c:void hl_multi_cs_completion_init(struct hl_device *hdev)
drivers/accel/habanalabs/common/command_submission.c:	struct multi_cs_completion *mcs_cmpl;
drivers/accel/habanalabs/common/command_submission.c:		mcs_cmpl = &hdev->multi_cs_completion[i];
drivers/accel/habanalabs/common/command_submission.c:		init_completion(&mcs_cmpl->completion);
drivers/accel/habanalabs/common/command_submission.c:	struct multi_cs_completion *mcs_compl;
drivers/accel/habanalabs/common/command_submission.c:	mcs_compl = hl_wait_multi_cs_completion_init(hdev);
drivers/accel/habanalabs/common/command_submission.c:	 * skip wait for CS completion when one of the below is true:
drivers/accel/habanalabs/common/command_submission.c:	if (rc || mcs_data.completion_bitmap || !args->in.timeout_us)
drivers/accel/habanalabs/common/command_submission.c:		goto completion_fini;
drivers/accel/habanalabs/common/command_submission.c:		rc = hl_wait_multi_cs_completion(&mcs_data, mcs_compl);
drivers/accel/habanalabs/common/command_submission.c:		if (rc || mcs_data.completion_bitmap)
drivers/accel/habanalabs/common/command_submission.c:		 * if hl_wait_multi_cs_completion returned before timeout (i.e.
drivers/accel/habanalabs/common/command_submission.c:		 * it got a completion) it either got completed by CS in the multi CS list
drivers/accel/habanalabs/common/command_submission.c:		 * (in which case the indication will be non empty completion_bitmap) or it
drivers/accel/habanalabs/common/command_submission.c:completion_fini:
drivers/accel/habanalabs/common/command_submission.c:	hl_wait_multi_cs_completion_fini(mcs_compl);
drivers/accel/habanalabs/common/command_submission.c:	if (mcs_data.completion_bitmap) {
drivers/accel/habanalabs/common/command_submission.c:		args->out.cs_completion_map = mcs_data.completion_bitmap;
drivers/accel/habanalabs/common/command_submission.c:	/* We check for completion value as interrupt could have been received
drivers/accel/habanalabs/common/command_submission.c:	long completion_rc;
drivers/accel/habanalabs/common/command_submission.c:	/* We check for completion value as interrupt could have been received
drivers/accel/habanalabs/common/command_submission.c:	/* Wait for interrupt handler to signal completion */
drivers/accel/habanalabs/common/command_submission.c:	completion_rc = wait_for_completion_interruptible_timeout(&pend->fence.completion,
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc > 0) {
drivers/accel/habanalabs/common/command_submission.c:		if (completion_rc == -ERESTARTSYS) {
drivers/accel/habanalabs/common/command_submission.c:	 * for completion timeout case. and if it's a registration
drivers/accel/habanalabs/common/command_submission.c:	u64 completion_value;
drivers/accel/habanalabs/common/command_submission.c:	long completion_rc;
drivers/accel/habanalabs/common/command_submission.c:	/* We check for completion value as interrupt could have been received
drivers/accel/habanalabs/common/command_submission.c:	if (copy_from_user(&completion_value, u64_to_user_ptr(user_address), 8)) {
drivers/accel/habanalabs/common/command_submission.c:		dev_err(hdev->dev, "Failed to copy completion value from user\n");
drivers/accel/habanalabs/common/command_submission.c:	if (completion_value >= target_value) {
drivers/accel/habanalabs/common/command_submission.c:		/* There was no interrupt, we assume the completion is now. */
drivers/accel/habanalabs/common/command_submission.c:	/* Wait for interrupt handler to signal completion */
drivers/accel/habanalabs/common/command_submission.c:	completion_rc = wait_for_completion_interruptible_timeout(&pend->fence.completion,
drivers/accel/habanalabs/common/command_submission.c:	if (completion_rc > 0) {
drivers/accel/habanalabs/common/command_submission.c:		/* reinit_completion must be called before we check for user
drivers/accel/habanalabs/common/command_submission.c:		 * completion value, otherwise, if interrupt is received after
drivers/accel/habanalabs/common/command_submission.c:		 * the comparison and before the next wait_for_completion,
drivers/accel/habanalabs/common/command_submission.c:		reinit_completion(&pend->fence.completion);
drivers/accel/habanalabs/common/command_submission.c:		if (copy_from_user(&completion_value, u64_to_user_ptr(user_address), 8)) {
drivers/accel/habanalabs/common/command_submission.c:			dev_err(hdev->dev, "Failed to copy completion value from user\n");
drivers/accel/habanalabs/common/command_submission.c:		if (completion_value >= target_value) {
drivers/accel/habanalabs/common/command_submission.c:			/* set the command completion status as ABORTED */
drivers/accel/habanalabs/common/command_submission.c:			timeout = completion_rc;
drivers/accel/habanalabs/common/command_submission.c:	} else if (completion_rc == -ERESTARTSYS) {
drivers/accel/habanalabs/common/device.c:	if (hdev->asic_prop.completion_queues_count) {
drivers/accel/habanalabs/common/device.c:		hdev->cq_wq = kcalloc(hdev->asic_prop.completion_queues_count,
drivers/accel/habanalabs/common/device.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++) {
drivers/accel/habanalabs/common/device.c:	snprintf(workq_name, 32, "hl%u-cs-completions", hdev->cdev_idx);
drivers/accel/habanalabs/common/device.c:			"Failed to allocate CS completions workqueue\n");
drivers/accel/habanalabs/common/device.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/common/device.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/common/device.c:static void hl_abort_waiting_for_completions(struct hl_device *hdev)
drivers/accel/habanalabs/common/device.c:	hl_abort_waiting_for_cs_completions(hdev);
drivers/accel/habanalabs/common/device.c:	 * completions from H/W and we won't have any accesses from the
drivers/accel/habanalabs/common/device.c:	hl_abort_waiting_for_completions(hdev);
drivers/accel/habanalabs/common/device.c:	/* Block future CS/VM/JOB completion operations */
drivers/accel/habanalabs/common/device.c: * Flush all completions
drivers/accel/habanalabs/common/device.c:		/* Block future CS/VM/JOB completion operations */
drivers/accel/habanalabs/common/device.c:		/* This still allows the completion of some KDMA ops
drivers/accel/habanalabs/common/device.c:		/* This also blocks future CS/VM/JOB completion operations */
drivers/accel/habanalabs/common/device.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/common/device.c:		hl_cq_reset(hdev, &hdev->completion_queue[i]);
drivers/accel/habanalabs/common/device.c:	hl_abort_waiting_for_completions(hdev);
drivers/accel/habanalabs/common/device.c:	/* initialize completion structure for multi CS wait */
drivers/accel/habanalabs/common/device.c:	hl_multi_cs_completion_init(hdev);
drivers/accel/habanalabs/common/device.c:	cq_cnt = hdev->asic_prop.completion_queues_count;
drivers/accel/habanalabs/common/device.c:	 * Initialize the completion queues. Must be done before hw_init,
drivers/accel/habanalabs/common/device.c:	 * because there the addresses of the completion queues are being
drivers/accel/habanalabs/common/device.c:		hdev->completion_queue = kcalloc(cq_cnt,
drivers/accel/habanalabs/common/device.c:				sizeof(*hdev->completion_queue),
drivers/accel/habanalabs/common/device.c:		if (!hdev->completion_queue) {
drivers/accel/habanalabs/common/device.c:				"failed to allocate completion queues\n");
drivers/accel/habanalabs/common/device.c:		rc = hl_cq_init(hdev, &hdev->completion_queue[i],
drivers/accel/habanalabs/common/device.c:				"failed to initialize completion queue\n");
drivers/accel/habanalabs/common/device.c:		hdev->completion_queue[i].cq_idx = i;
drivers/accel/habanalabs/common/device.c:		hl_cq_fini(hdev, &hdev->completion_queue[i]);
drivers/accel/habanalabs/common/device.c:	kfree(hdev->completion_queue);
drivers/accel/habanalabs/common/device.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/common/device.c:		hl_cq_fini(hdev, &hdev->completion_queue[i]);
drivers/accel/habanalabs/common/device.c:	kfree(hdev->completion_queue);
drivers/accel/habanalabs/common/habanalabs.h:/* Completion queue entry relates to completed job */
drivers/accel/habanalabs/common/habanalabs.h:#define HL_COMPLETION_MODE_JOB		0
drivers/accel/habanalabs/common/habanalabs.h:/* Completion queue entry relates to completed command submission */
drivers/accel/habanalabs/common/habanalabs.h:#define HL_COMPLETION_MODE_CS		1
drivers/accel/habanalabs/common/habanalabs.h: * @QUEUE_TYPE_HW: queue of DMA and compute engines jobs, for which completion
drivers/accel/habanalabs/common/habanalabs.h: * @completion_queues_count: number of completion queues.
drivers/accel/habanalabs/common/habanalabs.h: * @completion_mode: 0 - job based completion, 1 - cs based completion
drivers/accel/habanalabs/common/habanalabs.h:	u8				completion_queues_count;
drivers/accel/habanalabs/common/habanalabs.h:	u8				completion_mode;
drivers/accel/habanalabs/common/habanalabs.h: * @completion: fence is implemented using completion
drivers/accel/habanalabs/common/habanalabs.h: * @timestamp: timestamp upon completion
drivers/accel/habanalabs/common/habanalabs.h:	struct completion	completion;
drivers/accel/habanalabs/common/habanalabs.h: * struct hl_cs_compl - command submission completion object.
drivers/accel/habanalabs/common/habanalabs.h: * @encaps_signals: indication whether it's a completion object of cs with
drivers/accel/habanalabs/common/habanalabs.h: *                     to signal its collective master queue upon completion.
drivers/accel/habanalabs/common/habanalabs.h: * struct hl_cq - describes a completion queue
drivers/accel/habanalabs/common/habanalabs.h: * @cq_idx: completion queue index in array
drivers/accel/habanalabs/common/habanalabs.h: * @fence: hl fence object for interrupt completion
drivers/accel/habanalabs/common/habanalabs.h: * @ts: completion ts
drivers/accel/habanalabs/common/habanalabs.h: * @completion_timestamp: timestamp of the last completed cs job.
drivers/accel/habanalabs/common/habanalabs.h: * @timestamp: true if a timestamp must be captured upon completion.
drivers/accel/habanalabs/common/habanalabs.h: * @staged_last: true if this is the last staged CS and needs completion.
drivers/accel/habanalabs/common/habanalabs.h:	ktime_t			completion_timestamp;
drivers/accel/habanalabs/common/habanalabs.h: *			wait for completion.
drivers/accel/habanalabs/common/habanalabs.h: * @timestamp: timestamp upon job completion
drivers/accel/habanalabs/common/habanalabs.h: *			job and wait for completion.
drivers/accel/habanalabs/common/habanalabs.h: * @completion: true if we need completion for this CS.
drivers/accel/habanalabs/common/habanalabs.h:	u8			completion;
drivers/accel/habanalabs/common/habanalabs.h: * struct multi_cs_completion - multi CS wait completion.
drivers/accel/habanalabs/common/habanalabs.h: * @completion: completion of any of the CS in the list
drivers/accel/habanalabs/common/habanalabs.h: * @lock: spinlock for the completion structure
drivers/accel/habanalabs/common/habanalabs.h: * @timestamp: timestamp for the multi-CS completion
drivers/accel/habanalabs/common/habanalabs.h:struct multi_cs_completion {
drivers/accel/habanalabs/common/habanalabs.h:	struct completion	completion;
drivers/accel/habanalabs/common/habanalabs.h: * @completion_bitmap: bitmap of completed CSs (1- completed, otherwise 0)
drivers/accel/habanalabs/common/habanalabs.h:	u32		completion_bitmap;
drivers/accel/habanalabs/common/habanalabs.h: * @completion_queue: array of hl_cq.
drivers/accel/habanalabs/common/habanalabs.h: * @cq_wq: work queues of completion queues for executing work in process
drivers/accel/habanalabs/common/habanalabs.h: * @cs_cmplt_wq: work queue of CS completions for executing work in process
drivers/accel/habanalabs/common/habanalabs.h: * @multi_cs_completion: array of multi-CS completion.
drivers/accel/habanalabs/common/habanalabs.h:	struct hl_cq			*completion_queue;
drivers/accel/habanalabs/common/habanalabs.h:	struct multi_cs_completion	multi_cs_completion[
drivers/accel/habanalabs/common/habanalabs.h:bool cs_needs_completion(struct hl_cs *cs);
drivers/accel/habanalabs/common/habanalabs.h:void hl_multi_cs_completion_init(struct hl_device *hdev);
drivers/accel/habanalabs/common/habanalabs.h:void hl_abort_waiting_for_cs_completions(struct hl_device *hdev);
drivers/accel/habanalabs/common/hw_queue.c:	 * completion, there are 2 scenarios this can happen:
drivers/accel/habanalabs/common/hw_queue.c:	 * 1. All queues of a non completion CS will never get a completion.
drivers/accel/habanalabs/common/hw_queue.c:	 * 2. Internal queues never gets completion.
drivers/accel/habanalabs/common/hw_queue.c:		if (!cs_needs_completion(cs) || q->queue_type == QUEUE_TYPE_INT)
drivers/accel/habanalabs/common/hw_queue.c: * - Make sure we have enough space in the completion queue
drivers/accel/habanalabs/common/hw_queue.c: * - Reserve space in the completion queue (needs to be reversed if there
drivers/accel/habanalabs/common/hw_queue.c:			&hdev->completion_queue[q->cq_id].free_slots_cnt;
drivers/accel/habanalabs/common/hw_queue.c:		 * Check we have enough space in the completion queue
drivers/accel/habanalabs/common/hw_queue.c:		 * we won't get ack on its completion
drivers/accel/habanalabs/common/hw_queue.c: * hl_hw_queue_send_cb_no_cmpl - send a single CB (not a JOB) without completion
drivers/accel/habanalabs/common/hw_queue.c: * This function sends a single CB, that must NOT generate a completion entry.
drivers/accel/habanalabs/common/hw_queue.c:	 * to write in the completion queue
drivers/accel/habanalabs/common/hw_queue.c:	/* Skip completion flow in case this is a non completion CS */
drivers/accel/habanalabs/common/hw_queue.c:	if (!cs_needs_completion(job->cs))
drivers/accel/habanalabs/common/hw_queue.c:	cq = &hdev->completion_queue[q->cq_id];
drivers/accel/habanalabs/common/hw_queue.c:	 * Upon PQE completion, COMP_DATA is used as the write data to the
drivers/accel/habanalabs/common/hw_queue.c:	 * completion queue (QMAN HBW message), and COMP_OFFSET is used as the
drivers/accel/habanalabs/common/hw_queue.c:	 * hw queue lock and completion object lock,
drivers/accel/habanalabs/common/hw_queue.c:	 * and the same completion object lock also protects
drivers/accel/habanalabs/common/hw_queue.c:	if (completion_done(&cs->signal_fence->completion)) {
drivers/accel/habanalabs/common/hw_queue.c:		/* set hw_sob pointer in completion object
drivers/accel/habanalabs/common/hw_queue.c:						cs_needs_completion(cs) ?
drivers/accel/habanalabs/common/hw_queue.c:				&hdev->completion_queue[i].free_slots_cnt;
drivers/accel/habanalabs/common/hw_queue.c:	 * Completion. Thus, we don't need to release it again.
drivers/accel/habanalabs/common/irq.c: * @ptr: the current ci or pi value of the completion queue
drivers/accel/habanalabs/common/irq.c: * Increment ptr by 1. If it reaches the number of completion queue
drivers/accel/habanalabs/common/irq.c: * @cq: completion queue
drivers/accel/habanalabs/common/irq.c:	cs->completion_timestamp = timestamp;
drivers/accel/habanalabs/common/irq.c: * hl_irq_handler_cq - irq handler for completion queue
drivers/accel/habanalabs/common/irq.c: * @arg: pointer to completion queue structure
drivers/accel/habanalabs/common/irq.c:		 * 1. Interrupt per CS completion: (Single CQ for all queues)
drivers/accel/habanalabs/common/irq.c:		 * 2. Interrupt per CS job completion in queue: (CQ per queue)
drivers/accel/habanalabs/common/irq.c:			if (hdev->asic_prop.completion_mode ==
drivers/accel/habanalabs/common/irq.c:					HL_COMPLETION_MODE_CS)
drivers/accel/habanalabs/common/irq.c:			complete_all(&pend->fence.completion);
drivers/accel/habanalabs/common/irq.c: * @hw_queue_id: The H/W queue ID this completion queue belongs to
drivers/accel/habanalabs/common/irq.c: * Allocate dma-able memory for the completion queue and initialize fields
drivers/accel/habanalabs/common/irq.c: * hl_cq_fini - destroy completion queue
drivers/accel/habanalabs/common/irq.c: * Free the completion queue memory
drivers/accel/habanalabs/common/irq.c:	 * written valid completion entries before it was halted and therefore
drivers/accel/habanalabs/common/irq.c:	 * written valid completion entries before it was halted and therefore
drivers/accel/habanalabs/gaudi/gaudi.c:	prop->completion_queues_count = NUMBER_OF_CMPLT_QUEUES;
drivers/accel/habanalabs/gaudi/gaudi.c:	prop->completion_mode = HL_COMPLETION_MODE_JOB;
drivers/accel/habanalabs/gaudi/gaudi.c:		 * for the completion check before start going over the jobs
drivers/accel/habanalabs/gaudi/gaudi.c:	 * hw queue lock and completion object lock,
drivers/accel/habanalabs/gaudi/gaudi.c:	 * and the same completion object lock also protects
drivers/accel/habanalabs/gaudi/gaudi.c:	if (completion_done(&cs->signal_fence->completion)) {
drivers/accel/habanalabs/gaudi/gaudi.c:		 * 2 msg prot packets for completion and MSI
drivers/accel/habanalabs/gaudi/gaudi.c:	/* increment refcount as for external queues we get completion */
drivers/accel/habanalabs/gaudi/gaudi.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/gaudi/gaudi.c:		hl_irq_handler_cq(irq, &hdev->completion_queue[i]);
drivers/accel/habanalabs/gaudi/gaudi.c:	/* STOP_ON bit implies no completion to operation in case of RAZWI */
drivers/accel/habanalabs/gaudi/gaudi.c:	 * 2. A packet that will act as a completion packet
drivers/accel/habanalabs/gaudi/gaudi.c:	if (parser->completion)
drivers/accel/habanalabs/gaudi/gaudi.c:	 * 2. A packet that will act as a completion packet
drivers/accel/habanalabs/gaudi/gaudi.c:	if (parser->completion)
drivers/accel/habanalabs/gaudi2/gaudi2.c:	prop->completion_queues_count = GAUDI2_RESERVED_CQ_NUMBER;
drivers/accel/habanalabs/gaudi2/gaudi2.c:	prop->completion_mode = HL_COMPLETION_MODE_CS;
drivers/accel/habanalabs/gaudi2/gaudi2.c:	case GAUDI2_IRQ_NUM_COMPLETION:
drivers/accel/habanalabs/gaudi2/gaudi2.c:		return "gaudi2 completion";
drivers/accel/habanalabs/gaudi2/gaudi2.c:		return "gaudi2 user completion";
drivers/accel/habanalabs/gaudi2/gaudi2.c:	irq = pci_irq_vector(hdev->pdev, GAUDI2_IRQ_NUM_COMPLETION);
drivers/accel/habanalabs/gaudi2/gaudi2.c:	cq = &hdev->completion_queue[GAUDI2_RESERVED_CQ_CS_COMPLETION];
drivers/accel/habanalabs/gaudi2/gaudi2.c:	rc = request_irq(irq, hl_irq_handler_cq, 0, gaudi2_irq_name(GAUDI2_IRQ_NUM_COMPLETION), cq);
drivers/accel/habanalabs/gaudi2/gaudi2.c:		goto free_completion_irq;
drivers/accel/habanalabs/gaudi2/gaudi2.c:free_completion_irq:
drivers/accel/habanalabs/gaudi2/gaudi2.c:	irq = pci_irq_vector(hdev->pdev, GAUDI2_IRQ_NUM_COMPLETION);
drivers/accel/habanalabs/gaudi2/gaudi2.c:	synchronize_irq(pci_irq_vector(hdev->pdev, GAUDI2_IRQ_NUM_COMPLETION));
drivers/accel/habanalabs/gaudi2/gaudi2.c:	irq = pci_irq_vector(hdev->pdev, GAUDI2_IRQ_NUM_COMPLETION);
drivers/accel/habanalabs/gaudi2/gaudi2.c:	cq = &hdev->completion_queue[GAUDI2_RESERVED_CQ_CS_COMPLETION];
drivers/accel/habanalabs/gaudi2/gaudi2.c:	/* Enable QMAN H/W completion */
drivers/accel/habanalabs/gaudi2/gaudi2.c:		hdev->kernel_queues[queue_id_base + pq_id].cq_id = GAUDI2_RESERVED_CQ_CS_COMPLETION;
drivers/accel/habanalabs/gaudi2/gaudi2.c: * Some initiators cannot have HBW address in their completion address registers, and thus cannot
drivers/accel/habanalabs/gaudi2/gaudi2.c: * completion, by decrementing the sync object value and re-arming the monitor.
drivers/accel/habanalabs/gaudi2/gaudi2.c:	/* Enable HBW/LBW CQ for completion monitors */
drivers/accel/habanalabs/gaudi2/gaudi2.c:	/* Enable only HBW CQ for KDMA completion monitor */
drivers/accel/habanalabs/gaudi2/gaudi2.c:	WREG32(mmDCORE0_SYNC_MNGR_GLBL_LBW_DATA_0, GAUDI2_IRQ_NUM_COMPLETION);
drivers/accel/habanalabs/gaudi2/gaudi2.c:			hdev->completion_queue[i].bus_address;
drivers/accel/habanalabs/gaudi2/gaudi2.c:	gaudi2_arm_cq_monitor(hdev, GAUDI2_RESERVED_SOB_KDMA_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2.c:				GAUDI2_RESERVED_MON_KDMA_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2.c:				GAUDI2_RESERVED_CQ_KDMA_COMPLETION, 1, 1);
drivers/accel/habanalabs/gaudi2/gaudi2.c:			(GAUDI2_RESERVED_SOB_KDMA_COMPLETION * sizeof(u32));
drivers/accel/habanalabs/gaudi2/gaudi2.c:	/* Wait for completion */
drivers/accel/habanalabs/gaudi2/gaudi2.c:	cq = &hdev->completion_queue[GAUDI2_RESERVED_CQ_KDMA_COMPLETION];
drivers/accel/habanalabs/gaudi2/gaudi2.c:static int gaudi2_test_queue_wait_completion(struct hl_device *hdev, u32 hw_queue_id, u32 sob_val)
drivers/accel/habanalabs/gaudi2/gaudi2.c:		rc = gaudi2_test_queue_wait_completion(hdev, i, sob_val);
drivers/accel/habanalabs/gaudi2/gaudi2.c:	 * also set the sob addr for all edma cores for completion.
drivers/accel/habanalabs/gaudi2/gaudi2.c:	if (!cs_needs_completion(cs))
drivers/accel/habanalabs/gaudi2/gaudi2.c:	 * First 64 SOB/MON are reserved for driver for QMAN auto completion
drivers/accel/habanalabs/gaudi2/gaudi2.c:	gaudi2_arm_cq_monitor(hdev, sob_id, mon_id, GAUDI2_RESERVED_CQ_CS_COMPLETION, mon_payload,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_SOB_CS_COMPLETION_FIRST,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_SOB_CS_COMPLETION_LAST =
drivers/accel/habanalabs/gaudi2/gaudi2P.h:			GAUDI2_RESERVED_SOB_CS_COMPLETION_FIRST + GAUDI2_MAX_PENDING_CS - 1,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_SOB_KDMA_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_MON_CS_COMPLETION_FIRST,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_MON_CS_COMPLETION_LAST =
drivers/accel/habanalabs/gaudi2/gaudi2P.h:			GAUDI2_RESERVED_MON_CS_COMPLETION_FIRST + GAUDI2_MAX_PENDING_CS - 1,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_MON_KDMA_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_CQ_CS_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_RESERVED_CQ_KDMA_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2P.h:	GAUDI2_IRQ_NUM_COMPLETION,
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 1},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 2},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 3},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 4},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 5},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 6},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 7},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 8},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 9},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 10},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 11},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 12},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 13},
drivers/accel/habanalabs/gaudi2/gaudi2_security.c:		mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX + HL_BLOCK_SIZE * 14},
drivers/accel/habanalabs/goya/goya.c: *     - CP writes to MSIX register and to kernel address space (completion
drivers/accel/habanalabs/goya/goya.c:	prop->completion_queues_count = NUMBER_OF_CMPLT_QUEUES;
drivers/accel/habanalabs/goya/goya.c:	prop->completion_mode = HL_COMPLETION_MODE_JOB;
drivers/accel/habanalabs/goya/goya.c:	int cq_cnt = hdev->asic_prop.completion_queues_count;
drivers/accel/habanalabs/goya/goya.c:				&hdev->completion_queue[i]);
drivers/accel/habanalabs/goya/goya.c:			&hdev->completion_queue[i]);
drivers/accel/habanalabs/goya/goya.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++)
drivers/accel/habanalabs/goya/goya.c:	for (i = 0 ; i < hdev->asic_prop.completion_queues_count ; i++) {
drivers/accel/habanalabs/goya/goya.c:		free_irq(irq, &hdev->completion_queue[i]);
drivers/accel/habanalabs/goya/goya.c:	 * 1. A packet that will act as a completion packet
drivers/accel/habanalabs/goya/goya.c:	 * 1. A packet that will act as a completion packet
drivers/accel/habanalabs/goya/goyaP.h: * Each completion queue has 1 ID
drivers/accel/habanalabs/include/common/qman_if.h: * COMPLETION QUEUE
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5400100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5400180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5401100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5401180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5402100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5402180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5403100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5403180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5404100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5404180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5405100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5405180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5406100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5406180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5407100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5407180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5408100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5408180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5409100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5409180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x540A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x540A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x540B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x540B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x540C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x540C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x540D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x540D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x540E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x540E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5420100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5420180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5421100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5421180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5422100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5422180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5423100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5423180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5424100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5424180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5425100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5425180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5426100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5426180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5427100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5427180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5428100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5428180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5429100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5429180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x542A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x542A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x542B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x542B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x542C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x542C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x542D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x542D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x542E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC0_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x542E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC0_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5480100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5480180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5481100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5481180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5482100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5482180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5483100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5483180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5484100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5484180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5485100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5485180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5486100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5486180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5487100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5487180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5488100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5488180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5489100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5489180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x548A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x548A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x548B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x548B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x548C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x548C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x548D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x548D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x548E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x548E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x54A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x54A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x54A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x54A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x54A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x54A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x54A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x54A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x54A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x54A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x54A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x54A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x54A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x54A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x54A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x54A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x54A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x54A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x54A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x54A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x54AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x54AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x54AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x54AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x54AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x54AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x54AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x54AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x54AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC1_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x54AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC1_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5500100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5500180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5501100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5501180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5502100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5502180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5503100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5503180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5504100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5504180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5505100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5505180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5506100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5506180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5507100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5507180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5508100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5508180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5509100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5509180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x550A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x550A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x550B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x550B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x550C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x550C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x550D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x550D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x550E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x550E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5520100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5520180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5521100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5521180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5522100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5522180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5523100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5523180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5524100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5524180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5525100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5525180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5526100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5526180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5527100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5527180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5528100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5528180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5529100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5529180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x552A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x552A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x552B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x552B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x552C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x552C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x552D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x552D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x552E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC2_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x552E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC2_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5580100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5580180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5581100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5581180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5582100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5582180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5583100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5583180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5584100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5584180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5585100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5585180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5586100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5586180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5587100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5587180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5588100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5588180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5589100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5589180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x558A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x558A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x558B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x558B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x558C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x558C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x558D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x558D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x558E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x558E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x55A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x55A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x55A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x55A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x55A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x55A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x55A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x55A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x55A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x55A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x55A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x55A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x55A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x55A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x55A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x55A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x55A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x55A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x55A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x55A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x55AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x55AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x55AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x55AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x55AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x55AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x55AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x55AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x55AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC3_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x55AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC3_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5600100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5600180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5601100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5601180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5602100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5602180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5603100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5603180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5604100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5604180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5605100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5605180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5606100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5606180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5607100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5607180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5608100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5608180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5609100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5609180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x560A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x560A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x560B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x560B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x560C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x560C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x560D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x560D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x560E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x560E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5620100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5620180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5621100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5621180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5622100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5622180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5623100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5623180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5624100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5624180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5625100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5625180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5626100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5626180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5627100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5627180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5628100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5628180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5629100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5629180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x562A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x562A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x562B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x562B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x562C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x562C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x562D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x562D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x562E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC4_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x562E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC4_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5680100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5680180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5681100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5681180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5682100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5682180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5683100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5683180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5684100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5684180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5685100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5685180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5686100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5686180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5687100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5687180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5688100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5688180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5689100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5689180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x568A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x568A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x568B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x568B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x568C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x568C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x568D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x568D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x568E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x568E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x56A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x56A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x56A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x56A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x56A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x56A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x56A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x56A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x56A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x56A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x56A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x56A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x56A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x56A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x56A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x56A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x56A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x56A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x56A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x56A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x56AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x56AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x56AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x56AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x56AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x56AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x56AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x56AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x56AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC5_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x56AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC5_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5700100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5700180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5701100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5701180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5702100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5702180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5703100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5703180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5704100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5704180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5705100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5705180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5706100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5706180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5707100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5707180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5708100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5708180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5709100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5709180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x570A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x570A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x570B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x570B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x570C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x570C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x570D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x570D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x570E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x570E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5720100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5720180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5721100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5721180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5722100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5722180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5723100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5723180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5724100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5724180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5725100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5725180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5726100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5726180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5727100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5727180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5728100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5728180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5729100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5729180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x572A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x572A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x572B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x572B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x572C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x572C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x572D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x572D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x572E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC6_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x572E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC6_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5780100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5780180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5781100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5781180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5782100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5782180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5783100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5783180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5784100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5784180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5785100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5785180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5786100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5786180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5787100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5787180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5788100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5788180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5789100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5789180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x578A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x578A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x578B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x578B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x578C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x578C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x578D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x578D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x578E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x578E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x57A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x57A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x57A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x57A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x57A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x57A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x57A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x57A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x57A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x57A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x57A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x57A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x57A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x57A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x57A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x57A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x57A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x57A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x57A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x57A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x57AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x57AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x57AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x57AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x57AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x57AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x57AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x57AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x57AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC7_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x57AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC7_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5800100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5800180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5801100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5801180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5802100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5802180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5803100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5803180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5804100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5804180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5805100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5805180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5806100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5806180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5807100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5807180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5808100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5808180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5809100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5809180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x580A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x580A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x580B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x580B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x580C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x580C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x580D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x580D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x580E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x580E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5820100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5820180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5821100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5821180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5822100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5822180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5823100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5823180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5824100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5824180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5825100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5825180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5826100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5826180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5827100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5827180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5828100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5828180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5829100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5829180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x582A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x582A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x582B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x582B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x582C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x582C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x582D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x582D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x582E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC8_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x582E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC8_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5880100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5880180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5881100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5881180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5882100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5882180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5883100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5883180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5884100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5884180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5885100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5885180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5886100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5886180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5887100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5887180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5888100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5888180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5889100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5889180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x588A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x588A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x588B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x588B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x588C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x588C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x588D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x588D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x588E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x588E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x58A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x58A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x58A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x58A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x58A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x58A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x58A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x58A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x58A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x58A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x58A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x58A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x58A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x58A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x58A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x58A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x58A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x58A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x58A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x58A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x58AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x58AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x58AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x58AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x58AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x58AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x58AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x58AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x58AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC9_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x58AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC9_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5900100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5900180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5901100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5901180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5902100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5902180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5903100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5903180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5904100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5904180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5905100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5905180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5906100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5906180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5907100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5907180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5908100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5908180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5909100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5909180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x590A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x590A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x590B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x590B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x590C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x590C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x590D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x590D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x590E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x590E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x5920100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x5920180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x5921100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x5921180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x5922100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x5922180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x5923100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x5923180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x5924100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x5924180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x5925100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x5925180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x5926100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x5926180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x5927100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x5927180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x5928100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x5928180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x5929100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x5929180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x592A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x592A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x592B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x592B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x592C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x592C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x592D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x592D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x592E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC10_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x592E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC10_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_0_COMPLETION_QUEUE_CI_0_BASE 0x5980100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_0_COMPLETION_QUEUE_CI_1_BASE 0x5980180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_1_COMPLETION_QUEUE_CI_0_BASE 0x5981100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_1_COMPLETION_QUEUE_CI_1_BASE 0x5981180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_2_COMPLETION_QUEUE_CI_0_BASE 0x5982100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_2_COMPLETION_QUEUE_CI_1_BASE 0x5982180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_3_COMPLETION_QUEUE_CI_0_BASE 0x5983100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_3_COMPLETION_QUEUE_CI_1_BASE 0x5983180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_4_COMPLETION_QUEUE_CI_0_BASE 0x5984100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_4_COMPLETION_QUEUE_CI_1_BASE 0x5984180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_5_COMPLETION_QUEUE_CI_0_BASE 0x5985100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_5_COMPLETION_QUEUE_CI_1_BASE 0x5985180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_6_COMPLETION_QUEUE_CI_0_BASE 0x5986100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_6_COMPLETION_QUEUE_CI_1_BASE 0x5986180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_7_COMPLETION_QUEUE_CI_0_BASE 0x5987100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_7_COMPLETION_QUEUE_CI_1_BASE 0x5987180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_8_COMPLETION_QUEUE_CI_0_BASE 0x5988100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_8_COMPLETION_QUEUE_CI_1_BASE 0x5988180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_9_COMPLETION_QUEUE_CI_0_BASE 0x5989100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_9_COMPLETION_QUEUE_CI_1_BASE 0x5989180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_10_COMPLETION_QUEUE_CI_0_BASE 0x598A100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_10_COMPLETION_QUEUE_CI_1_BASE 0x598A180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_11_COMPLETION_QUEUE_CI_0_BASE 0x598B100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_11_COMPLETION_QUEUE_CI_1_BASE 0x598B180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_12_COMPLETION_QUEUE_CI_0_BASE 0x598C100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_12_COMPLETION_QUEUE_CI_1_BASE 0x598C180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_13_COMPLETION_QUEUE_CI_0_BASE 0x598D100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_13_COMPLETION_QUEUE_CI_1_BASE 0x598D180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_14_COMPLETION_QUEUE_CI_0_BASE 0x598E100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR0_14_COMPLETION_QUEUE_CI_1_BASE 0x598E180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR0_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_0_COMPLETION_QUEUE_CI_0_BASE 0x59A0100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_0_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_0_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_0_COMPLETION_QUEUE_CI_1_BASE 0x59A0180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_0_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_0_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_1_COMPLETION_QUEUE_CI_0_BASE 0x59A1100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_1_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_1_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_1_COMPLETION_QUEUE_CI_1_BASE 0x59A1180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_1_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_1_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_2_COMPLETION_QUEUE_CI_0_BASE 0x59A2100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_2_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_2_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_2_COMPLETION_QUEUE_CI_1_BASE 0x59A2180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_2_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_2_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_3_COMPLETION_QUEUE_CI_0_BASE 0x59A3100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_3_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_3_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_3_COMPLETION_QUEUE_CI_1_BASE 0x59A3180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_3_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_3_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_4_COMPLETION_QUEUE_CI_0_BASE 0x59A4100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_4_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_4_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_4_COMPLETION_QUEUE_CI_1_BASE 0x59A4180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_4_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_4_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_5_COMPLETION_QUEUE_CI_0_BASE 0x59A5100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_5_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_5_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_5_COMPLETION_QUEUE_CI_1_BASE 0x59A5180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_5_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_5_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_6_COMPLETION_QUEUE_CI_0_BASE 0x59A6100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_6_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_6_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_6_COMPLETION_QUEUE_CI_1_BASE 0x59A6180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_6_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_6_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_7_COMPLETION_QUEUE_CI_0_BASE 0x59A7100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_7_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_7_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_7_COMPLETION_QUEUE_CI_1_BASE 0x59A7180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_7_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_7_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_8_COMPLETION_QUEUE_CI_0_BASE 0x59A8100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_8_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_8_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_8_COMPLETION_QUEUE_CI_1_BASE 0x59A8180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_8_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_8_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_9_COMPLETION_QUEUE_CI_0_BASE 0x59A9100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_9_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_9_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_9_COMPLETION_QUEUE_CI_1_BASE 0x59A9180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_9_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_9_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_10_COMPLETION_QUEUE_CI_0_BASE 0x59AA100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_10_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_10_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_10_COMPLETION_QUEUE_CI_1_BASE 0x59AA180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_10_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_10_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_11_COMPLETION_QUEUE_CI_0_BASE 0x59AB100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_11_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_11_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_11_COMPLETION_QUEUE_CI_1_BASE 0x59AB180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_11_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_11_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_12_COMPLETION_QUEUE_CI_0_BASE 0x59AC100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_12_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_12_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_12_COMPLETION_QUEUE_CI_1_BASE 0x59AC180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_12_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_12_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_13_COMPLETION_QUEUE_CI_0_BASE 0x59AD100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_13_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_13_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_13_COMPLETION_QUEUE_CI_1_BASE 0x59AD180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_13_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_13_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_14_COMPLETION_QUEUE_CI_0_BASE 0x59AE100ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_14_COMPLETION_QUEUE_CI_0_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_14_COMPLETION_QUEUE_CI_0_SECTION 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define mmNIC11_UMR1_14_COMPLETION_QUEUE_CI_1_BASE 0x59AE180ull
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_14_COMPLETION_QUEUE_CI_1_MAX_OFFSET 0x8000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_blocks_linux_driver.h:#define NIC11_UMR1_14_COMPLETION_QUEUE_CI_1_SECTION 0xD000
drivers/accel/habanalabs/include/gaudi2/asic_reg/gaudi2_regs.h:#include "nic0_umr0_0_completion_queue_ci_1_regs.h"
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h:#ifndef ASIC_REG_NIC0_UMR0_0_COMPLETION_QUEUE_CI_1_REGS_H_
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h:#define ASIC_REG_NIC0_UMR0_0_COMPLETION_QUEUE_CI_1_REGS_H_
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h: *   NIC0_UMR0_0_COMPLETION_QUEUE_CI_1
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h: *   (Prototype: COMPLETION_QUEUE_CI)
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h:#define mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_NUMBER 0x5400180
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h:#define mmNIC0_UMR0_0_COMPLETION_QUEUE_CI_1_CQ_CONSUMER_INDEX 0x5400184
drivers/accel/habanalabs/include/gaudi2/asic_reg/nic0_umr0_0_completion_queue_ci_1_regs.h:#endif /* ASIC_REG_NIC0_UMR0_0_COMPLETION_QUEUE_CI_1_REGS_H_ */
drivers/accel/ivpu/ivpu_hw_btrs.c:		ivpu_err(vdev, "Timed out waiting for RESET completion\n");
drivers/accel/ivpu/ivpu_hw_btrs.c:		ivpu_err(vdev, "Timed out waiting for RESET completion\n");
drivers/accel/ivpu/ivpu_job.h: * @submit_status_offset: Offset within batch buffer where job completion handler
drivers/accel/ivpu/vpu_boot_api.h:	/* VPU -> ARM job done interrupt. VPU is notifying ARM of compute job completion. */
drivers/accel/ivpu/vpu_boot_api.h:	/* ARM -> VPU IRQ line to use to notify of MMU update completion. */
drivers/accel/ivpu/vpu_boot_api.h:	/* VPU -> ARM IRQ line to use to notify of power level change completion. */
drivers/accel/ivpu/vpu_boot_api.h:	/* ARM -> VPU IRQ line to use to notify of counter reset completion. */
drivers/accel/ivpu/vpu_boot_api.h:	/* VPU -> ARM IRQ line to use to notify of preemption completion. */
drivers/accel/ivpu/vpu_jsm_api.h:	/* IPC Device -> Host, Job completion */
drivers/accel/ivpu/vpu_jsm_api.h:	/* IPC Device -> Host, Async command completion */
drivers/accel/ivpu/vpu_jsm_api.h:	/* IPC Device -> Host, HWS completion of a context suspend request */
drivers/accel/ivpu/vpu_jsm_api.h:	/* IPC Device -> Host, General command completion */
drivers/accel/ivpu/vpu_jsm_api.h:	 * Acknowledgment of completion of the save procedure initiated by
drivers/accel/ivpu/vpu_jsm_api.h: *   - Notify the host of completion of these operations via
drivers/accel/ivpu/vpu_jsm_api.h: * Same structure used when VPU notifies host of completion of a context suspend
drivers/accel/ivpu/vpu_jsm_api.h: * Metric group description placed in the metric buffer after successful completion
drivers/accel/qaic/qaic.h:	/* Wait on this for completion of DMA transfer of this BO */
drivers/accel/qaic/qaic.h:	struct completion	xfer_done;
drivers/accel/qaic/qaic.h:		 * Latest timestamp(ns) at which kernel received a completion
drivers/accel/qaic/qaic_control.c:#include <linux/completion.h>
drivers/accel/qaic/qaic_control.c:	/* This is used to wait on until completion of transfer request */
drivers/accel/qaic/qaic_control.c:	struct completion xfer_done;
drivers/accel/qaic/qaic_control.c:	init_completion(&elem.xfer_done);
drivers/accel/qaic/qaic_control.c:		ret = wait_for_completion_timeout(&elem.xfer_done, control_resp_timeout_s * HZ);
drivers/accel/qaic/qaic_control.c:		ret = wait_for_completion_interruptible_timeout(&elem.xfer_done,
drivers/accel/qaic/qaic_data.c:#include <linux/completion.h>
drivers/accel/qaic/qaic_data.c:#define GEN_COMPLETION	BIT(4)
drivers/accel/qaic/qaic_data.c:	 * 4	1 - Generate completion element in the response queue
drivers/accel/qaic/qaic_data.c:	 *	0 - No Completion Code
drivers/accel/qaic/qaic_data.c:	slice->reqs[i].cmd |= GEN_COMPLETION;
drivers/accel/qaic/qaic_data.c:		reinit_completion(&bo->xfer_done);
drivers/accel/qaic/qaic_data.c:		init_completion(&bo->xfer_done);
drivers/accel/qaic/qaic_data.c:		reinit_completion(&bo->xfer_done);
drivers/accel/qaic/qaic_data.c: * Each dbc has a completion queue. Entries in the queue correspond to DMA
drivers/accel/qaic/qaic_data.c:	ret = wait_for_completion_interruptible_timeout(&bo->xfer_done, timeout);
drivers/accessibility/speakup/spk_ttyio.c:	struct completion completion;
drivers/accessibility/speakup/spk_ttyio.c:	init_completion(&ldisc_data->completion);
drivers/accessibility/speakup/spk_ttyio.c:	complete(&ldisc_data->completion);
drivers/accessibility/speakup/spk_ttyio.c:		if (!try_wait_for_completion(&ldisc_data->completion))
drivers/accessibility/speakup/spk_ttyio.c:	} else if (wait_for_completion_timeout(&ldisc_data->completion,
drivers/acpi/acpi_ffh.c:#include <linux/completion.h>
drivers/acpi/acpi_ipmi.c:	struct completion smi_selection_done;
drivers/acpi/acpi_ipmi.c:	struct completion tx_complete;
drivers/acpi/acpi_ipmi.c:	init_completion(&ipmi_msg->tx_complete);
drivers/acpi/acpi_ipmi.c:		if (msg->msg.data[0] == IPMI_TIMEOUT_COMPLETION_CODE) {
drivers/acpi/acpi_ipmi.c:	wait_for_completion(&tx_msg->tx_complete);
drivers/acpi/acpi_ipmi.c:	ret = wait_for_completion_interruptible_timeout(&driver_data.smi_selection_done,
drivers/acpi/acpi_ipmi.c:	init_completion(&driver_data.smi_selection_done);
drivers/acpi/acpi_pcc.c:#include <linux/completion.h>
drivers/acpi/acpi_pcc.c:	struct completion done;
drivers/acpi/acpi_pcc.c:	init_completion(&data->done);
drivers/acpi/acpi_pcc.c:	reinit_completion(&data->done);
drivers/acpi/acpi_pcc.c:	ret = wait_for_completion_timeout(&data->done,
drivers/acpi/acpica/aclocal.h:#define ACPI_EXT_INTERNAL_PATH_ALLOCATED    0x04	/* Deallocate internal path on completion */
drivers/acpi/acpica/dbexec.c:	/* Signal our completion */
drivers/acpi/acpica/dbinput.c:	{1, "  Go", "Allow method to run to completion\n"},
drivers/acpi/acpica/dbinput.c:		/* Notify the completion of the command */
drivers/acpi/acpica/dbxface.c:		/* Notify the completion of the command */
drivers/acpi/acpica/dspkginit.c: * Module Name: dspkginit - Completion of deferred package initialization
drivers/acpi/acpica/dswexec.c:			 * object is temporary and will be deleted upon completion of
drivers/acpi/acpica/psargs.c: * RETURN:      Decoded package length. On completion, the AML pointer points
drivers/acpi/acpica/psparse.c: * DESCRIPTION: Perform any cleanup at the completion of an Op.
drivers/acpi/cppc_acpi.c:		 * before write completion, so first send a WRITE command to
drivers/acpi/cppc_acpi.c:	 * "The minimum amount of time that OSPM must wait after the completion
drivers/acpi/cppc_acpi.c:	/* wait for completion and check for PCC error bit */
drivers/acpi/cppc_acpi.c:	 *              completion of a command before issuing the next command,
drivers/acpi/device_sysfs.c:		init_completion(&dn->kobj_done);
drivers/acpi/ec.c:	 * Note that successful completion of the query causes the ACPI_EC_SCI
drivers/acpi/nfit/core.c:	 * completion tracking.
drivers/acpi/property.c:		wait_for_completion(&dn->kobj_done);
drivers/acpi/sbshc.c:	 * Wait for completion. Save the status code, data size,
drivers/acpi/sbshc.c:	/* Check if it is only a completion notify */
drivers/ata/acard-ahci.c:static enum ata_completion_errors acard_ahci_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/acard-ahci.c:static enum ata_completion_errors acard_ahci_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/ahci.h:	HOST_CAP_CCC		= BIT(7),  /* Command Completion Coalescing */
drivers/ata/ahci_xgene.c: * Waits for completion of multiple commands and restarts
drivers/ata/ahci_xgene.c:	 * completion of outstanding IDENTIFY DEVICE commands before
drivers/ata/ahci_xgene.c: * a mismatch and results in command completion failure. The
drivers/ata/ahci_xgene.c: * a mismatch and results in command completion failure. The workaround
drivers/ata/ahci_xgene.c: * a mismatch and results in command completion failure. The workaround
drivers/ata/libahci.c:static enum ata_completion_errors ahci_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/libahci.c:	/* wait for completion, spec says 500ms, give it 1000 */
drivers/ata/libahci.c:static enum ata_completion_errors ahci_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/libahci.c:		 * received SDB FISes notifying successful completions.
drivers/ata/libahci.c:	 * in completion path to determine whether NCQ phase is in
drivers/ata/libata-core.c:#include <linux/completion.h>
drivers/ata/libata-core.c:	 * bit on completion.
drivers/ata/libata-core.c:	struct completion *waiting = qc->private_data;
drivers/ata/libata-core.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/ata/libata-core.c:	rc = wait_for_completion_timeout(&wait, msecs_to_jiffies(timeout));
drivers/ata/libata-core.c:	/* command should be marked inactive atomically with qc completion */
drivers/ata/libata-core.c:	/* call completion callback */
drivers/ata/libata-core.c:	/* Some commands need post-processing after successful completion. */
drivers/ata/libata-core.c:	init_completion(&ap->park_req_pending);
drivers/ata/libata-eh.c:	/* If we timed raced normal completion and there is nothing to
drivers/ata/libata-eh.c:	 * normal completion, error completion, and SCSI timeout.
drivers/ata/libata-eh.c:	 * Both completions can race against SCSI timeout.  When normal
drivers/ata/libata-eh.c:	 * completion wins, the qc never reaches EH.  When error
drivers/ata/libata-eh.c:	 * completion wins, the qc has ATA_QCFLAG_EH set.
drivers/ata/libata-eh.c:	 * Normal or error completion can occur after the timeout but
drivers/ata/libata-eh.c:	 * completions are honored.  A scmd is determined to have
drivers/ata/libata-eh.c:	 * this as if normal completion won the race
drivers/ata/libata-eh.c:			/* Normal completion occurred after
drivers/ata/libata-eh.c:	 * exception occurs after this point but before EH completion, SCSI
drivers/ata/libata-eh.c: *	For a regular SCSI command, the SCSI completion callback (scsi_done())
drivers/ata/libata-eh.c: *	data is usually returned in the completion itself (without invoking SCSI
drivers/ata/libata-eh.c: *	do not get the sense data as part of the completion.
drivers/ata/libata-eh.c:	 * Since the sense data is not part of the completion, we need to fetch
drivers/ata/libata-eh.c:	ehc->last_reset = jiffies;		/* update to completion time */
drivers/ata/libata-eh.c:	 * through reinit_completion() (see below) or complete_all()
drivers/ata/libata-eh.c:	 * wait_for_completion_timeout(), another ATA_EH_PARK action
drivers/ata/libata-eh.c:	reinit_completion(&ap->park_req_pending);
drivers/ata/libata-eh.c:		deadline = wait_for_completion_timeout(&ap->park_req_pending,
drivers/ata/libata-scsi.c:	/* handle completion from EH */
drivers/ata/libata-scsi.c:	/* successful completion path */
drivers/ata/libata-sff.c:	 * For normal completion, qc->result_tf is not relevant. For
drivers/ata/libata-sff.c:				 * sff_irq_clear() w/o racing with completion.
drivers/ata/libata-sff.c: *	@r_err: Value of error register on completion
drivers/ata/libata-sff.c:enum ata_completion_errors ata_bmdma_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/libata-sff.c:enum ata_completion_errors ata_bmdma_dumb_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/pata_arasan_cf.c:#include <linux/completion.h>
drivers/ata/pata_arasan_cf.c:	/* Completion for transfer complete interrupt from controller */
drivers/ata/pata_arasan_cf.c:	struct completion cf_completion;
drivers/ata/pata_arasan_cf.c:	/* Completion for DMA transfer complete. */
drivers/ata/pata_arasan_cf.c:	struct completion dma_completion;
drivers/ata/pata_arasan_cf.c:	complete(&acdev->dma_completion);
drivers/ata/pata_arasan_cf.c:	if (!wait_for_completion_timeout(&acdev->cf_completion, TIMEOUT)) {
drivers/ata/pata_arasan_cf.c:	if (!wait_for_completion_timeout(&acdev->dma_completion, TIMEOUT)) {
drivers/ata/pata_arasan_cf.c:		dev_err(acdev->host->dev, "wait_for_completion_timeout\n");
drivers/ata/pata_arasan_cf.c:		complete(&acdev->cf_completion);
drivers/ata/pata_arasan_cf.c:		complete(&acdev->cf_completion);
drivers/ata/pata_arasan_cf.c:			complete(&acdev->cf_completion);
drivers/ata/pata_arasan_cf.c:	init_completion(&acdev->cf_completion);
drivers/ata/pata_arasan_cf.c:	init_completion(&acdev->dma_completion);
drivers/ata/pata_macio.c:static enum ata_completion_errors pata_macio_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/pata_octeon_cf.c:	 * If the port is not waiting for completion, it must have
drivers/ata/pata_pxa.c:#include <linux/completion.h>
drivers/ata/pata_pxa.c:	struct completion	dma_done;
drivers/ata/pata_pxa.c:static enum ata_completion_errors pxa_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/pata_pxa.c:	init_completion(&pd->dma_done);
drivers/ata/pata_pxa.c:	    wait_for_completion_timeout(&pd->dma_done, HZ))
drivers/ata/pata_pxa.c:		ata_dev_err(qc->dev, "Timeout waiting for DMA completion!");
drivers/ata/pdc_adma.c:static enum ata_completion_errors adma_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/pdc_adma.c:static enum ata_completion_errors adma_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_dwc_460ex.c:	 * tags we have gotten a completion interrupt.  One interrupt may serve
drivers/ata/sata_dwc_460ex.c:	 * as completion for more than one operation when commands are queued
drivers/ata/sata_dwc_460ex.c:		/* To be picked up by completion functions */
drivers/ata/sata_fsl.c:static enum ata_completion_errors sata_fsl_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_inic162x.c:	PIRQ_COMPLETE		= (1 << 2),  /* completion interrupt */
drivers/ata/sata_inic162x.c:static enum ata_completion_errors inic_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_mv.c:static enum ata_completion_errors mv_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_mv.c:static enum ata_completion_errors mv_qc_prep_iie(struct ata_queued_cmd *qc);
drivers/ata/sata_mv.c:				cfg |= (1 << 18); /* enab early completion */
drivers/ata/sata_mv.c:static enum ata_completion_errors mv_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_mv.c:static enum ata_completion_errors mv_qc_prep_iie(struct ata_queued_cmd *qc)
drivers/ata/sata_mv.c: *	Note: we don't get updated shadow regs on *completion*
drivers/ata/sata_mv.c:	 *   MSB is saved ATA status from command completion.
drivers/ata/sata_nv.c:static enum ata_completion_errors nv_adma_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_nv.c:static enum ata_completion_errors nv_swncq_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_nv.c:		 * statuses, so that any CPB completions after this
drivers/ata/sata_nv.c:static enum ata_completion_errors nv_adma_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_nv.c:static enum ata_completion_errors nv_swncq_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_promise.c:static enum ata_completion_errors pdc_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_promise.c:static enum ata_completion_errors pdc_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_qstor.c:static enum ata_completion_errors qs_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_qstor.c:static enum ata_completion_errors qs_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_rcar.c:static enum ata_completion_errors sata_rcar_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_sil.c:static enum ata_completion_errors sil_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_sil.c:static enum ata_completion_errors sil_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_sil24.c:	PRB_CTRL_NIEN		= (1 << 6), /* Mask completion irq */
drivers/ata/sata_sil24.c:static enum ata_completion_errors sil24_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_sil24.c:	/* temporarily plug completion and error interrupts */
drivers/ata/sata_sil24.c:static enum ata_completion_errors sil24_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_sil24.c:	/* apply workaround for completion IRQ loss on PCI-X errata */
drivers/ata/sata_sil24.c:				 "Applying completion IRQ loss on PCI-X errata fix\n");
drivers/ata/sata_sx4.c:static enum ata_completion_errors pdc20621_qc_prep(struct ata_queued_cmd *qc);
drivers/ata/sata_sx4.c:static enum ata_completion_errors pdc20621_qc_prep(struct ata_queued_cmd *qc)
drivers/ata/sata_sx4.c:	/* command completion, but no data xfer */
drivers/atm/eni.c:		 * keeping track of TX completions all the time, so let's poll
drivers/atm/fore200e.c:		   not be popped after the completion of their emission, as they refer
drivers/atm/fore200e.c:		/* notify tx completion */
drivers/atm/fore200e.h:    u32              status_haddr;    /* host DMA address of completion status  */
drivers/atm/fore200e.h:    u32 status_haddr;    /* host DMA address of completion status  */
drivers/atm/fore200e.h:    u32 status_haddr;       /* host DMA address of completion status  */
drivers/atm/fore200e.h:/* completion status */
drivers/atm/fore200e.h:    STATUS_COMPLETE = (1<<1),    /* completion status (written by cp) */
drivers/atm/fore200e.h:    STATUS_ERROR    = (1<<3)     /* completion status (written by cp) */
drivers/atm/fore200e.h:    u32       status_haddr;    /* host DMA address of completion status */
drivers/atm/fore200e.h:    struct chunk           status;                          /* array of completion status      */
drivers/atm/fore200e.h:    struct chunk          status;                         /* arry of completion status              */
drivers/atm/fore200e.h:    struct chunk           status;                         /* array of completion status             */
drivers/atm/fore200e.h:    struct chunk          status;                         /* array of completion status                */
drivers/atm/iphase.c:	    IF_ERR(printk(DEV_LABEL "send desc:%d completion code %d error\n", 
drivers/auxdisplay/arm-charlcd.c:#include <linux/completion.h>
drivers/auxdisplay/arm-charlcd.c: * @complete: completion structure for the last LCD command
drivers/auxdisplay/arm-charlcd.c:	struct completion complete;
drivers/auxdisplay/arm-charlcd.c:	ret = wait_for_completion_interruptible_timeout(&lcd->complete,
drivers/auxdisplay/arm-charlcd.c:	/* Disable IRQ after completion */
drivers/auxdisplay/arm-charlcd.c:			"wait_for_completion_interruptible_timeout() "
drivers/auxdisplay/arm-charlcd.c:		init_completion(&lcd->complete);
drivers/base/core.c:	 * scheduled work has run to completion.
drivers/base/core.c:	 * model. device_add() doesn't guarantee probe completion of the device
drivers/base/devtmpfs.c:	struct completion done;
drivers/base/devtmpfs.c:	init_completion(&req->done);
drivers/base/devtmpfs.c:	wait_for_completion(&req->done);
drivers/base/devtmpfs.c:static __initdata DECLARE_COMPLETION(setup_done);
drivers/base/devtmpfs.c:		wait_for_completion(&setup_done);
drivers/base/firmware_loader/firmware.h:#include <linux/completion.h>
drivers/base/firmware_loader/firmware.h:	struct completion completion;
drivers/base/firmware_loader/firmware.h:	ret = wait_for_completion_killable_timeout(&fw_st->completion, timeout);
drivers/base/firmware_loader/firmware.h:		complete_all(&fw_st->completion);
drivers/base/firmware_loader/main.c:	init_completion(&fw_st->completion);
drivers/base/firmware_loader/main.c:	/* wait for completion of caching firmware for all devices */
drivers/base/power/main.c:	init_completion(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:		wait_for_completion(&dev->power.completion);
drivers/base/power/main.c:	 * we'll wait for its completion to change the state, but that's fine,
drivers/base/power/main.c:	reinit_completion(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/main.c:	complete_all(&dev->power.completion);
drivers/base/power/runtime.c: * __pm_runtime_barrier - Cancel pending requests and wait for completions.
drivers/base/power/runtime.c: * pm_runtime_barrier - Flush pending requests and wait for completions.
drivers/base/test/test_async_driver_probe.c:	 * required amount of time and then report completion.
drivers/base/test/test_async_driver_probe.c:	 * report successful completion.
drivers/bcma/driver_pci_host.c: * Retry Status (RRS) Completion Status to software then
drivers/bcma/driver_pci_host.c:		 * least return a completion TLP, with a completion status
drivers/bcma/driver_pci_host.c:		 * until we receive the successful completion status. Repeat
drivers/block/amiflop.c:static DECLARE_COMPLETION(motor_on_completion);
drivers/block/amiflop.c:static DECLARE_COMPLETION(ms_wait_completion);
drivers/block/amiflop.c:	complete(&ms_wait_completion);
drivers/block/amiflop.c:		wait_for_completion(&ms_wait_completion);
drivers/block/amiflop.c:		complete_all(&motor_on_completion);
drivers/block/amiflop.c:		reinit_completion(&motor_on_completion);
drivers/block/amiflop.c:		wait_for_completion(&motor_on_completion);
drivers/block/aoe/aoe.h:	struct completion rendez;
drivers/block/aoe/aoechr.c:#include <linux/completion.h>
drivers/block/aoe/aoechr.c:static struct completion emsgs_comp;
drivers/block/aoe/aoechr.c:		n = wait_for_completion_interruptible(&emsgs_comp);
drivers/block/aoe/aoechr.c:	init_completion(&emsgs_comp);
drivers/block/aoe/aoecmd.c: * doing I/O completion.  It is not important that the cap equal the
drivers/block/aoe/aoecmd.c:/* io completion queue */
drivers/block/aoe/aoecmd.c:	wait_for_completion(&k->rendez);
drivers/block/aoe/aoecmd.c:	init_completion(&k->rendez);
drivers/block/aoe/aoecmd.c:	wait_for_completion(&k->rendez); /* allow kthread to start */
drivers/block/aoe/aoecmd.c:	init_completion(&k->rendez);	/* for waiting for exit later */
drivers/block/ataflop.c:#include <linux/completion.h>
drivers/block/ataflop.c:static DECLARE_COMPLETION(format_wait);
drivers/block/ataflop.c:	wait_for_completion(&format_wait);
drivers/block/drbd/drbd_actlog.c:	bio_get(bio); /* one bio_put() is in the completion handler */
drivers/block/drbd/drbd_actlog.c:	atomic_inc(&device->md_io.in_use); /* drbd_md_put_buffer() is in the completion handler */
drivers/block/drbd/drbd_actlog.c:				 * delayed local completion of an application write),
drivers/block/drbd/drbd_debugfs.c:	seq_print_rq_state_bit(m, s & RQ_COMPLETION_SUSP, &sep, "suspended");
drivers/block/drbd/drbd_debugfs.c:			req = list_first_entry_or_null(&device->pending_master_completion[1],
drivers/block/drbd/drbd_debugfs.c:				struct drbd_request, req_pending_master_completion);
drivers/block/drbd/drbd_debugfs.c:		r1 = list_first_entry_or_null(&device->pending_master_completion[i],
drivers/block/drbd/drbd_debugfs.c:			struct drbd_request, req_pending_master_completion);
drivers/block/drbd/drbd_debugfs.c:		r2 = list_first_entry_or_null(&device->pending_completion[i],
drivers/block/drbd/drbd_int.h:	struct completion stop;
drivers/block/drbd/drbd_int.h:	 * or, after local IO completion, the ERR_PTR(error).
drivers/block/drbd/drbd_int.h:	/* epoch: used to check on "completion" whether this req was in
drivers/block/drbd/drbd_int.h:	struct list_head req_pending_master_completion;
drivers/block/drbd/drbd_int.h:	 *  master_completion_jif
drivers/block/drbd/drbd_int.h:	 *  local_completion_jif
drivers/block/drbd/drbd_int.h:	atomic_t completion_ref;
drivers/block/drbd/drbd_int.h:	atomic_t local_cnt;	 /* Waiting for local completion */
drivers/block/drbd/drbd_int.h:	struct list_head pending_master_completion[2];
drivers/block/drbd/drbd_int.h:	struct list_head pending_completion[2];
drivers/block/drbd/drbd_int.h: * drbd_chk_io_error: Handle the on_io_error setting, should be called from all io completion handlers
drivers/block/drbd/drbd_int.h: * @error:	 Error code passed to the IO completion callback
drivers/block/drbd/drbd_interval.h:	unsigned int waiting:1;		/* someone is waiting for completion */
drivers/block/drbd/drbd_main.c:		init_completion(&thi->stop);
drivers/block/drbd/drbd_main.c:		init_completion(&thi->stop);
drivers/block/drbd/drbd_main.c:		wait_for_completion(&thi->stop);
drivers/block/drbd/drbd_main.c: * But this means that in protocol A we might signal IO completion too early!
drivers/block/drbd/drbd_main.c:	INIT_LIST_HEAD(&device->pending_master_completion[0]);
drivers/block/drbd/drbd_main.c:	INIT_LIST_HEAD(&device->pending_master_completion[1]);
drivers/block/drbd/drbd_main.c:	INIT_LIST_HEAD(&device->pending_completion[0]);
drivers/block/drbd/drbd_main.c:	INIT_LIST_HEAD(&device->pending_completion[1]);
drivers/block/drbd/drbd_main.c:			expect(device, atomic_read(&req->completion_ref) == 0) &&
drivers/block/drbd/drbd_main.c:			drbd_err(device, "req=%p completion_ref=%d rq_state=%x\n",
drivers/block/drbd/drbd_main.c:				req, atomic_read(&req->completion_ref),
drivers/block/drbd/drbd_main.c:		 * "completion_ref" going zero in the code path that queued it
drivers/block/drbd/drbd_main.c:/* called via drbd_req_put_completion_ref(),
drivers/block/drbd/drbd_main.c:struct completion_work {
drivers/block/drbd/drbd_main.c:	struct completion done;
drivers/block/drbd/drbd_main.c:	struct completion_work *completion_work =
drivers/block/drbd/drbd_main.c:		container_of(w, struct completion_work, w);
drivers/block/drbd/drbd_main.c:	complete(&completion_work->done);
drivers/block/drbd/drbd_main.c:	struct completion_work completion_work;
drivers/block/drbd/drbd_main.c:	completion_work.w.cb = w_complete;
drivers/block/drbd/drbd_main.c:	init_completion(&completion_work.done);
drivers/block/drbd/drbd_main.c:	drbd_queue_work(work_queue, &completion_work.w);
drivers/block/drbd/drbd_main.c:	wait_for_completion(&completion_work.done);
drivers/block/drbd/drbd_nl.c:	 * wait_on_completion_killable(), will mistake our pending signal
drivers/block/drbd/drbd_nl.c:	/* If IO completion is currently blocked, we would likely wait
drivers/block/drbd/drbd_receiver.c:	struct completion door_bell;
drivers/block/drbd/drbd_receiver.c:	err = wait_for_completion_interruptible_timeout(&ad->door_bell, timeo);
drivers/block/drbd/drbd_receiver.c:		.door_bell = COMPLETION_INITIALIZER_ONSTACK(ad.door_bell),
drivers/block/drbd/drbd_receiver.c: * then wait for all completions.
drivers/block/drbd/drbd_receiver.c:	struct completion done;
drivers/block/drbd/drbd_receiver.c:		init_completion(&ctx.done);
drivers/block/drbd/drbd_receiver.c:			wait_for_completion(&ctx.done);
drivers/block/drbd/drbd_receiver.c:		/* wait for all pending IO completions, before we start
drivers/block/drbd/drbd_req.c:	INIT_LIST_HEAD(&req->req_pending_master_completion);
drivers/block/drbd/drbd_req.c:	atomic_set(&req->completion_ref, 1);
drivers/block/drbd/drbd_req.c:	/* one kref as long as completion_ref > 0 */
drivers/block/drbd/drbd_req.c:		atomic_read(&req->completion_ref) ||
drivers/block/drbd/drbd_req.c:		drbd_err(device, "drbd_req_destroy: Logic BUG rq_state = 0x%x, completion_ref = %d\n",
drivers/block/drbd/drbd_req.c:				s, atomic_read(&req->completion_ref));
drivers/block/drbd/drbd_req.c:		 * to the local io completion callback drbd_request_endio.
drivers/block/drbd/drbd_req.c:	 *	the bio_endio completion callbacks.
drivers/block/drbd/drbd_req.c:	    (s & RQ_COMPLETION_SUSP)) {
drivers/block/drbd/drbd_req.c:	 * local completion error, if any, has been stored as ERR_PTR
drivers/block/drbd/drbd_req.c:	/* Before we can signal completion to the upper layers,
drivers/block/drbd/drbd_req.c:	list_del_init(&req->req_pending_master_completion);
drivers/block/drbd/drbd_req.c:static void drbd_req_put_completion_ref(struct drbd_request *req, struct bio_and_error *m, int put)
drivers/block/drbd/drbd_req.c:	if (!atomic_sub_and_test(put, &req->completion_ref))
drivers/block/drbd/drbd_req.c:	/* local completion may still come in later,
drivers/block/drbd/drbd_req.c: * req->completion_ref and req->kref. */
drivers/block/drbd/drbd_req.c:	if (drbd_suspended(device) && !((s | clear) & RQ_COMPLETION_SUSP))
drivers/block/drbd/drbd_req.c:		set |= RQ_COMPLETION_SUSP;
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:	if (!(s & RQ_COMPLETION_SUSP) && (set & RQ_COMPLETION_SUSP))
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:	if ((s & RQ_COMPLETION_SUSP) && (clear & RQ_COMPLETION_SUSP))
drivers/block/drbd/drbd_req.c:	drbd_req_put_completion_ref(req, m, c_put);
drivers/block/drbd/drbd_req.c:				RQ_NET_OK|RQ_NET_PENDING|RQ_COMPLETION_SUSP,
drivers/block/drbd/drbd_req.c:		mod_rq_state(req, m, RQ_COMPLETION_SUSP, 0);
drivers/block/drbd/drbd_req.c:				RQ_COMPLETION_SUSP|RQ_LOCAL_COMPLETED,
drivers/block/drbd/drbd_req.c:			mod_rq_state(req, m, RQ_COMPLETION_SUSP, 0);
drivers/block/drbd/drbd_req.c:		   (or the local completion?) was missing when we suspended.
drivers/block/drbd/drbd_req.c:			mod_rq_state(req, m, RQ_COMPLETION_SUSP, RQ_NET_QUEUED|RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:		mod_rq_state(req, m, RQ_COMPLETION_SUSP,
drivers/block/drbd/drbd_req.c:	list_add_tail(&req->req_pending_master_completion,
drivers/block/drbd/drbd_req.c:			&device->pending_master_completion[1 /* WRITE */]);
drivers/block/drbd/drbd_req.c:	if (list_empty(&req->req_pending_master_completion))
drivers/block/drbd/drbd_req.c:		list_add_tail(&req->req_pending_master_completion,
drivers/block/drbd/drbd_req.c:			&device->pending_master_completion[rw == WRITE]);
drivers/block/drbd/drbd_req.c:			&device->pending_completion[rw == WRITE]);
drivers/block/drbd/drbd_req.c:		 * So we can not simply free it, we must go through drbd_req_put_completion_ref() */
drivers/block/drbd/drbd_req.c:	drbd_req_put_completion_ref(req, &m, 1);
drivers/block/drbd/drbd_req.c:	 * we hold a completion ref, and the request cannot disappear.
drivers/block/drbd/drbd_req.c:	req_read = list_first_entry_or_null(&device->pending_completion[0], struct drbd_request, req_pending_local);
drivers/block/drbd/drbd_req.c:	req_write = list_first_entry_or_null(&device->pending_completion[1], struct drbd_request, req_pending_local);
drivers/block/drbd/drbd_req.h: *    and completion will be signalled to the originator,
drivers/block/drbd/drbd_req.h:	 *    UNUSED, we could map: 011: submitted, completion still pending
drivers/block/drbd/drbd_req.h:	 * 1001: Aborted (before completion)
drivers/block/drbd/drbd_req.h:	__RQ_COMPLETION_SUSP,
drivers/block/drbd/drbd_req.h:#define RQ_COMPLETION_SUSP (1UL << __RQ_COMPLETION_SUSP)
drivers/block/drbd/drbd_req.h:/* completion of master bio is outside of our spinlock.
drivers/block/drbd/drbd_req.h: * of the lower level driver completion callback, so we need to
drivers/block/drbd/drbd_state.c:	struct completion *done;
drivers/block/drbd/drbd_state.c:	struct completion done;
drivers/block/drbd/drbd_state.c:	init_completion(&done);
drivers/block/drbd/drbd_state.c:		wait_for_completion(&done);
drivers/block/drbd/drbd_state.c: * @done:	Optional completion, that will get completed after the after_state_ch() finished
drivers/block/drbd/drbd_state.c:	        enum chg_state_flags flags, struct completion *done)
drivers/block/drbd/drbd_state.c:			/* Immediately allow completion of all application IO,
drivers/block/drbd/drbd_state.c:			 * that waits for completion from the local disk,
drivers/block/drbd/drbd_state.h:					  struct completion *done);
drivers/block/drbd/drbd_worker.c:	 * If this io completion runs after that timeout expired, this
drivers/block/drbd/drbd_worker.c:	 * completion, or we may (in drbd_al_read_log()) cycle so fast into the
drivers/block/drbd/drbd_worker.c:drbd_panic_after_delayed_completion_of_aborted_request(struct drbd_device *device)
drivers/block/drbd/drbd_worker.c:	panic("drbd%u %s/%u potential random memory corruption caused by delayed completion of aborted local request\n",
drivers/block/drbd/drbd_worker.c:	 * complete requests at all, not even do error completions.  In this
drivers/block/drbd/drbd_worker.c:	 * By "aborting", basically faking a local error-completion,
drivers/block/drbd/drbd_worker.c:	 * Which means delayed successful completion,
drivers/block/drbd/drbd_worker.c:	 * We assume that a delayed *error* completion is OK,
drivers/block/drbd/drbd_worker.c:			drbd_emerg(device, "delayed completion of aborted local request; disk-timeout may be too aggressive\n");
drivers/block/drbd/drbd_worker.c:			drbd_panic_after_delayed_completion_of_aborted_request(device);
drivers/block/floppy.c:#include <linux/completion.h>
drivers/block/floppy.c:static int fd_wait_for_completion(unsigned long expires,
drivers/block/floppy.c:	return fd_wait_for_completion(jiffies + 2UL * HZ / 100, floppy_ready);
drivers/block/floppy.c:		 * again just before spinup completion. Beware that
drivers/block/floppy.c:		if (fd_wait_for_completion(ready_date, function))
drivers/block/floppy.c:	/* wait_for_completion also schedules reset if needed. */
drivers/block/floppy.c:	return fd_wait_for_completion(drive_state[current_drive].select_date + drive_params[current_drive].select_delay,
drivers/block/floppy.c:/* schedules handler, waiting for completion. May be interrupted, will then
drivers/block/floppy.c:/* schedule the request and automatically unlock the driver on completion */
drivers/block/floppy.c:		 * on completion.
drivers/block/floppy.c:	struct completion complete;
drivers/block/floppy.c:	init_completion(&cbdata.complete);
drivers/block/floppy.c:	wait_for_completion(&cbdata.complete);
drivers/block/loop.c:#include <linux/completion.h>
drivers/block/loop.c:static void lo_rw_aio_do_completion(struct loop_cmd *cmd)
drivers/block/loop.c:	lo_rw_aio_do_completion(cmd);
drivers/block/loop.c:	lo_rw_aio_do_completion(cmd);
drivers/block/mtip32xx/mtip32xx.c: * Execute an internal command and wait for the completion.
drivers/block/mtip32xx/mtip32xx.c:	dbg_printk(MTIP_DRV_NAME " %s: Completion Status: stat %x, err %x , cyl_lo %x cyl_hi %x\n",
drivers/block/mtip32xx/mtip32xx.c: * return value -EFAULT An error occurred while copying the completion
drivers/block/mtip32xx/mtip32xx.c:	/* Collect the completion status. */
drivers/block/mtip32xx/mtip32xx.c:		" %s: Completion Status: stat %x, "
drivers/block/mtip32xx/mtip32xx.c:		" %s: Completion: stat %x,"
drivers/block/mtip32xx/mtip32xx.c: * to the device. Upon completion, the callback function will
drivers/block/mtip32xx/mtip32xx.c:		"FTL rebuild in progress. Polling for completion.\n");
drivers/block/mtip32xx/mtip32xx.c:					"Completion workers still active!");
drivers/block/mtip32xx/mtip32xx.c:			"Completion workers still active!\n");
drivers/block/nbd.c:#include <linux/completion.h>
drivers/block/nbd.c: * cleared in completion. Both setting and clearing of the flag are protected
drivers/block/nbd.c:	 * normal completion path
drivers/block/nbd.c:			 * The completion might already have come in,
drivers/block/nbd.c:	 * need to make sure the completion work doesn't mark this request done
drivers/block/nbd.c:	 * freed data if we have particularly fast completions (ie we get the
drivers/block/nbd.c:	 * completion before we exit sock_xmit on the last bvec) or in the case
drivers/block/nbd.c:	 * for the completion of netlink commands.
drivers/block/null_blk/main.c:MODULE_PARM_DESC(irqmode, "IRQ completion handler. 0-none, 1-softirq, 2-timer");
drivers/block/null_blk/main.c:static unsigned long g_completion_nsec = 10000;
drivers/block/null_blk/main.c:module_param_named(completion_nsec, g_completion_nsec, ulong, 0444);
drivers/block/null_blk/main.c:MODULE_PARM_DESC(completion_nsec, "Time in ns to complete a request in hardware. Default: 10,000ns");
drivers/block/null_blk/main.c:NULLB_DEVICE_ATTR(completion_nsec, ulong, NULL);
drivers/block/null_blk/main.c:	&nullb_device_attr_completion_nsec,
drivers/block/null_blk/main.c:			"completion_nsec,discard,home_node,hw_queue_depth,"
drivers/block/null_blk/main.c:	dev->completion_nsec = g_completion_nsec;
drivers/block/null_blk/main.c:	ktime_t kt = cmd->nq->dev->completion_nsec;
drivers/block/null_blk/null_blk.h:	unsigned long completion_nsec; /* time in ns to complete a request */
drivers/block/null_blk/null_blk.h:	unsigned int irqmode; /* IRQ completion handler */
drivers/block/pktcdvd.c: * wait for completion.
drivers/block/ps3vram.c:#define NOTIFIER 7	/* notifier used for completion report */
drivers/block/rbd.c:	struct completion	acquire_wait;
drivers/block/rbd.c:	struct completion	quiescing_wait;
drivers/block/rbd.c:	if (!completion_done(&rbd_dev->acquire_wait)) {
drivers/block/rbd.c:	rbd_assert(!completion_done(&rbd_dev->quiescing_wait));
drivers/block/rbd.c:	wait_for_completion(&rbd_dev->quiescing_wait);
drivers/block/rbd.c:	init_completion(&rbd_dev->acquire_wait);
drivers/block/rbd.c:	init_completion(&rbd_dev->quiescing_wait);
drivers/block/rbd.c:	ret = wait_for_completion_killable_timeout(&rbd_dev->acquire_wait,
drivers/block/rnbd/rnbd-srv.c:	DECLARE_COMPLETION_ONSTACK(dc);
drivers/block/rnbd/rnbd-srv.c:	wait_for_completion(&dc); /* wait for inflights to drop to zero */
drivers/block/rnbd/rnbd-srv.h:	struct completion               *destroy_comp;
drivers/block/rnull.rs://! - direct completion
drivers/block/sunvdc.c:#include <linux/completion.h>
drivers/block/sunvdc.c:	struct vdc_completion	*cmp;
drivers/block/sunvdc.c:	struct vio_completion comp;
drivers/block/sunvdc.c:	init_completion(&comp.com);
drivers/block/sunvdc.c:		wait_for_completion(&comp.com);
drivers/block/sunvdc.c:	struct vio_completion comp;
drivers/block/sunvdc.c:	init_completion(&comp.com);
drivers/block/sunvdc.c:	wait_for_completion(&comp.com);
drivers/block/ublk_drv.c:#include <linux/completion.h>
drivers/block/ublk_drv.c:	struct completion	completion;
drivers/block/ublk_drv.c:/* todo: handle partial completion */
drivers/block/ublk_drv.c:static void ublk_commit_completion(struct ublk_device *ub,
drivers/block/ublk_drv.c:		complete_all(&ub->completion);
drivers/block/ublk_drv.c:		ublk_commit_completion(ub, ub_cmd);
drivers/block/ublk_drv.c:	init_completion(&ub->completion);
drivers/block/ublk_drv.c:	if (wait_for_completion_interruptible(&ub->completion) != 0)
drivers/block/ublk_drv.c:	init_completion(&ub->completion);
drivers/block/ublk_drv.c:	if (wait_for_completion_interruptible(&ub->completion))
drivers/block/xen-blkback/blkback.c:		wait_for_completion_interruptible_timeout(
drivers/block/xen-blkback/common.h:	struct completion	drain_complete;
drivers/block/xen-blkback/xenbus.c:	init_completion(&blkif->drain_complete);
drivers/block/xen-blkfront.c:	 * completion more easy to handle even if the block I/O request is
drivers/block/xen-blkfront.c:static int blkif_completion(unsigned long *id,
drivers/block/xen-blkfront.c:		 * to make the completion code simpler.
drivers/block/xen-blkfront.c:			ret = blkif_completion(&id, rinfo, &bret);
drivers/block/xen-blkfront.c:	 * revoked in blkif_completion or else an error is reported and the
drivers/bluetooth/btintel_pcie.h: * @cr_msi_vec: Completion Ring MSI-X Vector
drivers/bluetooth/btintel_pcie.h: * @cmpl_count: Completion count. Always 0x01
drivers/bluetooth/btintel_pcie.h: * @immediate_cmpl: Immediate completion flag: Always 0x01
drivers/bluetooth/btmtk.c:	 * will clear that state and with that indicate completion of the
drivers/bluetooth/btmtksdio.c:	 * will clear that state and with that indicate completion of the
drivers/bluetooth/btmtkuart.c:	 * will clear that state and with that indicate completion of the
drivers/bluetooth/hci_bcm4377.c:#include <linux/completion.h>
drivers/bluetooth/hci_bcm4377.c:#define BCM4377_N_COMPLETION_RINGS 6
drivers/bluetooth/hci_bcm4377.c:enum bcm4377_completion_ring_id {
drivers/bluetooth/hci_bcm4377.c: * id: Message id to recognize the answer in the completion ring entry
drivers/bluetooth/hci_bcm4377.c: * Completion ring entry
drivers/bluetooth/hci_bcm4377.c:struct bcm4377_completion_ring_entry {
drivers/bluetooth/hci_bcm4377.c:static_assert(sizeof(struct bcm4377_completion_ring_entry) == 0x10);
drivers/bluetooth/hci_bcm4377.c:	BCM4377_CONTROL_MSG_CREATE_COMPLETION_RING = 2,
drivers/bluetooth/hci_bcm4377.c:	BCM4377_CONTROL_MSG_DESTROY_COMPLETION_RING = 4,
drivers/bluetooth/hci_bcm4377.c: * Control message used to create a completion ring
drivers/bluetooth/hci_bcm4377.c: * msg_type: Must be BCM4377_CONTROL_MSG_CREATE_COMPLETION_RING
drivers/bluetooth/hci_bcm4377.c: * id/id_again: Completion ring index
drivers/bluetooth/hci_bcm4377.c:struct bcm4377_create_completion_ring_msg {
drivers/bluetooth/hci_bcm4377.c:static_assert(sizeof(struct bcm4377_create_completion_ring_msg) ==
drivers/bluetooth/hci_bcm4377.c: * Control ring message used to destroy a completion ring
drivers/bluetooth/hci_bcm4377.c: * msg_type: Must be BCM4377_CONTROL_MSG_DESTROY_COMPLETION_RING
drivers/bluetooth/hci_bcm4377.c: * ring_id: Completion ring to be destroyed
drivers/bluetooth/hci_bcm4377.c:struct bcm4377_destroy_completion_ring_msg {
drivers/bluetooth/hci_bcm4377.c:static_assert(sizeof(struct bcm4377_destroy_completion_ring_msg) ==
drivers/bluetooth/hci_bcm4377.c: * completion_ring_id: Completion ring index for acknowledgements and events
drivers/bluetooth/hci_bcm4377.c: *                     corresponding completion ring is used
drivers/bluetooth/hci_bcm4377.c:	__le16 completion_ring_id;
drivers/bluetooth/hci_bcm4377.c: * {completion,xfer}_ring_{tails,heads}_addr: DMA pointers to ring heads/tails
drivers/bluetooth/hci_bcm4377.c: * n_completion_rings: Number of completion rings, the firmware only works if
drivers/bluetooth/hci_bcm4377.c: *                     this is set to BCM4377_N_COMPLETION_RINGS.
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_addr: Control completion ring buffer DMA address
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_n_entries: Number of control completion ring entries
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_doorbell: Control completion ring doorbell,
drivers/bluetooth/hci_bcm4377.c: * control_xfer_ring_msi: Control completion ring MSI index, must be 0
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_msi: Control completion ring MSI index, must be 0.
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_header_size: Number of 32 bit words reserved in front
drivers/bluetooth/hci_bcm4377.c: *                                      of every control completion ring entry
drivers/bluetooth/hci_bcm4377.c: * control_completion_ring_footer_size: Number of 32 bit words reserved after
drivers/bluetooth/hci_bcm4377.c: *                                      every control completion ring entry
drivers/bluetooth/hci_bcm4377.c:	__le64 completion_ring_heads_addr;
drivers/bluetooth/hci_bcm4377.c:	__le64 completion_ring_tails_addr;
drivers/bluetooth/hci_bcm4377.c:	__le16 n_completion_rings;
drivers/bluetooth/hci_bcm4377.c:	__le64 control_completion_ring_addr;
drivers/bluetooth/hci_bcm4377.c:	__le16 control_completion_ring_n_entries;
drivers/bluetooth/hci_bcm4377.c:	__le16 control_completion_ring_doorbell;
drivers/bluetooth/hci_bcm4377.c:	__le16 control_completion_ring_msi;
drivers/bluetooth/hci_bcm4377.c:	u8 control_completion_ring_header_size;
drivers/bluetooth/hci_bcm4377.c:	u8 control_completion_ring_footer_size;
drivers/bluetooth/hci_bcm4377.c:	__le16 completion_ring_head[BCM4377_N_COMPLETION_RINGS];
drivers/bluetooth/hci_bcm4377.c:	__le16 completion_ring_tail[BCM4377_N_COMPLETION_RINGS];
drivers/bluetooth/hci_bcm4377.c: *     in the corresponding completion ring
drivers/bluetooth/hci_bcm4377.c: *     of the completion ring the transfer ring can be configured to be
drivers/bluetooth/hci_bcm4377.c: * completion_ring: index of corresponding completion ring
drivers/bluetooth/hci_bcm4377.c: *          setup a corresponding completion ring for device->host messages
drivers/bluetooth/hci_bcm4377.c: *                   buffers used by device->host messages in the completion
drivers/bluetooth/hci_bcm4377.c: * events: pointer to array of completions if waiting is allowed
drivers/bluetooth/hci_bcm4377.c:	u8 completion_ring;
drivers/bluetooth/hci_bcm4377.c:	struct completion **events;
drivers/bluetooth/hci_bcm4377.c: * A completion ring can be either used to either acknowledge messages sent in
drivers/bluetooth/hci_bcm4377.c: * ring_id: completion ring id, hardcoded in firmware
drivers/bluetooth/hci_bcm4377.c: * ring: ring buffer for entries (struct bcm4377_completion_ring_entry)
drivers/bluetooth/hci_bcm4377.c:struct bcm4377_completion_ring {
drivers/bluetooth/hci_bcm4377.c:	enum bcm4377_completion_ring_id ring_id;
drivers/bluetooth/hci_bcm4377.c: * {control,hci_acl,sco}_ack_ring: Completion rings used to acknowledge messages
drivers/bluetooth/hci_bcm4377.c: * {hci_acl,sco}_event_ring: Completion rings used for device->host messages
drivers/bluetooth/hci_bcm4377.c: *                         corresponding completion ring
drivers/bluetooth/hci_bcm4377.c:	struct completion event;
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring control_ack_ring;
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring hci_acl_ack_ring;
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring hci_acl_event_ring;
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring sco_ack_ring;
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring sco_event_ring;
drivers/bluetooth/hci_bcm4377.c:static void bcm4377_handle_completion(struct bcm4377_data *bcm4377,
drivers/bluetooth/hci_bcm4377.c:				      struct bcm4377_completion_ring *ring,
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_completion_ring_entry *entry;
drivers/bluetooth/hci_bcm4377.c:			 "invalid offset %d for completion ring %d\n", pos,
drivers/bluetooth/hci_bcm4377.c:			"invalid entry at offset %d for transfer ring %d in completion ring %d\n",
drivers/bluetooth/hci_bcm4377.c:		"entry in completion ring %d for transfer ring %d with msg_id %d\n",
drivers/bluetooth/hci_bcm4377.c:			"entry in completion ring %d for unknown transfer ring %d with msg_id %d\n",
drivers/bluetooth/hci_bcm4377.c:static void bcm4377_poll_completion_ring(struct bcm4377_data *bcm4377,
drivers/bluetooth/hci_bcm4377.c:					 struct bcm4377_completion_ring *ring)
drivers/bluetooth/hci_bcm4377.c:	__le16 *heads = bcm4377->ring_state->completion_ring_head;
drivers/bluetooth/hci_bcm4377.c:	__le16 *tails = bcm4377->ring_state->completion_ring_tail;
drivers/bluetooth/hci_bcm4377.c:		"completion ring #%d: head: %d, tail: %d\n", ring->ring_id,
drivers/bluetooth/hci_bcm4377.c:		bcm4377_handle_completion(bcm4377, ring, tail);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_poll_completion_ring(bcm4377, &bcm4377->control_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_poll_completion_ring(bcm4377, &bcm4377->hci_acl_event_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_poll_completion_ring(bcm4377, &bcm4377->hci_acl_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_poll_completion_ring(bcm4377, &bcm4377->sco_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_poll_completion_ring(bcm4377, &bcm4377->sco_event_ring);
drivers/bluetooth/hci_bcm4377.c:	DECLARE_COMPLETION_ONSTACK(event);
drivers/bluetooth/hci_bcm4377.c:		ret = wait_for_completion_interruptible_timeout(
drivers/bluetooth/hci_bcm4377.c:static int bcm4377_create_completion_ring(struct bcm4377_data *bcm4377,
drivers/bluetooth/hci_bcm4377.c:					  struct bcm4377_completion_ring *ring)
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_create_completion_ring_msg msg;
drivers/bluetooth/hci_bcm4377.c:			 "completion ring %d already enabled\n", ring->ring_id);
drivers/bluetooth/hci_bcm4377.c:	       ring->n_entries * (sizeof(struct bcm4377_completion_ring_entry) +
drivers/bluetooth/hci_bcm4377.c:	msg.msg_type = BCM4377_CONTROL_MSG_CREATE_COMPLETION_RING;
drivers/bluetooth/hci_bcm4377.c:static int bcm4377_destroy_completion_ring(struct bcm4377_data *bcm4377,
drivers/bluetooth/hci_bcm4377.c:					   struct bcm4377_completion_ring *ring)
drivers/bluetooth/hci_bcm4377.c:	struct bcm4377_destroy_completion_ring_msg msg;
drivers/bluetooth/hci_bcm4377.c:	msg.msg_type = BCM4377_CONTROL_MSG_DESTROY_COMPLETION_RING;
drivers/bluetooth/hci_bcm4377.c:			 "failed to destroy completion ring %d\n",
drivers/bluetooth/hci_bcm4377.c:	msg.completion_ring_id = cpu_to_le16(ring->completion_ring);
drivers/bluetooth/hci_bcm4377.c:	 * to reply by acknowledging them in the completion ring
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_create_completion_ring(bcm4377,
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_create_completion_ring(bcm4377,
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_create_completion_ring(bcm4377, &bcm4377->sco_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_create_completion_ring(bcm4377, &bcm4377->sco_event_ring);
drivers/bluetooth/hci_bcm4377.c:		"all completion rings successfully created!\n");
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->sco_event_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->sco_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->hci_acl_event_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->hci_acl_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->sco_event_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->sco_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->hci_acl_event_ring);
drivers/bluetooth/hci_bcm4377.c:	bcm4377_destroy_completion_ring(bcm4377, &bcm4377->hci_acl_ack_ring);
drivers/bluetooth/hci_bcm4377.c:static int bcm4377_alloc_completion_ring(struct bcm4377_data *bcm4377,
drivers/bluetooth/hci_bcm4377.c:					 struct bcm4377_completion_ring *ring)
drivers/bluetooth/hci_bcm4377.c:		     sizeof(struct bcm4377_completion_ring_entry);
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->completion_ring_heads_addr = cpu_to_le64(
drivers/bluetooth/hci_bcm4377.c:		offsetof(struct bcm4377_ring_state, completion_ring_head));
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->completion_ring_tails_addr = cpu_to_le64(
drivers/bluetooth/hci_bcm4377.c:		offsetof(struct bcm4377_ring_state, completion_ring_tail));
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->n_completion_rings =
drivers/bluetooth/hci_bcm4377.c:		cpu_to_le16(BCM4377_N_COMPLETION_RINGS);
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_addr =
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_n_entries =
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_doorbell = cpu_to_le16(0xffff);
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_msi = 0;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_header_size = 0;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->ctx->control_completion_ring_footer_size = 0;
drivers/bluetooth/hci_bcm4377.c:	 * and completion ring ids and their mapping (e.g. both HCI and ACL
drivers/bluetooth/hci_bcm4377.c:	 * entries will always be queued in completion rings 1 and 2 no matter
drivers/bluetooth/hci_bcm4377.c:	bcm4377->control_h2d_ring.completion_ring = BCM4377_ACK_RING_CONTROL;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->hci_h2d_ring.completion_ring = BCM4377_ACK_RING_HCI_ACL;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->hci_d2h_ring.completion_ring = BCM4377_EVENT_RING_HCI_ACL;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->sco_h2d_ring.completion_ring = BCM4377_ACK_RING_SCO;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->sco_d2h_ring.completion_ring = BCM4377_EVENT_RING_SCO;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->acl_h2d_ring.completion_ring = BCM4377_ACK_RING_HCI_ACL;
drivers/bluetooth/hci_bcm4377.c:	bcm4377->acl_d2h_ring.completion_ring = BCM4377_EVENT_RING_HCI_ACL;
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_alloc_completion_ring(bcm4377,
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_alloc_completion_ring(bcm4377,
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_alloc_completion_ring(bcm4377,
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_alloc_completion_ring(bcm4377, &bcm4377->sco_ack_ring);
drivers/bluetooth/hci_bcm4377.c:	ret = bcm4377_alloc_completion_ring(bcm4377, &bcm4377->sco_event_ring);
drivers/bluetooth/hci_bcm4377.c:	ret = wait_for_completion_interruptible_timeout(&bcm4377->event,
drivers/bluetooth/hci_bcm4377.c:	ret = wait_for_completion_interruptible_timeout(&bcm4377->event,
drivers/bluetooth/hci_bcm4377.c:	ret = wait_for_completion_interruptible_timeout(&bcm4377->event,
drivers/bluetooth/hci_bcm4377.c:	init_completion(&bcm4377->event);
drivers/bluetooth/hci_nokia.c:	struct completion init_completion;
drivers/bluetooth/hci_nokia.c:	init_completion(&btdev->init_completion);
drivers/bluetooth/hci_nokia.c:	if (!wait_for_completion_interruptible_timeout(&btdev->init_completion,
drivers/bluetooth/hci_nokia.c:	init_completion(&btdev->init_completion);
drivers/bluetooth/hci_nokia.c:	if (!wait_for_completion_interruptible_timeout(&btdev->init_completion,
drivers/bluetooth/hci_nokia.c:	complete(&btdev->init_completion);
drivers/bluetooth/hci_nokia.c:	complete(&btdev->init_completion);
drivers/bluetooth/hci_qca.c:#include <linux/completion.h>
drivers/bluetooth/hci_qca.c:	struct completion drop_ev_comp;
drivers/bluetooth/hci_qca.c:	init_completion(&qca->drop_ev_comp);
drivers/bluetooth/hci_qca.c:			reinit_completion(&qca->drop_ev_comp);
drivers/bluetooth/hci_qca.c:			if (!wait_for_completion_timeout(&qca->drop_ev_comp,
drivers/bus/arm-cci.c:	/* poll the status reg for completion */
drivers/bus/fsl-mc/mc-sys.c: * Timeout in milliseconds to wait for the completion of an MC command
drivers/bus/fsl-mc/mc-sys.c:#define MC_CMD_COMPLETION_TIMEOUT_MS	500
drivers/bus/fsl-mc/mc-sys.c: * iterations while waiting for MC command completion
drivers/bus/fsl-mc/mc-sys.c:#define MC_CMD_COMPLETION_POLLING_MIN_SLEEP_USECS    10
drivers/bus/fsl-mc/mc-sys.c:#define MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS    500
drivers/bus/fsl-mc/mc-sys.c: * mc_polling_wait_preemptible() - Waits for the completion of an MC
drivers/bus/fsl-mc/mc-sys.c: * @mc_status: MC command completion status
drivers/bus/fsl-mc/mc-sys.c:		jiffies + msecs_to_jiffies(MC_CMD_COMPLETION_TIMEOUT_MS);
drivers/bus/fsl-mc/mc-sys.c:		 * TODO: When MC command completion interrupts are supported
drivers/bus/fsl-mc/mc-sys.c:		usleep_range(MC_CMD_COMPLETION_POLLING_MIN_SLEEP_USECS,
drivers/bus/fsl-mc/mc-sys.c:			     MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
drivers/bus/fsl-mc/mc-sys.c: * mc_polling_wait_atomic() - Waits for the completion of an MC command
drivers/bus/fsl-mc/mc-sys.c: * @mc_status: MC command completion status
drivers/bus/fsl-mc/mc-sys.c:	unsigned long timeout_usecs = MC_CMD_COMPLETION_TIMEOUT_MS * 1000;
drivers/bus/fsl-mc/mc-sys.c:	BUILD_BUG_ON((MC_CMD_COMPLETION_TIMEOUT_MS * 1000) %
drivers/bus/fsl-mc/mc-sys.c:		     MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS != 0);
drivers/bus/fsl-mc/mc-sys.c:		udelay(MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
drivers/bus/fsl-mc/mc-sys.c:		timeout_usecs -= MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS;
drivers/bus/mhi/common.h:/* Command Completion event */
drivers/bus/mhi/common.h:	MHI_PKT_TYPE_CMD_COMPLETION_EVENT = 0x21,
drivers/bus/mhi/common.h:/* MHI transfer completion events */
drivers/bus/mhi/ep/main.c:static int mhi_ep_send_completion_event(struct mhi_ep_cntrl *mhi_cntrl, struct mhi_ep_ring *ring,
drivers/bus/mhi/ep/main.c:	event->dword[1] = MHI_CC_EV_DWORD1(MHI_PKT_TYPE_CMD_COMPLETION_EVENT);
drivers/bus/mhi/ep/main.c:					dev_err(dev, "Error sending completion event: %d\n", ret);
drivers/bus/mhi/ep/main.c:			dev_err(dev, "Error sending command completion event (%u)\n",
drivers/bus/mhi/ep/main.c:			dev_err(dev, "Error sending command completion event (%u)\n",
drivers/bus/mhi/ep/main.c:			dev_err(dev, "Error sending command completion event (%u)\n",
drivers/bus/mhi/ep/main.c:static void mhi_ep_read_completion(struct mhi_ep_buf_info *buf_info)
drivers/bus/mhi/ep/main.c:			 * it expects the completion event for all TREs of a TD.
drivers/bus/mhi/ep/main.c:				ret = mhi_ep_send_completion_event(mhi_cntrl, ring, el,
drivers/bus/mhi/ep/main.c:			 * for the last TRE of the TD and expects the completion event for
drivers/bus/mhi/ep/main.c:				ret = mhi_ep_send_completion_event(mhi_cntrl, ring, el,
drivers/bus/mhi/ep/main.c:		buf_info.cb = mhi_ep_read_completion;
drivers/bus/mhi/ep/main.c:static void mhi_ep_skb_completion(struct mhi_ep_buf_info *buf_info)
drivers/bus/mhi/ep/main.c:	ret = mhi_ep_send_completion_event(mhi_cntrl, ring, el, buf_info->size,
drivers/bus/mhi/ep/main.c:		dev_err(dev, "Error sending transfer completion event\n");
drivers/bus/mhi/ep/main.c:		buf_info.cb = mhi_ep_skb_completion;
drivers/bus/mhi/ep/main.c:		 * will be updated by the completion handler.
drivers/bus/mhi/host/boot.c:	 * image download completion.
drivers/bus/mhi/host/init.c:		init_completion(&mhi_chan->completion);
drivers/bus/mhi/host/init.c:		/* Wake all threads waiting for completion */
drivers/bus/mhi/host/init.c:		complete_all(&mhi_chan->completion);
drivers/bus/mhi/host/internal.h:	struct completion completion;
drivers/bus/mhi/host/main.c:	 * Note: We're arbitrarily incrementing RP even though, completion
drivers/bus/mhi/host/main.c:	 * receive, so even though completion event is different we can re-use
drivers/bus/mhi/host/main.c:	 * The completion event we just serviced is descriptor C.
drivers/bus/mhi/host/main.c:	 * even though host did not receive any completions.
drivers/bus/mhi/host/main.c:static void mhi_process_cmd_completion(struct mhi_controller *mhi_cntrl,
drivers/bus/mhi/host/main.c:		complete(&mhi_chan->completion);
drivers/bus/mhi/host/main.c:			"Completion packet for invalid channel ID: %d\n", chan);
drivers/bus/mhi/host/main.c:		case MHI_PKT_TYPE_CMD_COMPLETION_EVENT:
drivers/bus/mhi/host/main.c:			mhi_process_cmd_completion(mhi_cntrl, local_rp);
drivers/bus/mhi/host/main.c:	 * for host->device buffer, balanced put is done on buffer completion
drivers/bus/mhi/host/main.c:	reinit_completion(&mhi_chan->completion);
drivers/bus/mhi/host/main.c:	ret = wait_for_completion_timeout(&mhi_chan->completion,
drivers/bus/mhi/host/main.c:			"%d: Failed to receive %s channel command completion\n",
drivers/bus/mhi/host/pm.c:/* MHI M3 completion handler */
drivers/bus/mhi/host/pm.c:	/* Set MHI to M3 and wait for completion */
drivers/bus/mhi/host/pm.c:	dev_dbg(dev, "Waiting for M3 completion\n");
drivers/bus/mhi/host/pm.c:	/* Set MHI to M0 and wait for completion */
drivers/bus/sunxi-rsb.c:	struct completion complete;
drivers/bus/sunxi-rsb.c:	reinit_completion(&rsb->complete);
drivers/bus/sunxi-rsb.c:		timeout = !wait_for_completion_io_timeout(&rsb->complete,
drivers/bus/sunxi-rsb.c:	init_completion(&rsb->complete);
drivers/bus/ts-nbus.c:	/* wait for completion */
drivers/cdx/controller/mc_cdx_pcol.h: * All MCDI commands support completion by shared memory response. Each
drivers/cdx/controller/mc_cdx_pcol.h: * Some MCDI commands support completion by event, in which any associated
drivers/cdx/controller/mcdi.c: * cdx_mcdi_rpc - Issue an MCDI command and wait for completion
drivers/cdx/controller/mcdi.c: * @complete: Function to be called on completion or cancellation.
drivers/cdx/controller/mcdi.c: * event completions have been disabled due to an error.
drivers/cdx/controller/mcdi.c: * (a) the completion event is received (in process context)
drivers/cdx/controller/mcdi.h: * @cookie: Context for completion function
drivers/cdx/controller/mcdi.h: * @completer: Completion function
drivers/cdx/controller/mcdi.h: * @cmd_complete_wq: Waitqueue for command completion
drivers/cdx/controller/mcdi.h: * @mode: Poll for mcdi completion, or wait for an mcdi_event
drivers/char/apm-emulation.c:#include <linux/completion.h>
drivers/char/hw_random/cctrng.c:#include <linux/completion.h>
drivers/char/hw_random/cctrng.c:static bool cctrng_wait_for_reset_completion(struct cctrng_drvdata *drvdata)
drivers/char/hw_random/cctrng.c:	/* wait for Cryptocell reset completion */
drivers/char/hw_random/cctrng.c:	if (!cctrng_wait_for_reset_completion(drvdata)) {
drivers/char/hw_random/core.c:	reinit_completion(&rng->cleanup_done);
drivers/char/hw_random/core.c:	init_completion(&rng->cleanup_done);
drivers/char/hw_random/core.c:	init_completion(&rng->dying);
drivers/char/hw_random/core.c:	wait_for_completion(&rng->cleanup_done);
drivers/char/hw_random/core.c:	return wait_for_completion_interruptible_timeout(&rng->dying, timeout);
drivers/char/hw_random/core.c:	return wait_for_completion_interruptible_timeout(&rng->dying, 1);
drivers/char/hw_random/imx-rngc.c:#include <linux/completion.h>
drivers/char/hw_random/imx-rngc.c:	struct completion	rng_op_done;
drivers/char/hw_random/imx-rngc.c:	ret = wait_for_completion_timeout(&rngc->rng_op_done,
drivers/char/hw_random/imx-rngc.c:		ret = wait_for_completion_timeout(&rngc->rng_op_done,
drivers/char/hw_random/imx-rngc.c:	init_completion(&rngc->rng_op_done);
drivers/char/hw_random/jh7110-trng.c:#include <linux/completion.h>
drivers/char/hw_random/jh7110-trng.c:	struct completion	random_done;
drivers/char/hw_random/jh7110-trng.c:	struct completion	reseed_done;
drivers/char/hw_random/jh7110-trng.c:		reinit_completion(&trng->random_done);
drivers/char/hw_random/jh7110-trng.c:		if (!wait_for_completion_timeout(&trng->random_done, usecs_to_jiffies(wait_time)))
drivers/char/hw_random/jh7110-trng.c:		reinit_completion(&trng->reseed_done);
drivers/char/hw_random/jh7110-trng.c:		if (!wait_for_completion_timeout(&trng->reseed_done, usecs_to_jiffies(wait_time)))
drivers/char/hw_random/jh7110-trng.c:	init_completion(&trng->random_done);
drivers/char/hw_random/jh7110-trng.c:	init_completion(&trng->reseed_done);
drivers/char/hw_random/timeriomem-rng.c:#include <linux/completion.h>
drivers/char/hw_random/timeriomem-rng.c:	struct completion	completion;
drivers/char/hw_random/timeriomem-rng.c:	 * bail out.  Otherwise, wait for the completion.  If the new data has
drivers/char/hw_random/timeriomem-rng.c:	 * already been generated, the completion should already be available.
drivers/char/hw_random/timeriomem-rng.c:	wait_for_completion(&priv->completion);
drivers/char/hw_random/timeriomem-rng.c:	reinit_completion(&priv->completion);
drivers/char/hw_random/timeriomem-rng.c:	complete(&priv->completion);
drivers/char/hw_random/timeriomem-rng.c:	init_completion(&priv->completion);
drivers/char/hw_random/timeriomem-rng.c:	complete(&priv->completion);
drivers/char/hw_random/virtio-rng.c:	struct completion have_data;
drivers/char/hw_random/virtio-rng.c:	reinit_completion(&vi->have_data);
drivers/char/hw_random/virtio-rng.c:		ret = wait_for_completion_killable(&vi->have_data);
drivers/char/hw_random/virtio-rng.c:	init_completion(&vi->have_data);
drivers/char/ipmi/ipmi_bt_sm.c:#include <linux/ipmi_msgdefs.h>		/* for completion codes */
drivers/char/ipmi/ipmi_bt_sm.c:/* Jam a completion code (probably an error) into a response */
drivers/char/ipmi/ipmi_bt_sm.c:static void force_result(struct si_sm_data *bt, unsigned char completion_code)
drivers/char/ipmi/ipmi_bt_sm.c:	bt->read_data[4] = completion_code;
drivers/char/ipmi/ipmi_bt_sm.c:/* Restart if retries are left, or return an error completion code */
drivers/char/ipmi/ipmi_ipmb.c:		/* Response messages have an added completion code. */
drivers/char/ipmi/ipmi_kcs_sm.c:#include <linux/ipmi_msgdefs.h>		/* for completion codes */
drivers/char/ipmi/ipmi_msghandler.c:	unsigned char	       cc; /* completion code */
drivers/char/ipmi/ipmi_msghandler.c:	 * run_to_completion duplicate of smb_info, smi_info
drivers/char/ipmi/ipmi_msghandler.c:	int run_to_completion;
drivers/char/ipmi/ipmi_msghandler.c:	int run_to_completion = intf->run_to_completion;
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	/* Responses must have a completion code. */
drivers/char/ipmi/ipmi_msghandler.c:		/* record completion code when error */
drivers/char/ipmi/ipmi_msghandler.c:	 * completion code.
drivers/char/ipmi/ipmi_msghandler.c:		msg->data[9] = IPMI_INVALID_CMD_COMPLETION_CODE;
drivers/char/ipmi/ipmi_msghandler.c:		msg->data[4] = IPMI_INVALID_CMD_COMPLETION_CODE;
drivers/char/ipmi/ipmi_msghandler.c:	 * completion code.
drivers/char/ipmi/ipmi_msghandler.c:	int                  run_to_completion = intf->run_to_completion;
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:		if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:		if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	int run_to_completion = intf->run_to_completion;
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	int run_to_completion = intf->run_to_completion;
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:	if (run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:		deliver_err_response(intf, msg, IPMI_TIMEOUT_COMPLETION_CODE);
drivers/char/ipmi/ipmi_msghandler.c:	/* For every registered interface, set it to run to completion. */
drivers/char/ipmi/ipmi_msghandler.c:		intf->run_to_completion = 1;
drivers/char/ipmi/ipmi_msghandler.c:		if (intf->handlers->set_run_to_completion)
drivers/char/ipmi/ipmi_msghandler.c:			intf->handlers->set_run_to_completion(intf->send_info,
drivers/char/ipmi/ipmi_powernv.c:		struct ipmi_smi_msg *msg, u8 completion_code)
drivers/char/ipmi/ipmi_powernv.c:	msg->rsp[2] = completion_code;
drivers/char/ipmi/ipmi_powernv.c:static void ipmi_powernv_set_run_to_completion(void *send_info,
drivers/char/ipmi/ipmi_powernv.c:		bool run_to_completion)
drivers/char/ipmi/ipmi_powernv.c:	.set_run_to_completion	= ipmi_powernv_set_run_to_completion,
drivers/char/ipmi/ipmi_poweroff.c:#include <linux/completion.h>
drivers/char/ipmi/ipmi_poweroff.c:	struct completion *comp = recv_msg->user_msg_data;
drivers/char/ipmi/ipmi_poweroff.c:	struct completion comp;
drivers/char/ipmi/ipmi_poweroff.c:	init_completion(&comp);
drivers/char/ipmi/ipmi_poweroff.c:	wait_for_completion(&comp);
drivers/char/ipmi/ipmi_poweroff.c:	if (rv && rv != IPMI_UNKNOWN_ERR_COMPLETION_CODE)
drivers/char/ipmi/ipmi_poweroff.c:	 * it may be better to ignore IPMI_UNKNOWN_ERR_COMPLETION_CODE
drivers/char/ipmi/ipmi_poweroff.c:	if (rv && rv != IPMI_UNKNOWN_ERR_COMPLETION_CODE) {
drivers/char/ipmi/ipmi_poweroff.c:	/* Use run-to-completion mode, since interrupts may be off. */
drivers/char/ipmi/ipmi_si_intf.c:	 * If true, run the state machine to completion on every send
drivers/char/ipmi/ipmi_si_intf.c:	bool                run_to_completion;
drivers/char/ipmi/ipmi_si_intf.c:	 * Currently, this function is called only in run-to-completion
drivers/char/ipmi/ipmi_si_intf.c:	if (smi_info->run_to_completion) {
drivers/char/ipmi/ipmi_si_intf.c:		 * If we are running to completion, start it.  Upper
drivers/char/ipmi/ipmi_si_intf.c:static void set_run_to_completion(void *send_info, bool i_run_to_completion)
drivers/char/ipmi/ipmi_si_intf.c:	smi_info->run_to_completion = i_run_to_completion;
drivers/char/ipmi/ipmi_si_intf.c:	if (i_run_to_completion)
drivers/char/ipmi/ipmi_si_intf.c:	bool run_to_completion = smi_info->run_to_completion;
drivers/char/ipmi/ipmi_si_intf.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_si_intf.c:	if (!run_to_completion)
drivers/char/ipmi/ipmi_si_intf.c:	.set_run_to_completion  = set_run_to_completion,
drivers/char/ipmi/ipmi_si_intf.c:		/* record completion code */
drivers/char/ipmi/ipmi_si_intf.c:	new_smi->run_to_completion = false;
drivers/char/ipmi/ipmi_smic_sm.c:#include <linux/ipmi_msgdefs.h>		/* for completion codes */
drivers/char/ipmi/ipmi_ssif.c:	struct completion wake_thread;
drivers/char/ipmi/ipmi_ssif.c:		result = wait_for_completion_interruptible(
drivers/char/ipmi/ipmi_ssif.c:		init_completion(&ssif_info->wake_thread);
drivers/char/ipmi/ipmi_ssif.c:		init_completion(&ssif_info->wake_thread);
drivers/char/ipmi/ipmi_watchdog.c:#include <linux/completion.h>
drivers/char/ipmi/ipmi_watchdog.c:static DECLARE_COMPLETION(msg_wait);
drivers/char/ipmi/ipmi_watchdog.c:	wait_for_completion(&msg_wait);
drivers/char/ipmi/ipmi_watchdog.c: * at panic or halt time, in run-to-completion mode, when the caller
drivers/char/ipmi/ipmi_watchdog.c:	wait_for_completion(&msg_wait);
drivers/char/powernv-op-panel.c:	case OPAL_ASYNC_COMPLETION:
drivers/char/random.c:#include <linux/completion.h>
drivers/char/tpm/tpm_tis_i2c_cr50.c:#include <linux/completion.h>
drivers/char/tpm/tpm_tis_i2c_cr50.c:	struct completion tpm_ready;
drivers/char/tpm/tpm_tis_i2c_cr50.c: * Wait for completion interrupt if available, otherwise use a fixed
drivers/char/tpm/tpm_tis_i2c_cr50.c:	if (!wait_for_completion_timeout(&priv->tpm_ready, chip->timeout_a)) {
drivers/char/tpm/tpm_tis_i2c_cr50.c:		reinit_completion(&priv->tpm_ready);
drivers/char/tpm/tpm_tis_i2c_cr50.c:	/* Prepare for completion interrupt */
drivers/char/tpm/tpm_tis_i2c_cr50.c:	/* Prepare for completion interrupt */
drivers/char/tpm/tpm_tis_i2c_cr50.c:	init_completion(&priv->tpm_ready);
drivers/char/tpm/tpm_tis_spi.h:	struct completion ready;
drivers/char/tpm/tpm_tis_spi_cr50.c:#include <linux/completion.h>
drivers/char/tpm/tpm_tis_spi_cr50.c:		remaining = wait_for_completion_timeout(&phy->spi_phy.ready,
drivers/char/tpm/tpm_tis_spi_cr50.c:	init_completion(&phy->ready);
drivers/char/tpm/tpm_tis_spi_main.c:#include <linux/completion.h>
drivers/char/tpm/tpm_tis_spi_main.c:		reinit_completion(&phy->ready);
drivers/char/tpm/tpm_tis_spi_main.c:		reinit_completion(&phy->ready);
drivers/char/tpm/tpm_tis_spi_main.c:	init_completion(&phy->ready);
drivers/char/tpm/xen-tpmfront.c:	/* Wait for completion of any existing command or cancellation */
drivers/char/virtio_console.c:#include <linux/completion.h>
drivers/char/virtio_console.c:static DECLARE_COMPLETION(early_console_added);
drivers/char/xillybus/xillybus_core.c:		 * If partial completion is disallowed, there is no point in
drivers/clk/clk-fixed-rate_test.c:#include <linux/completion.h>
drivers/clk/clk-fixed-rate_test.c: * @hw: fixed rate clk to unregister upon test completion
drivers/clk/clk-fixed-rate_test.c:	struct completion probed;
drivers/clk/clk-fixed-rate_test.c:	init_completion(&ctx->probed);
drivers/clk/clk-fixed-rate_test.c:	KUNIT_ASSERT_NE(test, 0, wait_for_completion_timeout(&ctx->probed, HZ));
drivers/clk/qcom/reset.c:	/* Read back the register to ensure write completion, ignore the value */
drivers/clk/renesas/rcar-gen2-cpg.c:	 * clock change completion.
drivers/clk/renesas/rcar-gen3-cpg.c:	 * clock change completion.
drivers/clk/renesas/rcar-gen4-cpg.c:	 * clock change completion.
drivers/clk/renesas/rcar-gen4-cpg.c:	 * clock change completion.
drivers/comedi/drivers/amplc_pci230.c: * Returns false if AO finished due to completion or error, true if still going.
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_COMPLETION(x)	((x) << 8)
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_NOTPROCESSED	DPR_CMD_COMPLETION(0x00)
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_NOERROR		DPR_CMD_COMPLETION(0x55)
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_ERROR		DPR_CMD_COMPLETION(0xaa)
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_NOTSUPPORTED	DPR_CMD_COMPLETION(0xff)
drivers/comedi/drivers/dt3000.c:#define DPR_CMD_COMPLETION_MASK	DPR_CMD_COMPLETION(0xff)
drivers/comedi/drivers/dt3000.c:		status &= DPR_CMD_COMPLETION_MASK;
drivers/comedi/drivers/jr3_pci.c:			/* Allow 20 ms for completion */
drivers/comedi/drivers/jr3_pci.c:			/* Allow 20 ms for completion */
drivers/comedi/drivers/jr3_pci.c:			/* Allow 40 ms for completion */
drivers/comedi/drivers/jr3_pci.h:	 * command_word0 to indicate successful completion. Alternatively
drivers/comedi/drivers/ni_atmio16d.c:	/* enable interrupts for conversion completion */
drivers/comedi/drivers/plx9080.h:/* DMA Clear Count Mode - count in descriptor cleared on completion */
drivers/comedi/drivers/s626.c:	 * Wait for completion of upload from shadow RAM to
drivers/cpufreq/brcmstb-avs-cpufreq.c:#define AVS_TIMEOUT		300 /* in ms; expected completion is < 10ms */
drivers/cpufreq/brcmstb-avs-cpufreq.c:	struct completion done;
drivers/cpufreq/brcmstb-avs-cpufreq.c:		return wait_for_completion_timeout(&priv->done,
drivers/cpufreq/brcmstb-avs-cpufreq.c:	/* Polling for command completion */
drivers/cpufreq/brcmstb-avs-cpufreq.c:	reinit_completion(&priv->done);
drivers/cpufreq/brcmstb-avs-cpufreq.c:	init_completion(&priv->done);
drivers/cpufreq/cpufreq.c:	struct completion *cmp;
drivers/cpufreq/cpufreq.c:	wait_for_completion(cmp);
drivers/cpufreq/cpufreq.c:	init_completion(&policy->kobj_unregister);
drivers/cpufreq/maple-cpufreq.c:#include <linux/completion.h>
drivers/cpufreq/maple-cpufreq.c:	/* Wait for completion */
drivers/cpufreq/pmac64-cpufreq.c:#include <linux/completion.h>
drivers/cpufreq/pmac64-cpufreq.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/cpufreq/pmac64-cpufreq.c:	wait_for_completion(&comp);
drivers/cpufreq/pmac64-cpufreq.c:	/* Wait for completion */
drivers/cpuidle/sysfs.c:#include <linux/completion.h>
drivers/cpuidle/sysfs.c:	struct completion kobj_unregister;
drivers/cpuidle/sysfs.c:	struct completion kobj_unregister;
drivers/cpuidle/sysfs.c:	wait_for_completion(&device->kobjs[i]->kobj_unregister);
drivers/cpuidle/sysfs.c:		init_completion(&kobj->kobj_unregister);
drivers/cpuidle/sysfs.c:	struct completion kobj_unregister;
drivers/cpuidle/sysfs.c:	init_completion(&kdrv->kobj_unregister);
drivers/cpuidle/sysfs.c:	wait_for_completion(&kdrv->kobj_unregister);
drivers/cpuidle/sysfs.c:	init_completion(&kdev->kobj_unregister);
drivers/cpuidle/sysfs.c:	wait_for_completion(&kdev->kobj_unregister);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-core.c:	reinit_completion(&ce->chanlist[flow].complete);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-core.c:	wait_for_completion_interruptible_timeout(&ce->chanlist[flow].complete,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-core.c:		init_completion(&ce->chanlist[i].complete);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce.h: * @complete:	completion for the current task on this flow
drivers/crypto/allwinner/sun8i-ce/sun8i-ce.h:	struct completion complete;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-core.c:		reinit_completion(&ss->flows[flow].complete);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-core.c:		wait_for_completion_interruptible_timeout(&ss->flows[flow].complete,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-core.c:		init_completion(&ss->flows[i].complete);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:		reinit_completion(&ss->flows[flow].complete);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:		wait_for_completion_interruptible_timeout(&ss->flows[flow].complete,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-prng.c:	reinit_completion(&ss->flows[flow].complete);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-prng.c:	wait_for_completion_interruptible_timeout(&ss->flows[flow].complete,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-prng.c:	 * Since the cryptoengine wait for completion before submitting a new
drivers/crypto/allwinner/sun8i-ss/sun8i-ss.h: * @complete:	completion for the current task on this flow
drivers/crypto/allwinner/sun8i-ss/sun8i-ss.h:	struct completion complete;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	reinit_completion(&mc->chanlist[flow].complete);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	wait_for_completion_interruptible_timeout(&mc->chanlist[flow].complete,
drivers/crypto/amlogic/amlogic-gxl-core.c:		init_completion(&mc->chanlist[i].complete);
drivers/crypto/amlogic/amlogic-gxl.h: * @complete:	completion for the current task on this flow
drivers/crypto/amlogic/amlogic-gxl.h:	struct completion complete;
drivers/crypto/atmel-aes.c:	/* Check for transfer completion. */
drivers/crypto/atmel-i2c.h: * @cbk : pointer to a callback function to be invoked upon completion of this
drivers/crypto/atmel-sha.c:	/* wait for dma completion before can take more data */
drivers/crypto/axis/artpec6_crypto.c:	    struct list_head *completions)
drivers/crypto/axis/artpec6_crypto.c:		list_add_tail(&req->complete_in_progress, completions);
drivers/crypto/axis/artpec6_crypto.c:	/* Perform the completion callbacks without holding the queue lock
drivers/crypto/caam/Kconfig:	  Select number of descriptor completions to queue before
drivers/crypto/caam/Kconfig:	  more descriptor completions are queued without reaching the count
drivers/crypto/caam/blob_gen.c:	struct completion completion;
drivers/crypto/caam/blob_gen.c:	 * Upon completion, desc points to a buffer containing a CAAM job
drivers/crypto/caam/blob_gen.c:	complete(&res->completion);
drivers/crypto/caam/blob_gen.c:	init_completion(&testres.completion);
drivers/crypto/caam/blob_gen.c:		wait_for_completion(&testres.completion);
drivers/crypto/caam/caamalg.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caamalg.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caamalg_qi2.c:	struct completion completion;
drivers/crypto/caam/caamalg_qi2.c:	complete(&res->completion);
drivers/crypto/caam/caamalg_qi2.c:	init_completion(&result.completion);
drivers/crypto/caam/caamalg_qi2.c:		wait_for_completion(&result.completion);
drivers/crypto/caam/caamhash.c:	init_completion(&result.completion);
drivers/crypto/caam/caamhash.c:		wait_for_completion(&result.completion);
drivers/crypto/caam/caamhash.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caamhash.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caampkc.c:/* RSA Job Completion handler */
drivers/crypto/caam/caampkc.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caampkc.c:	 * If no backlog flag, the completion of the request is done
drivers/crypto/caam/caamprng.c:#include <linux/completion.h>
drivers/crypto/caam/caamprng.c:	struct completion done;
drivers/crypto/caam/caamprng.c:	init_completion(&ctx.done);
drivers/crypto/caam/caamprng.c:		wait_for_completion(&ctx.done);
drivers/crypto/caam/caamprng.c:	init_completion(&ctx.done);
drivers/crypto/caam/caamprng.c:		wait_for_completion(&ctx.done);
drivers/crypto/caam/caamrng.c:#include <linux/completion.h>
drivers/crypto/caam/caamrng.c:	struct completion *done;
drivers/crypto/caam/caamrng.c:			     struct completion *done)
drivers/crypto/caam/caamrng.c:	init_completion(done);
drivers/crypto/caam/caamrng.c:		wait_for_completion(done);
drivers/crypto/caam/caamrng.c:	struct completion done;
drivers/crypto/caam/caamrng.c:		struct completion done;
drivers/crypto/caam/jr.c:		goto wait_quiesce_completion;
drivers/crypto/caam/jr.c:wait_quiesce_completion:
drivers/crypto/caam/jr.c:	 * for reset completion status
drivers/crypto/caam/jr.c: * @cbk:  pointer to a callback function to be invoked upon completion
drivers/crypto/caam/key_gen.c:	complete(&res->completion);
drivers/crypto/caam/key_gen.c:	init_completion(&result.completion);
drivers/crypto/caam/key_gen.c:		wait_for_completion(&result.completion);
drivers/crypto/caam/key_gen.h:	struct completion completion;
drivers/crypto/caam/qi.h: * @status: completion status of request (0 - success, non-zero - error code)
drivers/crypto/caam/qi.h: *       responses. The request completion callback would be issued from this
drivers/crypto/cavium/cpt/cpt_hw_types.h: * CPT Completion Enumeration
drivers/crypto/cavium/cpt/cpt_hw_types.h: * each instruction completion produces exactly one result structure.
drivers/crypto/cavium/cpt/cpt_hw_types.h: *  compcode:8 [7:0] Indicates completion/error status of the CPT coprocessor
drivers/crypto/cavium/cpt/cpt_hw_types.h: *	0x0 before ringing the doorbell, and then poll for completion by
drivers/crypto/cavium/cpt/cpt_hw_types.h: *	completion interrupts the suggested scheme is to request a DONEINT on
drivers/crypto/cavium/cpt/cpt_hw_types.h: *	completions; even if a later command is acknowledged first this will
drivers/crypto/cavium/cpt/cpt_hw_types.h: *	not result in missing a completion.
drivers/crypto/cavium/cpt/cptvf.h:	volatile u64 *completion_addr; /* Completion address */
drivers/crypto/cavium/cpt/cptvf_main.c:	/* Read the number of completions */
drivers/crypto/cavium/cpt/cptvf_main.c:		 * scheduled completions for processing
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->out_buffer = kzalloc(COMPLETION_CODE_SIZE, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	*((u64 *)info->out_buffer) = ~((u64)COMPLETION_CODE_INIT);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:					  COMPLETION_CODE_SIZE,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:			COMPLETION_CODE_SIZE);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:				 COMPLETION_CODE_SIZE, DMA_BIDIRECTIONAL);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	kfree_sensitive((void *)info->completion_addr);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		status = (union cpt_res_s *)pentry->completion_addr;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:			pentry->completion_addr = NULL;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		} else if (status->s.compcode == COMPLETION_CODE_INIT) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:				pentry->completion_addr = NULL;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:				(~COMPLETION_CODE_INIT)) &&
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		pentry->completion_addr = NULL;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->completion_addr = kzalloc(sizeof(union cpt_res_s), req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	if (unlikely(!info->completion_addr)) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		dev_err(&pdev->dev, "Unable to allocate memory for completion_addr\n");
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	result = (union cpt_res_s *)info->completion_addr;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	result->s.compcode = COMPLETION_CODE_INIT;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:					       (void *)info->completion_addr,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	pentry->completion_addr = info->completion_addr;
drivers/crypto/cavium/cpt/request_manager.h:#define COMPLETION_CODE_SIZE 8
drivers/crypto/cavium/cpt/request_manager.h:#define COMPLETION_CODE_INIT 0
drivers/crypto/cavium/cpt/request_manager.h:	volatile u64 *completion_addr;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	/* IV, ORH, COMPLETION entries */
drivers/crypto/cavium/nitrox/nitrox_aead.c:	/* Allocate buffer to hold ORH, COMPLETION and output scatterlist
drivers/crypto/cavium/nitrox/nitrox_common.h:			      completion_t cb,
drivers/crypto/cavium/nitrox/nitrox_csr.h: * by AE engines for which completion interrupt is asserted.
drivers/crypto/cavium/nitrox/nitrox_csr.h: * @resend: Bit to request completion interrupt Resend.
drivers/crypto/cavium/nitrox/nitrox_csr.h: * @completion_status: Command completion status of the ring.
drivers/crypto/cavium/nitrox/nitrox_csr.h:		u64 completion_status : 1;
drivers/crypto/cavium/nitrox/nitrox_csr.h:		u64 completion_status : 1;
drivers/crypto/cavium/nitrox/nitrox_dev.h: * @compl_cnt_csr_addr: completion count register address of the slc port
drivers/crypto/cavium/nitrox/nitrox_hal.c:		/* set command completion threshold */
drivers/crypto/cavium/nitrox/nitrox_lib.c:		/* packet solicit port completion count address */
drivers/crypto/cavium/nitrox/nitrox_req.h:typedef void (*sereq_completion_t)(void *req, int err);
drivers/crypto/cavium/nitrox/nitrox_req.h: * @comp: completion address
drivers/crypto/cavium/nitrox/nitrox_req.h:	sereq_completion_t callback;
drivers/crypto/cavium/nitrox/nitrox_req.h:/* Completion bytes Length */
drivers/crypto/cavium/nitrox/nitrox_req.h:	u64 *completion;
drivers/crypto/cavium/nitrox/nitrox_req.h:typedef void (*completion_t)(void *arg, int err);
drivers/crypto/cavium/nitrox/nitrox_req.h: * @callback: callback after request completion/timeout
drivers/crypto/cavium/nitrox/nitrox_req.h:	completion_t callback;
drivers/crypto/cavium/nitrox/nitrox_req.h:	 * | ORH | IV | DST sg entries | COMPLETION Bytes|
drivers/crypto/cavium/nitrox/nitrox_req.h:	/* COMPLETION Bytes */
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c: *   Completion with no error
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c: * @callback: Completion callback
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c: * @cb_arg: Completion callback arguments
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:			      completion_t callback,
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->resp.completion = req->comp;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	while (READ_ONCE(*sr->resp.completion) == PENDING_SIG) {
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	completion_t callback;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:		/* check orh and completion bytes updates */
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	/* read completion count */
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	 * MSI-X interrupt generates if Completion count > Threshold
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	/* Allocate buffer to hold ORH, COMPLETION and output scatterlist
drivers/crypto/cavium/zip/common.h: * @compcode:            Completion status of the ZIP invocation
drivers/crypto/cavium/zip/zip_deflate.c:	/* Clearing completion code */
drivers/crypto/cavium/zip/zip_deflate.c:	/* Wait for completion or error */
drivers/crypto/cavium/zip/zip_inflate.c:	/* Clearing completion code */
drivers/crypto/cavium/zip/zip_inflate.c:	/* Wait for completion or error */
drivers/crypto/cavium/zip/zip_regs.h:/* ZIP invocation result completion status codes */
drivers/crypto/cavium/zip/zip_regs.h:/* Successful completion. */
drivers/crypto/ccp/ccp-crypto-main.c:	 * the completion callbacks and retrieve the next cmd (cmd with
drivers/crypto/ccp/ccp-crypto-main.c:	/* Completion callbacks */
drivers/crypto/ccp/ccp-crypto-main.c:	 * completion callback for the request and the req pointer
drivers/crypto/ccp/ccp-debugfs.c:	if (regval & INT_COMPLETION)
drivers/crypto/ccp/ccp-debugfs.c:		oboff += OSCNPRINTF(" COMPLETION");
drivers/crypto/ccp/ccp-dev.c:	struct completion completion;
drivers/crypto/ccp/ccp-dev.c: * called to notify the caller of completion (if the cmd was not
drivers/crypto/ccp/ccp-dev.c:	complete(&tdata->completion);
drivers/crypto/ccp/ccp-dev.c:		/* Schedule the completion callback */
drivers/crypto/ccp/ccp-dev.c:		init_completion(&tdata.completion);
drivers/crypto/ccp/ccp-dev.c:		wait_for_completion(&tdata.completion);
drivers/crypto/ccp/ccp-dev.h:#define INT_COMPLETION			0x1
drivers/crypto/ccp/ccp-dev.h:#define SUPPORTED_INTERRUPTS		(INT_COMPLETION | INT_ERROR)
drivers/crypto/ccp/ccp-dev.h:	 * backlog list is needed so that the backlog completion call
drivers/crypto/ccp/ccp-dmaengine.c:		/* Check for DMA descriptor completion */
drivers/crypto/ccp/sev-dev.c:	/* Check if it is command completion: */
drivers/crypto/ccp/sev-dev.c:	/* Check if it is SEV command completion: */
drivers/crypto/ccp/sev-dev.c:	 * so the PSP command completion interrupt can't be used. Poll for
drivers/crypto/ccp/sev-dev.c:	 * PSP command completion instead.
drivers/crypto/ccp/sev-dev.c:		/* Poll for SEV command completion: */
drivers/crypto/ccp/sev-dev.c:	 * After command completion, the command buffer needs to be put back
drivers/crypto/ccp/sev-dev.c:	 * the PSP command completion interrupt can't be used.
drivers/crypto/ccp/sev-dev.c:	 * polls for PSP command completion.  Ensure we do not request an
drivers/crypto/ccp/sev-dev.c:	/* wait for command completion */
drivers/crypto/ccp/tee-dev.c:static int tee_wait_cmd_completion(struct psp_tee_device *tee,
drivers/crypto/ccp/tee-dev.c:	ret = tee_wait_cmd_completion(tee, resp, TEE_DEFAULT_RING_TIMEOUT);
drivers/crypto/ccree/cc_aead.c:		/* read the digest result with setting the completion bit
drivers/crypto/ccree/cc_aead.c:		/* read the digest result with setting the completion bit
drivers/crypto/ccree/cc_buffer_mgr.c:			 * simplify MAC verification upon request completion
drivers/crypto/ccree/cc_buffer_mgr.c:		 * MAC verification upon request completion
drivers/crypto/ccree/cc_driver.c:	/* Completion interrupt - most probable */
drivers/crypto/ccree/cc_driver.c:		/* Mask all completion interrupts - will be unmasked in
drivers/crypto/ccree/cc_driver.c:		dev_dbg(dev, "AXI completion error: axim_mon_err=0x%08X\n",
drivers/crypto/ccree/cc_driver.c:bool cc_wait_for_reset_completion(struct cc_drvdata *drvdata)
drivers/crypto/ccree/cc_driver.c:	/* 712/710/63 has no reset completion indication, always return true */
drivers/crypto/ccree/cc_driver.c:	init_completion(&new_drvdata->hw_queue_avail);
drivers/crypto/ccree/cc_driver.c:	/* Wait for Cryptocell reset completion */
drivers/crypto/ccree/cc_driver.c:	if (!cc_wait_for_reset_completion(new_drvdata)) {
drivers/crypto/ccree/cc_driver.h:	struct completion seq_compl; /* request completion */
drivers/crypto/ccree/cc_driver.h:	struct completion hw_queue_avail; /* wait for HW queue availability */
drivers/crypto/ccree/cc_driver.h:bool cc_wait_for_reset_completion(struct cc_drvdata *drvdata);
drivers/crypto/ccree/cc_fips.c:	 * unmask AXI completion interrupt.
drivers/crypto/ccree/cc_hash.c:	struct completion setkey_comp;
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_IRR_DSCRPTR_COMPLETION_LOW_INT_BIT_SHIFT	0x2UL
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_IRR_DSCRPTR_COMPLETION_LOW_INT_BIT_SIZE	0x1UL
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_IMR_DSCRPTR_COMPLETION_MASK_BIT_SHIFT	0x2UL
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_IMR_DSCRPTR_COMPLETION_MASK_BIT_SIZE	0x1UL
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_ICR_DSCRPTR_COMPLETION_BIT_SHIFT	0x2UL
drivers/crypto/ccree/cc_host_regs.h:#define CC_HOST_ICR_DSCRPTR_COMPLETION_BIT_SIZE	0x1UL
drivers/crypto/ccree/cc_kernel_regs.h:#define CC_DSCRPTR_COMPLETION_COUNTER_REG_OFFSET	0xE00UL
drivers/crypto/ccree/cc_kernel_regs.h:#define CC_DSCRPTR_COMPLETION_COUNTER_COMPLETION_COUNTER_BIT_SHIFT	0x0UL
drivers/crypto/ccree/cc_kernel_regs.h:#define CC_DSCRPTR_COMPLETION_COUNTER_COMPLETION_COUNTER_BIT_SIZE	0x6UL
drivers/crypto/ccree/cc_kernel_regs.h:#define CC_DSCRPTR_COMPLETION_COUNTER_OVERFLOW_COUNTER_BIT_SHIFT	0x6UL
drivers/crypto/ccree/cc_kernel_regs.h:#define CC_DSCRPTR_COMPLETION_COUNTER_OVERFLOW_COUNTER_BIT_SIZE	0x1UL
drivers/crypto/ccree/cc_pm.c:	/* wait for Cryptocell reset completion */
drivers/crypto/ccree/cc_pm.c:	if (!cc_wait_for_reset_completion(drvdata)) {
drivers/crypto/ccree/cc_request_mgr.c:	dev_dbg(dev, "Initializing completion workqueue\n");
drivers/crypto/ccree/cc_request_mgr.c:	dev_dbg(dev, "Initializing completion tasklet\n");
drivers/crypto/ccree/cc_request_mgr.c:	/* Allocate DMA word for "dummy" completion descriptor use */
drivers/crypto/ccree/cc_request_mgr.c:	/* Init. "dummy" completion descriptor */
drivers/crypto/ccree/cc_request_mgr.c: * request_mgr_complete() - Completion will take place if and only if user
drivers/crypto/ccree/cc_request_mgr.c: * requested completion by cc_send_sync_request().
drivers/crypto/ccree/cc_request_mgr.c: * @dx_compl_h: The completion event to signal
drivers/crypto/ccree/cc_request_mgr.c:	struct completion *this_compl = dx_compl_h;
drivers/crypto/ccree/cc_request_mgr.c: * @add_comp: If "true": add an artificial dout DMA to mark completion
drivers/crypto/ccree/cc_request_mgr.c:			 * on the next completion irq.
drivers/crypto/ccree/cc_request_mgr.c:	init_completion(&cc_req->seq_compl);
drivers/crypto/ccree/cc_request_mgr.c:		wait_for_completion_interruptible(&drvdata->hw_queue_avail);
drivers/crypto/ccree/cc_request_mgr.c:		reinit_completion(&drvdata->hw_queue_avail);
drivers/crypto/ccree/cc_request_mgr.c:	wait_for_completion(&cc_req->seq_compl);
drivers/crypto/ccree/cc_request_mgr.c:static void proc_completions(struct cc_drvdata *drvdata)
drivers/crypto/ccree/cc_request_mgr.c:			/* We are supposed to handle a completion but our
drivers/crypto/ccree/cc_request_mgr.c:			dev_dbg(dev, "CPP request completion slot: %d alg:%d\n",
drivers/crypto/ccree/cc_request_mgr.c:			dev_dbg(dev, "None CPP request completion\n");
drivers/crypto/ccree/cc_request_mgr.c:	dev_dbg(dev, "Completion handler called!\n");
drivers/crypto/ccree/cc_request_mgr.c:	/* Avoid race with above clear: Test completion counter once more */
drivers/crypto/ccree/cc_request_mgr.c:	dev_dbg(dev, "AXI completion after updated: %d\n",
drivers/crypto/ccree/cc_request_mgr.c:			proc_completions(drvdata);
drivers/crypto/ccree/cc_request_mgr.c:			/* At this point (after proc_completions()),
drivers/crypto/ccree/cc_request_mgr.c:	 * unmask AXI completion interrupt
drivers/crypto/chelsio/chcr_algo.c:			wait_for_completion(&ctx->cbc_aes_aio_done);
drivers/crypto/chelsio/chcr_algo.c:	init_completion(&ctx->cbc_aes_aio_done);
drivers/crypto/chelsio/chcr_core.c:	init_completion(&dev->detach_comp);
drivers/crypto/chelsio/chcr_core.c:	/* call completion callback with failure status */
drivers/crypto/chelsio/chcr_core.c:		wait_for_completion(&dev->detach_comp);
drivers/crypto/chelsio/chcr_core.h:	struct completion detach_comp;
drivers/crypto/chelsio/chcr_crypto.h:	struct completion cbc_aes_aio_done;
drivers/crypto/gemini/sl3516-ce-core.c:	reinit_completion(&ce->complete);
drivers/crypto/gemini/sl3516-ce-core.c:	wait_for_completion_interruptible_timeout(&ce->complete,
drivers/crypto/gemini/sl3516-ce-core.c:	init_completion(&ce->complete);
drivers/crypto/gemini/sl3516-ce.h:		 * @desc_count:		Upon completion of a DMA operation, DMA
drivers/crypto/gemini/sl3516-ce.h: * @complete:	completion for the current task on this flow
drivers/crypto/gemini/sl3516-ce.h:	struct completion complete;
drivers/crypto/hisilicon/qm.c:	/* hardware completion status should be available by this time */
drivers/crypto/hisilicon/sec/sec_algs.c:	 * The dance is needed as the lock is freed in the completion
drivers/crypto/hisilicon/sec/sec_drv.h: * @cb: completion callback.
drivers/crypto/hisilicon/sec/sec_drv.h: * @task_irq: Completion interrupt for the queue.
drivers/crypto/hisilicon/sec/sec_drv.h: * @next: Virtual address used to stash the next sgl - useful in completion.
drivers/crypto/inside-secure/safexcel_cipher.c:			"cipher: sync: invalidate: completion error %d\n",
drivers/crypto/inside-secure/safexcel_hash.c:	init_completion(&result.completion);
drivers/crypto/inside-secure/safexcel_hash.c:		dev_warn(priv->dev, "hash: completion error (%d)\n", err);
drivers/crypto/intel/iaa/iaa_crypto.h:#define IAA_COMPLETION_TIMEOUT		1000000
drivers/crypto/intel/iaa/iaa_crypto_main.c: *              immediately.  Completion interrupts are not used so
drivers/crypto/intel/iaa/iaa_crypto_main.c: *              for completion.  This mode is applicable to only the
drivers/crypto/intel/iaa/iaa_crypto_main.c: *              returns immediately.  Completion interrupts are
drivers/crypto/intel/iaa/iaa_crypto_main.c: *              enabled so the caller can wait for the completion and
drivers/crypto/intel/iaa/iaa_crypto_main.c: *              decompression completes, the completion is signaled
drivers/crypto/intel/iaa/iaa_crypto_main.c:static int check_completion(struct device *dev,
drivers/crypto/intel/iaa/iaa_crypto_main.c:			    struct iax_completion_record *comp,
drivers/crypto/intel/iaa/iaa_crypto_main.c:static inline int check_completion(struct device *dev,
drivers/crypto/intel/iaa/iaa_crypto_main.c:				   struct iax_completion_record *comp,
drivers/crypto/intel/iaa/iaa_crypto_main.c:			update_completion_timeout_errs();
drivers/crypto/intel/iaa/iaa_crypto_main.c:			update_completion_comp_buf_overflow_errs();
drivers/crypto/intel/iaa/iaa_crypto_main.c:		update_completion_einval_errs();
drivers/crypto/intel/iaa/iaa_crypto_main.c:	ret = check_completion(dev, idxd_desc->iax_completion,
drivers/crypto/intel/iaa/iaa_crypto_main.c:		dev_dbg(dev, "%s: check_completion failed ret=%d\n", __func__, ret);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		    idxd_desc->iax_completion->status == IAA_ANALYTICS_ERROR) {
drivers/crypto/intel/iaa/iaa_crypto_main.c:				idxd_desc->iax_completion->error_code);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		ctx->req->dlen = idxd_desc->iax_completion->output_size;
drivers/crypto/intel/iaa/iaa_crypto_main.c:		compression_crc = idxd_desc->iax_completion->crc;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	desc->completion_addr = idxd_desc->compl_dma;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	ret = check_completion(dev, idxd_desc->iax_completion, true, false);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		dev_dbg(dev, "check_completion failed ret=%d\n", ret);
drivers/crypto/intel/iaa/iaa_crypto_main.c:	*dlen = idxd_desc->iax_completion->output_size;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	*compression_crc = idxd_desc->iax_completion->crc;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	desc->completion_addr = idxd_desc->compl_dma;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	ret = check_completion(dev, idxd_desc->iax_completion, false, false);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		dev_dbg(dev, "(verify) check_completion failed ret=%d\n", ret);
drivers/crypto/intel/iaa/iaa_crypto_main.c:	if (compression_crc != idxd_desc->iax_completion->crc) {
drivers/crypto/intel/iaa/iaa_crypto_main.c:			idxd_desc->iax_completion->crc);
drivers/crypto/intel/iaa/iaa_crypto_main.c:			       8, 1, idxd_desc->iax_completion, 64, 0);
drivers/crypto/intel/iaa/iaa_crypto_main.c:	desc->completion_addr = idxd_desc->compl_dma;
drivers/crypto/intel/iaa/iaa_crypto_main.c:	ret = check_completion(dev, idxd_desc->iax_completion, false, false);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		dev_dbg(dev, "%s: check_completion failed ret=%d\n", __func__, ret);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		if (idxd_desc->iax_completion->status == IAA_ANALYTICS_ERROR) {
drivers/crypto/intel/iaa/iaa_crypto_main.c:				idxd_desc->iax_completion->error_code);
drivers/crypto/intel/iaa/iaa_crypto_main.c:		req->dlen = idxd_desc->iax_completion->output_size;
drivers/crypto/intel/iaa/iaa_crypto_stats.c:static atomic64_t total_completion_einval_errors;
drivers/crypto/intel/iaa/iaa_crypto_stats.c:static atomic64_t total_completion_timeout_errors;
drivers/crypto/intel/iaa/iaa_crypto_stats.c:static atomic64_t total_completion_comp_buf_overflow_errors;
drivers/crypto/intel/iaa/iaa_crypto_stats.c:void update_completion_einval_errs(void)
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_inc(&total_completion_einval_errors);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:void update_completion_timeout_errs(void)
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_inc(&total_completion_timeout_errors);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:void update_completion_comp_buf_overflow_errs(void)
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_inc(&total_completion_comp_buf_overflow_errors);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_set(&total_completion_einval_errors, 0);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_set(&total_completion_timeout_errors, 0);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	atomic64_set(&total_completion_comp_buf_overflow_errors, 0);
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	seq_printf(m, "  total_completion_einval_errors: %llu\n",
drivers/crypto/intel/iaa/iaa_crypto_stats.c:		   atomic64_read(&total_completion_einval_errors));
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	seq_printf(m, "  total_completion_timeout_errors: %llu\n",
drivers/crypto/intel/iaa/iaa_crypto_stats.c:		   atomic64_read(&total_completion_timeout_errors));
drivers/crypto/intel/iaa/iaa_crypto_stats.c:	seq_printf(m, "  total_completion_comp_buf_overflow_errors: %llu\n\n",
drivers/crypto/intel/iaa/iaa_crypto_stats.c:		   atomic64_read(&total_completion_comp_buf_overflow_errors));
drivers/crypto/intel/iaa/iaa_crypto_stats.h:void	update_completion_einval_errs(void);
drivers/crypto/intel/iaa/iaa_crypto_stats.h:void	update_completion_timeout_errs(void);
drivers/crypto/intel/iaa/iaa_crypto_stats.h:void	update_completion_comp_buf_overflow_errs(void);
drivers/crypto/intel/iaa/iaa_crypto_stats.h:static inline void	update_completion_einval_errs(void) {}
drivers/crypto/intel/iaa/iaa_crypto_stats.h:static inline void	update_completion_timeout_errs(void) {}
drivers/crypto/intel/iaa/iaa_crypto_stats.h:static inline void	update_completion_comp_buf_overflow_errs(void) {}
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:	struct completion completion;
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:			complete(&ctx->completion);
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:			complete(&ctx->completion);
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:	init_completion(&ctx->completion);
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:		wait_for_completion(&ctx->completion);
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:	init_completion(&ctx->completion);
drivers/crypto/intel/ixp4xx/ixp4xx_crypto.c:		wait_for_completion(&ctx->completion);
drivers/crypto/intel/keembay/keembay-ocs-aes-core.c:#include <linux/completion.h>
drivers/crypto/intel/keembay/keembay-ocs-aes-core.c:	init_completion(&aes_dev->irq_completion);
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:#include <linux/completion.h>
drivers/crypto/intel/keembay/keembay-ocs-ecc.c: * @irq_done: IRQ done completion.
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:	struct completion irq_done;
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:/* Start OCS ECC operation and wait for its completion. */
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:	reinit_completion(&ecc_dev->irq_done);
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:	return wait_for_completion_interruptible(&ecc_dev->irq_done);
drivers/crypto/intel/keembay/keembay-ocs-ecc.c:	init_completion(&ecc_dev->irq_done);
drivers/crypto/intel/keembay/keembay-ocs-hcu-core.c:#include <linux/completion.h>
drivers/crypto/intel/keembay/keembay-ocs-hcu-core.c:	init_completion(&hcu_dev->irq_done);
drivers/crypto/intel/keembay/ocs-aes.c:	reinit_completion(&aes_dev->irq_completion);
drivers/crypto/intel/keembay/ocs-aes.c:	rc = wait_for_completion_interruptible(&aes_dev->irq_completion);
drivers/crypto/intel/keembay/ocs-aes.c:	/* Signal IRQ completion. */
drivers/crypto/intel/keembay/ocs-aes.c:	complete(&aes_dev->irq_completion);
drivers/crypto/intel/keembay/ocs-aes.h: * @irq_copy_completion:	Completion to indicate IRQ has been triggered.
drivers/crypto/intel/keembay/ocs-aes.h:	struct completion irq_completion;
drivers/crypto/intel/keembay/ocs-hcu.c:	/* Only operating on DMA source completion and error interrupts. */
drivers/crypto/intel/keembay/ocs-hcu.c:	rc = wait_for_completion_interruptible(&hcu_dev->irq_done);
drivers/crypto/intel/keembay/ocs-hcu.c:	reinit_completion(&hcu_dev->irq_done);
drivers/crypto/intel/keembay/ocs-hcu.c:	reinit_completion(&hcu_dev->irq_done);
drivers/crypto/intel/keembay/ocs-hcu.c:	reinit_completion(&hcu_dev->irq_done);
drivers/crypto/intel/keembay/ocs-hcu.h: * @irq_done:	Completion for IRQ.
drivers/crypto/intel/keembay/ocs-hcu.h:	struct completion irq_done;
drivers/crypto/intel/qat/qat_c3xxxvf/adf_drv.c:	/* Completion for VF2PF request/response message exchange */
drivers/crypto/intel/qat/qat_c3xxxvf/adf_drv.c:	init_completion(&accel_dev->vf.msg_received);
drivers/crypto/intel/qat/qat_c62xvf/adf_drv.c:	/* Completion for VF2PF request/response message exchange */
drivers/crypto/intel/qat/qat_c62xvf/adf_drv.c:	init_completion(&accel_dev->vf.msg_received);
drivers/crypto/intel/qat/qat_common/adf_accel_devices.h:			struct completion msg_received;
drivers/crypto/intel/qat/qat_common/adf_aer.c:#include <linux/completion.h>
drivers/crypto/intel/qat/qat_common/adf_aer.c:	struct completion compl;
drivers/crypto/intel/qat/qat_common/adf_aer.c:	struct completion compl;
drivers/crypto/intel/qat/qat_common/adf_aer.c:	init_completion(&sriov_data.compl);
drivers/crypto/intel/qat/qat_common/adf_aer.c:	if (wait_for_completion_timeout(&sriov_data.compl, wait_jiffies))
drivers/crypto/intel/qat/qat_common/adf_aer.c:	init_completion(&reset_data->compl);
drivers/crypto/intel/qat/qat_common/adf_aer.c:		unsigned long timeout = wait_for_completion_timeout(
drivers/crypto/intel/qat/qat_common/adf_pfvf_vf_proto.c:#include <linux/completion.h>
drivers/crypto/intel/qat/qat_common/adf_pfvf_vf_proto.c:	reinit_completion(&accel_dev->vf.msg_received);
drivers/crypto/intel/qat/qat_common/adf_pfvf_vf_proto.c:		ret = wait_for_completion_timeout(&accel_dev->vf.msg_received,
drivers/crypto/intel/qat/qat_dh895xccvf/adf_drv.c:	/* Completion for VF2PF request/response message exchange */
drivers/crypto/intel/qat/qat_dh895xccvf/adf_drv.c:	init_completion(&accel_dev->vf.msg_received);
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: * CPT OcteonTX Completion Enumeration
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: * each instruction completion produces exactly one result structure.
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *  compcode:8 [7:0] Indicates completion/error status of the CPT coprocessor
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *	0x0 before ringing the doorbell, and then poll for completion by
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *	completion interrupts the suggested scheme is to request a DONEINT on
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *	completions; even if a later command is acknowledged first this will
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *	not result in missing a completion.
drivers/crypto/marvell/octeontx/otx_cpt_hw_types.h: *  [63:56](R) 8-bit completion code
drivers/crypto/marvell/octeontx/otx_cptvf_main.c:	/* Read the number of completions */
drivers/crypto/marvell/octeontx/otx_cptvf_main.c:		 * Acknowledge the number of scheduled completions for
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:/* Completion code size and initial value */
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:#define COMPLETION_CODE_SIZE	8
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:#define COMPLETION_CODE_INIT	0
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pentry->completion_addr = NULL;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	total_mem_len = align_dlen + info_len + rlen + COMPLETION_CODE_SIZE;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	info->completion_addr = (u64 *)(info->in_buffer + align_dlen);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	info->out_buffer = (u8 *)info->completion_addr + rlen;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	*((u64 *) info->out_buffer) = ~((u64) COMPLETION_CODE_INIT);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	result = (union otx_cpt_res_s *) info->completion_addr;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	result->s.compcode = COMPLETION_CODE_INIT;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pentry->completion_addr = info->completion_addr;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	case COMPLETION_CODE_INIT:
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:		/* Check microcode completion code */
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:		cpt_status = (union otx_cpt_res_s *) pentry->completion_addr;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			dev_err(&pdev->dev, "Completion address NULL\n");
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:	u64 *completion_addr;	/* Completion address */
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:	u64 *completion_addr;
drivers/crypto/marvell/octeontx2/otx2_cpt_hw_types.h: * OcteonTX2 CPT Completion Enumeration
drivers/crypto/marvell/octeontx2/otx2_cpt_hw_types.h: * each instruction completion produces exactly one result structure.
drivers/crypto/marvell/octeontx2/otx2_cpt_hw_types.h: *  compcode:8 [7:0] Indicates completion/error status of the CPT coprocessor
drivers/crypto/marvell/octeontx2/otx2_cpt_hw_types.h: *	0x0 before ringing the doorbell, and then poll for completion by
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:/* Completion code size and initial value */
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:#define OTX2_CPT_COMPLETION_CODE_SIZE 8
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:#define OTX2_CPT_COMPLETION_CODE_INIT OTX2_CPT_COMP_E_NOTDONE
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:	void *completion_addr;	/* Completion address */
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:	void *completion_addr;
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:	info->completion_addr = info->in_buffer + sg_len;
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:	info->completion_addr = info->in_buffer + align_dlen;
drivers/crypto/marvell/octeontx2/otx2_cptpf_ucode.c:		result->s.compcode = OTX2_CPT_COMPLETION_CODE_INIT;
drivers/crypto/marvell/octeontx2/otx2_cptpf_ucode.c:						OTX2_CPT_COMPLETION_CODE_INIT)
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pentry->completion_addr = NULL;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	result = info->completion_addr;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	result->s.compcode = OTX2_CPT_COMPLETION_CODE_INIT;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pentry->completion_addr = info->completion_addr;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:		 * Check microcode completion code, it is only valid
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:		 * when completion code is CPT_COMP_E::GOOD
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:		cpt_status = pentry->completion_addr;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			dev_err(&pdev->dev, "Completion address NULL\n");
drivers/crypto/mxs-dcp.c:	struct completion		completion[DCP_MAX_CHANS];
drivers/crypto/mxs-dcp.c:	reinit_completion(&sdcp->completion[chan]);
drivers/crypto/mxs-dcp.c:	ret = wait_for_completion_timeout(&sdcp->completion[chan],
drivers/crypto/mxs-dcp.c:			complete(&sdcp->completion[i]);
drivers/crypto/mxs-dcp.c:		init_completion(&sdcp->completion[i]);
drivers/crypto/nx/nx-842.h:/* CCB Completion Modes (CM) for 842
drivers/crypto/nx/nx-842.h:#define CCB_CM_EXTRA_WRITE	(CCB_CM0_ALL_COMPLETIONS & CCB_CM12_STORE)
drivers/crypto/nx/nx-842.h:#define CCB_CM_INTERRUPT	(CCB_CM0_ALL_COMPLETIONS & CCB_CM12_INTERRUPT)
drivers/crypto/nx/nx-aes-ccm.c:		/* for partial completion, copy following for next
drivers/crypto/nx/nx-aes-ccm.c:		/* for partial completion, copy following for next
drivers/crypto/nx/nx-common-powernv.c:	/* verify CSB completion sequence is 0 */
drivers/crypto/nx/nx-common-powernv.c:		CSB_ERR(csb, "Invalid CSB completion sequence");
drivers/crypto/nx/nx-common-powernv.c:	/* check CSB Completion Code */
drivers/crypto/nx/nx-common-powernv.c:	/* check Completion Extension state */
drivers/crypto/nx/nx-common-powernv.c:	/* successful completion */
drivers/crypto/nx/nx-common-pseries.c:/* CE macros operate on the completion_extension field bits in the csbcpb.
drivers/crypto/nx/nx-common-pseries.c: * CE0 0=full completion, 1=partial completion
drivers/crypto/nx/nx-common-pseries.c: * CE1 0=CE0 indicates completion, 1=termination (output may be modified)
drivers/crypto/nx/nx-common-pseries.c:		dev_err(dev, "%s: cspcbp not valid upon completion.\n",
drivers/crypto/nx/nx-common-pseries.c:				csb->completion_code,
drivers/crypto/nx/nx-common-pseries.c:				csb->completion_extension);
drivers/crypto/nx/nx-common-pseries.c:	switch (csb->completion_code) {
drivers/crypto/nx/nx-common-pseries.c:					__func__, csb->completion_code);
drivers/crypto/nx/nx-common-pseries.c:					__func__, csb->completion_code);
drivers/crypto/nx/nx-common-pseries.c:	if (!NX842_CSBCPB_CE2(csb->completion_extension)) {
drivers/crypto/nx/nx_csbcpb.h:	u8 completion_code;
drivers/crypto/nx/nx_csbcpb.h:	u8 completion_extension;
drivers/crypto/omap-aes.h:	struct completion completion;
drivers/crypto/omap-sham.c:	/* wait for dma completion before can take more data */
drivers/crypto/rockchip/rk3288_crypto.c:	init_completion(&crypto_info->complete);
drivers/crypto/rockchip/rk3288_crypto.h:	struct completion complete;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		reinit_completion(&rkc->complete);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		wait_for_completion_interruptible_timeout(&rkc->complete,
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		reinit_completion(&rkc->complete);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		wait_for_completion_interruptible_timeout(&rkc->complete,
drivers/crypto/s5p-sss.c:/* Calls the completion. Cannot be called with dev->lock hold. */
drivers/crypto/sahara.c:	struct completion	dma_completion;
drivers/crypto/sahara.c:	reinit_completion(&dev->dma_completion);
drivers/crypto/sahara.c:	time_left = wait_for_completion_timeout(&dev->dma_completion,
drivers/crypto/sahara.c:	reinit_completion(&dev->dma_completion);
drivers/crypto/sahara.c:	time_left = wait_for_completion_timeout(&dev->dma_completion,
drivers/crypto/sahara.c:	complete(&dev->dma_completion);
drivers/crypto/sahara.c:	init_completion(&dev->dma_completion);
drivers/crypto/starfive/jh7110-aes.c:	init_completion(&cryp->dma_done);
drivers/crypto/starfive/jh7110-aes.c:	reinit_completion(&cryp->dma_done);
drivers/crypto/starfive/jh7110-aes.c:	if (!wait_for_completion_timeout(&cryp->dma_done,
drivers/crypto/starfive/jh7110-cryp.c:#include <linux/completion.h>
drivers/crypto/starfive/jh7110-cryp.h:	struct completion			dma_done;
drivers/crypto/starfive/jh7110-hash.c:	init_completion(&cryp->dma_done);
drivers/crypto/starfive/jh7110-hash.c:	reinit_completion(&cryp->dma_done);
drivers/crypto/starfive/jh7110-hash.c:	if (!wait_for_completion_timeout(&cryp->dma_done,
drivers/crypto/stm32/stm32-cryp.c:	struct completion	dma_completion;
drivers/crypto/stm32/stm32-cryp.c:		/* Wait for completion */
drivers/crypto/stm32/stm32-cryp.c:	complete(&cryp->dma_completion); /* completion to indicate no timeout */
drivers/crypto/stm32/stm32-cryp.c:	reinit_completion(&cryp->dma_completion);
drivers/crypto/stm32/stm32-cryp.c:	if (!wait_for_completion_timeout(&cryp->dma_completion, msecs_to_jiffies(1000))) {
drivers/crypto/stm32/stm32-cryp.c:	/* h) wait for completion */
drivers/crypto/stm32/stm32-cryp.c:	init_completion(&cryp->dma_completion);
drivers/crypto/stm32/stm32-hash.c:#define HASH_MASK_CALC_COMPLETION	BIT(0)
drivers/crypto/stm32/stm32-hash.c:	struct completion	dma_completion;
drivers/crypto/stm32/stm32-hash.c:	reinit_completion(&hdev->dma_completion);
drivers/crypto/stm32/stm32-hash.c:	if (!wait_for_completion_timeout(&hdev->dma_completion,
drivers/crypto/stm32/stm32-hash.c:	complete(&hdev->dma_completion);
drivers/crypto/stm32/stm32-hash.c:	init_completion(&hdev->dma_completion);
drivers/crypto/stm32/stm32-hash.c:	/* If we have an IRQ, wait for that, else poll for completion */
drivers/crypto/virtio/virtio_crypto_common.h:	struct completion compl;
drivers/crypto/virtio/virtio_crypto_core.c:	init_completion(&vc_ctrl_req->compl);
drivers/crypto/virtio/virtio_crypto_core.c:	wait_for_completion(&vc_ctrl_req->compl);
drivers/cxl/core/memdev.c:	 * No need to wait for completions here - any errors would've been
drivers/cxl/cxlmem.h: * @sanitize_active: sanitize completion pending
drivers/cxl/pci.c: * Return: -ETIMEDOUT if timeout occurred waiting for completion. 0 on success.
drivers/cxl/pci.c:		 * and allow userspace to poll(2) for completion.
drivers/dma-buf/dma-buf.c: * Note that this only signals the completion of the respective fences, i.e. the
drivers/dma-buf/dma-fence.c: * * Drivers may have different ideas of what completion within a reasonable
drivers/dma-buf/dma-fence.c: *   This means any code required for fence completion cannot acquire a
drivers/dma-buf/dma-fence.c: *   callbacks. This means any code required for fence completion cannot
drivers/dma-buf/dma-fence.c: *   for fence completion cannot allocate memory with GFP_NOFS or GFP_NOIO.
drivers/dma-buf/dma-fence.c: *   scheduler code, interrupt and workers to process job completion,
drivers/dma-buf/dma-fence.c: *   guarantee completion of a &dma_fence. The usual example is a wait IOCTL
drivers/dma-buf/dma-fence.c: *   which calls dma_fence_signal(), while the mandatory completion path goes
drivers/dma-buf/dma-fence.c: *   through a hardware interrupt and possible job completion worker.
drivers/dma-buf/dma-fence.c: * dma_fence_signal_timestamp_locked - signal completion of a fence
drivers/dma-buf/dma-fence.c: * Signal completion for software callbacks on a fence, this will unblock
drivers/dma-buf/dma-fence.c: * dma_fence_signal_timestamp - signal completion of a fence
drivers/dma-buf/dma-fence.c: * Signal completion for software callbacks on a fence, this will unblock
drivers/dma-buf/dma-fence.c: * dma_fence_signal_locked - signal completion of a fence
drivers/dma-buf/dma-fence.c: * Signal completion for software callbacks on a fence, this will unblock
drivers/dma-buf/dma-fence.c: * dma_fence_signal - signal completion of a fence
drivers/dma-buf/dma-fence.c: * Signal completion for software callbacks on a fence, this will unblock
drivers/dma-buf/dma-fence.c: * dma_fence_get_status - returns the status upon completion
drivers/dma/altera-msgdma.c: * msgdma_tasklet - Schedule completion tasklet
drivers/dma/amba-pl08x.c: * If slaves are relying on interrupts to signal completion this function
drivers/dma/at_hdmac.c:	/* enable interrupts on buffer transfer completion & error */
drivers/dma/at_hdmac.c: * atc_tx_status - poll for transaction completion
drivers/dma/at_hdmac.c:		/* wait for transaction completion (except in cyclic case) */
drivers/dma/at_xdmac.c:		/* Wait for transfer completion, except in cyclic case. */
drivers/dma/dma-jz4780.c:			 * completion of processing the previous descriptor.
drivers/dma/dmaengine.h: * repeated completions.
drivers/dma/dmatest.c:MODULE_PARM_DESC(polled, "Use polling for completion instead of interrupts");
drivers/dma/dmatest.c: * @polled:		use polling for completion instead of interrupts
drivers/dma/dmatest.c:/* poor man's completion - we want to use wait_event_freezable() on it */
drivers/dma/dmatest.c:			   !(dma_has_cap(DMA_COMPLETION_NO_ORDER,
drivers/dma/dmatest.c:			       "completion error status" :
drivers/dma/dmatest.c:			       "completion busy status", total_tests, src->off,
drivers/dma/dmatest.c:	if (dma_has_cap(DMA_COMPLETION_NO_ORDER, dma_dev->cap_mask) &&
drivers/dma/dmatest.c:		pr_warn("DMA_COMPLETION_NO_ORDER, polled disabled\n");
drivers/dma/fsl-qdma.c:	u8 completion_status;
drivers/dma/fsl-qdma.c:		completion_status = qdma_ccdf_get_status(status_addr);
drivers/dma/fsl-qdma.c:		/* The completion_status is evaluated here
drivers/dma/fsl-qdma.c:		if (completion_status) {
drivers/dma/fsl-qdma.c:			/* A completion error occurred! */
drivers/dma/fsl-qdma.c:			if (completion_status & QDMA_CCDF_STATUS_WTE) {
drivers/dma/fsl-qdma.c:			} else if (completion_status & QDMA_CCDF_STATUS_RTE) {
drivers/dma/fsl-qdma.c:					completion_status);
drivers/dma/idxd/cdev.c:	 * As per the programming specification, the completion address must be
drivers/dma/idxd/cdev.c:	if (!IS_ALIGNED(descriptor.completion_addr, comp_addr_align))
drivers/dma/idxd/cdev.c: * idxd_copy_cr - copy completion record to user address space found by wq and
drivers/dma/idxd/cdev.c: * @cr:		completion record
drivers/dma/idxd/cdev.c: * This is called by a work that handles completion record fault.
drivers/dma/idxd/cdev.c:	 * The completion record fault handling work is running in kernel
drivers/dma/idxd/cdev.c:	 * Copy status only after the rest of completion record is copied
drivers/dma/idxd/cdev.c:	 * successfully so that the user gets the complete completion record
drivers/dma/idxd/cdev.c:		 * Ensure that the completion record's status field is written
drivers/dma/idxd/cdev.c:		 * after the rest of the completion record has been written.
drivers/dma/idxd/cdev.c:		 * This ensures that the user receives the correct completion
drivers/dma/idxd/debugfs.c:	struct dsa_completion_record *cr;
drivers/dma/idxd/device.c:			desc->completion = &wq->compls[i];
drivers/dma/idxd/device.c:			desc->iax_completion = &wq->iax_compls[i];
drivers/dma/idxd/device.c:	reinit_completion(&wq->wq_dead);
drivers/dma/idxd/device.c:	reinit_completion(&wq->wq_resurrect);
drivers/dma/idxd/device.c:	reinit_completion(&wq->wq_resurrect);
drivers/dma/idxd/device.c:	wait_for_completion(&wq->wq_dead);
drivers/dma/idxd/device.c: * poll for completion. Once the device is setup with interrupts,
drivers/dma/idxd/device.c: * all commands will be done via interrupt completion.
drivers/dma/idxd/device.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/dma/idxd/device.c:	wait_for_completion(&done);
drivers/dma/idxd/device.c:		ctype = desc->completion->status ? IDXD_COMPLETE_NORMAL : IDXD_COMPLETE_ABORT;
drivers/dma/idxd/device.c:	 * need to re-enable user interrupts for kernel work queue completion
drivers/dma/idxd/dma.c:	if (desc->completion->status == DSA_COMP_SUCCESS) {
drivers/dma/idxd/dma.c:	} else if (desc->completion->status) {
drivers/dma/idxd/dma.c:		    desc->completion->status == DSA_COMP_INT_HANDLE_INVAL &&
drivers/dma/idxd/dma.c:	hw->completion_addr = compl;
drivers/dma/idxd/dma.c:	dma_cap_set(DMA_COMPLETION_NO_ORDER, dma->cap_mask);
drivers/dma/idxd/idxd.h:	struct completion wq_dead;
drivers/dma/idxd/idxd.h:	struct completion wq_resurrect;
drivers/dma/idxd/idxd.h:		struct dsa_completion_record *compls;
drivers/dma/idxd/idxd.h:		struct iax_completion_record *iax_compls;
drivers/dma/idxd/idxd.h:	struct completion *cmd_done;
drivers/dma/idxd/idxd.h:		struct dsa_completion_record *completion;
drivers/dma/idxd/idxd.h:		struct iax_completion_record *iax_completion;
drivers/dma/idxd/idxd.h: * This is software defined error for the completion status. We overload the error code
drivers/dma/idxd/idxd.h: * that will never appear in completion status and only SWERR register.
drivers/dma/idxd/idxd.h:enum idxd_completion_status {
drivers/dma/idxd/init.c:		.compl_size = sizeof(struct dsa_completion_record),
drivers/dma/idxd/init.c:		.cr_status_off = offsetof(struct dsa_completion_record, status),
drivers/dma/idxd/init.c:		.cr_result_off = offsetof(struct dsa_completion_record, result),
drivers/dma/idxd/init.c:		.compl_size = sizeof(struct iax_completion_record),
drivers/dma/idxd/init.c:		.cr_status_off = offsetof(struct iax_completion_record, status),
drivers/dma/idxd/init.c:		.cr_result_off = offsetof(struct iax_completion_record, error_code),
drivers/dma/idxd/init.c:		init_completion(&wq->wq_dead);
drivers/dma/idxd/init.c:		init_completion(&wq->wq_resurrect);
drivers/dma/idxd/init.c:	 * Since completion record in evl_cache will be copied to user
drivers/dma/idxd/init.c:	 * when handling completion record page fault, need to create
drivers/dma/idxd/init.c:	/* Since we set user privilege for kernel DMA, enable completion IRQ */
drivers/dma/idxd/irq.c:	/* Issue a simple drain operation with interrupt but no completion record */
drivers/dma/idxd/irq.c:		if (d->completion->status == DSA_COMP_INT_HANDLE_INVAL)
drivers/dma/idxd/irq.c:		reinit_completion(&wq->wq_resurrect);
drivers/dma/idxd/irq.c:		wait_for_completion(&wq->wq_dead);
drivers/dma/idxd/irq.c:	 * Copy completion record to fault_addr in user address space
drivers/dma/idxd/irq.c:	 * waiting for the completion record will time out on this
drivers/dma/idxd/irq.c:			dev_dbg_ratelimited(dev, "Failed to write to completion record: (%d:%d)\n",
drivers/dma/idxd/irq.c:			dev_dbg_ratelimited(dev, "Failed to write to batch completion record: (%d:%d)\n",
drivers/dma/idxd/irq.c:			dev_dbg_ratelimited(dev, "Failed to write to drain completion record: (%d:%d)\n",
drivers/dma/idxd/irq.c:				dev_dbg(dev, "Completion Int Req set, ignoring!\n");
drivers/dma/idxd/irq.c:			 * for the device command completions.
drivers/dma/idxd/irq.c:	desc->completion->status = 0;
drivers/dma/idxd/irq.c:			desc->completion->status = IDXD_COMP_DESC_ABORT;
drivers/dma/idxd/irq.c:		u8 status = desc->completion->status & DSA_COMP_STATUS_MASK;
drivers/dma/idxd/irq.c:			if (unlikely(desc->completion->status == IDXD_COMP_DESC_ABORT)) {
drivers/dma/idxd/irq.c:		if (desc->completion->status) {
drivers/dma/idxd/irq.c:		if (unlikely(desc->completion->status == IDXD_COMP_DESC_ABORT)) {
drivers/dma/idxd/registers.h:	struct dsa_completion_record cr;
drivers/dma/idxd/registers.h:	struct iax_completion_record cr;
drivers/dma/idxd/submit.c:	memset(desc->completion, 0, idxd->data->compl_size);
drivers/dma/idxd/submit.c:	 * At this point, the desc needs to be aborted is held by the completion
drivers/dma/idxd/submit.c:	 * IDXD_COMP_DESC_ABORT for completion status.
drivers/dma/idxd/submit.c:	desc->completion->status = IDXD_COMP_DESC_ABORT;
drivers/dma/idxd/submit.c:			if (d->completion->status)
drivers/dma/idxd/submit.c:		wait_for_completion(&wq->wq_resurrect);
drivers/dma/img-mdc-dma.c:	 * didn't miss a command completion.
drivers/dma/ioat/dma.c:static int completion_timeout = 200;
drivers/dma/ioat/dma.c:module_param(completion_timeout, int, 0644);
drivers/dma/ioat/dma.c:MODULE_PARM_DESC(completion_timeout,
drivers/dma/ioat/dma.c:		"set ioat completion timeout [msec] (default 200 [msec])");
drivers/dma/ioat/dma.c:#define COMPLETION_TIMEOUT msecs_to_jiffies(completion_timeout)
drivers/dma/ioat/dma.c:	"Completion Address Error",
drivers/dma/ioat/dma.c:	mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.c:		mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.c:		mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.c:static u64 ioat_get_current_completion(struct ioatdma_chan *ioat_chan)
drivers/dma/ioat/dma.c:	u64 completion;
drivers/dma/ioat/dma.c:	completion = *ioat_chan->completion;
drivers/dma/ioat/dma.c:	phys_complete = ioat_chansts_to_addr(completion);
drivers/dma/ioat/dma.c:	*phys_complete = ioat_get_current_completion(ioat_chan);
drivers/dma/ioat/dma.c:	if (*phys_complete == ioat_chan->last_completion)
drivers/dma/ioat/dma.c:	clear_bit(IOAT_COMPLETION_ACK, &ioat_chan->state);
drivers/dma/ioat/dma.c:	mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.c: * @phys_complete: zeroed (or not) completion address (from status)
drivers/dma/ioat/dma.c:	 * At restart of the channel, the completion address and the
drivers/dma/ioat/dma.c:	/* no active descs have written a completion? */
drivers/dma/ioat/dma.c:	ioat_chan->last_completion = phys_complete;
drivers/dma/ioat/dma.c:		dev_dbg(to_dev(ioat_chan), "%s: cancel completion timeout\n",
drivers/dma/ioat/dma.c:	if (is_ioat_halted(*ioat_chan->completion)) {
drivers/dma/ioat/dma.c:	/* set the completion address register again */
drivers/dma/ioat/dma.c:	writel(lower_32_bits(ioat_chan->completion_dma),
drivers/dma/ioat/dma.c:	writel(upper_32_bits(ioat_chan->completion_dma),
drivers/dma/ioat/dma.c:	ioat_chan->last_completion = *ioat_chan->completion = desc->txd.phys;
drivers/dma/ioat/dma.c:	*ioat_chan->completion = desc->txd.phys;
drivers/dma/ioat/dma.c:		mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.c:	 * programming errors before advancing the completion state
drivers/dma/ioat/dma.c:		 * and IOAT_COMPLETION_ACK cleared
drivers/dma/ioat/dma.c:	 * acknowledged a pending completion once, then be more
drivers/dma/ioat/dma.c:	if (test_bit(IOAT_COMPLETION_ACK, &ioat_chan->state)) {
drivers/dma/ioat/dma.c:			"Completion timeout with pending descriptors\n");
drivers/dma/ioat/dma.c:	set_bit(IOAT_COMPLETION_ACK, &ioat_chan->state);
drivers/dma/ioat/dma.c:	mod_timer(&ioat_chan->timer, jiffies + COMPLETION_TIMEOUT);
drivers/dma/ioat/dma.h: * @completion_pool: DMA buffers for completion ops
drivers/dma/ioat/dma.h:	struct dma_pool *completion_pool;
drivers/dma/ioat/dma.h:	dma_addr_t last_completion;
drivers/dma/ioat/dma.h:	#define IOAT_COMPLETION_ACK 1
drivers/dma/ioat/dma.h:	dma_addr_t completion_dma;
drivers/dma/ioat/dma.h:	u64 *completion;
drivers/dma/ioat/init.c:	struct completion *cmp = dma_async_param;
drivers/dma/ioat/init.c:	struct completion cmp;
drivers/dma/ioat/init.c:	init_completion(&cmp);
drivers/dma/ioat/init.c:	tmo = wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000));
drivers/dma/ioat/init.c:	ioat_dma->completion_pool = dma_pool_create("completion_pool", dev,
drivers/dma/ioat/init.c:	if (!ioat_dma->completion_pool) {
drivers/dma/ioat/init.c:	dma_pool_destroy(ioat_dma->completion_pool);
drivers/dma/ioat/init.c:	dma_pool_free(ioat_dma->completion_pool, ioat_chan->completion,
drivers/dma/ioat/init.c:		      ioat_chan->completion_dma);
drivers/dma/ioat/init.c:	ioat_chan->last_completion = 0;
drivers/dma/ioat/init.c:	ioat_chan->completion_dma = 0;
drivers/dma/ioat/init.c:	/* Setup register to interrupt and write completion status on error */
drivers/dma/ioat/init.c:	/* allocate a completion writeback area */
drivers/dma/ioat/init.c:	ioat_chan->completion =
drivers/dma/ioat/init.c:		dma_pool_zalloc(ioat_chan->ioat_dma->completion_pool,
drivers/dma/ioat/init.c:				GFP_NOWAIT, &ioat_chan->completion_dma);
drivers/dma/ioat/init.c:	if (!ioat_chan->completion)
drivers/dma/ioat/init.c:	writel(((u64)ioat_chan->completion_dma) & 0x00000000FFFFFFFF,
drivers/dma/ioat/init.c:	writel(((u64)ioat_chan->completion_dma) >> 32,
drivers/dma/ioat/init.c:	struct completion cmp;
drivers/dma/ioat/init.c:	init_completion(&cmp);
drivers/dma/ioat/init.c:	tmo = wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000));
drivers/dma/ioat/init.c:	init_completion(&cmp);
drivers/dma/ioat/init.c:	tmo = wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000));
drivers/dma/ioat/init.c:	init_completion(&cmp);
drivers/dma/ioat/init.c:	tmo = wait_for_completion_timeout(&cmp, msecs_to_jiffies(3000));
drivers/dma/ioat/init.c:	dma_pool_destroy(ioat_dma->completion_pool);
drivers/dma/ioat/init.c:		 *    completion of the timer's handler.
drivers/dma/ioat/init.c:	dma_pool_destroy(d->completion_pool);
drivers/dma/ioat/prep.c:	/* completion writes from the raid engine may pass completion
drivers/dma/ioat/prep.c:	 * (legacy) descriptor to ensure all completion writes arrive in
drivers/dma/ioat/prep.c:	/* completion descriptor carries interrupt bit */
drivers/dma/ioat/prep.c:	/* completion writes from the raid engine may pass completion
drivers/dma/ioat/prep.c:	 * (legacy) descriptor to ensure all completion writes arrive in
drivers/dma/ioat/prep.c:		/* completion descriptor carries interrupt bit */
drivers/dma/ioat/prep.c:	 * 16 source pq is only available on cb3.3 and has no completion
drivers/dma/ioat/prep.c:	/* with cb3.3 we should be able to do completion w/o a null desc */
drivers/dma/ioat/registers.h:#define IOAT_CHANCTRL_ERR_COMPLETION_EN		0x0004
drivers/dma/ioat/registers.h:						 IOAT_CHANCTRL_ERR_COMPLETION_EN |\
drivers/dma/ioat/registers.h:#define IOAT_CHANCMP_OFFSET			0x18	/* 64-bit Channel Completion Address Register */
drivers/dma/ioat/registers.h:#define IOAT_CHANERR_COMPLETION_ADDR_ERR	0x1000
drivers/dma/k3dma.c:			/* descriptor asks for TC2 interrupt on completion */
drivers/dma/mediatek/mtk-cqdma.c: * @issue_completion:	   The wait for all issued descriptors completited
drivers/dma/mediatek/mtk-cqdma.c:	struct completion issue_completion;
drivers/dma/mediatek/mtk-cqdma.c:		/* setup completion if this VC is under synchronization */
drivers/dma/mediatek/mtk-cqdma.c:			complete(&cvc->issue_completion);
drivers/dma/mediatek/mtk-cqdma.c:		 * free child CVD after completion.
drivers/dma/mediatek/mtk-cqdma.c:	/* waiting for the completion of this VC */
drivers/dma/mediatek/mtk-cqdma.c:		wait_for_completion(&cvc->issue_completion);
drivers/dma/mediatek/mtk-cqdma.c:		/* wait for the completion of flush operation */
drivers/dma/mediatek/mtk-cqdma.c:		init_completion(&vc->issue_completion);
drivers/dma/mediatek/mtk-hsdma.c: * @issue_completion:	   The wait for all issued descriptors completited
drivers/dma/mediatek/mtk-hsdma.c:	struct completion issue_completion;
drivers/dma/mediatek/mtk-hsdma.c:	/* Disable HSDMA and wait for the completion */
drivers/dma/mediatek/mtk-hsdma.c:	/* Disable HSDMA and then wait for the completion */
drivers/dma/mediatek/mtk-hsdma.c:				complete(&hvc->issue_completion);
drivers/dma/mediatek/mtk-hsdma.c:		wait_for_completion(&hvc->issue_completion);
drivers/dma/mediatek/mtk-hsdma.c:		init_completion(&vc->issue_completion);
drivers/dma/mpc512x_dma.c:/* Check request completion status */
drivers/dma/mxs-dma.c:	/* completion status */
drivers/dma/mxs-dma.c:	 * When both completion and error of termination bits set at the
drivers/dma/mxs-dma.c:	 * error or a termination error with no completion. 0x01 is termination
drivers/dma/pl330.c:	/* Schedule desc completion */
drivers/dma/ppc4xx/adma.c:static struct completion ppc440spe_r6_test_comp;
drivers/dma/ppc4xx/adma.c:		/* Enable interrupt on completion */
drivers/dma/ppc4xx/adma.c:		/* Enable interrupt on completion */
drivers/dma/ppc4xx/adma.c: * upon completion
drivers/dma/ppc4xx/adma.c:					/* Should wait for ZeroSum completion */
drivers/dma/ppc4xx/adma.c:		} else if (slots_per_op) /* wait for group completion */
drivers/dma/ppc4xx/adma.c:	init_completion(&ppc440spe_r6_test_comp);
drivers/dma/ppc4xx/adma.c:	wait_for_completion(&ppc440spe_r6_test_comp);
drivers/dma/ptdma/ptdma-debugfs.c:	if (regval & INT_COMPLETION)
drivers/dma/ptdma/ptdma-debugfs.c:		seq_puts(s, " COMPLETION");
drivers/dma/ptdma/ptdma-dev.c:		/* Acknowledge the completion */
drivers/dma/ptdma/ptdma-dmaengine.c:		/* Check for DMA descriptor completion */
drivers/dma/ptdma/ptdma.h:#define INT_COMPLETION			BIT(0)
drivers/dma/ptdma/ptdma.h:#define SUPPORTED_INTERRUPTS		(INT_COMPLETION | INT_ERROR)
drivers/dma/ptdma/ptdma.h:	struct completion completion;
drivers/dma/ptdma/ptdma.h: * @callback: operation completion callback function
drivers/dma/ptdma/ptdma.h:	/* Completion callback support */
drivers/dma/pxa_dma.c:	 * completion, so that a curr inside a status updater
drivers/dma/qcom/bam_dma.c:		 *  - If a callback completion was requested for this DESC,
drivers/dma/qcom/bam_dma.c:		 *     In this case, BAM will deliver the completion callback
drivers/dma/qcom/gpi.c:	struct completion cmd_completion;
drivers/dma/qcom/gpi.c:	/* send opcode and wait for completion */
drivers/dma/qcom/gpi.c:	reinit_completion(&gpii->cmd_completion);
drivers/dma/qcom/gpi.c:	timeout = wait_for_completion_timeout(&gpii->cmd_completion,
drivers/dma/qcom/gpi.c:		dev_err(gpii->gpi_dev->dev, "cmd: %s completion timeout:%u\n",
drivers/dma/qcom/gpi.c:/* process transfer completion interrupt */
drivers/dma/qcom/gpi.c:			complete_all(&gpii->cmd_completion);
drivers/dma/qcom/gpi.c:			complete_all(&gpii->cmd_completion);
drivers/dma/qcom/gpi.c:/* process DMA Immediate completion data events */
drivers/dma/qcom/gpi.c:/* processing transfer completion events */
drivers/dma/qcom/gpi.c:		init_completion(&gpii->cmd_completion);
drivers/dma/qcom/hidma.h:	u8 err_code;			/* completion code		    */
drivers/dma/qcom/hidma_ll.c:		dev_warn(lldev->dev, "tre count mismatch on completion");
drivers/dma/qcom/hidma_ll.c:static int hidma_handle_tre_completion(struct hidma_lldev *lldev)
drivers/dma/qcom/hidma_ll.c:	hidma_handle_tre_completion(lldev);
drivers/dma/sh/rcar-dmac.c:		 * and the transfer completion interrupt.
drivers/dma/ste_dma40_ll.c:	 * Relink happens after transfer completion.
drivers/dma/tegra186-gpc-dma.c:#define TEGRA_GPCDMA_BURST_COMPLETION_TIMEOUT	5000 /* 5 msec */
drivers/dma/tegra186-gpc-dma.c:			TEGRA_GPCDMA_BURST_COMPLETION_TIMEOUT);
drivers/dma/tegra186-gpc-dma.c:			TEGRA_GPCDMA_BURST_COMPLETION_TIMEOUT);
drivers/dma/tegra186-gpc-dma.c:				TEGRA_GPCDMA_BURST_COMPLETION_TIMEOUT);
drivers/dma/tegra186-gpc-dma.c:		dev_err(tdc2dev(tdc), "Timeout waiting for DMA burst completion!\n");
drivers/dma/tegra20-apb-dma.c:		 * burst's completion and counter is less than the actual
drivers/dma/ti/cppi41.c:	u16 first_completion_queue;
drivers/dma/ti/cppi41.c:	u16 first_completion_queue;
drivers/dma/ti/cppi41.c:	u16 first_completion_queue = cdd->first_completion_queue;
drivers/dma/ti/cppi41.c:	for (i = QMGR_PENDING_SLOT_Q(first_completion_queue); i < qmgr_num_pend;
drivers/dma/ti/cppi41.c:		if (i == QMGR_PENDING_SLOT_Q(first_completion_queue) && val) {
drivers/dma/ti/cppi41.c:			/* set corresponding bit for completion Q 93 */
drivers/dma/ti/cppi41.c:			mask = 1 << QMGR_PENDING_BIT_Q(first_completion_queue);
drivers/dma/ti/cppi41.c:	.first_completion_queue = 93,
drivers/dma/ti/cppi41.c:	.first_completion_queue = 24,
drivers/dma/ti/cppi41.c:	cdd->first_completion_queue = glue_info->first_completion_queue;
drivers/dma/ti/edma.c:	 * completion callback.
drivers/dma/ti/edma.c:	/* clear possibly pending completion interrupt */
drivers/dma/ti/edma.c:			/* Enable completion interrupt */
drivers/dma/ti/edma.c:			 * Enable early completion interrupt for the
drivers/dma/ti/edma.c:static void edma_completion_handler(struct edma_chan *echan)
drivers/dma/ti/edma.c:			edma_completion_handler(&ecc->slave_chans[channel]);
drivers/dma/ti/edma.c:/* Check request completion status */
drivers/dma/ti/edma.c:	/* Provide a dummy dma_tx_state for completion checking */
drivers/dma/ti/k3-udma.c:#include <linux/completion.h>
drivers/dma/ti/k3-udma.c:	struct k3_ring *tc_ring; /* Transmit Completion ring */
drivers/dma/ti/k3-udma.c:	struct completion teardown_completed;
drivers/dma/ti/k3-udma.c:	/* Teardown completion */
drivers/dma/ti/k3-udma.c:	reinit_completion(&uc->teardown_completed);
drivers/dma/ti/k3-udma.c:	 * completion calculation, consumer must ensure that there is no stale
drivers/dma/ti/k3-udma.c:static void udma_check_tx_completion(struct work_struct *work)
drivers/dma/ti/k3-udma.c:	/* Teardown completion message */
drivers/dma/ti/k3-udma.c:	 * Make sure that the completion is in a known state:
drivers/dma/ti/k3-udma.c:	reinit_completion(&uc->teardown_completed);
drivers/dma/ti/k3-udma.c:	 * Make sure that the completion is in a known state:
drivers/dma/ti/k3-udma.c:	reinit_completion(&uc->teardown_completed);
drivers/dma/ti/k3-udma.c:				  udma_check_tx_completion);
drivers/dma/ti/k3-udma.c:	 * Make sure that the completion is in a known state:
drivers/dma/ti/k3-udma.c:	reinit_completion(&uc->teardown_completed);
drivers/dma/ti/k3-udma.c:				  udma_check_tx_completion);
drivers/dma/ti/k3-udma.c:			      false, CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:				      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:			      true, CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:				      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:			      false, CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:				      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:		      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:			      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:		timeout = wait_for_completion_timeout(&uc->teardown_completed,
drivers/dma/ti/k3-udma.c: * This tasklet handles the completion of a DMA descriptor by
drivers/dma/ti/k3-udma.c:		      CPPI5_TR_EVENT_SIZE_COMPLETION, 0);
drivers/dma/ti/k3-udma.c:		/* Use custom vchan completion handling */
drivers/dma/ti/k3-udma.c:		init_completion(&uc->teardown_completed);
drivers/dma/ti/k3-udma.c:		INIT_DELAYED_WORK(&uc->tx_drain.work, udma_check_tx_completion);
drivers/dma/ti/omap-dma.c:	 * aborts immediately after completion of current read/write
drivers/dma/txx9dmac.c:		/* Make chain-completion interrupt happen */
drivers/dma/txx9dmac.c:	dev_crit(chan2dev(&dc->chan), "Abnormal Chain Completion\n");
drivers/dma/txx9dmac.c:		 * calling of callback on the completion will be more
drivers/dma/uniphier-mdmac.c:	 * is aborted. To distinguish the normal completion and the abort,
drivers/dma/virt-dma.c: * This tasklet handles the completion of a DMA descriptor by
drivers/dma/virt-dma.h: * vchan_cookie_complete - report completion of a descriptor
drivers/dma/virt-dma.h: * vchan_cyclic_callback - report the completion of a period
drivers/dma/xgene-dma.c: *	execution, but still waiting for completion,
drivers/dma/xilinx/xdma.c: * fetches from host memory and processes. Events such as descriptor completion
drivers/dma/xilinx/xdma.c:	struct completion		last_interrupt;
drivers/dma/xilinx/xdma.c:	reinit_completion(&xchan->last_interrupt);
drivers/dma/xilinx/xdma.c:		init_completion(&xchan->last_interrupt);
drivers/dma/xilinx/xdma.c:		wait_for_completion_timeout(&xdma_chan->last_interrupt, msecs_to_jiffies(1000));
drivers/dma/xilinx/xilinx_dma.c: * xilinx_dma_do_tasklet - Schedule completion tasklet
drivers/dma/xilinx/xilinx_dpdma.c: * Stop a previously paused channel by first waiting for completion of all
drivers/dma/xilinx/xilinx_dpdma.c: * xilinx_dpdma_chan_done_irq - Handle hardware descriptor completion
drivers/dma/xilinx/xilinx_dpdma.c: * Handle completion of the currently active descriptor (@chan->desc.active). As
drivers/dma/xilinx/xilinx_dpdma.c: * for completion is performed by xilinx_dpdma_synchronize() that will disable
drivers/dma/xilinx/xilinx_dpdma.c: * touched, and will be freed either upon completion, or by
drivers/dma/xilinx/zynqmp_dma.c: * zynqmp_dma_do_tasklet - Schedule completion tasklet
drivers/edac/e752x_edac.c:					 * 6:5     Scrub Completion Count
drivers/edac/e752x_edac.c:	"Completion Timeout",				/* bit 23, non-fatal */
drivers/edac/e752x_edac.c:	"Unexpected Completion",			/* bit 25, non-fatal */
drivers/edac/edac_mc.h:#include <linux/completion.h>
drivers/extcon/extcon-axp288.c:	/* Check charger detection completion status */
drivers/firewire/core-card.c:#include <linux/completion.h>
drivers/firewire/core-card.c:	init_completion(&card->done);
drivers/firewire/core-card.c:static int dummy_flush_iso_completions(struct fw_iso_context *ctx)
drivers/firewire/core-card.c:	.flush_iso_completions	= dummy_flush_iso_completions,
drivers/firewire/core-card.c:	wait_for_completion(&card->done);
drivers/firewire/core-cdev.c:	return fw_iso_context_flush_completions(client->iso_context);
drivers/firewire/core-iso.c: * fw_iso_context_flush_completions() - process isochronous context in current process context.
drivers/firewire/core-iso.c: * required to process the context asynchronously, fw_iso_context_schedule_flush_completions() is
drivers/firewire/core-iso.c:int fw_iso_context_flush_completions(struct fw_iso_context *ctx)
drivers/firewire/core-iso.c:	trace_isoc_outbound_flush_completions(ctx);
drivers/firewire/core-iso.c:	trace_isoc_inbound_single_flush_completions(ctx);
drivers/firewire/core-iso.c:	trace_isoc_inbound_multiple_flush_completions(ctx);
drivers/firewire/core-iso.c:	err = ctx->card->driver->flush_iso_completions(ctx);
drivers/firewire/core-iso.c:EXPORT_SYMBOL(fw_iso_context_flush_completions);
drivers/firewire/core-trace.c:EXPORT_TRACEPOINT_SYMBOL_GPL(isoc_inbound_single_completions);
drivers/firewire/core-trace.c:EXPORT_TRACEPOINT_SYMBOL_GPL(isoc_inbound_multiple_completions);
drivers/firewire/core-trace.c:EXPORT_TRACEPOINT_SYMBOL_GPL(isoc_outbound_completions);
drivers/firewire/core-transaction.c:#include <linux/completion.h>
drivers/firewire/core-transaction.c: * @callback_data:	data to be passed to the transaction completion callback
drivers/firewire/core-transaction.c: * transaction completion and hence execution of @callback may happen even
drivers/firewire/core-transaction.c:	struct completion done;
drivers/firewire/core-transaction.c:	init_completion(&d.done);
drivers/firewire/core-transaction.c:	wait_for_completion(&d.done);
drivers/firewire/core-transaction.c:static DECLARE_COMPLETION(phy_config_done);
drivers/firewire/core-transaction.c:	reinit_completion(&phy_config_done);
drivers/firewire/core-transaction.c:	wait_for_completion_timeout(&phy_config_done, timeout);
drivers/firewire/core.h:	int (*flush_iso_completions)(struct fw_iso_context *ctx);
drivers/firewire/ohci.c:	unsigned long flushing_completions;
drivers/firewire/ohci.c:			fw_iso_context_schedule_flush_completions(&ohci->ir_context_list[i].base);
drivers/firewire/ohci.c:			fw_iso_context_schedule_flush_completions(&ohci->it_context_list[i].base);
drivers/firewire/ohci.c:static void flush_iso_completions(struct iso_context *ctx, enum fw_iso_context_completions_cause cause)
drivers/firewire/ohci.c:	trace_isoc_inbound_single_completions(&ctx->base, ctx->last_timestamp, cause, ctx->header,
drivers/firewire/ohci.c:	trace_isoc_outbound_completions(&ctx->base, ctx->last_timestamp, cause, ctx->header,
drivers/firewire/ohci.c:		flush_iso_completions(ctx, FW_ISO_CONTEXT_COMPLETIONS_CAUSE_HEADER_OVERFLOW);
drivers/firewire/ohci.c:		flush_iso_completions(ctx, FW_ISO_CONTEXT_COMPLETIONS_CAUSE_INTERRUPT);
drivers/firewire/ohci.c:		trace_isoc_inbound_multiple_completions(&ctx->base, completed,
drivers/firewire/ohci.c:							FW_ISO_CONTEXT_COMPLETIONS_CAUSE_INTERRUPT);
drivers/firewire/ohci.c:	trace_isoc_inbound_multiple_completions(&ctx->base, ctx->mc_completed,
drivers/firewire/ohci.c:						FW_ISO_CONTEXT_COMPLETIONS_CAUSE_FLUSH);
drivers/firewire/ohci.c:		flush_iso_completions(ctx, FW_ISO_CONTEXT_COMPLETIONS_CAUSE_HEADER_OVERFLOW);
drivers/firewire/ohci.c:		flush_iso_completions(ctx, FW_ISO_CONTEXT_COMPLETIONS_CAUSE_INTERRUPT);
drivers/firewire/ohci.c:static int ohci_flush_iso_completions(struct fw_iso_context *base)
drivers/firewire/ohci.c:	if (!test_and_set_bit_lock(0, &ctx->flushing_completions)) {
drivers/firewire/ohci.c:				flush_iso_completions(ctx, FW_ISO_CONTEXT_COMPLETIONS_CAUSE_FLUSH);
drivers/firewire/ohci.c:		clear_bit_unlock(0, &ctx->flushing_completions);
drivers/firewire/ohci.c:	.flush_iso_completions	= ohci_flush_iso_completions,
drivers/firewire/sbp2.c:#include <linux/completion.h>
drivers/firewire/sbp2.c:	struct completion done;
drivers/firewire/sbp2.c:	init_completion(&orb->done);
drivers/firewire/sbp2.c:	wait_for_completion_timeout(&orb->done, msecs_to_jiffies(timeout));
drivers/firmware/arm_ffa/driver.c:static inline void ffa_msg_send_wait_for_completion(ffa_value_t *ret)
drivers/firmware/arm_ffa/driver.c:	ffa_msg_send_wait_for_completion(&ret);
drivers/firmware/arm_ffa/driver.c:	ffa_msg_send_wait_for_completion(&ret);
drivers/firmware/arm_scmi/clock.c:	t->hdr.poll_completion = atomic;
drivers/firmware/arm_scmi/clock.c:	t->hdr.poll_completion = false;
drivers/firmware/arm_scmi/clock.c:	t->hdr.poll_completion = atomic;
drivers/firmware/arm_scmi/clock.c:	t->hdr.poll_completion = atomic;
drivers/firmware/arm_scmi/clock.c:	t->hdr.poll_completion = atomic;
drivers/firmware/arm_scmi/common.h:#include <linux/completion.h>
drivers/firmware/arm_scmi/common.h: * @no_completion_irq: Flag to indicate that this channel has no completion
drivers/firmware/arm_scmi/common.h:	bool no_completion_irq;
drivers/firmware/arm_scmi/common.h: *		   mechanism instead of completion interrupts even if available.
drivers/firmware/arm_scmi/common.h: *				if a completion irq was found use that anyway.
drivers/firmware/arm_scmi/common.h:	return cinfo->no_completion_irq || desc->force_polling;
drivers/firmware/arm_scmi/common.h: * @channel_intr_enabled: Check is @shmem channel has requested a completion irq
drivers/firmware/arm_scmi/driver.c:		if (!xfer->hdr.poll_completion)
drivers/firmware/arm_scmi/driver.c: * signals completion of the transfer.
drivers/firmware/arm_scmi/driver.c:	       try_wait_for_completion(&xfer->done) ||
drivers/firmware/arm_scmi/driver.c:	if (xfer->hdr.poll_completion) {
drivers/firmware/arm_scmi/driver.c:			 * assumes no completion interrupt was available.
drivers/firmware/arm_scmi/driver.c:		if (!wait_for_completion_timeout(&xfer->done,
drivers/firmware/arm_scmi/driver.c: * configuration flags like xfer->hdr.poll_completion.
drivers/firmware/arm_scmi/driver.c:				      xfer->hdr.poll_completion);
drivers/firmware/arm_scmi/driver.c:	if (xfer->hdr.poll_completion &&
drivers/firmware/arm_scmi/driver.c:		xfer->hdr.poll_completion = true;
drivers/firmware/arm_scmi/driver.c:	reinit_completion(&xfer->done);
drivers/firmware/arm_scmi/driver.c:			      xfer->hdr.poll_completion);
drivers/firmware/arm_scmi/driver.c:	DECLARE_COMPLETION_ONSTACK(async_response);
drivers/firmware/arm_scmi/driver.c:	WARN_ON_ONCE(xfer->hdr.poll_completion);
drivers/firmware/arm_scmi/driver.c:		if (!wait_for_completion_timeout(xfer->async_done, timeout)) {
drivers/firmware/arm_scmi/driver.c:	xfer->hdr.poll_completion = false;
drivers/firmware/arm_scmi/driver.c:		init_completion(&xfer->done);
drivers/firmware/arm_scmi/perf.c:	t->hdr.poll_completion = poll;
drivers/firmware/arm_scmi/perf.c:	t->hdr.poll_completion = poll;
drivers/firmware/arm_scmi/protocols.h:#include <linux/completion.h>
drivers/firmware/arm_scmi/protocols.h: * @poll_completion: Indicate if the transfer needs to be polled for
drivers/firmware/arm_scmi/protocols.h: *	completion or interrupt mode is used
drivers/firmware/arm_scmi/protocols.h:	bool poll_completion;
drivers/firmware/arm_scmi/protocols.h: * @done: command message transmit completion event
drivers/firmware/arm_scmi/protocols.h: * @async_done: pointer to delayed response message received event completion
drivers/firmware/arm_scmi/protocols.h:	struct completion done;
drivers/firmware/arm_scmi/protocols.h:	struct completion *async_done;
drivers/firmware/arm_scmi/raw_mode.c: * @async_response: A completion to be, optionally, used for async waits: it
drivers/firmware/arm_scmi/raw_mode.c:	struct completion async_response;
drivers/firmware/arm_scmi/raw_mode.c:			reinit_completion(&rw->async_response);
drivers/firmware/arm_scmi/raw_mode.c:				      rw->xfer->hdr.poll_completion);
drivers/firmware/arm_scmi/raw_mode.c: * scmi_xfer_raw_worker  - Work function to wait for Raw xfers completions
drivers/firmware/arm_scmi/raw_mode.c: * on the RX path, nonetheless we have to properly wait for their completion as
drivers/firmware/arm_scmi/raw_mode.c: * usual (and async_completion too if needed) in order to properly release the
drivers/firmware/arm_scmi/raw_mode.c: * timeout for the completion, BUT we do not really care here if we end up
drivers/firmware/arm_scmi/raw_mode.c:		 * have to check the completion status anyway just in case a
drivers/firmware/arm_scmi/raw_mode.c:			if (!wait_for_completion_timeout(xfer->async_done, tmo))
drivers/firmware/arm_scmi/raw_mode.c:	xfer->hdr.poll_completion = false;
drivers/firmware/arm_scmi/raw_mode.c:		xfer->hdr.poll_completion = true;
drivers/firmware/arm_scmi/raw_mode.c:	reinit_completion(&xfer->done);
drivers/firmware/arm_scmi/raw_mode.c:			      xfer->hdr.poll_completion);
drivers/firmware/arm_scmi/raw_mode.c:		init_completion(&rw->async_response);
drivers/firmware/arm_scmi/scmi_power_control.c: * completion after which they are converted to forceful ones: the assumption
drivers/firmware/arm_scmi/shmem.c:	iowrite32(xfer->hdr.poll_completion ? 0 : SCMI_SHMEM_FLAG_INTR_ENABLED,
drivers/firmware/arm_scmi/transports/mailbox.c:	 * the SMT channel and then sends the completion interrupt.
drivers/firmware/arm_scmi/transports/mailbox.c: * @p2a_rx_chan: A reference to the optional p2a completion channel.
drivers/firmware/arm_scmi/transports/optee.c:	cinfo->no_completion_irq = true;
drivers/firmware/arm_scmi/transports/smc.c: * @irq: An optional IRQ for completion
drivers/firmware/arm_scmi/transports/smc.c:	 * completion of a message is signaled by an interrupt rather than by
drivers/firmware/arm_scmi/transports/smc.c:		cinfo->no_completion_irq = true;
drivers/firmware/arm_scmi/transports/virtio.c:#include <linux/completion.h>
drivers/firmware/arm_scmi/transports/virtio.c: * @shutdown_done: A reference to a completion used when freeing this channel.
drivers/firmware/arm_scmi/transports/virtio.c:	struct completion *shutdown_done;
drivers/firmware/arm_scmi/transports/virtio.c:	DECLARE_COMPLETION_ONSTACK(vioch_shutdown_done);
drivers/firmware/arm_scmi/transports/virtio.c:	wait_for_completion(vioch->shutdown_done);
drivers/firmware/arm_scmi/transports/virtio.c:	if (xfer->hdr.poll_completion) {
drivers/firmware/arm_scmi/transports/virtio.c:		if (xfer->hdr.poll_completion)
drivers/firmware/arm_scmi/transports/virtio.c:	if (!xfer->hdr.poll_completion || scmi_vio_msg_release(vioch, msg)) {
drivers/firmware/arm_scpi.c:	struct completion done;
drivers/firmware/arm_scpi.c:	/* check if wait_for_completion is in progress or timed-out */
drivers/firmware/arm_scpi.c:	if (match && !completion_done(&match->done)) {
drivers/firmware/arm_scpi.c:	reinit_completion(&msg->done);
drivers/firmware/arm_scpi.c:	if (!wait_for_completion_timeout(&msg->done, MAX_RX_TIMEOUT))
drivers/firmware/arm_scpi.c:		init_completion(&xfers->done);
drivers/firmware/efi/runtime-wrappers.c: * 2. Caller thread waits for completion until the work is finished
drivers/firmware/efi/runtime-wrappers.c:#include <linux/completion.h>
drivers/firmware/efi/runtime-wrappers.c: * efi_queue_work:	Queue EFI runtime service call and wait for completion
drivers/firmware/efi/runtime-wrappers.c: * thread waits for completion.
drivers/firmware/efi/runtime-wrappers.c:	init_completion(&efi_rts_work.efi_rts_comp);
drivers/firmware/efi/runtime-wrappers.c:		wait_for_completion(&efi_rts_work.efi_rts_comp);
drivers/firmware/imx/imx-scu.c:	struct completion tx_done;
drivers/firmware/imx/imx-scu.c:	struct completion done;
drivers/firmware/imx/imx-scu.c:			wait_for_completion(&sc_chan->tx_done);
drivers/firmware/imx/imx-scu.c:			reinit_completion(&sc_chan->tx_done);
drivers/firmware/imx/imx-scu.c:	reinit_completion(&sc_ipc->done);
drivers/firmware/imx/imx-scu.c:		if (!wait_for_completion_timeout(&sc_ipc->done,
drivers/firmware/imx/imx-scu.c:			/* Initial tx_done completion as "done" */
drivers/firmware/imx/imx-scu.c:			init_completion(&sc_chan->tx_done);
drivers/firmware/imx/imx-scu.c:	init_completion(&sc_ipc->done);
drivers/firmware/microchip/mpfs-auto-update.c:	struct completion programming_complete;
drivers/firmware/microchip/mpfs-auto-update.c:	ret = wait_for_completion_timeout(&priv->programming_complete,
drivers/firmware/microchip/mpfs-auto-update.c:	reinit_completion(&priv->programming_complete);
drivers/firmware/microchip/mpfs-auto-update.c:	init_completion(&priv->programming_complete);
drivers/firmware/psci/psci_checker.c:#include <linux/completion.h>
drivers/firmware/psci/psci_checker.c:static struct completion suspend_threads_started =
drivers/firmware/psci/psci_checker.c:	COMPLETION_INITIALIZER(suspend_threads_started);
drivers/firmware/psci/psci_checker.c:static struct completion suspend_threads_done =
drivers/firmware/psci/psci_checker.c:	COMPLETION_INITIALIZER(suspend_threads_done);
drivers/firmware/psci/psci_checker.c:	wait_for_completion(&suspend_threads_started);
drivers/firmware/psci/psci_checker.c:	 * wait for the completion of suspend_threads_started.
drivers/firmware/psci/psci_checker.c:	wait_for_completion(&suspend_threads_done);
drivers/firmware/qcom/qcom_scm-smc.c:			ret = qcom_scm_wait_for_wq_completion(wq_ctx);
drivers/firmware/qcom/qcom_scm.c:#include <linux/completion.h>
drivers/firmware/qcom/qcom_scm.c:	struct completion waitq_comp;
drivers/firmware/qcom/qcom_scm.c:	 * completion structs when FW supports more wq_ctx values.
drivers/firmware/qcom/qcom_scm.c:int qcom_scm_wait_for_wq_completion(u32 wq_ctx)
drivers/firmware/qcom/qcom_scm.c:	wait_for_completion(&__scm->waitq_comp);
drivers/firmware/qcom/qcom_scm.c:	init_completion(&scm->waitq_comp);
drivers/firmware/qcom/qcom_scm.h:int qcom_scm_wait_for_wq_completion(u32 wq_ctx);
drivers/firmware/raspberrypi.c:	struct completion c;
drivers/firmware/raspberrypi.c:	reinit_completion(&fw->c);
drivers/firmware/raspberrypi.c:		if (wait_for_completion_timeout(&fw->c, HZ)) {
drivers/firmware/raspberrypi.c:	init_completion(&fw->c);
drivers/firmware/stratix10-rsu.c:#include <linux/completion.h>
drivers/firmware/stratix10-rsu.c: * @completion: state for callback completion
drivers/firmware/stratix10-rsu.c: * @lock: a mutex to protect callback completion state
drivers/firmware/stratix10-rsu.c:	struct completion completion;
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	complete(&priv->completion);
drivers/firmware/stratix10-rsu.c:	reinit_completion(&priv->completion);
drivers/firmware/stratix10-rsu.c:	ret = wait_for_completion_interruptible_timeout(&priv->completion,
drivers/firmware/stratix10-rsu.c:	init_completion(&priv->completion);
drivers/firmware/stratix10-svc.c:#include <linux/completion.h>
drivers/firmware/stratix10-svc.c: * @sync_complete: state for a completion
drivers/firmware/stratix10-svc.c:	struct completion sync_complete;
drivers/firmware/stratix10-svc.c: * @complete_status: state for completion
drivers/firmware/stratix10-svc.c:	struct completion complete_status;
drivers/firmware/stratix10-svc.c:	reinit_completion(&ctrl->complete_status);
drivers/firmware/stratix10-svc.c:		 wait_for_completion_timeout(&ctrl->complete_status, timeout));
drivers/firmware/stratix10-svc.c:	init_completion(&sh_memory->sync_complete);
drivers/firmware/stratix10-svc.c:	if (!wait_for_completion_timeout(&sh_memory->sync_complete, 10 * HZ)) {
drivers/firmware/stratix10-svc.c:	init_completion(&controller->complete_status);
drivers/firmware/tegra/bpmp-tegra186.c:	init_completion(&channel->completion);
drivers/firmware/tegra/bpmp-tegra210.c:	init_completion(&channel->completion);
drivers/firmware/tegra/bpmp.c:	err = wait_for_completion_timeout(&channel->completion, timeout);
drivers/firmware/tegra/bpmp.c:	complete(&channel->completion);
drivers/firmware/ti_sci.c: * @done:	completion event
drivers/firmware/ti_sci.c:	struct completion done;
drivers/firmware/ti_sci.c: * signals completion of the transfer.
drivers/firmware/ti_sci.c:	reinit_completion(&xfer->done);
drivers/firmware/ti_sci.c:		if (!wait_for_completion_timeout(&xfer->done, timeout))
drivers/firmware/ti_sci.c:		 * If we are !running, we cannot use wait_for_completion_timeout
drivers/firmware/ti_sci.c:		 * during noirq phase, so we must manually poll the completion.
drivers/firmware/ti_sci.c:		ret = read_poll_timeout_atomic(try_wait_for_completion, done_state,
drivers/firmware/ti_sci.c:		init_completion(&xfer->done);
drivers/firmware/ti_sci.h: * @txcq_qnum: UDMAP transmit channel completion queue configuration to be
drivers/firmware/ti_sci.h: * completion queue must be assigned to the host, or a subordinate of the host,
drivers/firmware/ti_sci.h: * 1 - Wait for completion message from remote peer
drivers/firmware/ti_sci.h: * @rxcq_qnum: UDMAP receive channel completion queue configuration to be
drivers/firmware/ti_sci.h: * The specified completion queue must be assigned to the host, or a subordinate
drivers/firmware/turris-mox-rwtm.c:#include <linux/completion.h>
drivers/firmware/turris-mox-rwtm.c:	struct completion cmd_done;
drivers/firmware/turris-mox-rwtm.c:	if (completion_done(&rwtm->cmd_done))
drivers/firmware/turris-mox-rwtm.c:		ret = wait_for_completion_interruptible(&rwtm->cmd_done);
drivers/firmware/turris-mox-rwtm.c:		if (!wait_for_completion_timeout(&rwtm->cmd_done, HZ / 2))
drivers/firmware/turris-mox-rwtm.c:	init_completion(&rwtm->cmd_done);
drivers/fpga/dfl-fme-mgr.c:#define FME_PR_CTRL_PR_COMPLETE	BIT_ULL(13) /* PR data push completion */
drivers/fpga/dfl-fme-mgr.c:		dev_err(dev, "PR Completion ACK timeout.\n");
drivers/fpga/socfpga.c:#include <linux/completion.h>
drivers/fpga/socfpga.c:	struct completion status_complete;
drivers/fpga/socfpga.c:	init_completion(&priv->status_complete);
drivers/fpga/socfpga.c:	timeout = wait_for_completion_interruptible_timeout(
drivers/fpga/stratix10-soc.c:#include <linux/completion.h>
drivers/fpga/stratix10-soc.c:	struct completion status_return_completion;
drivers/fpga/stratix10-soc.c:	complete(&priv->status_return_completion);
drivers/fpga/stratix10-soc.c:	reinit_completion(&priv->status_return_completion);
drivers/fpga/stratix10-soc.c:	ret = wait_for_completion_timeout(
drivers/fpga/stratix10-soc.c:		&priv->status_return_completion, S10_RECONFIG_TIMEOUT);
drivers/fpga/stratix10-soc.c:		reinit_completion(&priv->status_return_completion);
drivers/fpga/stratix10-soc.c:			wait_status = wait_for_completion_timeout(
drivers/fpga/stratix10-soc.c:				&priv->status_return_completion,
drivers/fpga/stratix10-soc.c:		reinit_completion(&priv->status_return_completion);
drivers/fpga/stratix10-soc.c:		ret = wait_for_completion_timeout(
drivers/fpga/stratix10-soc.c:			&priv->status_return_completion, timeout);
drivers/fpga/stratix10-soc.c:	init_completion(&priv->status_return_completion);
drivers/fpga/zynq-fpga.c:#include <linux/completion.h>
drivers/fpga/zynq-fpga.c:/* Timeout for DMA completion */
drivers/fpga/zynq-fpga.c:	struct completion dma_done;
drivers/fpga/zynq-fpga.c:			 * the completion too early.
drivers/fpga/zynq-fpga.c:	/* If anything other than DMA completion is reported stop and hand
drivers/fpga/zynq-fpga.c:	reinit_completion(&priv->dma_done);
drivers/fpga/zynq-fpga.c:	timeout = wait_for_completion_timeout(&priv->dma_done,
drivers/fpga/zynq-fpga.c:	 * wait_for_completion_interruptible too.
drivers/fpga/zynq-fpga.c:	init_completion(&priv->dma_done);
drivers/fsi/fsi-master-ast-cf.c:	/* Wait for status to indicate completion (or error) */
drivers/fsi/fsi-master-ast-cf.c:				 "Timeout waiting for coprocessor completion\n");
drivers/fsi/fsi-master-ast-cf.c:	/* Wait for status register to indicate command completion
drivers/gpio/gpio-sim.c:#include <linux/completion.h>
drivers/gpio/gpio-sim.c:	struct completion probe_completion;
drivers/gpio/gpio-sim.c:	complete(&simdev->probe_completion);
drivers/gpio/gpio-sim.c:	reinit_completion(&dev->probe_completion);
drivers/gpio/gpio-sim.c:	wait_for_completion(&dev->probe_completion);
drivers/gpio/gpio-sim.c:	init_completion(&dev->probe_completion);
drivers/gpio/gpio-virtio.c:#include <linux/completion.h>
drivers/gpio/gpio-virtio.c:	struct completion completion;
drivers/gpio/gpio-virtio.c:	reinit_completion(&line->completion);
drivers/gpio/gpio-virtio.c:	wait_for_completion(&line->completion);
drivers/gpio/gpio-virtio.c:		complete(&line->completion);
drivers/gpio/gpio-virtio.c:		init_completion(&vgpio->lines[i].completion);
drivers/gpio/gpio-virtuser.c:#include <linux/completion.h>
drivers/gpio/gpio-virtuser.c:	struct completion work_completion;
drivers/gpio/gpio-virtuser.c:	init_completion(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	wait_for_completion(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	complete(&ctx->work_completion);
drivers/gpio/gpio-virtuser.c:	struct completion probe_completion;
drivers/gpio/gpio-virtuser.c:	complete(&vdev->probe_completion);
drivers/gpio/gpio-virtuser.c:	reinit_completion(&dev->probe_completion);
drivers/gpio/gpio-virtuser.c:	wait_for_completion(&dev->probe_completion);
drivers/gpio/gpio-virtuser.c:	init_completion(&dev->probe_completion);
drivers/gpu/drm/amd/amdgpu/amdgpu_acpi.c:	atcs_input.flags = ATCS_WAIT_FOR_COMPLETION;
drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c:		amdgpu_fence_driver_force_completion(ring);
drivers/gpu/drm/amd/amdgpu/amdgpu_device.c:		/* Clear job fence from fence drv to avoid force_completion
drivers/gpu/drm/amd/amdgpu/amdgpu_device.c:		/* after all hw jobs are reset, hw fence is meaningless, so force_completion */
drivers/gpu/drm/amd/amdgpu/amdgpu_device.c:		amdgpu_fence_driver_force_completion(ring);
drivers/gpu/drm/amd/amdgpu/amdgpu_device.c:			dev_dbg(adev->dev, "Detected RAS error, wait for FLR completion\n");
drivers/gpu/drm/amd/amdgpu/amdgpu_fence.c:			amdgpu_fence_driver_force_completion(ring);
drivers/gpu/drm/amd/amdgpu/amdgpu_fence.c: * amdgpu_fence_driver_force_completion - force signal latest fence of ring
drivers/gpu/drm/amd/amdgpu/amdgpu_fence.c:void amdgpu_fence_driver_force_completion(struct amdgpu_ring *ring)
drivers/gpu/drm/amd/amdgpu/amdgpu_job.c:			amdgpu_fence_driver_force_completion(ring);
drivers/gpu/drm/amd/amdgpu/amdgpu_mode.h:	int deferred_flip_completion;
drivers/gpu/drm/amd/amdgpu/amdgpu_ring.h:void amdgpu_fence_driver_force_completion(struct amdgpu_ring *ring);
drivers/gpu/drm/amd/amdgpu/amdgpu_ring_mux.h:	IB_COMPLETION_STATUS_DEFAULT = 0,
drivers/gpu/drm/amd/amdgpu/amdgpu_ring_mux.h:	IB_COMPLETION_STATUS_PREEMPTED = 1,
drivers/gpu/drm/amd/amdgpu/amdgpu_ring_mux.h:	IB_COMPLETION_STATUS_COMPLETED = 2,
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			amdgpu_fence_driver_force_completion(&adev->uvd.inst[i].ring);
drivers/gpu/drm/amd/amdgpu/amdgv_sriovmsg.h:	MB_RES_MSG_FLR_NOTIFICATION_COMPLETION,
drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c:	((struct v9_de_ib_state *)de_payload_cpu_addr)->ib_completion_status =
drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c:		IB_COMPLETION_STATUS_PREEMPTED;
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:static int mes_v11_0_submit_pkt_and_poll_completion(struct amdgpu_mes *mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	api_status->api_completion_fence_addr = status_gpu_addr;
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	api_status->api_completion_fence_value = 1;
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	mes_status_pkt.api_status.api_completion_fence_addr =
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	mes_status_pkt.api_status.api_completion_fence_value = seq;
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v11_0.c:	return mes_v11_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:static int mes_v12_0_submit_pkt_and_poll_completion(struct amdgpu_mes *mes,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	api_status->api_completion_fence_addr = status_gpu_addr;
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	api_status->api_completion_fence_value = 1;
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	mes_status_pkt.api_status.api_completion_fence_addr =
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	mes_status_pkt.api_status.api_completion_fence_value = seq;
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/mes_v12_0.c:	return mes_v12_0_submit_pkt_and_poll_completion(mes, pipe,
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/navi10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/sdma_v6_0_0_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	set_hw_resources.api_status.api_completion_fence_addr = umsch->ring.fence_drv.gpu_addr;
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	set_hw_resources.api_status.api_completion_fence_value = ++umsch->ring.fence_drv.sync_seq;
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	add_queue.api_status.api_completion_fence_addr = umsch->ring.fence_drv.gpu_addr;
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	add_queue.api_status.api_completion_fence_value = ++umsch->ring.fence_drv.sync_seq;
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	remove_queue.api_status.api_completion_fence_addr = umsch->ring.fence_drv.gpu_addr;
drivers/gpu/drm/amd/amdgpu/umsch_mm_v4_0.c:	remove_queue.api_status.api_completion_fence_value = ++umsch->ring.fence_drv.sync_seq;
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_COPY_LINEAR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_LO word*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for completion_signal_31_0 field*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_offset 14
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift  0
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_COMPLETION_SIGNAL_31_0(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_LO_completion_signal_31_0_shift)
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for COMPLETION_SIGNAL_HI word*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:/*define for completion_signal_63_32 field*/
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_offset 15
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask   0xFFFFFFFF
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift  0
drivers/gpu/drm/amd/amdgpu/vega10_sdma_pkt_open.h:#define SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_COMPLETION_SIGNAL_63_32(x) (((x) & SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_mask) << SDMA_AQL_PKT_BARRIER_OR_COMPLETION_SIGNAL_HI_completion_signal_63_32_shift)
drivers/gpu/drm/amd/amdkfd/kfd_events.c: * @all:           Return completion only if all events have signaled
drivers/gpu/drm/amd/amdkfd/kfd_packet_manager_v9.c:			interrupt_sel__mes_query_status__completion_status;
drivers/gpu/drm/amd/amdkfd/kfd_packet_manager_vi.c:			interrupt_sel__mes_query_status__completion_status;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers.h:	uint32_t completion_signal_lo32;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers.h:uint32_t completion_signal_hi32;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_ai.h:	uint32_t completion_signal_lo;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_ai.h:	uint32_t completion_signal_hi;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_ai.h:	uint32_t completion_signal_lo32;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_ai.h:	uint32_t completion_signal_hi32;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_ai.h:	interrupt_sel__mes_query_status__completion_status = 0,
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_aldebaran.h:	uint32_t completion_signal_lo;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_aldebaran.h:	uint32_t completion_signal_hi;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_vi.h:	uint32_t completion_signal_lo;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_vi.h:	uint32_t completion_signal_hi;
drivers/gpu/drm/amd/amdkfd/kfd_pm4_headers_vi.h:	interrupt_sel__mes_query_status__completion_status = 0,
drivers/gpu/drm/amd/amdkfd/kfd_priv.h: * Return: returns ioctl completion code.
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		 * count and timestamp of vblank of flip completion.
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	 * of pageflip completion, so last_flip_vblank is the forbidden count
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		 * page-flip completion events that have been queued to us
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:				drm_writeback_signal_completion(acrtc->wb_conn, 0);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	 * In that case, pageflip completion interrupts won't fire and pageflip
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	 * completion events won't get delivered. Prevent this by sending
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	 * avoid race conditions between flip programming and completion,
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	 * which could cause too early flip completion events.
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c: * Dmub AUX or SET_CONFIG command completion processing callback
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		init_completion(&adev->dm.dmub_aux_transfer_done);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	/* Signal HW programming completion */
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c: * Waits for completion of all non blocking commits.
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		ret = wait_for_completion_interruptible_timeout(&commit->hw_done, 10*HZ);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:			ret = wait_for_completion_interruptible_timeout(
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c: * that any such full update commit will wait for completion of any outstanding
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	if (!wait_for_completion_timeout(&adev->dm.dmub_aux_transfer_done, 10 * HZ)) {
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		DRM_ERROR("wait_for_completion_timeout timeout!");
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	reinit_completion(&adev->dm.dmub_aux_transfer_done);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:	if (is_cmd_complete || wait_for_completion_timeout(&adev->dm.dmub_aux_transfer_done, 10 * HZ)) {
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		DRM_ERROR("wait_for_completion_timeout timeout!");
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c:		reinit_completion(&adev->dm.dmub_aux_transfer_done);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h: * @dmub_aux_transfer_done: struct completion used to indicate when DMUB
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h:	struct completion dmub_aux_transfer_done;
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_crc.c:		ret = wait_for_completion_interruptible_timeout(
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_crtc.c:	/* Send completion event for cursor-only commits */
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_hdcp.c:			ret = wait_for_completion_interruptible_timeout(&conn_state->commit->hw_done,
drivers/gpu/drm/amd/display/dc/dc.h: * or power up event. Upon completion, the function will update link structure
drivers/gpu/drm/amd/display/dc/dm_services.h:/* DAL calls this function to notify PP about completion of Mode Set.
drivers/gpu/drm/amd/display/dc/link/protocols/link_dp_phy.c:			 * completion. Using 1 lane RBR should have the maximum
drivers/gpu/drm/amd/display/dc/link/protocols/link_dp_training_dpia.c: * - Clock recovery (CR) for link is handled by DPOA, which reports result to DPIA on completion.
drivers/gpu/drm/amd/display/dc/link/protocols/link_dp_training_dpia.c: * - equalization (EQ) for link is handled by DPOA, which reports result to DPIA on completion.
drivers/gpu/drm/amd/include/amd_acpi.h:#       define ATCS_WAIT_FOR_COMPLETION                            (1 << 1)
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_4_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D2F5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK 0xc0000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT 0x12
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK 0x200
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT 0x9
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK 0x8
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT 0x3
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK 0x80000
drivers/gpu/drm/amd/include/asic_reg/bif/bif_5_1_sh_mask.h:#define D3F5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT 0x13
drivers/gpu/drm/amd/include/asic_reg/dce/dce_10_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK 0x4
drivers/gpu/drm/amd/include/asic_reg/dce/dce_10_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT 0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_10_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK 0x4000000
drivers/gpu/drm/amd/include/asic_reg/dce/dce_10_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT 0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET= 0x0,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET= 0x1,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED= 0x0,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED= 0x1,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK 0x4
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT 0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK 0x4000000
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT 0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET= 0x0,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET= 0x1,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED= 0x0,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:	OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED= 0x1,
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK 0x4
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT 0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK 0x4000000
drivers/gpu/drm/amd/include/asic_reg/dce/dce_11_2_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT 0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_12_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dce/dce_8_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK 0x4
drivers/gpu/drm/amd/include/asic_reg/dce/dce_8_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT 0x2
drivers/gpu/drm/amd/include/asic_reg/dce/dce_8_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK 0x4000000
drivers/gpu/drm/amd/include/asic_reg/dce/dce_8_0_sh_mask.h:#define OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT 0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_2_0_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_5_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_1_6_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_0_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM2_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM3_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM4_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM5_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM6_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT          0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT      0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK            0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_3_2_1_sh_mask.h:#define AZSTREAM7_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK        0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_0_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM0_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM1_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM2_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM3_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM4_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM5_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM6_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE__SHIFT        0x2
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS__SHIFT    0x1a
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__INTERRUPT_ON_COMPLETION_ENABLE_MASK          0x00000004L
drivers/gpu/drm/amd/include/asic_reg/dcn/dcn_4_1_0_sh_mask.h:#define AZSTREAM7_1_OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS__BUFFER_COMPLETION_INTERRUPT_STATUS_MASK      0x04000000L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_default.h:#define mmCP_PFP_COMPLETION_STATUS_DEFAULT                                       0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_default.h:#define mmCP_CE_COMPLETION_STATUS_DEFAULT                                        0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_offset.h:#define mmCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_offset.h:#define mmCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_1_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_default.h:#define mmCP_PFP_COMPLETION_STATUS_DEFAULT                                       0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_default.h:#define mmCP_CE_COMPLETION_STATUS_DEFAULT                                        0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_offset.h:#define mmCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_offset.h:#define mmCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_10_3_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_default.h:#define regCP_PFP_COMPLETION_STATUS_DEFAULT                                       0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_3_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_3_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_3_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_3_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_0_3_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_5_0_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_5_0_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_5_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_5_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_11_5_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_12_0_0_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_12_0_0_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_12_0_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_12_0_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_12_0_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_default.h:#define mmCP_PFP_COMPLETION_STATUS_DEFAULT                                       0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_default.h:#define mmCP_CE_COMPLETION_STATUS_DEFAULT                                        0x00000000
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_offset.h:#define mmCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_offset.h:#define mmCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_offset.h:#define mmCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_offset.h:#define mmCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_offset.h:#define mmCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_offset.h:#define mmCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_offset.h:#define mmCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_offset.h:#define mmCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_offset.h:#define mmCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_offset.h:#define mmCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_offset.h:#define mmCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_2_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_offset.h:#define regCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_offset.h:#define regCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_2_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_offset.h:#define regCP_PFP_COMPLETION_STATUS                                                                     0x20ec
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_offset.h:#define regCP_PFP_COMPLETION_STATUS_BASE_IDX                                                            1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_offset.h:#define regCP_CE_COMPLETION_STATUS                                                                      0x20ed
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_offset.h:#define regCP_CE_COMPLETION_STATUS_BASE_IDX                                                             1
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h://CP_PFP_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT                                                               0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK                                                                 0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h://CP_CE_COMPLETION_STATUS
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT                                                                0x0
drivers/gpu/drm/amd/include/asic_reg/gc/gc_9_4_3_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK                                                                  0x00000003L
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_d.h:#define mmCP_PFP_COMPLETION_STATUS                                              0xc0ec
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_d.h:#define mmCP_CE_COMPLETION_STATUS                                               0xc0ed
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_enum.h:	TCC_PERF_SEL_MDC_TAG_WAITING_FOR_INVALIDATE_COMPLETION_STALL= 0x69,
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK 0x3
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT 0x0
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK 0x3
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_0_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT 0x0
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_d.h:#define mmCP_PFP_COMPLETION_STATUS                                              0xc0ec
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_d.h:#define mmCP_CE_COMPLETION_STATUS                                               0xc0ed
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_enum.h:	TCC_PERF_SEL_MDC_TAG_WAITING_FOR_INVALIDATE_COMPLETION_STALL= 0x69,
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS_MASK 0x3
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_sh_mask.h:#define CP_PFP_COMPLETION_STATUS__STATUS__SHIFT 0x0
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS_MASK 0x3
drivers/gpu/drm/amd/include/asic_reg/gca/gfx_8_1_sh_mask.h:#define CP_CE_COMPLETION_STATUS__STATUS__SHIFT 0x0
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCCSTRAPRCCSTRAP_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT               0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__MASK                                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__MASK                                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__MASK                                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__MASK                                 0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCCSTRAPRCCSTRAP_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__MASK                0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_1_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1__MASK                                 0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbif/nbif_6_3_1_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                  0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                              0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                             0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                               0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                       0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                         0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                  0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                              0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                       0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                         0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF16_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF17_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF18_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF19_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF20_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF21_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF22_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF23_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF24_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF25_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF26_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF27_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF28_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF29_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_2_3_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF30_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                  0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                              0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                             0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                               0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                     0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                       0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                   0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                     0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                  0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                              0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define PSWUSCFG0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_4_3_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_SWDS1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                             0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_6_1_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                               0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP6_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFP6_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR5_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIFPLR6_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_11_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                          0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                            0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                          0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                            0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                              0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                                0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                  0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                    0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP2_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP3_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP4_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP6_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFP6_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP3_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define RCC_STRAP3_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIFPLR6_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_2_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PSWUSCFG0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                       0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                         0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                         0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                           0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                       0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                         0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                       0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                         0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                   0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_SWDS0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                     0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF8_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF9_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF10_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF11_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF12_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF13_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF14_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                   0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                     0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                 0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF15_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                   0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                             0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_4_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                               0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                          0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                            0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                          0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                            0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF3_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF4_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                    0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                      0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                  0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                    0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_DEV1_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV1_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2__SHIFT                                0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_DEV2_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV2_MASK                                  0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP0_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP0_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP1_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP1_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP2_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP2_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP3_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP3_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP4_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP4_0_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_0_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP0_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP0_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP1_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP1_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP2_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP2_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP3_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP3_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP4_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                     0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP4_1_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                       0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                       0x12
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFP5_PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                         0x000C0000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP3_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define RCC_STRAP3_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR0_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR1_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR2_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR3_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR4_2_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                                  0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                                    0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                                0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                                  0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                                0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                                  0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                            0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                              0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL__SHIFT                                                0x2
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIFPLR5_1_PCIE_DPC_CNTL__DPC_COMPLETION_CONTROL_MASK                                                  0x0004L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_RC1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF3_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF4_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF5_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF6_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV0_EPF7_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV1_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF0_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF1_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_7_0_sh_mask.h:#define BIF_CFG_DEV2_EPF2_1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP0_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                          0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                            0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                        0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                          0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                        0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                          0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                    0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                      0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                           0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                             0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                         0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                           0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                         0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                           0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                     0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                       0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                        0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                          0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                      0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                        0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                  0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF1_0_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                    0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP1_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0__SHIFT                     0x1a
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define RCC_STRAP2_RCC_DEV0_PORT_STRAP5__STRAP_ACS_P2P_COMPLETION_REDIRECT_DN_DEV0_MASK                       0x04000000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                            0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                              0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                          0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                            0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT__SHIFT                                          0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CAP__P2P_COMPLETION_REDIRECT_MASK                                            0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN__SHIFT                                      0x3
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_RC_PCIE_ACS_CNTL__P2P_COMPLETION_REDIRECT_EN_MASK                                        0x0008L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF0_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF1_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF2_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF3_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF4_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF5_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF6_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE__SHIFT                                      0x9
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_DEVICE_CNTL2__IDO_COMPLETION_ENABLE_MASK                                        0x0200L
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE__SHIFT                    0xc
drivers/gpu/drm/amd/include/asic_reg/nbio/nbio_7_9_0_sh_mask.h:#define BIF_CFG_DEV0_EPF0_VF7_PCIE_ADV_ERR_CAP_CNTL__COMPLETION_TIMEOUT_LOG_CAPABLE_MASK                      0x00001000L
drivers/gpu/drm/amd/include/asic_reg/pcie/pcie_6_1_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT__SHIFT                             0x12
drivers/gpu/drm/amd/include/asic_reg/pcie/pcie_6_1_0_sh_mask.h:#define PCIEP_ERROR_INJECT_TRANSACTION__ERROR_INJECT_TL_COMPLETION_TIMEOUT_MASK                               0x000C0000L
drivers/gpu/drm/amd/include/mes_v11_api_def.h:	uint64_t	api_completion_fence_addr;
drivers/gpu/drm/amd/include/mes_v11_api_def.h:	uint64_t	api_completion_fence_value;
drivers/gpu/drm/amd/include/mes_v12_api_def.h:	uint64_t api_completion_fence_addr;
drivers/gpu/drm/amd/include/mes_v12_api_def.h:	uint64_t api_completion_fence_value;
drivers/gpu/drm/amd/include/navi10_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS enum
drivers/gpu/drm/amd/include/navi10_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/navi10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET  = 0x00000000,
drivers/gpu/drm/amd/include/navi10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET  = 0x00000001,
drivers/gpu/drm/amd/include/navi10_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/navi10_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE enum
drivers/gpu/drm/amd/include/navi10_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/navi10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED  = 0x00000000,
drivers/gpu/drm/amd/include/navi10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED  = 0x00000001,
drivers/gpu/drm/amd/include/navi10_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/navi10_enum.h:GL2C_PERF_SEL_MDC_TAG_WAITING_FOR_INVALIDATE_COMPLETION_STALL  = 0x000000aa,
drivers/gpu/drm/amd/include/soc21_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS enum
drivers/gpu/drm/amd/include/soc21_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/soc21_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET = 0x00000000,
drivers/gpu/drm/amd/include/soc21_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET = 0x00000001,
drivers/gpu/drm/amd/include/soc21_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/soc21_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE enum
drivers/gpu/drm/amd/include/soc21_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/soc21_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED = 0x00000000,
drivers/gpu/drm/amd/include/soc21_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED = 0x00000001,
drivers/gpu/drm/amd/include/soc21_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/soc21_enum.h:GL2C_PERF_SEL_MDC_TAG_WAITING_FOR_INVALIDATE_COMPLETION_STALL = 0x000000ba,
drivers/gpu/drm/amd/include/soc24_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS enum
drivers/gpu/drm/amd/include/soc24_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/soc24_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET = 0x00000000,
drivers/gpu/drm/amd/include/soc24_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET = 0x00000001,
drivers/gpu/drm/amd/include/soc24_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/soc24_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE enum
drivers/gpu/drm/amd/include/soc24_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/soc24_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED = 0x00000000,
drivers/gpu/drm/amd/include/soc24_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED = 0x00000001,
drivers/gpu/drm/amd/include/soc24_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/umsch_mm_4_0_api_def.h:	uint64_t api_completion_fence_addr;
drivers/gpu/drm/amd/include/umsch_mm_4_0_api_def.h:	uint32_t api_completion_fence_value;
drivers/gpu/drm/amd/include/v10_structs.h:	uint32_t ce_ib_completion_status;
drivers/gpu/drm/amd/include/v10_structs.h:	uint32_t ib_completion_status;
drivers/gpu/drm/amd/include/v9_structs.h:    uint32_t ce_ib_completion_status;
drivers/gpu/drm/amd/include/v9_structs.h:    uint32_t ib_completion_status;
drivers/gpu/drm/amd/include/vega10_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS enum
drivers/gpu/drm/amd/include/vega10_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS {
drivers/gpu/drm/amd/include/vega10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_NOT_SET  = 0x00000000,
drivers/gpu/drm/amd/include/vega10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS_SET  = 0x00000001,
drivers/gpu/drm/amd/include/vega10_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_BUFFER_COMPLETION_INTERRUPT_STATUS;
drivers/gpu/drm/amd/include/vega10_enum.h: * OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE enum
drivers/gpu/drm/amd/include/vega10_enum.h:typedef enum OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE {
drivers/gpu/drm/amd/include/vega10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_DISABLED  = 0x00000000,
drivers/gpu/drm/amd/include/vega10_enum.h:OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE_INTERRUPT_ENABLED  = 0x00000001,
drivers/gpu/drm/amd/include/vega10_enum.h:} OUTPUT_STREAM_DESCRIPTOR_CONTROL_AND_STATUS_INTERRUPT_ON_COMPLETION_ENABLE;
drivers/gpu/drm/amd/include/vega10_enum.h:TCC_PERF_SEL_MDC_TAG_WAITING_FOR_INVALIDATE_COMPLETION_STALL  = 0x0000006d,
drivers/gpu/drm/amd/include/vi_structs.h:	uint32_t    ce_ib_completion_status;
drivers/gpu/drm/amd/include/vi_structs.h:	uint32_t    ib_completion_status;
drivers/gpu/drm/amd/include/vi_structs.h:	uint32_t    ce_ib_completion_status;
drivers/gpu/drm/amd/include/vi_structs.h:	uint32_t    ib_completion_status;
drivers/gpu/drm/amd/pm/swsmu/smu_cmn.c: * completion of the command, and return back a value from the SMU in
drivers/gpu/drm/amd/pm/swsmu/smu_cmn.c: * Command completion status is printed only if the -errno is
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:			drm_writeback_signal_completion(&wb_conn->base, 0);
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:					 struct completion *input_flip_done)
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:	struct completion *flip_done;
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:	struct completion temp;
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:		init_completion(&temp);
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:	if (wait_for_completion_timeout(flip_done, HZ) == 0) {
drivers/gpu/drm/arm/display/komeda/komeda_crtc.c:	struct completion *disable_done;
drivers/gpu/drm/arm/display/komeda/komeda_kms.c:			struct completion *flip_done = NULL;
drivers/gpu/drm/arm/display/komeda/komeda_kms.c:				flip_done = kcrtc->base.state->event->base.completion;
drivers/gpu/drm/arm/display/komeda/komeda_kms.h:	struct completion *disable_done;
drivers/gpu/drm/arm/display/komeda/komeda_kms.h:					      struct completion *input_flip_done);
drivers/gpu/drm/arm/malidp_hw.c:			drm_writeback_signal_completion(&malidp->mw_connector, 0);
drivers/gpu/drm/arm/malidp_hw.c:			drm_writeback_signal_completion(&malidp->mw_connector, 0);
drivers/gpu/drm/arm/malidp_hw.c:			drm_writeback_signal_completion(&malidp->mw_connector, 0);
drivers/gpu/drm/bridge/cadence/cdns-dsi-core.c:	reinit_completion(&dsi->direct_cmd_comp);
drivers/gpu/drm/bridge/cadence/cdns-dsi-core.c:	wait_for_completion_timeout(&dsi->direct_cmd_comp,
drivers/gpu/drm/bridge/cadence/cdns-dsi-core.c:	init_completion(&dsi->direct_cmd_comp);
drivers/gpu/drm/bridge/cadence/cdns-dsi-core.h:#include <linux/completion.h>
drivers/gpu/drm/bridge/cadence/cdns-dsi-core.h:	struct completion direct_cmd_comp;
drivers/gpu/drm/bridge/ite-it6505.c:	struct completion extcon_completion;
drivers/gpu/drm/bridge/ite-it6505.c:		wait_for_completion_timeout(&it6505->extcon_completion,
drivers/gpu/drm/bridge/ite-it6505.c:		complete_all(&it6505->extcon_completion);
drivers/gpu/drm/bridge/ite-it6505.c:		reinit_completion(&it6505->extcon_completion);
drivers/gpu/drm/bridge/ite-it6505.c:	init_completion(&it6505->extcon_completion);
drivers/gpu/drm/bridge/nwl-dsi.c:	struct completion completed;
drivers/gpu/drm/bridge/nwl-dsi.c:	init_completion(&xfer.completed);
drivers/gpu/drm/bridge/nwl-dsi.c:	if (!wait_for_completion_timeout(&xfer.completed,
drivers/gpu/drm/bridge/samsung-dsim.c:	if (wait_for_completion_timeout(&dsi->completed, msecs_to_jiffies(300)))
drivers/gpu/drm/bridge/samsung-dsim.c:	reinit_completion(&dsi->completed);
drivers/gpu/drm/bridge/samsung-dsim.c:	init_completion(&xfer->completed);
drivers/gpu/drm/bridge/samsung-dsim.c:	wait_for_completion_timeout(&xfer->completed,
drivers/gpu/drm/bridge/samsung-dsim.c:	init_completion(&dsi->completed);
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:	struct completion	cmp;
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:	stat = wait_for_completion_timeout(&i2c->cmp, HZ / 10);
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:		stat = wait_for_completion_timeout(&i2c->cmp, HZ / 10);
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:		reinit_completion(&i2c->cmp);
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:		reinit_completion(&i2c->cmp);
drivers/gpu/drm/bridge/synopsys/dw-hdmi.c:	init_completion(&i2c->cmp);
drivers/gpu/drm/display/drm_dp_tunnel.c: * Handle any pending DP tunnel IRQs, waking up waiters for a completion
drivers/gpu/drm/drm_atomic.c:	ret = wait_for_completion_timeout(&commit->hw_done, timeout);
drivers/gpu/drm/drm_atomic.c:	ret = wait_for_completion_timeout(&commit->flip_done, timeout);
drivers/gpu/drm/drm_atomic_helper.c: * drm_atomic_helper_wait_for_vblanks() this waits for the completion on all
drivers/gpu/drm/drm_atomic_helper.c: * CRTCs, assuming that cursors-only updates are signalling their completion
drivers/gpu/drm/drm_atomic_helper.c:		ret = wait_for_completion_timeout(&commit->flip_done, 10 * HZ);
drivers/gpu/drm/drm_atomic_helper.c:	    !try_wait_for_completion(&old_plane_state->commit->hw_done)) {
drivers/gpu/drm/drm_atomic_helper.c:	 * checked in parallel to the asynchronous completion of the previous
drivers/gpu/drm/drm_atomic_helper.c:			completed = try_wait_for_completion(&commit->flip_done);
drivers/gpu/drm/drm_atomic_helper.c:	ret = wait_for_completion_interruptible_timeout(&stall_commit->cleanup_done,
drivers/gpu/drm/drm_atomic_helper.c:static void release_crtc_commit(struct completion *completion)
drivers/gpu/drm/drm_atomic_helper.c:	struct drm_crtc_commit *commit = container_of(completion,
drivers/gpu/drm/drm_atomic_helper.c:	init_completion(&commit->flip_done);
drivers/gpu/drm/drm_atomic_helper.c:	init_completion(&commit->hw_done);
drivers/gpu/drm/drm_atomic_helper.c:	init_completion(&commit->cleanup_done);
drivers/gpu/drm/drm_atomic_helper.c: * Completion of the hardware commit step must be signalled using
drivers/gpu/drm/drm_atomic_helper.c:		new_crtc_state->event->base.completion = &commit->flip_done;
drivers/gpu/drm/drm_atomic_helper.c:		new_crtc_state->event->base.completion_release = release_crtc_commit;
drivers/gpu/drm/drm_atomic_helper.c:		commit->abort_completion = true;
drivers/gpu/drm/drm_atomic_helper.c:		    !try_wait_for_completion(&old_conn_state->commit->flip_done)) {
drivers/gpu/drm/drm_atomic_helper.c:		    !try_wait_for_completion(&old_plane_state->commit->flip_done)) {
drivers/gpu/drm/drm_atomic_helper.c: * This function is used to signal completion of the hardware commit step. After
drivers/gpu/drm/drm_atomic_helper.c: * drm_atomic_helper_commit_cleanup_done - signal completion of commit
drivers/gpu/drm/drm_atomic_helper.c: * This signals completion of the atomic update @old_state, including any
drivers/gpu/drm/drm_atomic_helper.c:		WARN_ON(!try_wait_for_completion(&commit->hw_done));
drivers/gpu/drm/drm_atomic_helper.c:		WARN_ON(!try_wait_for_completion(&old_state->fake_commit->hw_done));
drivers/gpu/drm/drm_atomic_helper.c:			ret = wait_for_completion_interruptible(&commit->hw_done);
drivers/gpu/drm/drm_atomic_helper.c:			ret = wait_for_completion_interruptible(&commit->hw_done);
drivers/gpu/drm/drm_atomic_helper.c:			ret = wait_for_completion_interruptible(&commit->hw_done);
drivers/gpu/drm/drm_atomic_helper.c: * @event: optional DRM event to signal upon completion
drivers/gpu/drm/drm_atomic_helper.c: * @event: optional DRM event to signal upon completion
drivers/gpu/drm/drm_atomic_state_helper.c:		 * state->event->base.completion.
drivers/gpu/drm/drm_atomic_state_helper.c:		if (state->event && state->commit->abort_completion)
drivers/gpu/drm/drm_connector.c: *	property to reflect the new state on completion of the commit of the
drivers/gpu/drm/drm_crtc_helper.c:	 * are later needed by vblank and swap-completion
drivers/gpu/drm/drm_file.c: * page flip completions by the KMS API. But drivers can also use it for their
drivers/gpu/drm/drm_file.c: * own needs, e.g. to signal completion of rendering.
drivers/gpu/drm/drm_file.c: * Since events are used by the KMS API for vblank and page flip completion this
drivers/gpu/drm/drm_file.c: * events are used by the KMS API for vblank and page flip completion this means
drivers/gpu/drm/drm_file.c: * using drm_send_event() or drm_send_event_locked() to signal completion of the
drivers/gpu/drm/drm_file.c: * using drm_send_event() or drm_send_event_locked() to signal completion of the
drivers/gpu/drm/drm_file.c:	if (e->completion) {
drivers/gpu/drm/drm_file.c:		complete_all(e->completion);
drivers/gpu/drm/drm_file.c:		e->completion_release(e->completion);
drivers/gpu/drm/drm_file.c:		e->completion = NULL;
drivers/gpu/drm/drm_file.c: * completion of the asynchronous work unconditionally.
drivers/gpu/drm/drm_file.c: * completion of the asynchronous work unconditionally.
drivers/gpu/drm/drm_file.c: * completion of the asynchronous work unconditionally.
drivers/gpu/drm/drm_syncobj.c: * signaled by the completion of that work.
drivers/gpu/drm/drm_syncobj.c: * completion of the DRM driver's work and also any work associated with the
drivers/gpu/drm/drm_vblank.c: * swap-completion timestamping, e.g, by
drivers/gpu/drm/drm_vblank.c: * commit sequence has run to completion. If the hardware does not have such a
drivers/gpu/drm/drm_writeback.c: * signaled via drm_writeback_signal_completion).
drivers/gpu/drm/drm_writeback.c: * drm_writeback_signal_completion()
drivers/gpu/drm/drm_writeback.c: * See also: drm_writeback_signal_completion()
drivers/gpu/drm/drm_writeback.c: * The job cannot be cleaned up directly in drm_writeback_signal_completion,
drivers/gpu/drm/drm_writeback.c: * drm_writeback_signal_completion - Signal the completion of a writeback job
drivers/gpu/drm/drm_writeback.c: * Drivers should call this to signal the completion of a previously queued
drivers/gpu/drm/drm_writeback.c:drm_writeback_signal_completion(struct drm_writeback_connector *wb_connector,
drivers/gpu/drm/drm_writeback.c:EXPORT_SYMBOL(drm_writeback_signal_completion);
drivers/gpu/drm/etnaviv/etnaviv_gpu.c:	init_completion(&gpu->event_free);
drivers/gpu/drm/etnaviv/etnaviv_gpu.c:	 * GPU lock must already be held, otherwise fence completion order might
drivers/gpu/drm/etnaviv/etnaviv_gpu.c:		remaining = wait_for_completion_timeout(&gpu->event_free, timeout);
drivers/gpu/drm/etnaviv/etnaviv_gpu.c:			dev_err(gpu->dev, "wait_for_completion_timeout failed");
drivers/gpu/drm/etnaviv/etnaviv_gpu.c:		/* No timeout was requested: just test for completion */
drivers/gpu/drm/etnaviv/etnaviv_gpu.h:	struct completion event_free;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	struct completion	complete;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:			 * pool to be released after the dma access completion.
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	 * The engine is busy and the completion of the current node is going
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	init_completion(&runqueue_node->complete);
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	wait_for_completion(&runqueue_node->complete);
drivers/gpu/drm/gma500/oaktrail_hdmi_i2c.c:	struct completion complete;
drivers/gpu/drm/gma500/oaktrail_hdmi_i2c.c:	reinit_completion(&i2c_dev->complete);
drivers/gpu/drm/gma500/oaktrail_hdmi_i2c.c:		wait_for_completion_interruptible_timeout(&i2c_dev->complete,
drivers/gpu/drm/gma500/oaktrail_hdmi_i2c.c:	init_completion(&i2c_dev->complete);
drivers/gpu/drm/gma500/psb_reg.h: * Scheduler completion actions.
drivers/gpu/drm/hyperv/hyperv_drm.h:	struct completion wait;
drivers/gpu/drm/hyperv/hyperv_drm_drv.c:	init_completion(&hv->wait);
drivers/gpu/drm/hyperv/hyperv_drm_proto.c:	t = wait_for_completion_timeout(&hv->wait, VMBUS_VSP_TIMEOUT);
drivers/gpu/drm/hyperv/hyperv_drm_proto.c:	t = wait_for_completion_timeout(&hv->wait, VMBUS_VSP_TIMEOUT);
drivers/gpu/drm/hyperv/hyperv_drm_proto.c:	t = wait_for_completion_timeout(&hv->wait, VMBUS_VSP_TIMEOUT);
drivers/gpu/drm/i915/Kconfig.profile:	int "Busywait for request completion limit (ns)"
drivers/gpu/drm/i915/Kconfig.profile:	  we may spend some time polling for its completion. As the IRQ may
drivers/gpu/drm/i915/display/hsw_ips.c:	    !try_wait_for_completion(&crtc_state->uapi.commit->hw_done))
drivers/gpu/drm/i915/display/intel_atomic_plane.c:	 * we've already signalled flip completion. We can resume LP1+
drivers/gpu/drm/i915/display/intel_cdclk.c:		 * FIXME: Waiting for the request completion could be delayed
drivers/gpu/drm/i915/display/intel_cursor.c:	    !try_wait_for_completion(&old_plane_state->uapi.commit->hw_done))
drivers/gpu/drm/i915/display/intel_ddi.c:	    !try_wait_for_completion(&conn_state->commit->hw_done))
drivers/gpu/drm/i915/display/intel_display.c:			try_wait_for_completion(&commit->cleanup_done) : true;
drivers/gpu/drm/i915/display/intel_display_debugfs.c:			ret = wait_for_completion_interruptible(&commit->hw_done);
drivers/gpu/drm/i915/display/intel_display_debugfs.c:				ret = wait_for_completion_interruptible(&commit->flip_done);
drivers/gpu/drm/i915/display/intel_dp.c:				    !wait_for_completion_timeout(&conn_state->commit->hw_done,
drivers/gpu/drm/i915/display/intel_dp.c:		    !try_wait_for_completion(&conn_state->commit->hw_done))
drivers/gpu/drm/i915/display/intel_drrs.c:		ret = wait_for_completion_interruptible(&commit->hw_done);
drivers/gpu/drm/i915/display/intel_frontbuffer.c: * frontbuffer flushing will be delayed until completion is signalled with
drivers/gpu/drm/i915/display/intel_global_state.c:	struct completion done;
drivers/gpu/drm/i915/display/intel_global_state.c:	init_completion(&commit->done);
drivers/gpu/drm/i915/display/intel_global_state.c:		ret = wait_for_completion_timeout(&commit->done, 10 * HZ);
drivers/gpu/drm/i915/display/intel_opregion.c:#define SWSCI_SBCB_INIT_COMPLETION	SWSCI_FUNCTION_CODE(SWSCI_SBCB, 1)
drivers/gpu/drm/i915/display/intel_psr_regs.h:#define   EDP_PSR_DEBUG_ENTRY_COMPLETION	REG_BIT(1)  /* hsw/bdw */
drivers/gpu/drm/i915/gem/i915_gem_object.c: * On successful completion, the object will have pages pointing to
drivers/gpu/drm/i915/gem/i915_gem_object.c: * On successful completion, the object will have pages pointing to
drivers/gpu/drm/i915/gem/i915_gem_pm.c:	 * On rare occasions, we've observed the fence completion triggers
drivers/gpu/drm/i915/gt/intel_breadcrumbs.c:	 * its signal completion.
drivers/gpu/drm/i915/gt/intel_context_types.h:	 * upon completion/cancellation of the last request.
drivers/gpu/drm/i915/gt/intel_engine_pm.c:	 * list of active timelines looking for completions. Meanwhile as soon
drivers/gpu/drm/i915/gt/intel_engine_pm.c:	 * engine->wakeref.count, we may see the request completion and retire
drivers/gpu/drm/i915/gt/intel_engine_types.h:	struct completion completion;
drivers/gpu/drm/i915/gt/intel_execlists_submission.c:	 * (each request in the timeline waits for the completion fence of
drivers/gpu/drm/i915/gt/intel_execlists_submission.c:	 * may not be visible to the HW prior to the completion of the UC
drivers/gpu/drm/i915/gt/intel_execlists_submission.c:	 * the resubmission of a completed request (background completion
drivers/gpu/drm/i915/gt/intel_execlists_submission.c:	if (ve->request) { /* background completion from preempt-to-busy */
drivers/gpu/drm/i915/gt/intel_ggtt_fencing.c: * fences used to track command completion but hardware detiler objects which
drivers/gpu/drm/i915/gt/intel_ggtt_fencing.c:	/* Wait for completion of pending flips which consume fences */
drivers/gpu/drm/i915/gt/intel_reset.c:	 * state is not cleared until shortly after GDRST reports completion,
drivers/gpu/drm/i915/gt/intel_ring.c:		/* Would completion of this request free enough space? */
drivers/gpu/drm/i915/gt/selftest_execlists.c:			 * Ensure we do the switch to ce[1] on completion.
drivers/gpu/drm/i915/gt/selftest_execlists.c:			 * uses the submit fence, not the completion fence),
drivers/gpu/drm/i915/gt/selftest_execlists.c:	 * completion event.
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:		GEM_TRACE("%s timed out waiting for completion of fence %llx:%lld\n",
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:	struct completion completion;
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:	complete(&arg->completion);
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:	complete(&arg->completion);
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:	init_completion(&arg.completion);
drivers/gpu/drm/i915/gt/selftest_hangcheck.c:	wait_for_completion(&arg.completion);
drivers/gpu/drm/i915/gt/uc/intel_guc_fw.c: * the value matches either completion or a known failure code.
drivers/gpu/drm/i915/i915_active.h: * signal its completion to the owner through a callback as well as mark
drivers/gpu/drm/i915/i915_active.h: * after completion, the optional callback @func is invoked.
drivers/gpu/drm/i915/i915_active.h: * i915_active_fence_set() watches the given @rq for completion. While
drivers/gpu/drm/i915/i915_active.h: * signals a fence upon completion. struct i915_request combines the
drivers/gpu/drm/i915/i915_request.c:	 * completion order.
drivers/gpu/drm/i915/i915_request.c:	 * and HuC loading completion to be small (a few hundred ms).
drivers/gpu/drm/i915/i915_request.c:	 * alternatively we use completion fence if gem context has a single
drivers/gpu/drm/i915/i915_request.c: * request is not being tracked for completion but the work itself is
drivers/gpu/drm/i915/i915_request.c:	 * rate. By busywaiting on the request completion for a short while we
drivers/gpu/drm/i915/i915_request.c:	 * completion. That requires having a good predictor for the request
drivers/gpu/drm/i915/i915_sw_fence.h:struct completion;
drivers/gpu/drm/i915/intel_pcode.c:	 * the request completion.
drivers/gpu/drm/i915/intel_uncore.c:		drm_err(&i915->drm, "Driver-FLR-teardown wait completion failed! %d\n", ret);
drivers/gpu/drm/i915/intel_uncore.c:		drm_err(&i915->drm, "Driver-FLR-reinit wait completion failed! %d\n", ret);
drivers/gpu/drm/i915/intel_uncore.c:	/* Clear sticky completion status */
drivers/gpu/drm/i915/pxp/intel_pxp.c:	 * we'll use the completion to check if there is a termination pending,
drivers/gpu/drm/i915/pxp/intel_pxp.c:	init_completion(&pxp->termination);
drivers/gpu/drm/i915/pxp/intel_pxp.c:	reinit_completion(&pxp->termination);
drivers/gpu/drm/i915/pxp/intel_pxp.c:	 * To ensure synchronous and coherent session teardown completion
drivers/gpu/drm/i915/pxp/intel_pxp.c:	if (!wait_for_completion_timeout(&pxp->termination, msecs_to_jiffies(timeout)))
drivers/gpu/drm/i915/pxp/intel_pxp.c:	if (!wait_for_completion_timeout(&pxp->termination, msecs_to_jiffies(timeout))) {
drivers/gpu/drm/i915/pxp/intel_pxp.c: * termination completion interrupt
drivers/gpu/drm/i915/pxp/intel_pxp_debugfs.c:	if (!wait_for_completion_timeout(&pxp->termination,
drivers/gpu/drm/i915/pxp/intel_pxp_gsccs.c:	/* copy caller provided gsc message handle if this is polling for a prior msg completion */
drivers/gpu/drm/i915/pxp/intel_pxp_gsccs.c:		 * operation has begun but the completion is pending and the caller needs
drivers/gpu/drm/i915/pxp/intel_pxp_gsccs.c:	 * sessions. Checking for completion on HuC authentication and
drivers/gpu/drm/i915/pxp/intel_pxp_types.h:#include <linux/completion.h>
drivers/gpu/drm/i915/pxp/intel_pxp_types.h:	struct completion termination;
drivers/gpu/drm/i915/selftests/i915_request.c:static int measure_completion(struct intel_context *ce)
drivers/gpu/drm/i915/selftests/i915_request.c:	 * Completion latency: B - A
drivers/gpu/drm/i915/selftests/i915_request.c:	pr_info("%s: completion latency %d cycles, %lluns\n",
drivers/gpu/drm/i915/selftests/i915_request.c:			err = measure_completion(ce);
drivers/gpu/drm/i915/selftests/i915_selftest.c:	 * and in corner cases (the first time after an IFWI flash), init-completion
drivers/gpu/drm/i915/selftests/i915_selftest.c:		pr_warn(DRIVER_NAME "Timed out waiting for gsc_proxy_completion!\n");
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:#include <linux/completion.h>
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:	/* Test i915_sw_fence signaling and completion testing */
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:	struct completion started;
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:	/* use a completion to avoid chicken-and-egg testing */
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:	init_completion(&ipc.started);
drivers/gpu/drm/i915/selftests/i915_sw_fence.c:	wait_for_completion(&ipc.started);
drivers/gpu/drm/imagination/pvr_ccb.c: * pvr_kccb_wait_for_completion() - Wait for a KCCB command to complete
drivers/gpu/drm/imagination/pvr_ccb.c:pvr_kccb_wait_for_completion(struct pvr_device *pvr_dev, u32 slot_nr,
drivers/gpu/drm/imagination/pvr_ccb.h:int pvr_kccb_wait_for_completion(struct pvr_device *pvr_dev, u32 slot_nr, u32 timeout,
drivers/gpu/drm/imagination/pvr_fw.c: * On successful completion of the function the PowerVR device will be
drivers/gpu/drm/imagination/pvr_fw.c:	err = pvr_kccb_wait_for_completion(pvr_dev, slot_nr, HZ, &rtn);
drivers/gpu/drm/imagination/pvr_mmu.c:	err = pvr_kccb_wait_for_completion(pvr_dev, slot, HZ, NULL);
drivers/gpu/drm/imagination/pvr_mmu.c:		err = pvr_kccb_wait_for_completion(pvr_dev, slot, HZ, NULL);
drivers/gpu/drm/imagination/pvr_mmu.c: *        completion. This (High) field holds bits 39..18 of the value; the
drivers/gpu/drm/imagination/pvr_rogue_fwif_sf.h:	  "Waiting for transfer of type 0x%02x completion..." },
drivers/gpu/drm/imx/dcss/dcss-crtc.c:	reinit_completion(&dcss->disable_completion);
drivers/gpu/drm/imx/dcss/dcss-crtc.c:		if (!wait_for_completion_timeout(&dcss->disable_completion,
drivers/gpu/drm/imx/dcss/dcss-ctxld.c:#define CTXLD_IRQ_COMPLETION		(DB_COMP | SB_HP_COMP | SB_LP_COMP)
drivers/gpu/drm/imx/dcss/dcss-ctxld.c:	if (irq_status & CTXLD_IRQ_COMPLETION &&
drivers/gpu/drm/imx/dcss/dcss-ctxld.c:	dcss_clr(irq_status & (CTXLD_IRQ_ERROR | CTXLD_IRQ_COMPLETION),
drivers/gpu/drm/imx/dcss/dcss-dev.c:	complete(&dcss->disable_completion);
drivers/gpu/drm/imx/dcss/dcss-dev.c:	init_completion(&dcss->disable_completion);
drivers/gpu/drm/imx/dcss/dcss-dev.h:	struct completion disable_completion;
drivers/gpu/drm/imx/dcss/dcss-dev.h:void dcss_ctxld_register_completion(struct dcss_ctxld *ctxld,
drivers/gpu/drm/imx/dcss/dcss-dev.h:				    struct completion *dis_completion);
drivers/gpu/drm/lima/lima_sched.c:	 * To prevent a race condition on its completion, mask all irqs
drivers/gpu/drm/mediatek/mtk_disp_ovl.c:	/* Clear frame completion interrupt */
drivers/gpu/drm/mediatek/mtk_disp_rdma.c:	/* Clear frame completion interrupt */
drivers/gpu/drm/mediatek/mtk_dp.c:static int mtk_dp_aux_wait_for_completion(struct mtk_dp *mtk_dp, bool is_read)
drivers/gpu/drm/mediatek/mtk_dp.c:		/* Give the hardware a chance to reach completion before retrying */
drivers/gpu/drm/mediatek/mtk_dp.c:	ret = mtk_dp_aux_wait_for_completion(mtk_dp, is_read);
drivers/gpu/drm/msm/adreno/a5xx_gpu.c:	/* Yield the floor on command completion */
drivers/gpu/drm/msm/adreno/a5xx_gpu.c:	/* Yield the floor on command completion */
drivers/gpu/drm/msm/adreno/a6xx_gmu.c:	init_completion(&gmu->pd_gate);
drivers/gpu/drm/msm/adreno/a6xx_gmu.c:	init_completion(&gmu->pd_gate);
drivers/gpu/drm/msm/adreno/a6xx_gmu.h:#include <linux/completion.h>
drivers/gpu/drm/msm/adreno/a6xx_gmu.h:	struct completion pd_gate;
drivers/gpu/drm/msm/adreno/a6xx_gpu.c:	reinit_completion(&gmu->pd_gate);
drivers/gpu/drm/msm/adreno/a6xx_gpu.c:	if (!wait_for_completion_timeout(&gmu->pd_gate, msecs_to_jiffies(1000)))
drivers/gpu/drm/msm/adreno/a6xx_hfi.c:#include <linux/completion.h>
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	DPU_ATRACE_BEGIN("frame done completion wait");
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	ret = wait_for_completion_timeout(&dpu_crtc->frame_done_comp,
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	DPU_ATRACE_END("frame done completion wait");
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	reinit_completion(&dpu_crtc->frame_done_comp);
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	/* wait for frame_event_done completion */
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.c:	init_completion(&dpu_crtc->frame_done_comp);
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.h:	struct completion frame_done_comp;
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.h: * dpu_crtc_vblank_callback - called on vblank irq, issues completion events
drivers/gpu/drm/msm/disp/dpu1/dpu_crtc.h: * dpu_crtc_complete_commit - callback signalling completion of current commit
drivers/gpu/drm/msm/disp/dpu1/dpu_encoder_phys_vid.c:	 * frame, need to check and wait for hw initiated ctl reset completion
drivers/gpu/drm/msm/disp/dpu1/dpu_encoder_phys_wb.c:		drm_writeback_signal_completion(wb_enc->wb_conn, 0);
drivers/gpu/drm/msm/disp/dpu1/dpu_encoder_phys_wb.c:		drm_writeback_signal_completion(wb_enc->wb_conn, 0);
drivers/gpu/drm/msm/disp/mdp5/mdp5_crtc.c:	struct completion pp_completion;
drivers/gpu/drm/msm/disp/mdp5/mdp5_crtc.c:	reinit_completion(&mdp5_crtc->pp_completion);
drivers/gpu/drm/msm/disp/mdp5/mdp5_crtc.c:	complete_all(&mdp5_crtc->pp_completion);
drivers/gpu/drm/msm/disp/mdp5/mdp5_crtc.c:	ret = wait_for_completion_timeout(&mdp5_crtc->pp_completion,
drivers/gpu/drm/msm/disp/mdp5/mdp5_crtc.c:	init_completion(&mdp5_crtc->pp_completion);
drivers/gpu/drm/msm/dp/dp_aux.c:	struct completion comp;
drivers/gpu/drm/msm/dp/dp_aux.c:	reinit_completion(&aux->comp);
drivers/gpu/drm/msm/dp/dp_aux.c:	time_left = wait_for_completion_timeout(&aux->comp,
drivers/gpu/drm/msm/dp/dp_aux.c:	init_completion(&aux->comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:#include <linux/completion.h>
drivers/gpu/drm/msm/dp/dp_ctrl.c:#define IDLE_PATTERN_COMPLETION_TIMEOUT_JIFFIES	(30 * HZ / 1000) /* 30 ms */
drivers/gpu/drm/msm/dp/dp_ctrl.c:#define PSR_OPERATION_COMPLETION_TIMEOUT_JIFFIES       (300 * HZ / 1000) /* 300 ms */
drivers/gpu/drm/msm/dp/dp_ctrl.c:	struct completion idle_comp;
drivers/gpu/drm/msm/dp/dp_ctrl.c:	struct completion psr_op_comp;
drivers/gpu/drm/msm/dp/dp_ctrl.c:	struct completion video_comp;
drivers/gpu/drm/msm/dp/dp_ctrl.c:	reinit_completion(&ctrl->idle_comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:	if (!wait_for_completion_timeout(&ctrl->idle_comp,
drivers/gpu/drm/msm/dp/dp_ctrl.c:			IDLE_PATTERN_COMPLETION_TIMEOUT_JIFFIES))
drivers/gpu/drm/msm/dp/dp_ctrl.c:	if (!wait_for_completion_timeout(&ctrl->video_comp,
drivers/gpu/drm/msm/dp/dp_ctrl.c:		reinit_completion(&ctrl->psr_op_comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:		if (!wait_for_completion_timeout(&ctrl->psr_op_comp,
drivers/gpu/drm/msm/dp/dp_ctrl.c:			PSR_OPERATION_COMPLETION_TIMEOUT_JIFFIES)) {
drivers/gpu/drm/msm/dp/dp_ctrl.c:	reinit_completion(&ctrl->video_comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:	init_completion(&ctrl->idle_comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:	init_completion(&ctrl->psr_op_comp);
drivers/gpu/drm/msm/dp/dp_ctrl.c:	init_completion(&ctrl->video_comp);
drivers/gpu/drm/msm/dp/dp_display.c:	struct completion audio_comp;
drivers/gpu/drm/msm/dp/dp_display.c:	reinit_completion(&dp->audio_comp);
drivers/gpu/drm/msm/dp/dp_display.c:		if (!wait_for_completion_timeout(&dp->audio_comp,
drivers/gpu/drm/msm/dp/dp_display.c:	init_completion(&dp->audio_comp);
drivers/gpu/drm/msm/dsi/dsi_host.c:	struct completion dma_comp;
drivers/gpu/drm/msm/dsi/dsi_host.c:	struct completion video_comp;
drivers/gpu/drm/msm/dsi/dsi_host.c:	reinit_completion(&msm_host->video_comp);
drivers/gpu/drm/msm/dsi/dsi_host.c:	ret = wait_for_completion_timeout(&msm_host->video_comp,
drivers/gpu/drm/msm/dsi/dsi_host.c:	reinit_completion(&msm_host->dma_comp);
drivers/gpu/drm/msm/dsi/dsi_host.c:		ret = wait_for_completion_timeout(&msm_host->dma_comp,
drivers/gpu/drm/msm/dsi/dsi_host.c:	init_completion(&msm_host->dma_comp);
drivers/gpu/drm/msm/dsi/dsi_host.c:	init_completion(&msm_host->video_comp);
drivers/gpu/drm/msm/hdmi/hdmi_hdcp.c:	/* Check if need to wait for HW completion */
drivers/gpu/drm/nouveau/dispnv04/disp.c:	/* Disable flip completion events. */
drivers/gpu/drm/nouveau/dispnv04/disp.c:	/* Enable flip completion events. */
drivers/gpu/drm/nouveau/dispnv04/disp.c:	/* Request page flip completion event. */
drivers/gpu/drm/nouveau/dispnv50/core507d.c:		if (NVBO_TD32(bo, offset, NV_DISP_CORE_NOTIFIER_1, COMPLETION_0, DONE, ==, TRUE))
drivers/gpu/drm/nouveau/dispnv50/core507d.c:	NVBO_WR32(bo, offset, NV_DISP_CORE_NOTIFIER_1, COMPLETION_0,
drivers/gpu/drm/nouveau/dispnv50/core507d.c:			NVDEF(NV_DISP_CORE_NOTIFIER_1, COMPLETION_0, DONE, FALSE));
drivers/gpu/drm/nouveau/dispnv50/disp.c:	/* Wait for HW to signal completion. */
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0                                         0x00000000
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0_DONE                                    0:0
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0_DONE_FALSE                              0x00000000
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0_DONE_TRUE                               0x00000001
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0_R0                                      15:1
drivers/gpu/drm/nouveau/include/nvhw/class/cl507d.h:#define NV_DISP_CORE_NOTIFIER_1_COMPLETION_0_TIMESTAMP                               29:16
drivers/gpu/drm/nouveau/include/nvhw/class/cl9039.h:#define NV9039_LAUNCH_DMA_COMPLETION_TYPE                                                                   13:12
drivers/gpu/drm/nouveau/include/nvhw/class/cl9039.h:#define NV9039_LAUNCH_DMA_COMPLETION_TYPE_FLUSH_DISABLE                                                0x00000000
drivers/gpu/drm/nouveau/include/nvhw/class/cl9039.h:#define NV9039_LAUNCH_DMA_COMPLETION_TYPE_FLUSH_ONLY                                                   0x00000001
drivers/gpu/drm/nouveau/include/nvhw/class/cl9039.h:#define NV9039_LAUNCH_DMA_COMPLETION_TYPE_RELEASE_SEMAPHORE                                            0x00000002
drivers/gpu/drm/nouveau/include/nvkm/subdev/pmu.h:	struct completion wpr_ready;
drivers/gpu/drm/nouveau/nouveau_bo9039.c:			  NVDEF(NV9039, LAUNCH_DMA, COMPLETION_TYPE, FLUSH_DISABLE) |
drivers/gpu/drm/nouveau/nouveau_drv.h: *      - fixes multiple bugs in flip completion events and timestamping
drivers/gpu/drm/nouveau/nouveau_uvmm.c:	init_completion(&reg->complete);
drivers/gpu/drm/nouveau/nouveau_uvmm.c:					wait_for_completion(&bind_job->complete);
drivers/gpu/drm/nouveau/nouveau_uvmm.c:		wait_for_completion(&reg->complete);
drivers/gpu/drm/nouveau/nouveau_uvmm.c:	init_completion(&job->complete);
drivers/gpu/drm/nouveau/nouveau_uvmm.h:	struct completion complete;
drivers/gpu/drm/nouveau/nouveau_uvmm.h:	struct completion complete;
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/gpc.fuc:// fall through to main loop after completion.
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/gpc.fuc://	     31:31: set to signal completion
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/gpc.fuc:// Set this GPC's bit in HUB_BAR, used to signal completion of various
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/gpc.fuc:	// mark completion in HUB's barrier
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/hub.fuc:// fall through to main loop after completion.
drivers/gpu/drm/nouveau/nvkm/engine/gr/fuc/hub.fuc://	     31:31: set to signal completion
drivers/gpu/drm/nouveau/nvkm/falcon/cmdq.c:	if (!wait_for_completion_timeout(&cmdq->ready,
drivers/gpu/drm/nouveau/nvkm/falcon/cmdq.c:		if (!wait_for_completion_timeout(&seq->done, timeout)) {
drivers/gpu/drm/nouveau/nvkm/falcon/cmdq.c:	reinit_completion(&cmdq->ready);
drivers/gpu/drm/nouveau/nvkm/falcon/cmdq.c:	init_completion(&cmdq->ready);
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.c:	reinit_completion(&seq->done);
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.c:		init_completion(&qmgr->seq.id[i].done);
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.h: * can be called and/or a completion signaled.
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.h: * @completion:	completion to signal after callback is called
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.h:	struct completion done;
drivers/gpu/drm/nouveau/nvkm/falcon/qmgr.h:	struct completion ready;
drivers/gpu/drm/nouveau/nvkm/subdev/clk/gm20b.c:	 * wait for completion, and use results along with default slope to
drivers/gpu/drm/nouveau/nvkm/subdev/pmu/base.c:	init_completion(&pmu->wpr_ready);
drivers/gpu/drm/nouveau/nvkm/subdev/pmu/fuc/memx.fuc:	// send completion reply
drivers/gpu/drm/nouveau/nvkm/subdev/pmu/gm20b.c:	reinit_completion(&pmu->wpr_ready);
drivers/gpu/drm/omapdrm/dss/dsi.c:static void dsi_completion_handler(void *data, u32 mask)
drivers/gpu/drm/omapdrm/dss/dsi.c:	complete((struct completion *)data);
drivers/gpu/drm/omapdrm/dss/dsi.c:		complete(vp_data->completion);
drivers/gpu/drm/omapdrm/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/gpu/drm/omapdrm/dss/dsi.c:		.completion = &completion
drivers/gpu/drm/omapdrm/dss/dsi.c:	/* Wait for completion only if TE_EN/TE_START is still set */
drivers/gpu/drm/omapdrm/dss/dsi.c:		if (wait_for_completion_timeout(&completion,
drivers/gpu/drm/omapdrm/dss/dsi.c:		complete(l4_data->completion);
drivers/gpu/drm/omapdrm/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/gpu/drm/omapdrm/dss/dsi.c:		.completion = &completion
drivers/gpu/drm/omapdrm/dss/dsi.c:	/* Wait for completion only if TX_FIFO_NOT_EMPTY is still set */
drivers/gpu/drm/omapdrm/dss/dsi.c:		if (wait_for_completion_timeout(&completion,
drivers/gpu/drm/omapdrm/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/gpu/drm/omapdrm/dss/dsi.c:	r = dsi_register_isr_vc(dsi, vc, dsi_completion_handler,
drivers/gpu/drm/omapdrm/dss/dsi.c:			&completion, DSI_VC_IRQ_BTA);
drivers/gpu/drm/omapdrm/dss/dsi.c:	r = dsi_register_isr(dsi, dsi_completion_handler, &completion,
drivers/gpu/drm/omapdrm/dss/dsi.c:	if (wait_for_completion_timeout(&completion,
drivers/gpu/drm/omapdrm/dss/dsi.c:	dsi_unregister_isr(dsi, dsi_completion_handler, &completion,
drivers/gpu/drm/omapdrm/dss/dsi.c:	dsi_unregister_isr_vc(dsi, vc, dsi_completion_handler,
drivers/gpu/drm/omapdrm/dss/dsi.c:			&completion, DSI_VC_IRQ_BTA);
drivers/gpu/drm/omapdrm/dss/dsi.h:	struct completion *completion;
drivers/gpu/drm/omapdrm/dss/venc.c:#include <linux/completion.h>
drivers/gpu/drm/omapdrm/omap_dmm_priv.h:	struct completion compl;
drivers/gpu/drm/omapdrm/omap_dmm_tiler.c:#include <linux/completion.h>
drivers/gpu/drm/omapdrm/omap_dmm_tiler.c:	reinit_completion(&engine->compl);
drivers/gpu/drm/omapdrm/omap_dmm_tiler.c:	/* verify that the irq handler sees the 'async' and completion value */
drivers/gpu/drm/omapdrm/omap_dmm_tiler.c:		if (!wait_for_completion_timeout(&engine->compl,
drivers/gpu/drm/omapdrm/omap_dmm_tiler.c:		init_completion(&omap_dmm->engines[i].compl);
drivers/gpu/drm/omapdrm/omap_drv.c:static void omap_atomic_wait_for_completion(struct drm_device *dev,
drivers/gpu/drm/omapdrm/omap_drv.c:		omap_atomic_wait_for_completion(dev, old_state);
drivers/gpu/drm/omapdrm/omap_drv.c:	 * Wait for completion of the page flips to ensure that old buffers
drivers/gpu/drm/omapdrm/omap_drv.c:	omap_atomic_wait_for_completion(dev, old_state);
drivers/gpu/drm/panfrost/panfrost_issues.h:	/* Intermittent missing interrupt on job completion */
drivers/gpu/drm/panfrost/panfrost_issues.h:	/* When a hard-stop follows close after a soft-stop, the completion
drivers/gpu/drm/panfrost/panfrost_job.c:	kref_get(&job->refcount); /* put by scheduler job completion */
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:#include <linux/completion.h>
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	struct completion dump_comp;
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	reinit_completion(&pfdev->perfcnt->dump_comp);
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	ret = wait_for_completion_interruptible_timeout(&pfdev->perfcnt->dump_comp,
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	reinit_completion(&pfdev->perfcnt->dump_comp);
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	ret = wait_for_completion_timeout(&pfdev->perfcnt->dump_comp,
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	init_completion(&perfcnt->dump_comp);
drivers/gpu/drm/panthor/panthor_device.c:		wait_for_completion(&ptdev->unplug.done);
drivers/gpu/drm/panthor/panthor_device.c:	init_completion(&ptdev->unplug.done);
drivers/gpu/drm/panthor/panthor_device.h:		 * @done: Completion object signaled when the unplug
drivers/gpu/drm/panthor/panthor_device.h:		struct completion done;
drivers/gpu/drm/panthor/panthor_heap.c: * @pending_frag_count: Number of fragment jobs waiting for execution/completion.
drivers/gpu/drm/pl111/pl111_drv.c: *   vsync firing the pageflip completion.
drivers/gpu/drm/radeon/radeon.h:void radeon_fence_driver_force_completion(struct radeon_device *rdev, int ring);
drivers/gpu/drm/radeon/radeon_acpi.c:	atcs_input.flags = ATCS_WAIT_FOR_COMPLETION;
drivers/gpu/drm/radeon/radeon_acpi.h:#       define ATCS_WAIT_FOR_COMPLETION                            (1 << 1)
drivers/gpu/drm/radeon/radeon_device.c:			radeon_fence_driver_force_completion(rdev, i);
drivers/gpu/drm/radeon/radeon_device.c:			radeon_fence_driver_force_completion(rdev, i);
drivers/gpu/drm/radeon/radeon_display.c:	/* Skip the pageflip completion check below (based on polling) on
drivers/gpu/drm/radeon/radeon_display.c:	 * asics which reliably support hw pageflip completion irqs. pflip
drivers/gpu/drm/radeon/radeon_display.c:	 * completion detection. A use_pflipirq module parameter < 2 allows
drivers/gpu/drm/radeon/radeon_display.c:	 * Note that this method of completion handling is still not 100% race
drivers/gpu/drm/radeon/radeon_display.c:	 * vblank, leading to a delayed emission of the flip completion event.
drivers/gpu/drm/radeon/radeon_display.c:	 * flip completion handling from vblank irq, as these old asics don't
drivers/gpu/drm/radeon/radeon_display.c:	 * have reliable pageflip completion interrupts.
drivers/gpu/drm/radeon/radeon_dp_auxch.c:		dev_err(rdev->dev, "auxch hw never signalled completion, error %08x\n", tmp);
drivers/gpu/drm/radeon/radeon_drv.c:MODULE_PARM_DESC(use_pflipirq, "Pflip irqs for pageflip completion (0 = disable, 1 = as fallback, 2 = exclusive (default))");
drivers/gpu/drm/radeon/radeon_fence.c:			radeon_fence_driver_force_completion(rdev, ring);
drivers/gpu/drm/radeon/radeon_fence.c: * radeon_fence_driver_force_completion - force all fence waiter to complete
drivers/gpu/drm/radeon/radeon_fence.c:void radeon_fence_driver_force_completion(struct radeon_device *rdev, int ring)
drivers/gpu/drm/radeon/radeon_ib.c:			radeon_fence_driver_force_completion(rdev, i);
drivers/gpu/drm/renesas/rcar-du/rcar_du_crtc.c:	 * for page flip completion before stopping the CRTC as userspace
drivers/gpu/drm/renesas/rcar-du/rcar_du_crtc.h: * @flip_wait: wait queue used to signal page flip completion
drivers/gpu/drm/renesas/rcar-du/rcar_du_plane.c: * updates from .atomic_check() up to completion (when swapping the states if
drivers/gpu/drm/renesas/rcar-du/rcar_du_writeback.c:	drm_writeback_signal_completion(&rcrtc->writeback, 0);
drivers/gpu/drm/renesas/rz-du/rzg2l_du_crtc.c:	 * for page flip completion before stopping the CRTC as userspace
drivers/gpu/drm/renesas/rz-du/rzg2l_du_crtc.h: * @flip_wait: wait queue used to signal page flip completion
drivers/gpu/drm/renesas/shmobile/shmob_drm_crtc.c:	 * for page flip completion before stopping the CRTC as userspace
drivers/gpu/drm/rockchip/inno_hdmi.c:	struct completion cmp;
drivers/gpu/drm/rockchip/inno_hdmi.c:	ret = wait_for_completion_timeout(&hdmi->i2c->cmp, HZ / 10);
drivers/gpu/drm/rockchip/inno_hdmi.c:	reinit_completion(&hdmi->i2c->cmp);
drivers/gpu/drm/rockchip/inno_hdmi.c:	init_completion(&i2c->cmp);
drivers/gpu/drm/rockchip/rk3066_hdmi.c:	struct completion cmpltn;
drivers/gpu/drm/rockchip/rk3066_hdmi.c:	ret = wait_for_completion_timeout(&hdmi->i2c->cmpltn, HZ / 10);
drivers/gpu/drm/rockchip/rk3066_hdmi.c:	reinit_completion(&hdmi->i2c->cmpltn);
drivers/gpu/drm/rockchip/rk3066_hdmi.c:	init_completion(&i2c->cmpltn);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	struct completion dsp_hold_completion;
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	struct completion line_flag_completion;
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	reinit_completion(&vop->dsp_hold_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	if (!wait_for_completion_timeout(&vop->dsp_hold_completion,
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	 * signalling flip completion we need to wait for it to finish.
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:		complete(&vop->dsp_hold_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:		complete(&vop->line_flag_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	init_completion(&vop->dsp_hold_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	init_completion(&vop->line_flag_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	reinit_completion(&vop->line_flag_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop.c:	jiffies_left = wait_for_completion_timeout(&vop->line_flag_completion,
drivers/gpu/drm/rockchip/rockchip_drm_vop2.c:	struct completion dsp_hold_completion;
drivers/gpu/drm/rockchip/rockchip_drm_vop2.c:	reinit_completion(&vp->dsp_hold_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop2.c:	ret = wait_for_completion_timeout(&vp->dsp_hold_completion,
drivers/gpu/drm/rockchip/rockchip_drm_vop2.c:			complete(&vp->dsp_hold_completion);
drivers/gpu/drm/rockchip/rockchip_drm_vop2.c:		init_completion(&vp->dsp_hold_completion);
drivers/gpu/drm/scheduler/sched_entity.c:#include <linux/completion.h>
drivers/gpu/drm/scheduler/sched_entity.c:	init_completion(&entity->entity_idle);
drivers/gpu/drm/scheduler/sched_entity.c:	wait_for_completion(&entity->entity_idle);
drivers/gpu/drm/scheduler/sched_main.c:#include <linux/completion.h>
drivers/gpu/drm/scheduler/sched_main.c:				reinit_completion(&entity->entity_idle);
drivers/gpu/drm/scheduler/sched_main.c:			reinit_completion(&entity->entity_idle);
drivers/gpu/drm/scheduler/sched_main.c:			reinit_completion(&entity->entity_idle);
drivers/gpu/drm/scheduler/sched_main.c: * or other places that need to track the completion of this job.
drivers/gpu/drm/sun4i/sun6i_mipi_dsi.c:static int sun6i_dsi_inst_wait_for_completion(struct sun6i_dsi *dsi)
drivers/gpu/drm/sun4i/sun6i_mipi_dsi.c:	ret = sun6i_dsi_inst_wait_for_completion(dsi);
drivers/gpu/drm/sun4i/sun6i_mipi_dsi.c:	ret = sun6i_dsi_inst_wait_for_completion(dsi);
drivers/gpu/drm/sun4i/sun6i_mipi_dsi.c:	ret = sun6i_dsi_inst_wait_for_completion(dsi);
drivers/gpu/drm/tegra/dc.c:		 * opposite applies to the completion phase (post_commit).
drivers/gpu/drm/tegra/dpaux.c:	struct completion complete;
drivers/gpu/drm/tegra/dpaux.c:	status = wait_for_completion_timeout(&dpaux->complete, timeout);
drivers/gpu/drm/tegra/dpaux.c:	init_completion(&dpaux->complete);
drivers/gpu/drm/tidss/tidss_crtc.c:	complete(&tcrtc->framedone_completion);
drivers/gpu/drm/tidss/tidss_crtc.c:	reinit_completion(&tcrtc->framedone_completion);
drivers/gpu/drm/tidss/tidss_crtc.c:	if (!wait_for_completion_timeout(&tcrtc->framedone_completion,
drivers/gpu/drm/tidss/tidss_crtc.c:	init_completion(&tcrtc->framedone_completion);
drivers/gpu/drm/tidss/tidss_crtc.h:#include <linux/completion.h>
drivers/gpu/drm/tidss/tidss_crtc.h:	struct completion framedone_completion;
drivers/gpu/drm/tilcdc/tilcdc_crtc.c:	struct completion palette_loaded;
drivers/gpu/drm/tilcdc/tilcdc_crtc.c:	reinit_completion(&tilcdc_crtc->palette_loaded);
drivers/gpu/drm/tilcdc/tilcdc_crtc.c:	ret = wait_for_completion_timeout(&tilcdc_crtc->palette_loaded,
drivers/gpu/drm/tilcdc/tilcdc_crtc.c:	init_completion(&tilcdc_crtc->palette_loaded);
drivers/gpu/drm/udl/udl_drv.h:void udl_urb_completion(struct urb *urb);
drivers/gpu/drm/udl/udl_main.c:void udl_urb_completion(struct urb *urb)
drivers/gpu/drm/udl/udl_main.c:				  buf, size, udl_urb_completion, unode);
drivers/gpu/drm/udl/udl_main.c:		udl_urb_completion(urb); /* because no one else will */
drivers/gpu/drm/udl/udl_modeset.c:		udl_urb_completion(urb);
drivers/gpu/drm/udl/udl_transfer.c:		udl_urb_completion(urb);
drivers/gpu/drm/v3d/v3d_gem.c:	 * need to wait for completion before dispatching the job --
drivers/gpu/drm/v3d/v3d_gem.c: * signaling job completion.  So, we synchronously wait before
drivers/gpu/drm/v3d/v3d_submit.c:	/* put by scheduler job completion */
drivers/gpu/drm/vboxvideo/vboxvideo.h: * The guest driver can handle asynch guest cmd completion by reading the
drivers/gpu/drm/vc4/vc4_dsi.c:#include <linux/completion.h>
drivers/gpu/drm/vc4/vc4_dsi.c:	struct completion xfer_completion;
drivers/gpu/drm/vc4/vc4_dsi.c:	/* Enable the appropriate interrupt for the transfer completion. */
drivers/gpu/drm/vc4/vc4_dsi.c:	reinit_completion(&dsi->xfer_completion);
drivers/gpu/drm/vc4/vc4_dsi.c:	if (!wait_for_completion_timeout(&dsi->xfer_completion,
drivers/gpu/drm/vc4/vc4_dsi.c:		complete(&dsi->xfer_completion);
drivers/gpu/drm/vc4/vc4_dsi.c:		complete(&dsi->xfer_completion);
drivers/gpu/drm/vc4/vc4_dsi.c:	init_completion(&dsi->xfer_completion);
drivers/gpu/drm/vc4/vc4_hdmi.c:	    !try_wait_for_completion(&conn_state->commit->hw_done)) {
drivers/gpu/drm/vc4/vc4_txp.c:	drm_writeback_signal_completion(&txp->connector, 0);
drivers/gpu/drm/vgem/vgem_fence.c: * completion. Note that if a conflicting fence is already on the dma-buf (i.e.
drivers/gpu/drm/virtio/virtgpu_object.c:		/* completion handler calls virtio_gpu_cleanup_object() */
drivers/gpu/drm/vkms/vkms_composer.c:		drm_writeback_signal_completion(&out->wb_connector, 0);
drivers/gpu/drm/vmwgfx/ttm_object.h: * @existed: Upon completion, indicates that an identical reference object
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c: * The backup buffer will be fenced or idle upon successful completion,
drivers/gpu/drm/xe/display/xe_display.c:			wait_for_completion(&commit->cleanup_done);
drivers/gpu/drm/xe/xe_bo.c: * On successful completion, the object memory will be moved to sytem memory.
drivers/gpu/drm/xe/xe_bo.c: * On successful completion, the object memory will be moved back to VRAM.
drivers/gpu/drm/xe/xe_bo.c: * On successful completion, the object memory type will be updated,
drivers/gpu/drm/xe/xe_bo.c: * On successful completion, the object memory will be moved to evict
drivers/gpu/drm/xe/xe_device.c:		drm_err(&xe->drm, "Driver-FLR-teardown wait completion failed! %d\n", ret);
drivers/gpu/drm/xe/xe_device.c:		drm_err(&xe->drm, "Driver-FLR-reinit wait completion failed! %d\n", ret);
drivers/gpu/drm/xe/xe_device.c:	/* Clear sticky completion status */
drivers/gpu/drm/xe/xe_exec_queue_types.h:	/** @fence_irq: fence IRQ used to signal job completion */
drivers/gpu/drm/xe/xe_execlist.c:	 * may not be visible to the HW prior to the completion of the UC
drivers/gpu/drm/xe/xe_ggtt.c:	 * to wait for completion of prior GTT writes before letting this through.
drivers/gpu/drm/xe/xe_gsc.c:void xe_gsc_wait_for_worker_completion(struct xe_gsc *gsc)
drivers/gpu/drm/xe/xe_gsc.h:void xe_gsc_wait_for_worker_completion(struct xe_gsc *gsc);
drivers/gpu/drm/xe/xe_gsc_proxy.c:	xe_gsc_wait_for_worker_completion(gsc);
drivers/gpu/drm/xe/xe_gsc_proxy.c:	xe_gsc_wait_for_worker_completion(gsc);
drivers/gpu/drm/xe/xe_gt_sriov_pf_config.c: * @timeout: maximum timeout to wait for completion in jiffies
drivers/gpu/drm/xe/xe_gt_sriov_pf_control.c:		reinit_completion(&cs->done);
drivers/gpu/drm/xe/xe_gt_sriov_pf_control.c:	return wait_for_completion_timeout(&cs->done, timeout) ? 0 : -ETIMEDOUT;
drivers/gpu/drm/xe/xe_gt_sriov_pf_control.c:		init_completion(&cs->done);
drivers/gpu/drm/xe/xe_gt_sriov_pf_control_types.h:#include <linux/completion.h>
drivers/gpu/drm/xe/xe_gt_sriov_pf_control_types.h:	/** @done: completion of async operations */
drivers/gpu/drm/xe/xe_gt_sriov_pf_control_types.h:	struct completion done;
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * completion
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * Issue a TLB invalidation for the GuC. Completion of TLB is asynchronous and
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * caller can use the invalidation fence to wait for completion.
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * Issue a TLB invalidation for the GGTT. Completion of TLB invalidation is
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * completion
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * TLB invalidation. Completion of TLB is asynchronous and caller can use
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * the invalidation fence to wait for completion.
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * completion, can be NULL
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * TLB invalidation. Completion of TLB is asynchronous and caller can use
drivers/gpu/drm/xe/xe_gt_tlb_invalidation.c: * the invalidation fence to wait for completion.
drivers/gpu/drm/xe/xe_gt_tlb_invalidation_types.h: * invalidation completion.
drivers/gpu/drm/xe/xe_guc.c: * known terminal states (either completion or failure) of either the
drivers/gpu/drm/xe/xe_guc.c: * successful completion, -1 for failure and 0 for any intermediate state.
drivers/gpu/drm/xe/xe_guc_relay.c:	/** @done: completion of the outgoing transaction. */
drivers/gpu/drm/xe/xe_guc_relay.c:	struct completion done;
drivers/gpu/drm/xe/xe_guc_relay.c:	init_completion(&txn->done);
drivers/gpu/drm/xe/xe_guc_relay.c:	n = wait_for_completion_timeout(&txn->done, timeout);
drivers/gpu/drm/xe/xe_guc_relay.c:		reinit_completion(&txn->done);
drivers/gpu/drm/xe/xe_migrate.c: * Return: A dma_fence that, when signaled, indicates the update completion.
drivers/gpu/drm/xe/xe_oa.c: * Exposes the metrics sysfs directory upon completion of module initialization
drivers/gpu/drm/xe/xe_pcode.c:	 * the request completion.
drivers/gpu/drm/xe/xe_sched_job_types.h:	 * @fence: dma fence to indicate completion. 1 way relationship - job
drivers/gpu/drm/xe/xe_uc.c:	xe_gsc_wait_for_worker_completion(&uc->gsc);
drivers/gpu/drm/xe/xe_vm_doc.h: * doc) are used instead to signal operation's completion.
drivers/gpu/drm/xen/xen_drm_front.c:	reinit_completion(&evtchnl->u.req.completion);
drivers/gpu/drm/xen/xen_drm_front.c:	if (wait_for_completion_timeout(&evtchnl->u.req.completion,
drivers/gpu/drm/xen/xen_drm_front_evtchnl.c:			complete(&evtchnl->u.req.completion);
drivers/gpu/drm/xen/xen_drm_front_evtchnl.c:		complete_all(&evtchnl->u.req.completion);
drivers/gpu/drm/xen/xen_drm_front_evtchnl.c:		init_completion(&evtchnl->u.req.completion);
drivers/gpu/drm/xen/xen_drm_front_evtchnl.h:#include <linux/completion.h>
drivers/gpu/drm/xen/xen_drm_front_evtchnl.h:			struct completion completion;
drivers/gpu/host1x/cdma.c:		wait_for_completion(&cdma->complete);
drivers/gpu/host1x/cdma.c:		wait_for_completion(&cdma->complete);
drivers/gpu/host1x/cdma.c:	init_completion(&cdma->complete);
drivers/gpu/host1x/cdma.h:#include <linux/completion.h>
drivers/gpu/host1x/cdma.h:	struct host1x_syncpt *syncpt;	/* buffer completion syncpt */
drivers/gpu/host1x/cdma.h:	struct completion complete;	/* signalled when event occurs */
drivers/gpu/ipu-v3/ipu-dc.c:	struct completion	comp;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct completion aborted;
drivers/gpu/ipu-v3/ipu-image-convert.c:		/* call the completion callback and free the run */
drivers/gpu/ipu-v3/ipu-image-convert.c: * completion handler for each.
drivers/gpu/ipu-v3/ipu-image-convert.c: * try to force the completion of runs for this ctx. Called when
drivers/gpu/ipu-v3/ipu-image-convert.c:	init_completion(&ctx->aborted);
drivers/gpu/ipu-v3/ipu-image-convert.c:		reinit_completion(&ctx->aborted);
drivers/gpu/ipu-v3/ipu-image-convert.c:		"%s: task %u: wait for completion: %d runs\n",
drivers/gpu/ipu-v3/ipu-image-convert.c:	ret = wait_for_completion_timeout(&ctx->aborted,
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct completion *comp = data;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct completion comp;
drivers/gpu/ipu-v3/ipu-image-convert.c:	init_completion(&comp);
drivers/gpu/ipu-v3/ipu-image-convert.c:	ret = wait_for_completion_timeout(&comp, msecs_to_jiffies(10000));
drivers/greybus/es2.c:	struct completion response_received;
drivers/greybus/es2.c:	init_completion(&rpc->response_received);
drivers/greybus/es2.c:	retval = wait_for_completion_interruptible_timeout(
drivers/greybus/interface.c:	complete(&intf->mode_switch_completion);
drivers/greybus/interface.c:	ret = wait_for_completion_interruptible_timeout(
drivers/greybus/interface.c:			&intf->mode_switch_completion, timeout);
drivers/greybus/interface.c:	reinit_completion(&intf->mode_switch_completion);
drivers/greybus/interface.c:	init_completion(&intf->mode_switch_completion);
drivers/greybus/interface.c:		complete(&intf->mode_switch_completion);
drivers/greybus/operation.c:/* Workqueue to handle Greybus operation completions. */
drivers/greybus/operation.c:static struct workqueue_struct *gb_operation_completion_wq;
drivers/greybus/operation.c:		queue_work(gb_operation_completion_wq, &operation->work);
drivers/greybus/operation.c:	init_completion(&operation->completion);
drivers/greybus/operation.c:	complete(&operation->completion);
drivers/greybus/operation.c: * @callback:	the operation completion callback
drivers/greybus/operation.c:	ret = wait_for_completion_interruptible(&operation->completion);
drivers/greybus/operation.c:	 * schedule its completion.
drivers/greybus/operation.c:			queue_work(gb_operation_completion_wq,
drivers/greybus/operation.c:		queue_work(gb_operation_completion_wq, &operation->work);
drivers/greybus/operation.c:		queue_work(gb_operation_completion_wq, &operation->work);
drivers/greybus/operation.c:	gb_operation_completion_wq = alloc_workqueue("greybus_completion",
drivers/greybus/operation.c:	if (!gb_operation_completion_wq)
drivers/greybus/operation.c:	destroy_workqueue(gb_operation_completion_wq);
drivers/greybus/operation.c:	gb_operation_completion_wq = NULL;
drivers/hid/amd-sfh-hid/amd_sfh_hid.h: * @hid_wait:		Completion waitq
drivers/hid/hid-ft260.c:	struct completion wait;
drivers/hid/hid-ft260.c:		reinit_completion(&dev->wait);
drivers/hid/hid-ft260.c:		if (!wait_for_completion_timeout(&dev->wait, timeout)) {
drivers/hid/hid-ft260.c:	init_completion(&dev->wait);
drivers/hid/hid-hyperv.c:#include <linux/completion.h>
drivers/hid/hid-hyperv.c:	struct completion	wait_event;
drivers/hid/hid-hyperv.c:	init_completion(&input_dev->wait_event);
drivers/hid/hid-hyperv.c:			VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/hid/hid-hyperv.c:	reinit_completion(&input_dev->wait_event);
drivers/hid/hid-hyperv.c:				VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/hid/hid-hyperv.c:	t = wait_for_completion_timeout(&input_dev->wait_event, 5*HZ);
drivers/hid/hid-hyperv.c:	t = wait_for_completion_timeout(&input_dev->wait_event, 5*HZ);
drivers/hid/hid-mcp2200.c:#include <linux/completion.h>
drivers/hid/hid-mcp2200.c:	struct completion wait_in_report;
drivers/hid/hid-mcp2200.c:	reinit_completion(&mcp->wait_in_report);
drivers/hid/hid-mcp2200.c:	t = wait_for_completion_timeout(&mcp->wait_in_report,
drivers/hid/hid-mcp2200.c:	init_completion(&mcp->wait_in_report);
drivers/hid/hid-mcp2221.c:#include <linux/completion.h>
drivers/hid/hid-mcp2221.c:	struct completion wait_in_report;
drivers/hid/hid-mcp2221.c:	reinit_completion(&mcp->wait_in_report);
drivers/hid/hid-mcp2221.c:	t = wait_for_completion_timeout(&mcp->wait_in_report,
drivers/hid/hid-mcp2221.c:	init_completion(&mcp->wait_in_report);
drivers/hid/hid-picolcd.h:	struct completion ready;
drivers/hid/hid-picolcd_cir.c:#include <linux/completion.h>
drivers/hid/hid-picolcd_core.c:#include <linux/completion.h>
drivers/hid/hid-picolcd_core.c:	init_completion(&work->ready);
drivers/hid/hid-picolcd_core.c:		wait_for_completion_interruptible_timeout(&work->ready, HZ*2);
drivers/hid/hid-picolcd_leds.c:#include <linux/completion.h>
drivers/hid/hid-sensor-hub.c:		init_completion(&hsdev->pending.ready);
drivers/hid/hid-sensor-hub.c:		wait_for_completion_interruptible_timeout(
drivers/hid/hid-u2fzero.c:	struct completion done;
drivers/hid/hid-u2fzero.c:	init_completion(&ctx.done);
drivers/hid/hid-u2fzero.c:	ret = (wait_for_completion_timeout(
drivers/hid/hid-wiimote-core.c:#include <linux/completion.h>
drivers/hid/hid-wiimote-core.c:	init_completion(&wdata->state.ready);
drivers/hid/hid-wiimote.h:#include <linux/completion.h>
drivers/hid/hid-wiimote.h:	struct completion ready;
drivers/hid/hid-wiimote.h:	reinit_completion(&wdata->state.ready);
drivers/hid/hid-wiimote.h:	/* The completion acts as implicit memory barrier so we can safely
drivers/hid/hid-wiimote.h:	ret = wait_for_completion_interruptible_timeout(&wdata->state.ready, HZ);
drivers/hid/hid-wiimote.h:	ret = wait_for_completion_timeout(&wdata->state.ready, HZ);
drivers/hid/intel-ish-hid/ipc/ipc.c:		/* ISHTP notification in IPC_RESET sequence completion */
drivers/hid/intel-ish-hid/ishtp-hid.h: * This structure is used to store completion flags and per client data like
drivers/hid/intel-ish-hid/ishtp-hid.h:	/* completion flags */
drivers/hid/intel-ish-hid/ishtp-hid.h: * @hid_wait:		Completion waitq
drivers/hid/intel-ish-hid/ishtp/bus.c: * @ipc_send_compl: completion callback
drivers/hid/intel-ish-hid/ishtp/bus.c: * @ipc_send_compl_prm: completion callback parameter
drivers/hid/intel-ish-hid/ishtp/bus.c: * the completion callback is called to schedule transmit of next fragment.
drivers/hid/intel-ish-hid/ishtp/bus.c: * ishtp_reset_compl_handler() - Reset completion handler
drivers/hid/intel-ish-hid/ishtp/bus.c: * ISHTP handler for IPC_RESET sequence completion to start
drivers/hid/usbhid/hid-core.c: * Input interrupt completion handler.
drivers/hid/usbhid/hid-core.c: * Output interrupt completion handler.
drivers/hid/usbhid/hid-core.c: * Control pipe completion handler.
drivers/hid/usbhid/usbkbd.c: *		submitted and its completion handler has not returned yet
drivers/hv/channel.c:	init_completion(&info->waitevent);
drivers/hv/channel.c:	 * the mutex and be unable to signal the completion.
drivers/hv/channel.c:	wait_for_completion(&info->waitevent);
drivers/hv/channel.c:	init_completion(&msginfo->waitevent);
drivers/hv/channel.c:	wait_for_completion(&msginfo->waitevent);
drivers/hv/channel.c:	init_completion(&open_info->waitevent);
drivers/hv/channel.c:	wait_for_completion(&open_info->waitevent);
drivers/hv/channel.c:	init_completion(&info->waitevent);
drivers/hv/channel.c:	wait_for_completion(&info->waitevent);
drivers/hv/channel.c:			wait_for_completion(&cur_channel->rescind_event);
drivers/hv/channel.c: * @flags: 0 or VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED
drivers/hv/channel.c:	desc.flags = flags; /* VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED; */
drivers/hv/channel.c: * @flags: 0 or VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED
drivers/hv/channel.c:	desc.flags = VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED;
drivers/hv/channel.c:	desc->flags = VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED;
drivers/hv/channel.c:	 * VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED requests with ID of
drivers/hv/channel_mgmt.c:#include <linux/completion.h>
drivers/hv/channel_mgmt.c:	init_completion(&channel->rescind_event);
drivers/hv/channel_mgmt.c:		if (completion_done(&vmbus_connection.unload_event))
drivers/hv/channel_mgmt.c:	reinit_completion(&vmbus_connection.unload_event);
drivers/hv/channel_mgmt.c:		wait_for_completion(&vmbus_connection.unload_event);
drivers/hv/connection.c:	.unload_event		= COMPLETION_INITIALIZER(
drivers/hv/connection.c:	.ready_for_suspend_event = COMPLETION_INITIALIZER(
drivers/hv/connection.c:	.ready_for_resume_event	= COMPLETION_INITIALIZER(
drivers/hv/connection.c:	init_completion(&msginfo->waitevent);
drivers/hv/connection.c:	wait_for_completion(&msginfo->waitevent);
drivers/hv/hv_balloon.c:#include <linux/completion.h>
drivers/hv/hv_balloon.c:	struct completion host_event;
drivers/hv/hv_balloon.c:	struct completion config_event;
drivers/hv/hv_balloon.c:	struct completion  ol_waitevent;
drivers/hv/hv_balloon.c:		reinit_completion(&dm_device.ol_waitevent);
drivers/hv/hv_balloon.c:		wait_for_completion_timeout(&dm_device.ol_waitevent, 5 * HZ);
drivers/hv/hv_balloon.c:		wait_for_completion_interruptible_timeout(&dm_device.config_event, 1 * HZ);
drivers/hv/hv_balloon.c:		reinit_completion(&dm_device.config_event);
drivers/hv/hv_balloon.c:	t = wait_for_completion_timeout(&dm_device.host_event, 5 * HZ);
drivers/hv/hv_balloon.c:	t = wait_for_completion_timeout(&dm_device.host_event, 5 * HZ);
drivers/hv/hv_balloon.c:	init_completion(&dm_device.host_event);
drivers/hv/hv_balloon.c:	init_completion(&dm_device.config_event);
drivers/hv/hv_balloon.c:	init_completion(&dm_device.ol_waitevent);
drivers/hv/hv_utils_transport.c:	init_completion(&hvt->release);
drivers/hv/hv_utils_transport.c:		wait_for_completion(&hvt->release);
drivers/hv/hv_utils_transport.h:	struct completion release;          /* synchronize with fd release */
drivers/hv/hyperv_vmbus.h:	struct completion  unload_event;
drivers/hv/hyperv_vmbus.h:	struct completion ready_for_suspend_event;
drivers/hv/hyperv_vmbus.h:	struct completion ready_for_resume_event;
drivers/hv/ring_buffer.c:	 * ring buffer.  Once this request ID is allocated, the completion
drivers/hv/ring_buffer.c:	if (desc->flags == VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED) {
drivers/hv/vmbus_drv.c:#include <linux/completion.h>
drivers/hv/vmbus_drv.c:		wait_for_completion(&vmbus_connection.ready_for_suspend_event);
drivers/hv/vmbus_drv.c:	reinit_completion(&vmbus_connection.ready_for_resume_event);
drivers/hv/vmbus_drv.c:	if (wait_for_completion_timeout(
drivers/hv/vmbus_drv.c:	reinit_completion(&vmbus_connection.ready_for_suspend_event);
drivers/hwmon/asus_rog_ryujin.c:	/* For reinitializing the completions below */
drivers/hwmon/asus_rog_ryujin.c:	struct completion cooler_status_received;
drivers/hwmon/asus_rog_ryujin.c:	struct completion controller_status_received;
drivers/hwmon/asus_rog_ryujin.c:	struct completion cooler_duty_received;
drivers/hwmon/asus_rog_ryujin.c:	struct completion controller_duty_received;
drivers/hwmon/asus_rog_ryujin.c:	struct completion cooler_duty_set;
drivers/hwmon/asus_rog_ryujin.c:	struct completion controller_duty_set;
drivers/hwmon/asus_rog_ryujin.c:				  struct completion *status_completion)
drivers/hwmon/asus_rog_ryujin.c:	 * completion. Reinit is done because hidraw could have triggered
drivers/hwmon/asus_rog_ryujin.c:	 * the raw event parsing and marked the passed in completion as done.
drivers/hwmon/asus_rog_ryujin.c:	reinit_completion(status_completion);
drivers/hwmon/asus_rog_ryujin.c:	ret = wait_for_completion_interruptible_timeout(status_completion,
drivers/hwmon/asus_rog_ryujin.c:		if (!completion_done(&priv->cooler_status_received))
drivers/hwmon/asus_rog_ryujin.c:		if (!completion_done(&priv->controller_status_received))
drivers/hwmon/asus_rog_ryujin.c:			if (!completion_done(&priv->cooler_duty_set))
drivers/hwmon/asus_rog_ryujin.c:			else if (!completion_done(&priv->cooler_duty_received))
drivers/hwmon/asus_rog_ryujin.c:		if (!completion_done(&priv->cooler_duty_received))
drivers/hwmon/asus_rog_ryujin.c:			if (!completion_done(&priv->controller_duty_set))
drivers/hwmon/asus_rog_ryujin.c:			else if (!completion_done(&priv->controller_duty_received))
drivers/hwmon/asus_rog_ryujin.c:		if (!completion_done(&priv->controller_duty_received))
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->cooler_status_received);
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->controller_status_received);
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->cooler_duty_received);
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->controller_duty_received);
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->cooler_duty_set);
drivers/hwmon/asus_rog_ryujin.c:	init_completion(&priv->controller_duty_set);
drivers/hwmon/bt1-pvt.c:#include <linux/completion.h>
drivers/hwmon/bt1-pvt.c: * a common interrupt vector of the sensors conversion completion events and
drivers/hwmon/bt1-pvt.c: * data conversion completion. The best driver design would be to have the
drivers/hwmon/bt1-pvt.c: * completion interrupts enabled only and keep the converted value in the
drivers/hwmon/bt1-pvt.c:	ret = wait_for_completion_timeout(&cache->conversion, timeout);
drivers/hwmon/bt1-pvt.c:		init_completion(&pvt->cache[idx].conversion);
drivers/hwmon/bt1-pvt.h:#include <linux/completion.h>
drivers/hwmon/bt1-pvt.h: * @conversion: data conversion completion.
drivers/hwmon/bt1-pvt.h:	struct completion conversion;
drivers/hwmon/chipcap2.c:#include <linux/completion.h>
drivers/hwmon/chipcap2.c:	struct completion complete;
drivers/hwmon/chipcap2.c:	/* clear any pending completion */
drivers/hwmon/chipcap2.c:	try_wait_for_completion(&data->complete);
drivers/hwmon/chipcap2.c:			ret = wait_for_completion_timeout(&data->complete,
drivers/hwmon/chipcap2.c:		ret = wait_for_completion_timeout(&data->complete, timeout);
drivers/hwmon/chipcap2.c:		ret = wait_for_completion_timeout(&data->complete, timeout);
drivers/hwmon/chipcap2.c:		ret = wait_for_completion_timeout(&data->complete, timeout);
drivers/hwmon/chipcap2.c:		init_completion(&data->complete);
drivers/hwmon/corsair-cpro.c:#include <linux/completion.h>
drivers/hwmon/corsair-cpro.c:	/* For reinitializing the completion below */
drivers/hwmon/corsair-cpro.c:	struct completion wait_input_report;
drivers/hwmon/corsair-cpro.c:	 * completion. Reinit is done because hidraw could have triggered
drivers/hwmon/corsair-cpro.c:	 * completion as done.
drivers/hwmon/corsair-cpro.c:	reinit_completion(&ccp->wait_input_report);
drivers/hwmon/corsair-cpro.c:	t = wait_for_completion_timeout(&ccp->wait_input_report, msecs_to_jiffies(REQ_TIMEOUT));
drivers/hwmon/corsair-cpro.c:	if (!completion_done(&ccp->wait_input_report)) {
drivers/hwmon/corsair-cpro.c:	init_completion(&ccp->wait_input_report);
drivers/hwmon/corsair-psu.c:#include <linux/completion.h>
drivers/hwmon/corsair-psu.c:	struct completion wait_completion;
drivers/hwmon/corsair-psu.c:	reinit_completion(&priv->wait_completion);
drivers/hwmon/corsair-psu.c:	time = wait_for_completion_timeout(&priv->wait_completion,
drivers/hwmon/corsair-psu.c:	init_completion(&priv->wait_completion);
drivers/hwmon/corsair-psu.c:	if (completion_done(&priv->wait_completion))
drivers/hwmon/corsair-psu.c:	complete(&priv->wait_completion);
drivers/hwmon/da9052-hwmon.c:	struct completion	tsidone;
drivers/hwmon/da9052-hwmon.c:	reinit_completion(&hwmon->tsidone);
drivers/hwmon/da9052-hwmon.c:	if (!wait_for_completion_timeout(&hwmon->tsidone,
drivers/hwmon/da9052-hwmon.c:	init_completion(&hwmon->tsidone);
drivers/hwmon/da9055-hwmon.c:#include <linux/completion.h>
drivers/hwmon/da9055-hwmon.c:	struct completion done;
drivers/hwmon/da9055-hwmon.c:	if (!wait_for_completion_timeout(&hwmon->done,
drivers/hwmon/da9055-hwmon.c:	init_completion(&hwmon->done);
drivers/hwmon/gigabyte_waterforce.c:	/* For reinitializing the completion below */
drivers/hwmon/gigabyte_waterforce.c:	struct completion status_report_received;
drivers/hwmon/gigabyte_waterforce.c:	struct completion fw_version_processed;
drivers/hwmon/gigabyte_waterforce.c:	 * completion. Reinit is done because hidraw could have triggered
drivers/hwmon/gigabyte_waterforce.c:	 * completion as done.
drivers/hwmon/gigabyte_waterforce.c:	reinit_completion(&priv->status_report_received);
drivers/hwmon/gigabyte_waterforce.c:	ret = wait_for_completion_interruptible_timeout(&priv->status_report_received,
drivers/hwmon/gigabyte_waterforce.c:	ret = wait_for_completion_interruptible_timeout(&priv->fw_version_processed,
drivers/hwmon/gigabyte_waterforce.c:		if (!completion_done(&priv->fw_version_processed))
drivers/hwmon/gigabyte_waterforce.c:	if (!completion_done(&priv->status_report_received))
drivers/hwmon/gigabyte_waterforce.c:	init_completion(&priv->status_report_received);
drivers/hwmon/gigabyte_waterforce.c:	init_completion(&priv->fw_version_processed);
drivers/hwmon/ibmaem.c:	struct completion	read_complete;
drivers/hwmon/ibmaem.c:	init_completion(&data->read_complete);
drivers/hwmon/ibmaem.c:		data->rx_result = IPMI_UNKNOWN_ERR_COMPLETION_CODE;
drivers/hwmon/ibmaem.c:	res = wait_for_completion_timeout(&ipmi->read_complete, IPMI_TIMEOUT);
drivers/hwmon/ibmaem.c:	res = wait_for_completion_timeout(&data->read_complete, IPMI_TIMEOUT);
drivers/hwmon/ibmaem.c:	res = wait_for_completion_timeout(&data->read_complete, IPMI_TIMEOUT);
drivers/hwmon/ibmpex.c:	struct completion	read_complete;
drivers/hwmon/ibmpex.c:	wait_for_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:	wait_for_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:	wait_for_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:	wait_for_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:	wait_for_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:	init_completion(&data->read_complete);
drivers/hwmon/ibmpex.c:		data->rx_result = IPMI_UNKNOWN_ERR_COMPLETION_CODE;
drivers/hwmon/nzxt-kraken3.c:	struct completion fw_version_processed;
drivers/hwmon/nzxt-kraken3.c:	struct completion status_report_processed;
drivers/hwmon/nzxt-kraken3.c:	/* For locking the above completion */
drivers/hwmon/nzxt-kraken3.c:	spinlock_t status_completion_lock;
drivers/hwmon/nzxt-kraken3.c:	if (completion_done(&priv->status_report_processed))
drivers/hwmon/nzxt-kraken3.c:	ret = wait_for_completion_interruptible_timeout(&priv->status_report_processed,
drivers/hwmon/nzxt-kraken3.c:	 * Disable interrupts for a moment to safely reinit the completion,
drivers/hwmon/nzxt-kraken3.c:	spin_lock_bh(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:	reinit_completion(&priv->status_report_processed);
drivers/hwmon/nzxt-kraken3.c:	spin_unlock_bh(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:	/* Wait for completion from kraken3_raw_event() */
drivers/hwmon/nzxt-kraken3.c:	ret = wait_for_completion_interruptible_timeout(&priv->status_report_processed,
drivers/hwmon/nzxt-kraken3.c:		if (!completion_done(&priv->fw_version_processed))
drivers/hwmon/nzxt-kraken3.c:		spin_lock(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:		if (priv->kind != X53 || !completion_done(&priv->status_report_processed)) {
drivers/hwmon/nzxt-kraken3.c:		spin_unlock(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:	spin_lock(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:	if (priv->kind == X53 && !completion_done(&priv->status_report_processed)) {
drivers/hwmon/nzxt-kraken3.c:		if (!completion_done(&priv->status_report_processed))
drivers/hwmon/nzxt-kraken3.c:	spin_unlock(&priv->status_completion_lock);
drivers/hwmon/nzxt-kraken3.c:	ret = wait_for_completion_interruptible_timeout(&priv->fw_version_processed,
drivers/hwmon/nzxt-kraken3.c:	init_completion(&priv->fw_version_processed);
drivers/hwmon/nzxt-kraken3.c:	init_completion(&priv->status_report_processed);
drivers/hwmon/nzxt-kraken3.c:	spin_lock_init(&priv->status_completion_lock);
drivers/hwmon/powerz.c:#include <linux/completion.h>
drivers/hwmon/powerz.c:	struct completion completion;
drivers/hwmon/powerz.c:	complete(&priv->completion);
drivers/hwmon/powerz.c:		complete(&priv->completion);
drivers/hwmon/powerz.c:	reinit_completion(&priv->completion);
drivers/hwmon/powerz.c:	if (!wait_for_completion_interruptible_timeout
drivers/hwmon/powerz.c:	    (&priv->completion, msecs_to_jiffies(5))) {
drivers/hwmon/powerz.c:	init_completion(&priv->completion);
drivers/hwmon/sbrmi.c:	 * an ALERT (if enabled) to initiator (BMC) to indicate completion
drivers/hwmon/sbrmi.c:			"Firmware fail to indicate command completion\n");
drivers/hwmon/xgene-hwmon.c:	struct completion	rd_complete;
drivers/hwmon/xgene-hwmon.c:	init_completion(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/hwmon/xgene-hwmon.c:	init_completion(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/hwtracing/coresight/coresight-config.h: * @available:		config can be activated - multi-stage load sets true on completion.
drivers/hwtracing/coresight/coresight-etb10.c:		"timeout while waiting for completion of Manual Flush\n");
drivers/hwtracing/coresight/coresight-tmc-core.c:		"timeout while waiting for completion of Manual Flush\n");
drivers/hwtracing/ptt/hisi_ptt.c: * completion TLPs. See hisi_ptt.rst documentation for more information.
drivers/hwtracing/ptt/hisi_ptt.c:		4,	/* completion */
drivers/i2c/algos/i2c-algo-pca.c:#define pca_wait(adap) adap->wait_for_completion(adap->data)
drivers/i2c/busses/i2c-altera.c: * @msg_complete: xfer completion object
drivers/i2c/busses/i2c-altera.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-altera.c:	reinit_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-altera.c:	time_left = wait_for_completion_timeout(&idev->msg_complete,
drivers/i2c/busses/i2c-altera.c:	init_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-amd-mp2-pci.c:			i2c_common->cmd_completion(i2c_common);
drivers/i2c/busses/i2c-amd-mp2-plat.c: * @cmd_complete: xfer completion object
drivers/i2c/busses/i2c-amd-mp2-plat.c:	struct completion cmd_complete;
drivers/i2c/busses/i2c-amd-mp2-plat.c:	reinit_completion(&i2c_dev->cmd_complete);
drivers/i2c/busses/i2c-amd-mp2-plat.c:static void i2c_amd_cmd_completion(struct amd_i2c_common *i2c_common)
drivers/i2c/busses/i2c-amd-mp2-plat.c:static int i2c_amd_check_cmd_completion(struct amd_i2c_dev *i2c_dev)
drivers/i2c/busses/i2c-amd-mp2-plat.c:	time_left = wait_for_completion_timeout(&i2c_dev->cmd_complete,
drivers/i2c/busses/i2c-amd-mp2-plat.c:	return i2c_amd_check_cmd_completion(i2c_dev);
drivers/i2c/busses/i2c-amd-mp2-plat.c:	return i2c_amd_check_cmd_completion(i2c_dev);
drivers/i2c/busses/i2c-amd-mp2-plat.c:	i2c_dev->common.cmd_completion = &i2c_amd_cmd_completion;
drivers/i2c/busses/i2c-amd-mp2-plat.c:	init_completion(&i2c_dev->cmd_complete);
drivers/i2c/busses/i2c-amd-mp2.h: * @cmd_completion: function called by the IRQ handler to signal
drivers/i2c/busses/i2c-amd-mp2.h:	void (*cmd_completion)(struct amd_i2c_common *i2c_common);
drivers/i2c/busses/i2c-amd756.c:		dev_dbg(&adap->dev, "Completion timeout!\n");
drivers/i2c/busses/i2c-aspeed.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-aspeed.c:	struct completion		cmd_complete;
drivers/i2c/busses/i2c-aspeed.c:		reinit_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-aspeed.c:		time_left = wait_for_completion_timeout(
drivers/i2c/busses/i2c-aspeed.c:		reinit_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-aspeed.c:		time_left = wait_for_completion_timeout(
drivers/i2c/busses/i2c-aspeed.c:	reinit_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-aspeed.c:	time_left = wait_for_completion_timeout(&bus->cmd_complete,
drivers/i2c/busses/i2c-aspeed.c:	init_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-at91-master.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-at91-master.c:	reinit_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-at91-master.c:	time_left = wait_for_completion_timeout(&dev->cmd_complete,
drivers/i2c/busses/i2c-at91-master.c:	init_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-at91.h:#include <linux/completion.h>
drivers/i2c/busses/i2c-at91.h:	struct completion cmd_complete;
drivers/i2c/busses/i2c-axxia.c: * @msg_complete: xfer completion object
drivers/i2c/busses/i2c-axxia.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-axxia.c:	reinit_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-axxia.c:	time_left = wait_for_completion_timeout(&idev->msg_complete,
drivers/i2c/busses/i2c-axxia.c:	reinit_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-axxia.c:	time_left = wait_for_completion_timeout(&idev->msg_complete,
drivers/i2c/busses/i2c-axxia.c:	init_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-bcm-iproc.c:	struct completion done;
drivers/i2c/busses/i2c-bcm-iproc.c:		time_left = wait_for_completion_timeout(&iproc_i2c->done,
drivers/i2c/busses/i2c-bcm-iproc.c:		reinit_completion(&iproc_i2c->done);
drivers/i2c/busses/i2c-bcm-iproc.c:	init_completion(&iproc_i2c->done);
drivers/i2c/busses/i2c-bcm-kona.c:	struct completion done;
drivers/i2c/busses/i2c-bcm-kona.c:	reinit_completion(&dev->done);
drivers/i2c/busses/i2c-bcm-kona.c:	time_left = wait_for_completion_timeout(&dev->done, time_left);
drivers/i2c/busses/i2c-bcm-kona.c:	reinit_completion(&dev->done);
drivers/i2c/busses/i2c-bcm-kona.c:	time_left = wait_for_completion_timeout(&dev->done, time_left);
drivers/i2c/busses/i2c-bcm-kona.c:	reinit_completion(&dev->done);
drivers/i2c/busses/i2c-bcm-kona.c:	time_left = wait_for_completion_timeout(&dev->done, time_left);
drivers/i2c/busses/i2c-bcm-kona.c:	reinit_completion(&dev->done);
drivers/i2c/busses/i2c-bcm-kona.c:		time_left = wait_for_completion_timeout(&dev->done, time_left);
drivers/i2c/busses/i2c-bcm-kona.c:		dev_err(dev->device, "completion timed out\n");
drivers/i2c/busses/i2c-bcm-kona.c:	init_completion(&dev->done);
drivers/i2c/busses/i2c-bcm2835.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-bcm2835.c:	struct completion completion;
drivers/i2c/busses/i2c-bcm2835.c:	complete(&i2c_dev->completion);
drivers/i2c/busses/i2c-bcm2835.c:	reinit_completion(&i2c_dev->completion);
drivers/i2c/busses/i2c-bcm2835.c:	time_left = wait_for_completion_timeout(&i2c_dev->completion,
drivers/i2c/busses/i2c-bcm2835.c:	init_completion(&i2c_dev->completion);
drivers/i2c/busses/i2c-brcmstb.c:	struct completion done;
drivers/i2c/busses/i2c-brcmstb.c:/* i2c xfer completion function, handles both irq and polling mode */
drivers/i2c/busses/i2c-brcmstb.c:static int brcmstb_i2c_wait_for_completion(struct brcmstb_i2c_dev *dev)
drivers/i2c/busses/i2c-brcmstb.c:		if (!wait_for_completion_timeout(&dev->done, timeout))
drivers/i2c/busses/i2c-brcmstb.c:/* Send I2C request check completion */
drivers/i2c/busses/i2c-brcmstb.c:		reinit_completion(&dev->done);
drivers/i2c/busses/i2c-brcmstb.c:	rc = brcmstb_i2c_wait_for_completion(dev);
drivers/i2c/busses/i2c-brcmstb.c:	/* Initiate xfer, the function will return on completion */
drivers/i2c/busses/i2c-brcmstb.c:	init_completion(&dev->done);
drivers/i2c/busses/i2c-cadence.c:	struct completion xfer_done;
drivers/i2c/busses/i2c-cadence.c:	/* Signal completion only after everything is updated */
drivers/i2c/busses/i2c-cadence.c:	/* When receiving, handle data interrupt and completion interrupt */
drivers/i2c/busses/i2c-cadence.c:		/* Clear hold (if not repeated start) and signal completion */
drivers/i2c/busses/i2c-cadence.c:			 * Signal the completion of transaction and
drivers/i2c/busses/i2c-cadence.c:	reinit_completion(&id->xfer_done);
drivers/i2c/busses/i2c-cadence.c:	/* Wait for the signal of completion */
drivers/i2c/busses/i2c-cadence.c:	time_left = wait_for_completion_timeout(&id->xfer_done, msg_timeout);
drivers/i2c/busses/i2c-cadence.c:		 * This controller does not give completion interrupt after a
drivers/i2c/busses/i2c-cadence.c:	init_completion(&id->xfer_done);
drivers/i2c/busses/i2c-cht-wc.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-davinci.c:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-davinci.c:	reinit_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-davinci.c:	time_left = wait_for_completion_timeout(&dev->cmd_complete,
drivers/i2c/busses/i2c-davinci.c:	init_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-designware-core.h:#include <linux/completion.h>
drivers/i2c/busses/i2c-designware-core.h: * @cmd_complete: tx completion indicator
drivers/i2c/busses/i2c-designware-core.h:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-designware-master.c:		ret = wait_for_completion_timeout(&dev->cmd_complete, timeout);
drivers/i2c/busses/i2c-designware-master.c:			ret = try_wait_for_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-designware-master.c:	reinit_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-designware-master.c:	init_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-digicolor.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-digicolor.c:#define II_COMMAND_COMPLETION_STATUS(r)	(((r) >> 5) & 3)
drivers/i2c/busses/i2c-digicolor.c:	struct completion	done;
drivers/i2c/busses/i2c-digicolor.c:	return II_COMMAND_COMPLETION_STATUS(cmd);
drivers/i2c/busses/i2c-digicolor.c:	reinit_completion(&i2c->done);
drivers/i2c/busses/i2c-digicolor.c:	time_left = wait_for_completion_timeout(&i2c->done, time_left);
drivers/i2c/busses/i2c-digicolor.c:	init_completion(&i2c->done);
drivers/i2c/busses/i2c-emev2.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-emev2.c:	struct completion msg_done;
drivers/i2c/busses/i2c-emev2.c:	reinit_completion(&priv->msg_done);
drivers/i2c/busses/i2c-emev2.c:	time_left = wait_for_completion_timeout(&priv->msg_done, priv->adap.timeout);
drivers/i2c/busses/i2c-emev2.c:	init_completion(&priv->msg_done);
drivers/i2c/busses/i2c-exynos5.c:	struct completion	msg_complete;
drivers/i2c/busses/i2c-exynos5.c:	reinit_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-exynos5.c:		time_left = wait_for_completion_timeout(&i2c->msg_complete,
drivers/i2c/busses/i2c-exynos5.c:	init_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-gpio.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-gpio.c:	struct completion scl_irq_completion;
drivers/i2c/busses/i2c-gpio.c:	reinit_completion(&priv->scl_irq_completion);
drivers/i2c/busses/i2c-gpio.c:	wait_for_completion_interruptible(&priv->scl_irq_completion);
drivers/i2c/busses/i2c-gpio.c:	complete(&priv->scl_irq_completion);
drivers/i2c/busses/i2c-gpio.c:	init_completion(&priv->scl_irq_completion);
drivers/i2c/busses/i2c-gxp.c:	struct completion completion;
drivers/i2c/busses/i2c-gxp.c:	reinit_completion(&drvdata->completion);
drivers/i2c/busses/i2c-gxp.c:	time_left = wait_for_completion_timeout(&drvdata->completion,
drivers/i2c/busses/i2c-gxp.c:	complete(&drvdata->completion);
drivers/i2c/busses/i2c-gxp.c:	init_completion(&drvdata->completion);
drivers/i2c/busses/i2c-highlander.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-highlander.c:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-highlander.c:		wait_for_completion_timeout(&dev->cmd_complete,
drivers/i2c/busses/i2c-highlander.c:	init_completion(&dev->cmd_complete);
drivers/i2c/busses/i2c-hisi.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-hisi.c:	struct completion *completion;
drivers/i2c/busses/i2c-hisi.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i2c/busses/i2c-hisi.c:	ctlr->completion = &done;
drivers/i2c/busses/i2c-hisi.c:	if (!wait_for_completion_timeout(ctlr->completion, adap->timeout)) {
drivers/i2c/busses/i2c-hisi.c:	ctlr->completion = NULL;
drivers/i2c/busses/i2c-hisi.c:	 * Don't handle the interrupt if cltr->completion is NULL. We may
drivers/i2c/busses/i2c-hisi.c:	if (!ctlr->completion)
drivers/i2c/busses/i2c-hisi.c:	 * Only use TRANS_CPLT to indicate the completion. On error cases we'll
drivers/i2c/busses/i2c-hisi.c:		complete(ctlr->completion);
drivers/i2c/busses/i2c-hix5hd2.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-hix5hd2.c:	reinit_completion(&priv->msg_complete);
drivers/i2c/busses/i2c-hix5hd2.c:	time_left = wait_for_completion_timeout(&priv->msg_complete,
drivers/i2c/busses/i2c-hix5hd2.c:	init_completion(&priv->msg_complete);
drivers/i2c/busses/i2c-i801.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-i801.c:	struct completion done;
drivers/i2c/busses/i2c-i801.c:		reinit_completion(&priv->done);
drivers/i2c/busses/i2c-i801.c:		result = wait_for_completion_timeout(&priv->done, adap->timeout);
drivers/i2c/busses/i2c-i801.c: * 1) i801 signals transaction completion with one of these interrupts:
drivers/i2c/busses/i2c-i801.c: *    When any of these occur, update ->status and signal completion.
drivers/i2c/busses/i2c-i801.c:		reinit_completion(&priv->done);
drivers/i2c/busses/i2c-i801.c:		result = wait_for_completion_timeout(&priv->done, adap->timeout);
drivers/i2c/busses/i2c-i801.c:		init_completion(&priv->done);
drivers/i2c/busses/i2c-ibm_iic.c:		/* Wait for completion */
drivers/i2c/busses/i2c-img-scb.c: *   ACK) is given to the hardware, with detection of completion by bits
drivers/i2c/busses/i2c-img-scb.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-img-scb.c: * This delays completion until we've finished with the registers, so that the
drivers/i2c/busses/i2c-img-scb.c: * function waiting for completion can safely disable the clock to save power.
drivers/i2c/busses/i2c-img-scb.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-img-scb.c:	/* We handle transaction completion AFTER accessing registers */
drivers/i2c/busses/i2c-img-scb.c:	/* now we've finished using regs, handle transaction completion */
drivers/i2c/busses/i2c-img-scb.c:	reinit_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-img-scb.c:	time_left = wait_for_completion_timeout(&i2c->msg_complete,
drivers/i2c/busses/i2c-img-scb.c:		reinit_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-img-scb.c:		time_left = wait_for_completion_timeout(&i2c->msg_complete,
drivers/i2c/busses/i2c-img-scb.c:	init_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-imx-lpi2c.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-imx-lpi2c.c:	struct completion	complete;
drivers/i2c/busses/i2c-imx-lpi2c.c:	time_left = wait_for_completion_timeout(&lpi2c_imx->complete, HZ);
drivers/i2c/busses/i2c-imx-lpi2c.c:		init_completion(&lpi2c_imx->complete);
drivers/i2c/busses/i2c-imx.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-imx.c:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-imx.c:	init_completion(&dma->cmd_complete);
drivers/i2c/busses/i2c-imx.c:	reinit_completion(&dma->cmd_complete);
drivers/i2c/busses/i2c-imx.c:	time_left = wait_for_completion_timeout(
drivers/i2c/busses/i2c-imx.c:	time_left = wait_for_completion_timeout(
drivers/i2c/busses/i2c-isch.c:			dev_dbg(&sch_adapter.dev, "Completion (%02x). "
drivers/i2c/busses/i2c-isch.c:			/* Completion clear failed */
drivers/i2c/busses/i2c-ismt.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-ismt.c:	struct completion cmp;			/* interrupt completion */
drivers/i2c/busses/i2c-ismt.c: * ismt_process_desc() - handle the completion of the descriptor
drivers/i2c/busses/i2c-ismt.c:	reinit_completion(&priv->cmp);
drivers/i2c/busses/i2c-ismt.c:	/* Now we wait for interrupt completion, 1s */
drivers/i2c/busses/i2c-ismt.c:	time_left = wait_for_completion_timeout(&priv->cmp, HZ*1);
drivers/i2c/busses/i2c-ismt.c:	init_completion(&priv->cmp);
drivers/i2c/busses/i2c-jz4780.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-jz4780.c:	struct completion	trans_waitq;
drivers/i2c/busses/i2c-jz4780.c:	time_left = wait_for_completion_timeout(&i2c->trans_waitq,
drivers/i2c/busses/i2c-jz4780.c:	time_left = wait_for_completion_timeout(&i2c->trans_waitq,
drivers/i2c/busses/i2c-jz4780.c:	init_completion(&i2c->trans_waitq);
drivers/i2c/busses/i2c-lpc2k.c:	/* Wait for transfer completion */
drivers/i2c/busses/i2c-ls2x.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-ls2x.c:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-ls2x.c:	time_left = wait_for_completion_timeout(&priv->cmd_complete,
drivers/i2c/busses/i2c-ls2x.c:	reinit_completion(&priv->cmd_complete);
drivers/i2c/busses/i2c-ls2x.c:	init_completion(&priv->cmd_complete);
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:#define SMB_CORE_COMPLETION_REG_OFF3	(SMBUS_MAST_CORE_ADDR_BASE + 0x23)
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:#define COMPLETION_MDONE		BIT(6)
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:#define COMPLETION_IDLE			BIT(5)
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:#define COMPLETION_MNAKX		BIT(0)
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	struct completion i2c_xfer_done;
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	regval = COMPLETION_MNAKX | COMPLETION_IDLE | COMPLETION_MDONE;
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	writeb(regval, i2c->i2c_base + SMB_CORE_COMPLETION_REG_OFF3);
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	reinit_completion(&i2c->i2c_xfer_done);
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	void __iomem *p2 = i2c->i2c_base + SMB_CORE_COMPLETION_REG_OFF3;
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:		time_left = wait_for_completion_timeout(&i2c->i2c_xfer_done,
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:		/* Read the completion reg to know the reason for DMA_TERM. */
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:		if (regval & COMPLETION_MNAKX) {
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:			writeb(COMPLETION_MNAKX, p2);
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	void __iomem *p2 = i2c->i2c_base + SMB_CORE_COMPLETION_REG_OFF3;
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:		time_left = wait_for_completion_timeout(&i2c->i2c_xfer_done,
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:		if (regval & COMPLETION_MNAKX) {
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:			writeb(COMPLETION_MNAKX, p2);
drivers/i2c/busses/i2c-mchp-pci1xxxx.c:	init_completion(&i2c->i2c_xfer_done);
drivers/i2c/busses/i2c-meson.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-meson.c: * @done:	Completion used to wait for transfer termination
drivers/i2c/busses/i2c-meson.c:	struct completion	done;
drivers/i2c/busses/i2c-meson.c:		reinit_completion(&i2c->done);
drivers/i2c/busses/i2c-meson.c:		time_left = wait_for_completion_timeout(&i2c->done, time_left);
drivers/i2c/busses/i2c-meson.c:	init_completion(&i2c->done);
drivers/i2c/busses/i2c-microchip-corei2c.c: * @msg_complete:	xfer completion object
drivers/i2c/busses/i2c-microchip-corei2c.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-microchip-corei2c.c:	reinit_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-microchip-corei2c.c:	time_left = wait_for_completion_timeout(&idev->msg_complete,
drivers/i2c/busses/i2c-microchip-corei2c.c:	init_completion(&idev->msg_complete);
drivers/i2c/busses/i2c-mlxcpld.c:	if (pdata && pdata->completion_notify)
drivers/i2c/busses/i2c-mlxcpld.c:		pdata->completion_notify(pdata->handle, mlxcpld_i2c_adapter.nr);
drivers/i2c/busses/i2c-mpc.c:static int mpc_i2c_wait_for_completion(struct mpc_i2c *i2c)
drivers/i2c/busses/i2c-mpc.c:	ret = mpc_i2c_wait_for_completion(i2c);
drivers/i2c/busses/i2c-mt65xx.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-mt65xx.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-mt65xx.c:	reinit_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-mt65xx.c:	ret = wait_for_completion_timeout(&i2c->msg_complete,
drivers/i2c/busses/i2c-mt65xx.c:	init_completion(&i2c->msg_complete);
drivers/i2c/busses/i2c-mv64xxx.c:mv64xxx_i2c_wait_for_completion(struct mv64xxx_i2c_data *drv_data)
drivers/i2c/busses/i2c-mv64xxx.c:		mv64xxx_i2c_wait_for_completion(drv_data);
drivers/i2c/busses/i2c-mv64xxx.c:	mv64xxx_i2c_wait_for_completion(drv_data);
drivers/i2c/busses/i2c-mxs.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-mxs.c: * @cmd_complete: completion object for transaction wait
drivers/i2c/busses/i2c-mxs.c:	struct completion cmd_complete;
drivers/i2c/busses/i2c-mxs.c:		reinit_completion(&i2c->cmd_complete);
drivers/i2c/busses/i2c-mxs.c:		time_left = wait_for_completion_timeout(&i2c->cmd_complete,
drivers/i2c/busses/i2c-mxs.c:	init_completion(&i2c->cmd_complete);
drivers/i2c/busses/i2c-nomadik.c:	 * On the completion, the I2C internal logic clears these
drivers/i2c/busses/i2c-nomadik.c:	 * should poll on these bits waiting for the completion.
drivers/i2c/busses/i2c-nomadik.c: * master mode. There is a completion timeout. If there is no transfer
drivers/i2c/busses/i2c-npcm7xx.c:	struct completion cmd_complete;
drivers/i2c/busses/i2c-npcm7xx.c:	if (completion_done(&bus->cmd_complete))
drivers/i2c/busses/i2c-npcm7xx.c:		if (completion_done(&bus->cmd_complete) == false) {
drivers/i2c/busses/i2c-npcm7xx.c:			 * completion of send address byte. If we NACK here, and
drivers/i2c/busses/i2c-npcm7xx.c:			 * completion of sending address byte
drivers/i2c/busses/i2c-npcm7xx.c:		 * Receiving one byte only - stall after successful completion
drivers/i2c/busses/i2c-npcm7xx.c:	reinit_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-npcm7xx.c:		time_left = wait_for_completion_timeout(&bus->cmd_complete,
drivers/i2c/busses/i2c-npcm7xx.c:	init_completion(&bus->cmd_complete);
drivers/i2c/busses/i2c-omap.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-omap.c:	struct completion	cmd_complete;
drivers/i2c/busses/i2c-omap.c:		reinit_completion(&omap->cmd_complete);
drivers/i2c/busses/i2c-omap.c:		time_left = wait_for_completion_timeout(&omap->cmd_complete,
drivers/i2c/busses/i2c-omap.c:	init_completion(&omap->cmd_complete);
drivers/i2c/busses/i2c-opal.c:	if (rc != OPAL_ASYNC_COMPLETION) {
drivers/i2c/busses/i2c-owl.c:	struct completion	msg_complete;
drivers/i2c/busses/i2c-owl.c:		reinit_completion(&i2c_dev->msg_complete);
drivers/i2c/busses/i2c-owl.c:		time_left = wait_for_completion_timeout(&i2c_dev->msg_complete,
drivers/i2c/busses/i2c-owl.c:	init_completion(&i2c_dev->msg_complete);
drivers/i2c/busses/i2c-pasemi-core.c:	reinit_completion(&smbus->irq_completion);
drivers/i2c/busses/i2c-pasemi-core.c:		reinit_completion(&smbus->irq_completion);
drivers/i2c/busses/i2c-pasemi-core.c:		wait_for_completion_timeout(&smbus->irq_completion, msecs_to_jiffies(100));
drivers/i2c/busses/i2c-pasemi-core.c:	init_completion(&smbus->irq_completion);
drivers/i2c/busses/i2c-pasemi-core.c:	complete(&smbus->irq_completion);
drivers/i2c/busses/i2c-pasemi-core.h:#include <linux/completion.h>
drivers/i2c/busses/i2c-pasemi-core.h:	struct completion	 irq_completion;
drivers/i2c/busses/i2c-pca-isa.c:static int pca_isa_waitforcompletion(void *pd)
drivers/i2c/busses/i2c-pca-isa.c:	.wait_for_completion	= pca_isa_waitforcompletion,
drivers/i2c/busses/i2c-pca-platform.c:static int i2c_pca_pf_waitforcompletion(void *pd)
drivers/i2c/busses/i2c-pca-platform.c:	i2c->algo_data.wait_for_completion = i2c_pca_pf_waitforcompletion;
drivers/i2c/busses/i2c-pnx.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-pnx.c:	struct completion	complete;	/* I/O completion */
drivers/i2c/busses/i2c-pnx.c:		/* initialize the completion var */
drivers/i2c/busses/i2c-pnx.c:		init_completion(&alg_data->mif.complete);
drivers/i2c/busses/i2c-pnx.c:		/* Wait for completion */
drivers/i2c/busses/i2c-pnx.c:		time_left = wait_for_completion_timeout(&alg_data->mif.complete,
drivers/i2c/busses/i2c-pnx.c:	init_completion(&alg_data->mif.complete);
drivers/i2c/busses/i2c-qcom-cci.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-qcom-cci.c:	struct completion irq_complete;
drivers/i2c/busses/i2c-qcom-cci.c:	reinit_completion(&master->irq_complete);
drivers/i2c/busses/i2c-qcom-cci.c:	if (!wait_for_completion_timeout(&master->irq_complete, CCI_TIMEOUT)) {
drivers/i2c/busses/i2c-qcom-cci.c:	reinit_completion(&cci->master[0].irq_complete);
drivers/i2c/busses/i2c-qcom-cci.c:	if (!wait_for_completion_timeout(&cci->master[0].irq_complete,
drivers/i2c/busses/i2c-qcom-cci.c:	reinit_completion(&cci->master[master].irq_complete);
drivers/i2c/busses/i2c-qcom-cci.c:	if (!wait_for_completion_timeout(&cci->master[master].irq_complete,
drivers/i2c/busses/i2c-qcom-cci.c:		init_completion(&master->irq_complete);
drivers/i2c/busses/i2c-qcom-geni.c:	struct completion done;
drivers/i2c/busses/i2c-qcom-geni.c:		time_left = wait_for_completion_timeout(&gi2c->done, time_left);
drivers/i2c/busses/i2c-qcom-geni.c:		time_left = wait_for_completion_timeout(&gi2c->done, time_left);
drivers/i2c/busses/i2c-qcom-geni.c:		time_left = wait_for_completion_timeout(&gi2c->done, time_left);
drivers/i2c/busses/i2c-qcom-geni.c:	time_left = wait_for_completion_timeout(&gi2c->done, XFER_TIMEOUT);
drivers/i2c/busses/i2c-qcom-geni.c:	time_left = wait_for_completion_timeout(&gi2c->done, XFER_TIMEOUT);
drivers/i2c/busses/i2c-qcom-geni.c:		time_left = wait_for_completion_timeout(&gi2c->done, XFER_TIMEOUT);
drivers/i2c/busses/i2c-qcom-geni.c:	reinit_completion(&gi2c->done);
drivers/i2c/busses/i2c-qcom-geni.c:	init_completion(&gi2c->done);
drivers/i2c/busses/i2c-qup.c:	struct completion	xfer;
drivers/i2c/busses/i2c-qup.c:	if (!wait_for_completion_timeout(&qup->xfer, qup->xfer_timeout))
drivers/i2c/busses/i2c-qup.c:		reinit_completion(&qup->xfer);
drivers/i2c/busses/i2c-qup.c:		if (!wait_for_completion_timeout(&qup->xfer, HZ))
drivers/i2c/busses/i2c-qup.c:	left = wait_for_completion_timeout(&qup->xfer, qup->xfer_timeout);
drivers/i2c/busses/i2c-qup.c:	reinit_completion(&qup->xfer);
drivers/i2c/busses/i2c-qup.c:	reinit_completion(&qup->xfer);
drivers/i2c/busses/i2c-qup.c:		reinit_completion(&qup->xfer);
drivers/i2c/busses/i2c-qup.c:	init_completion(&qup->xfer);
drivers/i2c/busses/i2c-riic.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-riic.c:	struct completion msg_done;
drivers/i2c/busses/i2c-riic.c:	reinit_completion(&riic->msg_done);
drivers/i2c/busses/i2c-riic.c:		time_left = wait_for_completion_timeout(&riic->msg_done, riic->adapter.timeout);
drivers/i2c/busses/i2c-riic.c:	init_completion(&riic->msg_done);
drivers/i2c/busses/i2c-rzv2m.c:	struct completion msg_tia_done;
drivers/i2c/busses/i2c-rzv2m.c:	reinit_completion(&priv->msg_tia_done);
drivers/i2c/busses/i2c-rzv2m.c:	time_left = wait_for_completion_timeout(&priv->msg_tia_done,
drivers/i2c/busses/i2c-rzv2m.c:	reinit_completion(&priv->msg_tia_done);
drivers/i2c/busses/i2c-rzv2m.c:	time_left = wait_for_completion_timeout(&priv->msg_tia_done,
drivers/i2c/busses/i2c-rzv2m.c:		time_left = wait_for_completion_timeout(&priv->msg_tia_done,
drivers/i2c/busses/i2c-rzv2m.c:	init_completion(&priv->msg_tia_done);
drivers/i2c/busses/i2c-sh7760.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-sh7760.c:	struct completion xfer_done;
drivers/i2c/busses/i2c-sh7760.c:		init_completion(&id->xfer_done);
drivers/i2c/busses/i2c-sh7760.c:		wait_for_completion(&id->xfer_done);
drivers/i2c/busses/i2c-sprd.c:	struct completion complete;
drivers/i2c/busses/i2c-sprd.c:	reinit_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-sprd.c:	time_left = wait_for_completion_timeout(&i2c_dev->complete,
drivers/i2c/busses/i2c-sprd.c:	init_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-st.c: * @complete: completion of I2C message
drivers/i2c/busses/i2c-st.c:	struct completion	complete;
drivers/i2c/busses/i2c-st.c:	reinit_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-st.c:	time_left = wait_for_completion_timeout(&i2c_dev->complete,
drivers/i2c/busses/i2c-st.c:	init_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-stm32.c:	init_completion(&dma->dma_complete);
drivers/i2c/busses/i2c-stm32.c:	reinit_completion(&dma->dma_complete);
drivers/i2c/busses/i2c-stm32.h: * @dma_complete: dma transfer completion
drivers/i2c/busses/i2c-stm32.h:	struct completion dma_complete;
drivers/i2c/busses/i2c-stm32f4.c: * @complete: completion of I2C message
drivers/i2c/busses/i2c-stm32f4.c:	struct completion complete;
drivers/i2c/busses/i2c-stm32f4.c:	reinit_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-stm32f4.c:	time_left = wait_for_completion_timeout(&i2c_dev->complete,
drivers/i2c/busses/i2c-stm32f4.c:	init_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-stm32f7.c: * @complete: completion of I2C message
drivers/i2c/busses/i2c-stm32f7.c:	struct completion complete;
drivers/i2c/busses/i2c-stm32f7.c:	reinit_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-stm32f7.c:	reinit_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-stm32f7.c:		/* Wait for dma transfer completion before sending next message */
drivers/i2c/busses/i2c-stm32f7.c:			ret = wait_for_completion_timeout(&i2c_dev->dma->dma_complete, HZ);
drivers/i2c/busses/i2c-stm32f7.c:		if (completion_done(&i2c_dev->complete))
drivers/i2c/busses/i2c-stm32f7.c:		time_left = wait_for_completion_timeout(&i2c_dev->complete,
drivers/i2c/busses/i2c-stm32f7.c:	time_left = wait_for_completion_timeout(&i2c_dev->complete,
drivers/i2c/busses/i2c-stm32f7.c:	init_completion(&i2c_dev->complete);
drivers/i2c/busses/i2c-sun6i-p2wi.c:	struct completion complete;
drivers/i2c/busses/i2c-sun6i-p2wi.c:	reinit_completion(&p2wi->complete);
drivers/i2c/busses/i2c-sun6i-p2wi.c:	wait_for_completion(&p2wi->complete);
drivers/i2c/busses/i2c-sun6i-p2wi.c:	init_completion(&p2wi->complete);
drivers/i2c/busses/i2c-synquacer.c:	struct completion	completion;
drivers/i2c/busses/i2c-synquacer.c:	complete(&i2c->completion);
drivers/i2c/busses/i2c-synquacer.c:	reinit_completion(&i2c->completion);
drivers/i2c/busses/i2c-synquacer.c:	time_left = wait_for_completion_timeout(&i2c->completion,
drivers/i2c/busses/i2c-synquacer.c:	init_completion(&i2c->completion);
drivers/i2c/busses/i2c-tegra.c: *		completion interrupt on per packet basis.
drivers/i2c/busses/i2c-tegra.c: * @msg_complete: transfer completion notifier
drivers/i2c/busses/i2c-tegra.c: * @dma_complete: DMA completion notifier
drivers/i2c/busses/i2c-tegra.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-tegra.c:	struct completion dma_complete;
drivers/i2c/busses/i2c-tegra.c:	reinit_completion(&i2c_dev->dma_complete);
drivers/i2c/busses/i2c-tegra.c:	 * DMA completion and during message write XFER_COMPLETE interrupt is
drivers/i2c/busses/i2c-tegra.c:	 * triggered after DMA completion.
drivers/i2c/busses/i2c-tegra.c:	 * PACKETS_XFER_COMPLETE indicates completion of all bytes of transfer,
drivers/i2c/busses/i2c-tegra.c:static unsigned long tegra_i2c_poll_completion(struct tegra_i2c_dev *i2c_dev,
drivers/i2c/busses/i2c-tegra.c:					       struct completion *complete,
drivers/i2c/busses/i2c-tegra.c:		if (completion_done(complete)) {
drivers/i2c/busses/i2c-tegra.c:static unsigned long tegra_i2c_wait_completion(struct tegra_i2c_dev *i2c_dev,
drivers/i2c/busses/i2c-tegra.c:					       struct completion *complete,
drivers/i2c/busses/i2c-tegra.c:		ret = tegra_i2c_poll_completion(i2c_dev, complete, timeout_ms);
drivers/i2c/busses/i2c-tegra.c:		ret = wait_for_completion_timeout(complete,
drivers/i2c/busses/i2c-tegra.c:			ret = tegra_i2c_poll_completion(i2c_dev, complete, 0);
drivers/i2c/busses/i2c-tegra.c:	reinit_completion(&i2c_dev->msg_complete);
drivers/i2c/busses/i2c-tegra.c:	time_left = tegra_i2c_wait_completion(i2c_dev, &i2c_dev->msg_complete, 50);
drivers/i2c/busses/i2c-tegra.c:	reinit_completion(&i2c_dev->msg_complete);
drivers/i2c/busses/i2c-tegra.c:		time_left = tegra_i2c_wait_completion(i2c_dev,
drivers/i2c/busses/i2c-tegra.c:		 * and we want to get a completion if transfer succeeded.
drivers/i2c/busses/i2c-tegra.c:		if (!time_left && !completion_done(&i2c_dev->dma_complete)) {
drivers/i2c/busses/i2c-tegra.c:	time_left = tegra_i2c_wait_completion(i2c_dev, &i2c_dev->msg_complete,
drivers/i2c/busses/i2c-tegra.c:		time_left, completion_done(&i2c_dev->msg_complete),
drivers/i2c/busses/i2c-tegra.c:	init_completion(&i2c_dev->msg_complete);
drivers/i2c/busses/i2c-tegra.c:	init_completion(&i2c_dev->dma_complete);
drivers/i2c/busses/i2c-uniphier-f.c:	struct completion comp;
drivers/i2c/busses/i2c-uniphier-f.c:			 * but do not wait for its completion.
drivers/i2c/busses/i2c-uniphier-f.c:		 * completion of the current message.
drivers/i2c/busses/i2c-uniphier-f.c:	reinit_completion(&priv->comp);
drivers/i2c/busses/i2c-uniphier-f.c:	time_left = wait_for_completion_timeout(&priv->comp, adap->timeout);
drivers/i2c/busses/i2c-uniphier-f.c:	init_completion(&priv->comp);
drivers/i2c/busses/i2c-uniphier.c:	struct completion comp;
drivers/i2c/busses/i2c-uniphier.c:	reinit_completion(&priv->comp);
drivers/i2c/busses/i2c-uniphier.c:	time_left = wait_for_completion_timeout(&priv->comp, adap->timeout);
drivers/i2c/busses/i2c-uniphier.c:	init_completion(&priv->comp);
drivers/i2c/busses/i2c-viai2c-common.c:	reinit_completion(&i2c->complete);
drivers/i2c/busses/i2c-viai2c-common.c:	if (!wait_for_completion_timeout(&i2c->complete, VIAI2C_TIMEOUT))
drivers/i2c/busses/i2c-viai2c-common.c:	reinit_completion(&i2c->complete);
drivers/i2c/busses/i2c-viai2c-common.c:	if (!wait_for_completion_timeout(&i2c->complete, VIAI2C_TIMEOUT))
drivers/i2c/busses/i2c-viai2c-common.c:	init_completion(&i2c->complete);
drivers/i2c/busses/i2c-viai2c-common.h:	struct completion	complete;
drivers/i2c/busses/i2c-viai2c-zhaoxin.c:		if (!wait_for_completion_timeout(&i2c->complete, VIAI2C_TIMEOUT))
drivers/i2c/busses/i2c-virtio.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-virtio.c: * @completion: completion of virtio I2C message
drivers/i2c/busses/i2c-virtio.c:	struct completion completion;
drivers/i2c/busses/i2c-virtio.c:		complete(&req->completion);
drivers/i2c/busses/i2c-virtio.c:		init_completion(&reqs[i].completion);
drivers/i2c/busses/i2c-virtio.c:		wait_for_completion(&req->completion);
drivers/i2c/busses/i2c-xgene-slimpro.c:	struct completion rd_complete;
drivers/i2c/busses/i2c-xgene-slimpro.c:		if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/i2c/busses/i2c-xgene-slimpro.c:		reinit_completion(&ctx->rd_complete);
drivers/i2c/busses/i2c-xgene-slimpro.c:		reinit_completion(&ctx->rd_complete);
drivers/i2c/busses/i2c-xgene-slimpro.c:	init_completion(&ctx->rd_complete);
drivers/i2c/busses/i2c-xiic.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-xiic.c: * @completion:	Completion for callers
drivers/i2c/busses/i2c-xiic.c:	struct completion completion;
drivers/i2c/busses/i2c-xiic.c:	complete(&i2c->completion);
drivers/i2c/busses/i2c-xiic.c:	init_completion(&i2c->completion);
drivers/i2c/busses/i2c-xiic.c:	err = wait_for_completion_timeout(&i2c->completion, XIIC_XFER_TIMEOUT);
drivers/i2c/busses/i2c-xlp9xx.c:#include <linux/completion.h>
drivers/i2c/busses/i2c-xlp9xx.c:	struct completion msg_complete;
drivers/i2c/busses/i2c-xlp9xx.c:	reinit_completion(&priv->msg_complete);
drivers/i2c/busses/i2c-xlp9xx.c:	timeleft = wait_for_completion_timeout(&priv->msg_complete, timeleft);
drivers/i2c/busses/i2c-xlp9xx.c:	init_completion(&priv->msg_complete);
drivers/i2c/i2c-core-base.c:#include <linux/completion.h>
drivers/i2c/i2c-core-base.c:	init_completion(&adap->dev_released);
drivers/i2c/i2c-core-base.c:	wait_for_completion(&adap->dev_released);
drivers/i2c/i2c-core-base.c:	init_completion(&adap->dev_released);
drivers/i2c/i2c-core-base.c:	wait_for_completion(&adap->dev_released);
drivers/i2c/i2c-slave-testunit.c:#include <linux/completion.h>
drivers/i2c/i2c-slave-testunit.c:	struct completion alert_done;
drivers/i2c/i2c-slave-testunit.c:		reinit_completion(&tu->alert_done);
drivers/i2c/i2c-slave-testunit.c:		time_left = wait_for_completion_timeout(&tu->alert_done, HZ);
drivers/i2c/i2c-slave-testunit.c:	init_completion(&tu->alert_done);
drivers/i2c/muxes/i2c-mux-mlxcpld.c:	if (pdata->completion_notify)
drivers/i2c/muxes/i2c-mux-mlxcpld.c:		pdata->completion_notify(pdata->handle, muxc->parent, muxc->adapter);
drivers/i3c/device.c:#include <linux/completion.h>
drivers/i3c/master.c:	reinit_completion(&dev->ibi->all_ibis_handled);
drivers/i3c/master.c:		wait_for_completion(&dev->ibi->all_ibis_handled);
drivers/i3c/master.c:	init_completion(&ibi->all_ibis_handled);
drivers/i3c/master/dw-i3c-master.c:#include <linux/completion.h>
drivers/i3c/master/dw-i3c-master.c:	struct completion comp;
drivers/i3c/master/dw-i3c-master.c:	init_completion(&xfer->comp);
drivers/i3c/master/dw-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
drivers/i3c/master/dw-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
drivers/i3c/master/dw-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
drivers/i3c/master/dw-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
drivers/i3c/master/dw-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
drivers/i3c/master/i3c-master-cdns.c:	struct completion comp;
drivers/i3c/master/i3c-master-cdns.c:	init_completion(&xfer->comp);
drivers/i3c/master/i3c-master-cdns.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/i3c/master/i3c-master-cdns.c:	if (!wait_for_completion_timeout(&cdns_xfer->comp,
drivers/i3c/master/i3c-master-cdns.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/i3c/master/mipi-i3c-hci/cmd_v1.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i3c/master/mipi-i3c-hci/cmd_v1.c:		xfer->completion = &done;
drivers/i3c/master/mipi-i3c-hci/cmd_v1.c:		if (!wait_for_completion_timeout(&done, HZ) &&
drivers/i3c/master/mipi-i3c-hci/cmd_v2.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i3c/master/mipi-i3c-hci/cmd_v2.c:	xfer[1].completion = &done;
drivers/i3c/master/mipi-i3c-hci/cmd_v2.c:		if (!wait_for_completion_timeout(&done, HZ) &&
drivers/i3c/master/mipi-i3c-hci/core.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i3c/master/mipi-i3c-hci/core.c:	xfer[last].completion = &done;
drivers/i3c/master/mipi-i3c-hci/core.c:	if (!wait_for_completion_timeout(&done, HZ) &&
drivers/i3c/master/mipi-i3c-hci/core.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i3c/master/mipi-i3c-hci/core.c:	xfer[last].completion = &done;
drivers/i3c/master/mipi-i3c-hci/core.c:	if (!wait_for_completion_timeout(&done, HZ) &&
drivers/i3c/master/mipi-i3c-hci/core.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/i3c/master/mipi-i3c-hci/core.c:	xfer[last].completion = &done;
drivers/i3c/master/mipi-i3c-hci/core.c:	if (!wait_for_completion_timeout(&done, HZ) &&
drivers/i3c/master/mipi-i3c-hci/dma.c:#define INTR_TRANSFER_COMPLETION	BIT(11)
drivers/i3c/master/mipi-i3c-hci/dma.c:#define DATA_BUF_IOC			BIT(30)	/* Interrupt on Completion */
drivers/i3c/master/mipi-i3c-hci/dma.c:	struct completion op_done;
drivers/i3c/master/mipi-i3c-hci/dma.c:		init_completion(&rh->op_done);
drivers/i3c/master/mipi-i3c-hci/dma.c:						 INTR_TRANSFER_COMPLETION |
drivers/i3c/master/mipi-i3c-hci/dma.c:	if (wait_for_completion_timeout(&rh->op_done, HZ) == 0) {
drivers/i3c/master/mipi-i3c-hci/dma.c:			if (xfer->completion)
drivers/i3c/master/mipi-i3c-hci/dma.c:				complete(xfer->completion);
drivers/i3c/master/mipi-i3c-hci/dma.c:		if (status & (INTR_TRANSFER_COMPLETION | INTR_TRANSFER_ERR))
drivers/i3c/master/mipi-i3c-hci/hci.h: * The completion field needs to be initialized before queueing with
drivers/i3c/master/mipi-i3c-hci/hci.h:	struct completion *completion;
drivers/i3c/master/mipi-i3c-hci/pio.c:			 * Response availability implies RX completion.
drivers/i3c/master/mipi-i3c-hci/pio.c:		if (xfer->completion)
drivers/i3c/master/mipi-i3c-hci/pio.c:			complete(xfer->completion);
drivers/i3c/master/mipi-i3c-hci/pio.c:		if (p->completion)
drivers/i3c/master/mipi-i3c-hci/pio.c:			complete(p->completion);
drivers/i3c/master/mipi-i3c-hci/pio.c:		if (p->completion)
drivers/i3c/master/mipi-i3c-hci/pio.c:			complete(p->completion);
drivers/i3c/master/svc-i3c-master.c:#include <linux/completion.h>
drivers/i3c/master/svc-i3c-master.c:	struct completion comp;
drivers/i3c/master/svc-i3c-master.c:	init_completion(&xfer->comp);
drivers/i3c/master/svc-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/i3c/master/svc-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/i3c/master/svc-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/i3c/master/svc-i3c-master.c:	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
drivers/iio/adc/ab8500-gpadc.c:#include <linux/completion.h>
drivers/iio/adc/ab8500-gpadc.c: * @complete: pointer to the completion that indicates
drivers/iio/adc/ab8500-gpadc.c: * the completion of an gpadc conversion cycle
drivers/iio/adc/ab8500-gpadc.c:	struct completion complete;
drivers/iio/adc/ab8500-gpadc.c:	unsigned long completion_timeout;
drivers/iio/adc/ab8500-gpadc.c:		completion_timeout = 2 * HZ;
drivers/iio/adc/ab8500-gpadc.c:		completion_timeout = msecs_to_jiffies(AB8500_GPADC_CONVERSION_TIME);
drivers/iio/adc/ab8500-gpadc.c:	/* Wait for completion of conversion */
drivers/iio/adc/ab8500-gpadc.c:	if (!wait_for_completion_timeout(&gpadc->complete,
drivers/iio/adc/ab8500-gpadc.c:			completion_timeout)) {
drivers/iio/adc/ab8500-gpadc.c:	 * GPADC status register to go low. In V1.1 there wait_for_completion
drivers/iio/adc/ab8500-gpadc.c: * ab8500_bm_gpadcconvend_handler() - isr for gpadc conversion completion
drivers/iio/adc/ab8500-gpadc.c: * This is a interrupt service routine for gpadc conversion completion.
drivers/iio/adc/ab8500-gpadc.c: * Notifies the gpadc completion is completed and the converted raw value
drivers/iio/adc/ab8500-gpadc.c:	/* Initialize completion used to notify completion of conversion */
drivers/iio/adc/ab8500-gpadc.c:	init_completion(&gpadc->complete);
drivers/iio/adc/ad4130.c:	struct completion		completion;
drivers/iio/adc/ad4130.c:		complete(&st->completion);
drivers/iio/adc/ad4130.c:	reinit_completion(&st->completion);
drivers/iio/adc/ad4130.c:	ret = wait_for_completion_timeout(&st->completion,
drivers/iio/adc/ad4130.c:	init_completion(&st->completion);
drivers/iio/adc/ad7606.c:	ret = wait_for_completion_timeout(&st->completion,
drivers/iio/adc/ad7606.c:		complete(&st->completion);
drivers/iio/adc/ad7606.c:	init_completion(&st->completion);
drivers/iio/adc/ad7606.h: * @complete		completion to indicate end of conversion
drivers/iio/adc/ad7606.h:	struct completion		completion;
drivers/iio/adc/ad7768-1.c:	struct completion completion;
drivers/iio/adc/ad7768-1.c:	reinit_completion(&st->completion);
drivers/iio/adc/ad7768-1.c:	ret = wait_for_completion_timeout(&st->completion,
drivers/iio/adc/ad7768-1.c:		complete(&st->completion);
drivers/iio/adc/ad7768-1.c:	init_completion(&st->completion);
drivers/iio/adc/ad_sigma_delta.c:	reinit_completion(&sigma_delta->completion);
drivers/iio/adc/ad_sigma_delta.c:	time_left = wait_for_completion_timeout(&sigma_delta->completion, 2 * HZ);
drivers/iio/adc/ad_sigma_delta.c:	reinit_completion(&sigma_delta->completion);
drivers/iio/adc/ad_sigma_delta.c:	ret = wait_for_completion_interruptible_timeout(
drivers/iio/adc/ad_sigma_delta.c:			&sigma_delta->completion, HZ);
drivers/iio/adc/ad_sigma_delta.c:	reinit_completion(&sigma_delta->completion);
drivers/iio/adc/ad_sigma_delta.c:	wait_for_completion_timeout(&sigma_delta->completion, HZ);
drivers/iio/adc/ad_sigma_delta.c:	complete(&sigma_delta->completion);
drivers/iio/adc/ad_sigma_delta.c:	init_completion(&sigma_delta->completion);
drivers/iio/adc/axp20x_adc.c:#include <linux/completion.h>
drivers/iio/adc/bcm_iproc_adc.c:	struct completion completion;
drivers/iio/adc/bcm_iproc_adc.c:				complete(&adc_priv->completion);
drivers/iio/adc/bcm_iproc_adc.c:	reinit_completion(&adc_priv->completion);
drivers/iio/adc/bcm_iproc_adc.c:	if (wait_for_completion_timeout(&adc_priv->completion,
drivers/iio/adc/bcm_iproc_adc.c:	init_completion(&adc_priv->completion);
drivers/iio/adc/da9150-gpadc.c:#include <linux/completion.h>
drivers/iio/adc/da9150-gpadc.c:	struct completion complete;
drivers/iio/adc/da9150-gpadc.c:	/* Consume left-over completion from a previous timeout */
drivers/iio/adc/da9150-gpadc.c:	try_wait_for_completion(&gpadc->complete);
drivers/iio/adc/da9150-gpadc.c:	/* Check for actual completion */
drivers/iio/adc/da9150-gpadc.c:	wait_for_completion_timeout(&gpadc->complete, msecs_to_jiffies(5));
drivers/iio/adc/da9150-gpadc.c:	init_completion(&gpadc->complete);
drivers/iio/adc/dln2-adc.c:	/* Called via URB completion handler */
drivers/iio/adc/envelope-detector.c:#include <linux/completion.h>
drivers/iio/adc/envelope-detector.c:	struct completion done;
drivers/iio/adc/envelope-detector.c:		wait_for_completion(&env->done);
drivers/iio/adc/envelope-detector.c:	init_completion(&env->done);
drivers/iio/adc/exynos_adc.c:#include <linux/completion.h>
drivers/iio/adc/exynos_adc.c:	struct completion	completion;
drivers/iio/adc/exynos_adc.c:	 * completion callback during a manual conversion. For this driver
drivers/iio/adc/exynos_adc.c:	reinit_completion(&info->completion);
drivers/iio/adc/exynos_adc.c:	time_left = wait_for_completion_timeout(&info->completion,
drivers/iio/adc/exynos_adc.c:	reinit_completion(&info->completion);
drivers/iio/adc/exynos_adc.c:	time_left = wait_for_completion_timeout(&info->completion,
drivers/iio/adc/exynos_adc.c:	complete(&info->completion);
drivers/iio/adc/exynos_adc.c:	init_completion(&info->completion);
drivers/iio/adc/fsl-imx25-gcq.c:	struct completion completed;
drivers/iio/adc/fsl-imx25-gcq.c:	 * of register writes, then a wait for a completion callback,
drivers/iio/adc/fsl-imx25-gcq.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/iio/adc/fsl-imx25-gcq.c:	init_completion(&priv->completed);
drivers/iio/adc/imx7d_adc.c:#include <linux/completion.h>
drivers/iio/adc/imx7d_adc.c:	struct completion completion;
drivers/iio/adc/imx7d_adc.c:		reinit_completion(&info->completion);
drivers/iio/adc/imx7d_adc.c:		ret = wait_for_completion_interruptible_timeout
drivers/iio/adc/imx7d_adc.c:				(&info->completion, IMX7D_ADC_TIMEOUT);
drivers/iio/adc/imx7d_adc.c:		complete(&info->completion);
drivers/iio/adc/imx7d_adc.c:	init_completion(&info->completion);
drivers/iio/adc/imx8qxp-adc.c:#include <linux/completion.h>
drivers/iio/adc/imx8qxp-adc.c:	struct completion completion;
drivers/iio/adc/imx8qxp-adc.c:		reinit_completion(&adc->completion);
drivers/iio/adc/imx8qxp-adc.c:		ret = wait_for_completion_interruptible_timeout(&adc->completion,
drivers/iio/adc/imx8qxp-adc.c:		complete(&adc->completion);
drivers/iio/adc/imx8qxp-adc.c:	init_completion(&adc->completion);
drivers/iio/adc/imx93_adc.c:#include <linux/completion.h>
drivers/iio/adc/imx93_adc.c:	struct completion completion;
drivers/iio/adc/imx93_adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/imx93_adc.c:	ret = wait_for_completion_interruptible_timeout(&adc->completion,
drivers/iio/adc/imx93_adc.c:		complete(&adc->completion);
drivers/iio/adc/imx93_adc.c:	init_completion(&adc->completion);
drivers/iio/adc/intel_mrfld_adc.c:#include <linux/completion.h>
drivers/iio/adc/intel_mrfld_adc.c:	struct completion completion;
drivers/iio/adc/intel_mrfld_adc.c:	complete(&adc->completion);
drivers/iio/adc/intel_mrfld_adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/intel_mrfld_adc.c:	time_left = wait_for_completion_interruptible_timeout(&adc->completion,
drivers/iio/adc/intel_mrfld_adc.c:	init_completion(&adc->completion);
drivers/iio/adc/lpc32xx_adc.c:#include <linux/completion.h>
drivers/iio/adc/lpc32xx_adc.c:	struct completion completion;
drivers/iio/adc/lpc32xx_adc.c:		wait_for_completion(&st->completion); /* set by ISR */
drivers/iio/adc/lpc32xx_adc.c:	complete(&st->completion);
drivers/iio/adc/lpc32xx_adc.c:	init_completion(&st->completion);
drivers/iio/adc/max1027.c:	struct completion		complete;
drivers/iio/adc/max1027.c:		ret = wait_for_completion_timeout(&st->complete,
drivers/iio/adc/max1027.c:		reinit_completion(&st->complete);
drivers/iio/adc/max1027.c:	init_completion(&st->complete);
drivers/iio/adc/max11410.c:	struct completion completion;
drivers/iio/adc/max11410.c:		reinit_completion(&st->completion);
drivers/iio/adc/max11410.c:		ret = wait_for_completion_timeout(&st->completion,
drivers/iio/adc/max11410.c:		complete(&st->completion);
drivers/iio/adc/max11410.c:	init_completion(&st->completion);
drivers/iio/adc/meson_saradc.c:	struct completion			done;
drivers/iio/adc/meson_saradc.c:	if (!wait_for_completion_timeout(&priv->done,
drivers/iio/adc/meson_saradc.c:	reinit_completion(&priv->done);
drivers/iio/adc/meson_saradc.c:	init_completion(&priv->done);
drivers/iio/adc/mxs-lradc-adc.c:#include <linux/completion.h>
drivers/iio/adc/mxs-lradc-adc.c:	struct completion	completion;
drivers/iio/adc/mxs-lradc-adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/mxs-lradc-adc.c:	/* Wait for completion on the channel, 1 second max. */
drivers/iio/adc/mxs-lradc-adc.c:	ret = wait_for_completion_killable_timeout(&adc->completion, HZ);
drivers/iio/adc/mxs-lradc-adc.c:		complete(&adc->completion);
drivers/iio/adc/mxs-lradc-adc.c:	init_completion(&adc->completion);
drivers/iio/adc/nau7802.c:	struct completion	value_ok;
drivers/iio/adc/nau7802.c:	reinit_completion(&st->value_ok);
drivers/iio/adc/nau7802.c:	ret = wait_for_completion_interruptible_timeout(&st->value_ok,
drivers/iio/adc/nau7802.c:	init_completion(&st->value_ok);
drivers/iio/adc/palmas_gpadc.c:#include <linux/completion.h>
drivers/iio/adc/palmas_gpadc.c: *		of register writes, then a wait for a completion callback,
drivers/iio/adc/palmas_gpadc.c:	struct completion		conv_completion;
drivers/iio/adc/palmas_gpadc.c:	complete(&adc->conv_completion);
drivers/iio/adc/palmas_gpadc.c:		init_completion(&adc->conv_completion);
drivers/iio/adc/palmas_gpadc.c:		ret = wait_for_completion_timeout(&adc->conv_completion,
drivers/iio/adc/palmas_gpadc.c:	init_completion(&adc->conv_completion);
drivers/iio/adc/qcom-pm8xxx-xoadc.c: * @complete: completion to indicate end of conversion
drivers/iio/adc/qcom-pm8xxx-xoadc.c:	struct completion complete;
drivers/iio/adc/qcom-pm8xxx-xoadc.c:	reinit_completion(&adc->complete);
drivers/iio/adc/qcom-pm8xxx-xoadc.c:	ret = wait_for_completion_timeout(&adc->complete,
drivers/iio/adc/qcom-pm8xxx-xoadc.c:	init_completion(&adc->complete);
drivers/iio/adc/qcom-spmi-adc5.c:#include <linux/completion.h>
drivers/iio/adc/qcom-spmi-adc5.c:	struct completion	complete;
drivers/iio/adc/qcom-spmi-adc5.c:		reinit_completion(&adc->complete);
drivers/iio/adc/qcom-spmi-adc5.c:		reinit_completion(&adc->complete);
drivers/iio/adc/qcom-spmi-adc5.c:		ret = wait_for_completion_timeout(&adc->complete,
drivers/iio/adc/qcom-spmi-adc5.c:			dev_dbg(adc->dev, "Did not get completion timeout.\n");
drivers/iio/adc/qcom-spmi-adc5.c:	wait_for_completion_timeout(&adc->complete, ADC7_CONV_TIMEOUT);
drivers/iio/adc/qcom-spmi-adc5.c:	init_completion(&adc->complete);
drivers/iio/adc/qcom-spmi-iadc.c:#include <linux/completion.h>
drivers/iio/adc/qcom-spmi-iadc.c:	struct completion complete;
drivers/iio/adc/qcom-spmi-iadc.c:		reinit_completion(&iadc->complete);
drivers/iio/adc/qcom-spmi-iadc.c:		ret = wait_for_completion_timeout(&iadc->complete,
drivers/iio/adc/qcom-spmi-iadc.c:	init_completion(&iadc->complete);
drivers/iio/adc/qcom-spmi-vadc.c:#include <linux/completion.h>
drivers/iio/adc/qcom-spmi-vadc.c:	struct completion	 complete;
drivers/iio/adc/qcom-spmi-vadc.c:		reinit_completion(&vadc->complete);
drivers/iio/adc/qcom-spmi-vadc.c:		ret = wait_for_completion_timeout(&vadc->complete, timeout);
drivers/iio/adc/qcom-spmi-vadc.c:	init_completion(&vadc->complete);
drivers/iio/adc/rn5t618-adc.c:#include <linux/completion.h>
drivers/iio/adc/rn5t618-adc.c:	struct completion conv_completion;
drivers/iio/adc/rn5t618-adc.c:		complete(&adc->conv_completion);
drivers/iio/adc/rn5t618-adc.c:	init_completion(&adc->conv_completion);
drivers/iio/adc/rn5t618-adc.c:	ret = wait_for_completion_timeout(&adc->conv_completion,
drivers/iio/adc/rn5t618-adc.c:	init_completion(&adc->conv_completion);
drivers/iio/adc/rockchip_saradc.c:#include <linux/completion.h>
drivers/iio/adc/rockchip_saradc.c:	struct completion	completion;
drivers/iio/adc/rockchip_saradc.c:	reinit_completion(&info->completion);
drivers/iio/adc/rockchip_saradc.c:	if (!wait_for_completion_timeout(&info->completion, SARADC_TIMEOUT))
drivers/iio/adc/rockchip_saradc.c:	complete(&info->completion);
drivers/iio/adc/rockchip_saradc.c:	init_completion(&info->completion);
drivers/iio/adc/rzg2l_adc.c:#include <linux/completion.h>
drivers/iio/adc/rzg2l_adc.c:	struct completion completion;
drivers/iio/adc/rzg2l_adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/rzg2l_adc.c:	if (!wait_for_completion_timeout(&adc->completion, RZG2L_ADC_TIMEOUT)) {
drivers/iio/adc/rzg2l_adc.c:	complete(&adc->completion);
drivers/iio/adc/rzg2l_adc.c:	init_completion(&adc->completion);
drivers/iio/adc/spear_adc.c:#include <linux/completion.h>
drivers/iio/adc/spear_adc.c:	struct completion completion;
drivers/iio/adc/spear_adc.c:	 * of register writes, then a wait for a completion callback,
drivers/iio/adc/spear_adc.c:		wait_for_completion(&st->completion); /* set by ISR */
drivers/iio/adc/spear_adc.c:	complete(&st->completion);
drivers/iio/adc/spear_adc.c:	init_completion(&st->completion);
drivers/iio/adc/stm32-adc.c: * @completion:		end of single conversion completion
drivers/iio/adc/stm32-adc.c:	struct completion	completion;
drivers/iio/adc/stm32-adc.c:	/* Start calibration, then wait for completion */
drivers/iio/adc/stm32-adc.c: * - Start conversion, then wait for interrupt completion.
drivers/iio/adc/stm32-adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/stm32-adc.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/iio/adc/stm32-adc.c:					&adc->completion, STM32_ADC_TIMEOUT);
drivers/iio/adc/stm32-adc.c:			complete(&adc->completion);
drivers/iio/adc/stm32-adc.c:	init_completion(&adc->completion);
drivers/iio/adc/stm32-dfsdm-adc.c:	struct completion completion;
drivers/iio/adc/stm32-dfsdm-adc.c:	reinit_completion(&adc->completion);
drivers/iio/adc/stm32-dfsdm-adc.c:	time_left = wait_for_completion_interruptible_timeout(&adc->completion,
drivers/iio/adc/stm32-dfsdm-adc.c:		complete(&adc->completion);
drivers/iio/adc/stm32-dfsdm-adc.c:	init_completion(&adc->completion);
drivers/iio/adc/stmpe-adc.c:#include <linux/completion.h>
drivers/iio/adc/stmpe-adc.c:	struct completion completion;
drivers/iio/adc/stmpe-adc.c:	reinit_completion(&info->completion);
drivers/iio/adc/stmpe-adc.c:	ret = wait_for_completion_timeout(&info->completion, STMPE_ADC_TIMEOUT);
drivers/iio/adc/stmpe-adc.c:	reinit_completion(&info->completion);
drivers/iio/adc/stmpe-adc.c:	ret = wait_for_completion_timeout(&info->completion, STMPE_ADC_TIMEOUT);
drivers/iio/adc/stmpe-adc.c:	complete(&info->completion);
drivers/iio/adc/stmpe-adc.c:	/* use temp irq for each conversion completion */
drivers/iio/adc/stmpe-adc.c:	init_completion(&info->completion);
drivers/iio/adc/sun20i-gpadc-iio.c:#include <linux/completion.h>
drivers/iio/adc/sun20i-gpadc-iio.c:	struct completion	completion;
drivers/iio/adc/sun20i-gpadc-iio.c:	 * of register writes, then a wait for a completion callback,
drivers/iio/adc/sun20i-gpadc-iio.c:	reinit_completion(&info->completion);
drivers/iio/adc/sun20i-gpadc-iio.c:	if (!wait_for_completion_timeout(&info->completion, msecs_to_jiffies(10))) {
drivers/iio/adc/sun20i-gpadc-iio.c:	complete(&info->completion);
drivers/iio/adc/sun20i-gpadc-iio.c:	init_completion(&info->completion);
drivers/iio/adc/sun4i-gpadc-iio.c:#include <linux/completion.h>
drivers/iio/adc/sun4i-gpadc-iio.c:	struct completion		completion;
drivers/iio/adc/sun4i-gpadc-iio.c:	reinit_completion(&info->completion);
drivers/iio/adc/sun4i-gpadc-iio.c:	if (!wait_for_completion_timeout(&info->completion,
drivers/iio/adc/sun4i-gpadc-iio.c:		complete(&info->completion);
drivers/iio/adc/sun4i-gpadc-iio.c:		complete(&info->completion);
drivers/iio/adc/sun4i-gpadc-iio.c:	init_completion(&info->completion);
drivers/iio/adc/ti-adc12138.c:#include <linux/completion.h>
drivers/iio/adc/ti-adc12138.c:	struct completion complete;
drivers/iio/adc/ti-adc12138.c:	if (!wait_for_completion_timeout(&adc->complete, timeout))
drivers/iio/adc/ti-adc12138.c:	reinit_completion(&adc->complete);
drivers/iio/adc/ti-adc12138.c:	reinit_completion(&adc->complete);
drivers/iio/adc/ti-adc12138.c:		reinit_completion(&adc->complete);
drivers/iio/adc/ti-adc12138.c:	init_completion(&adc->complete);
drivers/iio/adc/ti-ads1119.c:#include <linux/completion.h>
drivers/iio/adc/ti-ads1119.c:	struct completion completion;
drivers/iio/adc/ti-ads1119.c:	} else if (!wait_for_completion_timeout(&st->completion, timeout)) {
drivers/iio/adc/ti-ads1119.c:		complete(&st->completion);
drivers/iio/adc/ti-ads1119.c:	init_completion(&st->completion);
drivers/iio/adc/ti-ads1298.c:	struct completion completion;
drivers/iio/adc/ti-ads1298.c:	 * completion is reported. Hence its meaning is:
drivers/iio/adc/ti-ads1298.c:	 * 2 = DRDY during SPI transfer, start another transfer on completion
drivers/iio/adc/ti-ads1298.c:	reinit_completion(&priv->completion);
drivers/iio/adc/ti-ads1298.c:	ret = wait_for_completion_timeout(&priv->completion, msecs_to_jiffies(50));
drivers/iio/adc/ti-ads1298.c:		 * DRDY interrupt occurred before SPI completion. Start a new
drivers/iio/adc/ti-ads1298.c:/* Called from SPI completion interrupt handler */
drivers/iio/adc/ti-ads1298.c:		 * completion, avoiding a race with buffered IO.
drivers/iio/adc/ti-ads1298.c:		complete(&priv->completion);
drivers/iio/adc/ti-ads1298.c:	init_completion(&priv->completion);
drivers/iio/adc/ti-ads131e08.c:	struct completion completion;
drivers/iio/adc/ti-ads131e08.c:	reinit_completion(&st->completion);
drivers/iio/adc/ti-ads131e08.c:	ret = wait_for_completion_timeout(&st->completion, timeout);
drivers/iio/adc/ti-ads131e08.c:		complete(&st->completion);
drivers/iio/adc/ti-ads131e08.c:	init_completion(&st->completion);
drivers/iio/adc/twl4030-madc.c:/* MADC conversion completion */
drivers/iio/adc/twl6030-gpadc.c: * @irq_complete:	completion to signal end of conversion
drivers/iio/adc/twl6030-gpadc.c:	struct completion	irq_complete;
drivers/iio/adc/twl6030-gpadc.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/iio/adc/twl6030-gpadc.c:	init_completion(&gpadc->irq_complete);
drivers/iio/adc/vf610_adc.c:#include <linux/completion.h>
drivers/iio/adc/vf610_adc.c:	struct completion completion;
drivers/iio/adc/vf610_adc.c:	if (!wait_for_completion_timeout(&info->completion, VF610_ADC_TIMEOUT))
drivers/iio/adc/vf610_adc.c:			complete(&info->completion);
drivers/iio/adc/vf610_adc.c:	reinit_completion(&info->completion);
drivers/iio/adc/vf610_adc.c:	ret = wait_for_completion_interruptible_timeout(&info->completion,
drivers/iio/adc/vf610_adc.c:	init_completion(&info->completion);
drivers/iio/adc/xilinx-xadc-core.c:	reinit_completion(&xadc->completion);
drivers/iio/adc/xilinx-xadc-core.c:	ret = wait_for_completion_interruptible_timeout(&xadc->completion, HZ);
drivers/iio/adc/xilinx-xadc-core.c:	reinit_completion(&xadc->completion);
drivers/iio/adc/xilinx-xadc-core.c:	ret = wait_for_completion_interruptible_timeout(&xadc->completion, HZ);
drivers/iio/adc/xilinx-xadc-core.c:		complete(&xadc->completion);
drivers/iio/adc/xilinx-xadc-core.c:	init_completion(&xadc->completion);
drivers/iio/adc/xilinx-xadc.h:	struct completion completion;
drivers/iio/addac/ad74115.c:	struct completion		adc_data_completion;
drivers/iio/addac/ad74115.c:		complete(&st->adc_data_completion);
drivers/iio/addac/ad74115.c:	reinit_completion(&st->adc_data_completion);
drivers/iio/addac/ad74115.c:		ret = wait_for_completion_timeout(&st->adc_data_completion,
drivers/iio/addac/ad74115.c:	init_completion(&st->adc_data_completion);
drivers/iio/addac/ad74413r.c:	struct completion		adc_data_completion;
drivers/iio/addac/ad74413r.c:		complete(&st->adc_data_completion);
drivers/iio/addac/ad74413r.c:	reinit_completion(&st->adc_data_completion);
drivers/iio/addac/ad74413r.c:	ret = wait_for_completion_timeout(&st->adc_data_completion,
drivers/iio/addac/ad74413r.c:	init_completion(&st->adc_data_completion);
drivers/iio/addac/stx104.c:		 * wait for completion; the conversion time range is 5 microseconds to 53.68 seconds
drivers/iio/chemical/pms7003.c:#include <linux/completion.h>
drivers/iio/chemical/pms7003.c:	struct completion frame_ready;
drivers/iio/chemical/pms7003.c:	ret = wait_for_completion_interruptible_timeout(&state->frame_ready,
drivers/iio/chemical/pms7003.c:	init_completion(&state->frame_ready);
drivers/iio/chemical/scd30.h:#include <linux/completion.h>
drivers/iio/chemical/scd30.h:	struct completion meas_ready;
drivers/iio/chemical/scd30_core.c:#include <linux/completion.h>
drivers/iio/chemical/scd30_core.c:	reinit_completion(&state->meas_ready);
drivers/iio/chemical/scd30_core.c:	ret = wait_for_completion_interruptible_timeout(&state->meas_ready, timeout);
drivers/iio/chemical/scd30_core.c:	init_completion(&state->meas_ready);
drivers/iio/chemical/scd30_serial.c:	struct completion meas_ready;
drivers/iio/chemical/scd30_serial.c:	ret = wait_for_completion_interruptible_timeout(&priv->meas_ready, SCD30_SERDEV_TIMEOUT);
drivers/iio/chemical/scd30_serial.c:	init_completion(&priv->meas_ready);
drivers/iio/chemical/sps30_serial.c:#include <linux/completion.h>
drivers/iio/chemical/sps30_serial.c:	struct completion new_frame;
drivers/iio/chemical/sps30_serial.c:	ret = wait_for_completion_interruptible_timeout(&priv->new_frame, SPS30_SERIAL_TIMEOUT);
drivers/iio/chemical/sps30_serial.c:	init_completion(&priv->new_frame);
drivers/iio/common/ssp_sensors/ssp.h: * @pending_lock:	lock protecting pending list and completion
drivers/iio/common/ssp_sensors/ssp_spi.c:	struct completion *done;
drivers/iio/common/ssp_sensors/ssp_spi.c:			   struct completion *done, int timeout)
drivers/iio/common/ssp_sensors/ssp_spi.c:		if (wait_for_completion_timeout(done,
drivers/iio/common/ssp_sensors/ssp_spi.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/iio/common/ssp_sensors/ssp_spi.c:			if (!completion_done(msg->done))
drivers/iio/common/ssp_sensors/ssp_spi.c:			if (!completion_done(msg->done))
drivers/iio/humidity/dht11.c:#include <linux/completion.h>
drivers/iio/humidity/dht11.c:	struct completion		completion;
drivers/iio/humidity/dht11.c:			complete(&dht11->completion);
drivers/iio/humidity/dht11.c:		reinit_completion(&dht11->completion);
drivers/iio/humidity/dht11.c:		ret = wait_for_completion_killable_timeout(&dht11->completion,
drivers/iio/humidity/dht11.c:	init_completion(&dht11->completion);
drivers/iio/imu/bno055/bno055_ser_core.c:#include <linux/completion.h>
drivers/iio/imu/bno055/bno055_ser_core.c:	struct completion cmd_complete;
drivers/iio/imu/bno055/bno055_ser_core.c:		ret = wait_for_completion_interruptible_timeout(&priv->cmd_complete,
drivers/iio/imu/bno055/bno055_ser_core.c:		reinit_completion(&priv->cmd_complete);
drivers/iio/imu/bno055/bno055_ser_core.c:		ret = wait_for_completion_interruptible_timeout(&priv->cmd_complete,
drivers/iio/imu/bno055/bno055_ser_core.c:	init_completion(&priv->cmd_complete);
drivers/iio/industrialio-buffer.c:		 * Signal the error through the fence completion mechanism.
drivers/iio/light/as73211.c:#include <linux/completion.h>
drivers/iio/light/as73211.c: * @completion: Completion to wait for interrupt.
drivers/iio/light/as73211.c:	struct completion completion;
drivers/iio/light/as73211.c:		reinit_completion(&data->completion);
drivers/iio/light/as73211.c:		ret = wait_for_completion_timeout(&data->completion, usecs_to_jiffies(time_us));
drivers/iio/light/as73211.c:	complete(&data->completion);
drivers/iio/light/as73211.c:	init_completion(&data->completion);
drivers/iio/light/si1133.c:#define SI1133_COMPLETION_TIMEOUT_MS	500
drivers/iio/light/si1133.c:	struct completion completion;
drivers/iio/light/si1133.c:		reinit_completion(&data->completion);
drivers/iio/light/si1133.c:		if (!wait_for_completion_timeout(&data->completion,
drivers/iio/light/si1133.c:			msecs_to_jiffies(SI1133_COMPLETION_TIMEOUT_MS))) {
drivers/iio/light/si1133.c:	complete(&data->completion);
drivers/iio/light/si1133.c:	init_completion(&data->completion);
drivers/iio/magnetometer/ak8974.c:#include <linux/completion.h>
drivers/iio/magnetometer/ak8974.c: * @drdy_complete: completion for DRDY
drivers/iio/magnetometer/ak8974.c:	struct completion drdy_complete;
drivers/iio/magnetometer/ak8974.c:		init_completion(&ak8974->drdy_complete);
drivers/iio/magnetometer/ak8974.c:		ret = wait_for_completion_timeout(&ak8974->drdy_complete,
drivers/iio/magnetometer/rm3100-core.c:	struct completion measuring_done;
drivers/iio/magnetometer/rm3100-core.c:		reinit_completion(&data->measuring_done);
drivers/iio/magnetometer/rm3100-core.c:			ret = wait_for_completion_timeout(&data->measuring_done,
drivers/iio/magnetometer/rm3100-core.c:		init_completion(&data->measuring_done);
drivers/iio/potentiostat/lmp91000.c:	struct completion completion;
drivers/iio/potentiostat/lmp91000.c:	ret = wait_for_completion_timeout(&data->completion, HZ);
drivers/iio/potentiostat/lmp91000.c:	reinit_completion(&data->completion);
drivers/iio/potentiostat/lmp91000.c:	complete_all(&data->completion);
drivers/iio/potentiostat/lmp91000.c:	init_completion(&data->completion);
drivers/iio/pressure/bmp280-core.c:#include <linux/completion.h>
drivers/iio/pressure/bmp280-core.c:		reinit_completion(&data->done);
drivers/iio/pressure/bmp280-core.c:		 * If we have a completion interrupt, use it, wait up to
drivers/iio/pressure/bmp280-core.c:		ret = wait_for_completion_timeout(&data->done,
drivers/iio/pressure/bmp280-core.c:			dev_err(data->dev, "timeout waiting for completion\n");
drivers/iio/pressure/bmp280-core.c:	init_completion(&data->done);
drivers/iio/pressure/bmp280.h:	struct completion done;
drivers/iio/pressure/dlhl60d.c:	struct completion completion;
drivers/iio/pressure/dlhl60d.c:		reinit_completion(&st->completion);
drivers/iio/pressure/dlhl60d.c:		ret = wait_for_completion_timeout(&st->completion,
drivers/iio/pressure/dlhl60d.c:	complete(&st->completion);
drivers/iio/pressure/dlhl60d.c:		init_completion(&st->completion);
drivers/iio/pressure/mprls0025pa.c:	reinit_completion(&data->completion);
drivers/iio/pressure/mprls0025pa.c:		ret = wait_for_completion_timeout(&data->completion, HZ);
drivers/iio/pressure/mprls0025pa.c:	complete(&data->completion);
drivers/iio/pressure/mprls0025pa.c:	init_completion(&data->completion);
drivers/iio/pressure/mprls0025pa.h:#include <linux/completion.h>
drivers/iio/pressure/mprls0025pa.h: * @completion: handshake from irq to read
drivers/iio/pressure/mprls0025pa.h:	struct completion	completion;
drivers/iio/pressure/zpa2326.c: * pressure samples only). Measurement cycle completion may be signaled by a
drivers/iio/pressure/zpa2326.c: * @result:     Allows sampling logic to get completion status of operations
drivers/iio/pressure/zpa2326.c: *              operation completion.
drivers/iio/pressure/zpa2326.c: *              to detect completion.
drivers/iio/pressure/zpa2326.c:	struct completion               data_ready;
drivers/iio/pressure/zpa2326.c:	 *   - or oneshot completion polling machinery : see
drivers/iio/pressure/zpa2326.c: * completion, in which case we must simply wake it up.
drivers/iio/pressure/zpa2326.c: * zpa2326_wait_oneshot_completion() - Wait for oneshot data ready interrupt.
drivers/iio/pressure/zpa2326.c:static int zpa2326_wait_oneshot_completion(const struct iio_dev   *indio_dev,
drivers/iio/pressure/zpa2326.c:	zpa2326_dbg(indio_dev, "waiting for one shot completion interrupt");
drivers/iio/pressure/zpa2326.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/iio/pressure/zpa2326.c:	init_completion(&private->data_ready);
drivers/iio/pressure/zpa2326.c: * zpa2326_poll_oneshot_completion() - Actively poll for one shot data ready.
drivers/iio/pressure/zpa2326.c:static int zpa2326_poll_oneshot_completion(const struct iio_dev *indio_dev)
drivers/iio/pressure/zpa2326.c:	zpa2326_dbg(indio_dev, "polling for one shot completion");
drivers/iio/pressure/zpa2326.c:	/* Poll for conversion completion in hardware. */
drivers/iio/pressure/zpa2326.c:	zpa2326_warn(indio_dev, "failed to poll one shot completion (%d)", err);
drivers/iio/pressure/zpa2326.c:		ret = zpa2326_wait_oneshot_completion(indio_dev, priv);
drivers/iio/pressure/zpa2326.c:		ret = zpa2326_poll_oneshot_completion(indio_dev);
drivers/iio/pressure/zpa2326.c:			/* No interrupt available: poll for completion. */
drivers/iio/pressure/zpa2326.c:			if (zpa2326_poll_oneshot_completion(indio_dev))
drivers/iio/pressure/zpa2326.c:			if (zpa2326_wait_oneshot_completion(indio_dev, priv))
drivers/iio/proximity/mb1232.c:	struct completion	ranging;
drivers/iio/proximity/mb1232.c:	reinit_completion(&data->ranging);
drivers/iio/proximity/mb1232.c:		ret = wait_for_completion_killable_timeout(&data->ranging,
drivers/iio/proximity/mb1232.c:	init_completion(&data->ranging);
drivers/iio/proximity/ping.c:	struct completion	rising;
drivers/iio/proximity/ping.c:	struct completion	falling;
drivers/iio/proximity/ping.c:	reinit_completion(&data->rising);
drivers/iio/proximity/ping.c:	reinit_completion(&data->falling);
drivers/iio/proximity/ping.c:	ret = wait_for_completion_killable_timeout(&data->rising, HZ/50);
drivers/iio/proximity/ping.c:	ret = wait_for_completion_killable_timeout(&data->falling, HZ/20);
drivers/iio/proximity/ping.c:	init_completion(&data->rising);
drivers/iio/proximity/ping.c:	init_completion(&data->falling);
drivers/iio/proximity/srf04.c:	struct completion	rising;
drivers/iio/proximity/srf04.c:	struct completion	falling;
drivers/iio/proximity/srf04.c:	reinit_completion(&data->rising);
drivers/iio/proximity/srf04.c:	reinit_completion(&data->falling);
drivers/iio/proximity/srf04.c:	ret = wait_for_completion_killable_timeout(&data->rising, HZ/50);
drivers/iio/proximity/srf04.c:	ret = wait_for_completion_killable_timeout(&data->falling, HZ/20);
drivers/iio/proximity/srf04.c:	init_completion(&data->rising);
drivers/iio/proximity/srf04.c:	init_completion(&data->falling);
drivers/iio/proximity/sx9500.c:	struct completion completion;
drivers/iio/proximity/sx9500.c:		ret = wait_for_completion_interruptible(&data->completion);
drivers/iio/proximity/sx9500.c:	reinit_completion(&data->completion);
drivers/iio/proximity/sx9500.c:		complete(&data->completion);
drivers/iio/proximity/sx9500.c:	init_completion(&data->completion);
drivers/iio/proximity/sx_common.c:		ret = wait_for_completion_interruptible(&data->completion);
drivers/iio/proximity/sx_common.c:		reinit_completion(&data->completion);
drivers/iio/proximity/sx_common.c:		complete(&data->completion);
drivers/iio/proximity/sx_common.c:	init_completion(&data->completion);
drivers/iio/proximity/sx_common.h: * @completion:		completion object to wait for data acquisition.
drivers/iio/proximity/sx_common.h:	struct completion completion;
drivers/iio/proximity/vl53l0x-i2c.c:	struct completion completion;
drivers/iio/proximity/vl53l0x-i2c.c:	complete(&data->completion);
drivers/iio/proximity/vl53l0x-i2c.c:		reinit_completion(&data->completion);
drivers/iio/proximity/vl53l0x-i2c.c:		time_left = wait_for_completion_timeout(&data->completion, HZ/10);
drivers/iio/proximity/vl53l0x-i2c.c:		init_completion(&data->completion);
drivers/iio/temperature/ltc2983.c:#include <linux/completion.h>
drivers/iio/temperature/ltc2983.c:	struct completion completion;
drivers/iio/temperature/ltc2983.c:	reinit_completion(&st->completion);
drivers/iio/temperature/ltc2983.c:	time = wait_for_completion_timeout(&st->completion,
drivers/iio/temperature/ltc2983.c:	complete(&st->completion);
drivers/iio/temperature/ltc2983.c:	reinit_completion(&st->completion);
drivers/iio/temperature/ltc2983.c:	time = wait_for_completion_timeout(&st->completion,
drivers/iio/temperature/ltc2983.c:	init_completion(&st->completion);
drivers/infiniband/core/addr.c:	struct completion comp;
drivers/infiniband/core/addr.c:	init_completion(&ctx.comp);
drivers/infiniband/core/addr.c:	wait_for_completion(&ctx.comp);
drivers/infiniband/core/cm.c:#include <linux/completion.h>
drivers/infiniband/core/cm.c:	struct completion comp;
drivers/infiniband/core/cm.c:	init_completion(&cm_id_priv->comp);
drivers/infiniband/core/cm.c:		ret = wait_for_completion_timeout(&cm_id_priv->comp,
drivers/infiniband/core/cm.c: * @work: Work completion
drivers/infiniband/core/cm.c: * in the work completion.
drivers/infiniband/core/cm_trace.h:	TP_printk("state=%s completion status=%s",
drivers/infiniband/core/cma.c:#include <linux/completion.h>
drivers/infiniband/core/cma.c:	struct completion	comp;
drivers/infiniband/core/cma.c:	init_completion(&id_priv->comp);
drivers/infiniband/core/cma.c:	wait_for_completion(&id_priv->comp);
drivers/infiniband/core/cma.c:	wait_for_completion(&cma_dev->comp);
drivers/infiniband/core/cma.c:	init_completion(&cma_dev->comp);
drivers/infiniband/core/cma_priv.h:	struct completion	comp;
drivers/infiniband/core/cq.c: * not ask for completion interrupts from the HCA.
drivers/infiniband/core/cq.c: * of completions that will be processed is small.
drivers/infiniband/core/cq.c:static void ib_cq_completion_direct(struct ib_cq *cq, void *private)
drivers/infiniband/core/cq.c:	WARN_ONCE(1, "got unsolicited completion for CQ 0x%p\n", cq);
drivers/infiniband/core/cq.c:static void ib_cq_completion_softirq(struct ib_cq *cq, void *private)
drivers/infiniband/core/cq.c:static void ib_cq_completion_workqueue(struct ib_cq *cq, void *private)
drivers/infiniband/core/cq.c: * __ib_alloc_cq - allocate a completion queue
drivers/infiniband/core/cq.c: * @comp_vector:	HCA completion vectors for this CQ
drivers/infiniband/core/cq.c:		cq->comp_handler = ib_cq_completion_direct;
drivers/infiniband/core/cq.c:		cq->comp_handler = ib_cq_completion_softirq;
drivers/infiniband/core/cq.c:		cq->comp_handler = ib_cq_completion_workqueue;
drivers/infiniband/core/cq.c: * __ib_alloc_cq_any - allocate a completion queue
drivers/infiniband/core/cq.c: * Attempt to spread ULP Completion Queues over each device's interrupt
drivers/infiniband/core/cq.c: * ib_free_cq - free a completion queue
drivers/infiniband/core/cq.c: * @cq:		completion queue to free.
drivers/infiniband/core/cq.c: * ib_cq_pool_get() - Find the least used completion queue that matches
drivers/infiniband/core/cq.c: * @comp_vector_hint: completion vector hint (-1) for the driver to assign
drivers/infiniband/core/cq.c:	/* Project the affinty to the device completion vector range */
drivers/infiniband/core/cq.c:			 * correct completion vector
drivers/infiniband/core/device.c:		complete(&device->unreg_completion);
drivers/infiniband/core/device.c:	init_completion(&device->unreg_completion);
drivers/infiniband/core/device.c:	 * for completion here.
drivers/infiniband/core/device.c:	wait_for_completion(&device->unreg_completion);
drivers/infiniband/core/device.c:	init_completion(&client->uses_zero);
drivers/infiniband/core/device.c:	wait_for_completion(&client->uses_zero);
drivers/infiniband/core/iwcm.c:#include <linux/completion.h>
drivers/infiniband/core/iwcm.c:	init_completion(&cm_id_priv->destroy_comp);
drivers/infiniband/core/iwcm.h:	struct completion destroy_comp;
drivers/infiniband/core/mad.c:static void local_completions(struct work_struct *work);
drivers/infiniband/core/mad.c:	INIT_WORK(&mad_agent_priv->local_work, local_completions);
drivers/infiniband/core/mad.c:	init_completion(&mad_agent_priv->comp);
drivers/infiniband/core/mad.c:	wait_for_completion(&mad_agent_priv->comp);
drivers/infiniband/core/mad.c:			 * side of local completion handled
drivers/infiniband/core/mad.c:			 * generate send completion.
drivers/infiniband/core/mad.c:	/* Reference MAD agent until send side of local completion handled */
drivers/infiniband/core/mad.c:	/* Queue local completion to local list */
drivers/infiniband/core/mad.c:	list_add_tail(&local->completion_list, &mad_agent_priv->local_list);
drivers/infiniband/core/mad.c:	/* Set WR ID to find mad_send_wr upon completion */
drivers/infiniband/core/mad.c:		 * request associated with the completion
drivers/infiniband/core/mad.c:	/* Setup MAD receive work completion from "normal" work completion */
drivers/infiniband/core/mad.c: * Process a send work completion
drivers/infiniband/core/mad.c:	/* Remove send from MAD agent and notify client of completion */
drivers/infiniband/core/mad.c:static void local_completions(struct work_struct *work)
drivers/infiniband/core/mad.c:				   completion_list);
drivers/infiniband/core/mad.c:		list_del(&local->completion_list);
drivers/infiniband/core/mad.c:					"No receive MAD agent for local completion\n");
drivers/infiniband/core/mad.c:				goto local_send_completion;
drivers/infiniband/core/mad.c:local_send_completion:
drivers/infiniband/core/mad.c:			"Failed to request completion notification: %d\n",
drivers/infiniband/core/mad_priv.h:#include <linux/completion.h>
drivers/infiniband/core/mad_priv.h:		struct completion comp;
drivers/infiniband/core/mad_priv.h:	struct completion comp;
drivers/infiniband/core/mad_priv.h:	struct list_head completion_list;
drivers/infiniband/core/mad_rmpp.c:	struct completion comp;
drivers/infiniband/core/mad_rmpp.c:	wait_for_completion(&rmpp_recv->comp);
drivers/infiniband/core/mad_rmpp.c:	init_completion(&rmpp_recv->comp);
drivers/infiniband/core/multicast.c:#include <linux/completion.h>
drivers/infiniband/core/multicast.c:	struct completion	comp;
drivers/infiniband/core/multicast.c:	struct completion	comp;
drivers/infiniband/core/multicast.c:	init_completion(&member->comp);
drivers/infiniband/core/multicast.c:	wait_for_completion(&member->comp);
drivers/infiniband/core/multicast.c: * @ah_attr:	AH attribute to fillup on successful completion
drivers/infiniband/core/multicast.c:		init_completion(&port->comp);
drivers/infiniband/core/multicast.c:			wait_for_completion(&port->comp);
drivers/infiniband/core/rdma_core.c: * For example, this is used when attaching a completion channel to a CQ.
drivers/infiniband/core/restrack.c:	init_completion(&res->comp);
drivers/infiniband/core/restrack.c:	wait_for_completion(&res->comp);
drivers/infiniband/core/rw.c: * @cqe:	completion queue entry for the last WR
drivers/infiniband/core/rw.c: * completion notification.
drivers/infiniband/core/rw.c: * @cqe:	completion queue entry for the last WR
drivers/infiniband/core/rw.c: * is not set @cqe must be set so that the caller gets a completion
drivers/infiniband/core/rw.c: * Send Completion Queues.
drivers/infiniband/core/sa_query.c:	init_completion(&client->comp);
drivers/infiniband/core/sa_query.c:	wait_for_completion(&client->comp);
drivers/infiniband/core/sa_query.c:	struct completion	done;
drivers/infiniband/core/sa_query.c:	init_completion(&cb_context->done);
drivers/infiniband/core/sa_query.c:	wait_for_completion(&cb_context->done);
drivers/infiniband/core/security.c:#include <linux/completion.h>
drivers/infiniband/core/security.c:	init_completion(&qp->qp_sec->error_complete);
drivers/infiniband/core/security.c:	/* Record the error list count to know how many completions
drivers/infiniband/core/security.c:		wait_for_completion(&sec->error_complete);
drivers/infiniband/core/security.c:		wait_for_completion(&sec->error_complete);
drivers/infiniband/core/ucma.c:#include <linux/completion.h>
drivers/infiniband/core/ucma.c:	struct completion	comp;
drivers/infiniband/core/ucma.c:	wait_for_completion(&ctx->comp);
drivers/infiniband/core/ucma.c:	init_completion(&ctx->comp);
drivers/infiniband/core/ucma.c:	 * be 0 because the work ran to completion and consumed the ref from the
drivers/infiniband/core/uverbs.h:#include <linux/completion.h>
drivers/infiniband/core/uverbs.h: * struct ib_uverbs_async_event_file and struct ib_uverbs_completion_event_file.
drivers/infiniband/core/uverbs.h: * main context file and released when that file is closed.  For completion
drivers/infiniband/core/uverbs.h:	struct completion			comp;
drivers/infiniband/core/uverbs.h:struct ib_uverbs_completion_event_file {
drivers/infiniband/core/uverbs.h:void ib_uverbs_release_ucq(struct ib_uverbs_completion_event_file *ev_file,
drivers/infiniband/core/uverbs_cmd.c:static struct ib_uverbs_completion_event_file *
drivers/infiniband/core/uverbs_cmd.c:	return container_of(uobj, struct ib_uverbs_completion_event_file,
drivers/infiniband/core/uverbs_cmd.c:	struct ib_uverbs_completion_event_file	  *ev_file;
drivers/infiniband/core/uverbs_cmd.c:	ev_file = container_of(uobj, struct ib_uverbs_completion_event_file,
drivers/infiniband/core/uverbs_cmd.c:	struct ib_uverbs_completion_event_file    *ev_file = NULL;
drivers/infiniband/core/uverbs_main.c:void ib_uverbs_release_ucq(struct ib_uverbs_completion_event_file *ev_file,
drivers/infiniband/core/uverbs_main.c:	struct ib_uverbs_completion_event_file *comp_ev_file =
drivers/infiniband/core/uverbs_main.c:	struct ib_uverbs_completion_event_file *comp_ev_file =
drivers/infiniband/core/uverbs_main.c:	struct ib_uverbs_completion_event_file *comp_ev_file =
drivers/infiniband/core/uverbs_main.c:	init_completion(&uverbs_dev->comp);
drivers/infiniband/core/uverbs_main.c:	wait_for_completion(&uverbs_dev->comp);
drivers/infiniband/core/uverbs_main.c:		wait_for_completion(&uverbs_dev->comp);
drivers/infiniband/core/uverbs_std_types.c:uverbs_completion_event_file_destroy_uobj(struct ib_uobject *uobj,
drivers/infiniband/core/uverbs_std_types.c:	struct ib_uverbs_completion_event_file *file =
drivers/infiniband/core/uverbs_std_types.c:		container_of(uobj, struct ib_uverbs_completion_event_file,
drivers/infiniband/core/uverbs_std_types.c:	UVERBS_TYPE_ALLOC_FD(sizeof(struct ib_uverbs_completion_event_file),
drivers/infiniband/core/uverbs_std_types.c:			     uverbs_completion_event_file_destroy_uobj,
drivers/infiniband/core/uverbs_std_types_cq.c:					struct ib_uverbs_completion_event_file,
drivers/infiniband/core/uverbs_std_types_cq.c:	struct ib_uverbs_completion_event_file    *ev_file = NULL;
drivers/infiniband/core/uverbs_std_types_cq.c:				 IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION |
drivers/infiniband/core/uverbs_std_types_cq.c:				       struct ib_uverbs_completion_event_file,
drivers/infiniband/core/verbs.c:		complete(&qp->srq_completion);
drivers/infiniband/core/verbs.c:	init_completion(&qp->srq_completion);
drivers/infiniband/core/verbs.c:/* Completion queues */
drivers/infiniband/core/verbs.c:	struct completion done;
drivers/infiniband/core/verbs.c: * Post a WR and block until its completion is reaped for the SQ.
drivers/infiniband/core/verbs.c:	init_completion(&sdrain.done);
drivers/infiniband/core/verbs.c:		while (wait_for_completion_timeout(&sdrain.done, HZ / 10) <= 0)
drivers/infiniband/core/verbs.c:		wait_for_completion(&sdrain.done);
drivers/infiniband/core/verbs.c: * Post a WR and block until its completion is reaped for the RQ.
drivers/infiniband/core/verbs.c:	init_completion(&rdrain.done);
drivers/infiniband/core/verbs.c:		while (wait_for_completion_timeout(&rdrain.done, HZ / 10) <= 0)
drivers/infiniband/core/verbs.c:		wait_for_completion(&rdrain.done);
drivers/infiniband/core/verbs.c:	if (wait_for_completion_timeout(&qp->srq_completion, 60 * HZ) > 0) {
drivers/infiniband/core/verbs.c: * completion.
drivers/infiniband/core/verbs.c: * completion.
drivers/infiniband/core/verbs.c: * and completions.
drivers/infiniband/hw/bnxt_re/ib_verbs.c:	/* Store the wrid for reporting completion */
drivers/infiniband/hw/bnxt_re/ib_verbs.c:/* Completion Queues */
drivers/infiniband/hw/bnxt_re/ib_verbs.c:					/* Handle this completion with
drivers/infiniband/hw/bnxt_re/ib_verbs.c:					 * the stored completion
drivers/infiniband/hw/bnxt_re/ib_verbs.c:					/* Handle this completion with
drivers/infiniband/hw/bnxt_re/ib_verbs.c:					 * the stored completion
drivers/infiniband/hw/bnxt_re/ib_verbs.c:	/* Trigger on the very next completion */
drivers/infiniband/hw/bnxt_re/ib_verbs.c:	/* Trigger on the next solicited completion */
drivers/infiniband/hw/bnxt_re/qplib_fp.c:		qp_flags |= CMDQ_CREATE_QP_QP_FLAGS_FORCE_COMPLETION;
drivers/infiniband/hw/bnxt_re/qplib_fp.c:		/* Skip the FENCE WQE completions */
drivers/infiniband/hw/bnxt_re/qplib_fp.c:		/* Peek at the completions */
drivers/infiniband/hw/bnxt_re/qplib_fp.c:	 * Back to normal completion mode only after it has completed all of
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * Wait for command completion in sleepable context.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * wait for command completion. Maximum holding interval is 8 second.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * This function will just post and don't bother about completion.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * user must hold the completion queue hwq->lock.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * user must have used existing completion and free the resources.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * __poll_for_resp   -	self poll completion for rcfw command
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:/* This function will just post and do not bother about completion */
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c: * for completion because of non-blocking nature.
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:/* Completions */
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		 * the command send and completion reaping. This function
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		 * but completion took more time and driver already lost
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		 * no more used in stack. We don't care about completion
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:/* SP - CREQ Completion handlers */
drivers/infiniband/hw/bnxt_re/qplib_res.c: *             CQ ctx - holds completion queue states
drivers/infiniband/hw/bnxt_re/roce_hsi.h:	#define CMDQ_CREATE_QP_QP_FLAGS_FORCE_COMPLETION           0x2UL
drivers/infiniband/hw/bnxt_re/roce_hsi.h:	#define CMDQ_CREATE_QP1_QP_FLAGS_FORCE_COMPLETION     0x2UL
drivers/infiniband/hw/cxgb4/cq.c: * Deal with out-of-order and/or completions that complete
drivers/infiniband/hw/cxgb4/cq.c:			 * Eat completions for unsignaled read WRs.
drivers/infiniband/hw/cxgb4/cq.c:		/* if its a SQ completion, then do the magic to move all the
drivers/infiniband/hw/cxgb4/cq.c:		 * unsignaled and now in-order completions into the swcq.
drivers/infiniband/hw/cxgb4/cq.c:	 * Special cqe for drain WR completions...
drivers/infiniband/hw/cxgb4/cq.c:	 * Gotta tweak READ completions:
drivers/infiniband/hw/cxgb4/cq.c:		 * connection setup.  So ignore the completion.
drivers/infiniband/hw/cxgb4/cq.c:		 * Eat completions for unsignaled read WRs.
drivers/infiniband/hw/cxgb4/cq.c:	 * RECV completion.
drivers/infiniband/hw/cxgb4/cq.c:	 * If we get here its a send completion.
drivers/infiniband/hw/cxgb4/cq.c:	 * Handle out of order completion. These get stuffed
drivers/infiniband/hw/cxgb4/cq.c:	 * now in-order completions into the SW CQ.  This handles
drivers/infiniband/hw/cxgb4/cq.c:	 *	2) out of order read completions.
drivers/infiniband/hw/cxgb4/cq.c:		pr_debug("out of order completion going in sw_sq at idx %u\n",
drivers/infiniband/hw/cxgb4/cq.c:	 * completion.
drivers/infiniband/hw/cxgb4/cq.c:		* Account for any unsignaled completions completed by
drivers/infiniband/hw/cxgb4/cq.c:		* this signaled completion.  In this case, cidx points
drivers/infiniband/hw/cxgb4/cq.c:	wait_for_completion(&chp->cq_rel_comp);
drivers/infiniband/hw/cxgb4/cq.c:	init_completion(&chp->cq_rel_comp);
drivers/infiniband/hw/cxgb4/device.c:	init_completion(&rdev->rqt_compl);
drivers/infiniband/hw/cxgb4/device.c:	init_completion(&rdev->pbl_compl);
drivers/infiniband/hw/cxgb4/device.c:	wait_for_completion(&rdev->pbl_compl);
drivers/infiniband/hw/cxgb4/device.c:	wait_for_completion(&rdev->rqt_compl);
drivers/infiniband/hw/cxgb4/ev.c:	/* Completion Events */
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:#include <linux/completion.h>
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	struct completion rqt_compl;
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	struct completion pbl_compl;
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	struct completion completion;
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	init_completion(&wr_waitp->completion);
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	complete(&wr_waitp->completion);
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	ret = wait_for_completion_timeout(&wr_waitp->completion, C4IW_WR_TO);
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	struct completion cq_rel_comp;
drivers/infiniband/hw/cxgb4/iw_cxgb4.h:	struct completion qp_rel_comp;
drivers/infiniband/hw/cxgb4/qp.c:	wqe->write_cmpl.flags_send = send_signaled ? FW_RI_COMPLETION_FLAG : 0;
drivers/infiniband/hw/cxgb4/qp.c:		    write_signaled ? FW_RI_COMPLETION_FLAG : 0, len16);
drivers/infiniband/hw/cxgb4/qp.c:			fw_flags |= FW_RI_COMPLETION_FLAG;
drivers/infiniband/hw/cxgb4/qp.c:	wait_for_completion(&qhp->qp_rel_comp);
drivers/infiniband/hw/cxgb4/qp.c:	init_completion(&qhp->qp_rel_comp);
drivers/infiniband/hw/cxgb4/t4.h:/* used for RQ completion processing */
drivers/infiniband/hw/cxgb4/t4.h:/* used for SQ completion processing */
drivers/infiniband/hw/cxgb4/t4fw_ri_api.h:	FW_RI_COMPLETION_FLAG		= 0x01,
drivers/infiniband/hw/efa/efa.h:	/* Array of completion EQs */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Index of CQ to be associated with Send Queue completions */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Index of CQ to be associated with Recv Queue completions */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Index of sub-CQ for Send Queue completions */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Index of sub-CQ for Receive Queue completions */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Common Admin Queue completion descriptor */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	 *    filled on RX completions from unknown senders.
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* completion queue depth in # of entries. must be power of 2 */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* The maximum number of completion queues supported per VF */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	/* Maximum number of CQEs per Completion Queue */
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	u16 admin_completion_timeout;
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:	 * 0 : completion_events - Enable completion events
drivers/infiniband/hw/efa/efa_admin_cmds_defs.h:#define EFA_ADMIN_CREATE_EQ_CMD_COMPLETION_EVENTS_MASK      BIT(0)
drivers/infiniband/hw/efa/efa_admin_defs.h:enum efa_admin_aq_completion_status {
drivers/infiniband/hw/efa/efa_admin_defs.h:	EFA_ADMIN_EQE_EVENT_TYPE_COMPLETION         = 0,
drivers/infiniband/hw/efa/efa_admin_defs.h:/* Completion event */
drivers/infiniband/hw/efa/efa_admin_defs.h:		/* Completion Event */
drivers/infiniband/hw/efa/efa_com.c:	struct completion wait_event;
drivers/infiniband/hw/efa/efa_com.c:	ibdev_dbg(aq->efa_dev, "Put completion command_id %#x\n", cmd_id);
drivers/infiniband/hw/efa/efa_com.c:			"Completion context for command_id %#x is occupied\n",
drivers/infiniband/hw/efa/efa_com.c:			  "Take completion ctxt for command_id %#x\n", cmd_id);
drivers/infiniband/hw/efa/efa_com.c:	reinit_completion(&comp_ctx->wait_event);
drivers/infiniband/hw/efa/efa_com.c:			init_completion(&comp_ctx->wait_event);
drivers/infiniband/hw/efa/efa_com.c:static int efa_com_handle_single_admin_completion(struct efa_com_admin_queue *aq,
drivers/infiniband/hw/efa/efa_com.c:			  "Received completion with unexpected command id[%d], sq producer: %d, sq consumer: %d, cq consumer: %d\n",
drivers/infiniband/hw/efa/efa_com.c:static void efa_com_handle_admin_completion(struct efa_com_admin_queue *aq)
drivers/infiniband/hw/efa/efa_com.c:	/* Go over all the completions */
drivers/infiniband/hw/efa/efa_com.c:		 * Do not read the rest of the completion entry before the
drivers/infiniband/hw/efa/efa_com.c:		err = efa_com_handle_single_admin_completion(aq, cqe);
drivers/infiniband/hw/efa/efa_com.c:	timeout = jiffies + usecs_to_jiffies(aq->completion_timeout);
drivers/infiniband/hw/efa/efa_com.c:		efa_com_handle_admin_completion(aq);
drivers/infiniband/hw/efa/efa_com.c:				"Wait for completion (polling) timeout\n");
drivers/infiniband/hw/efa/efa_com.c:			/* EFA didn't have any completion */
drivers/infiniband/hw/efa/efa_com.c:			atomic64_inc(&aq->stats.no_completion);
drivers/infiniband/hw/efa/efa_com.c:	wait_for_completion_timeout(&comp_ctx->wait_event,
drivers/infiniband/hw/efa/efa_com.c:				    usecs_to_jiffies(aq->completion_timeout));
drivers/infiniband/hw/efa/efa_com.c:	 * 1) No completion (timeout reached)
drivers/infiniband/hw/efa/efa_com.c:	 * 2) There is completion but the device didn't get any msi-x interrupt.
drivers/infiniband/hw/efa/efa_com.c:		efa_com_handle_admin_completion(aq);
drivers/infiniband/hw/efa/efa_com.c:		atomic64_inc(&aq->stats.no_completion);
drivers/infiniband/hw/efa/efa_com.c:				"The device sent a completion but the driver didn't receive any MSI-X interrupt for admin cmd %s(%d) status %d (ctx: 0x%p, sq producer: %d, sq consumer: %d, cq consumer: %d)\n",
drivers/infiniband/hw/efa/efa_com.c:				"The device didn't send any completion for admin cmd %s(%d) status %d (ctx 0x%p, sq producer: %d, sq consumer: %d, cq consumer: %d)\n",
drivers/infiniband/hw/efa/efa_com.c: * There are two types to wait for completion.
drivers/infiniband/hw/efa/efa_com.c: * Polling mode - wait until the completion is available.
drivers/infiniband/hw/efa/efa_com.c: * Async mode - wait on wait queue until the completion is ready
drivers/infiniband/hw/efa/efa_com.c: * It is expected that the IRQ called efa_com_handle_admin_completion
drivers/infiniband/hw/efa/efa_com.c: * to mark the completions.
drivers/infiniband/hw/efa/efa_com.c: * @comp: command completion return entry.
drivers/infiniband/hw/efa/efa_com.c: * @comp_size: command completion size.
drivers/infiniband/hw/efa/efa_com.c: * completion.
drivers/infiniband/hw/efa/efa_com.c: * The completion will be copied into comp.
drivers/infiniband/hw/efa/efa_com.c: * efa_com_set_admin_polling_mode - Set the admin completion queue polling mode
drivers/infiniband/hw/efa/efa_com.c: * Set the admin completion mode.
drivers/infiniband/hw/efa/efa_com.c: * Initialize the admin submission and completion queues.
drivers/infiniband/hw/efa/efa_com.c:		aq->completion_timeout = timeout * 100000;
drivers/infiniband/hw/efa/efa_com.c:		aq->completion_timeout = ADMIN_CMD_TIMEOUT_US;
drivers/infiniband/hw/efa/efa_com.c: * This method goes over the admin completion queue and wakes up
drivers/infiniband/hw/efa/efa_com.c:	efa_com_handle_admin_completion(&edev->aq);
drivers/infiniband/hw/efa/efa_com.c:		 * Do not read the rest of the completion entry before the
drivers/infiniband/hw/efa/efa_com.c:		edev->aq.completion_timeout = timeout * 100000;
drivers/infiniband/hw/efa/efa_com.c:		edev->aq.completion_timeout = ADMIN_CMD_TIMEOUT_US;
drivers/infiniband/hw/efa/efa_com.c:		 * Do not read the rest of the completion entry before the
drivers/infiniband/hw/efa/efa_com.c:		EFA_ADMIN_CREATE_EQ_CMD_COMPLETION_EVENTS, 1);
drivers/infiniband/hw/efa/efa_com.h:	atomic64_t no_completion;
drivers/infiniband/hw/efa/efa_com.h:	u32 completion_timeout; /* usecs */
drivers/infiniband/hw/efa/efa_com.h:	spinlock_t comp_ctx_lock; /* Protects completion context pool */
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_create_qp_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->qp_handle = cmd_completion.qp_handle;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->qp_num = cmd_completion.qp_num;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->sq_db_offset = cmd_completion.sq_db_offset;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->rq_db_offset = cmd_completion.rq_db_offset;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->llq_descriptors_offset = cmd_completion.llq_descriptors_offset;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->send_sub_cq_idx = cmd_completion.send_sub_cq_idx;
drivers/infiniband/hw/efa/efa_com_cmd.c:	res->recv_sub_cq_idx = cmd_completion.recv_sub_cq_idx;
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_destroy_qp_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_create_cq_resp cmd_completion = {};
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->cq_idx = cmd_completion.cq_idx;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->db_off = cmd_completion.db_offset;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->db_valid = EFA_GET(&cmd_completion.flags,
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_reg_mr_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->l_key = cmd_completion.l_key;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->r_key = cmd_completion.r_key;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.recv_ic_id = cmd_completion.recv_ic_id;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.rdma_read_ic_id = cmd_completion.rdma_read_ic_id;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.rdma_recv_ic_id = cmd_completion.rdma_recv_ic_id;
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.recv_ic_id_valid = EFA_GET(&cmd_completion.validity,
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.rdma_read_ic_id_valid = EFA_GET(&cmd_completion.validity,
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ic_info.rdma_recv_ic_id_valid = EFA_GET(&cmd_completion.validity,
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_dereg_mr_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_create_ah_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->ah = cmd_completion.ah;
drivers/infiniband/hw/efa/efa_com_cmd.c:	struct efa_admin_destroy_ah_resp cmd_completion;
drivers/infiniband/hw/efa/efa_com_cmd.c:			       (struct efa_admin_acq_entry *)&cmd_completion,
drivers/infiniband/hw/efa/efa_com_cmd.c:			       sizeof(cmd_completion));
drivers/infiniband/hw/efa/efa_com_cmd.c:	result->admin_completion_timeout = resp.u.hw_hints.admin_completion_timeout;
drivers/infiniband/hw/efa/efa_com_cmd.h:	/* completion queue depth in # of entries */
drivers/infiniband/hw/efa/efa_com_cmd.h:	u16 admin_completion_timeout;
drivers/infiniband/hw/efa/efa_io_defs.h:	/* Successful completion */
drivers/infiniband/hw/efa/efa_io_defs.h:	 * 4 : comp_req - Indicates whether completion should
drivers/infiniband/hw/efa/efa_io_defs.h:	 *    within Tx message and reported in remote Rx completion.
drivers/infiniband/hw/efa/efa_io_defs.h:/* Common IO completion descriptor */
drivers/infiniband/hw/efa/efa_io_defs.h:	 *    present - for RX completions only
drivers/infiniband/hw/efa/efa_io_defs.h:/* Tx completion descriptor */
drivers/infiniband/hw/efa/efa_io_defs.h:	/* Common completion info */
drivers/infiniband/hw/efa/efa_io_defs.h:/* Rx Completion Descriptor */
drivers/infiniband/hw/efa/efa_io_defs.h:	/* Common completion info */
drivers/infiniband/hw/efa/efa_io_defs.h:/* Rx Completion Descriptor RDMA write info */
drivers/infiniband/hw/efa/efa_io_defs.h:/* Extended Rx Completion Descriptor */
drivers/infiniband/hw/efa/efa_io_defs.h:	/* Base RX completion info */
drivers/infiniband/hw/efa/efa_main.c:				      "Completion event on non-existent CQ[%u]",
drivers/infiniband/hw/efa/efa_main.c:			   EFA_ADMIN_EQE_EVENT_TYPE_COMPLETION))
drivers/infiniband/hw/efa/efa_main.c:	if (hw_hints->admin_completion_timeout)
drivers/infiniband/hw/efa/efa_main.c:		edev->aq.completion_timeout =
drivers/infiniband/hw/efa/efa_main.c:			hw_hints->admin_completion_timeout;
drivers/infiniband/hw/efa/efa_verbs.c:	op(EFA_NO_COMPLETION_CMDS, "no_completion_cmds") \
drivers/infiniband/hw/efa/efa_verbs.c:	if (cmd.flags & EFA_CREATE_CQ_WITH_COMPLETION_CHANNEL) {
drivers/infiniband/hw/efa/efa_verbs.c:	stats->value[EFA_NO_COMPLETION_CMDS] = atomic64_read(&as->no_completion);
drivers/infiniband/hw/erdma/erdma.h:	struct completion wait_event;
drivers/infiniband/hw/erdma/erdma.h:void erdma_cmdq_completion_handler(struct erdma_cmdq *cmdq);
drivers/infiniband/hw/erdma/erdma.h:void erdma_ceq_completion_handler(struct erdma_eq_cb *ceq_cb);
drivers/infiniband/hw/erdma/erdma_cmdq.c:		init_completion(&cmdq->wait_pool[i].wait_event);
drivers/infiniband/hw/erdma/erdma_cmdq.c:	reinit_completion(&comp_wait->wait_event);
drivers/infiniband/hw/erdma/erdma_cmdq.c:static int erdma_poll_single_cmd_completion(struct erdma_cmdq *cmdq)
drivers/infiniband/hw/erdma/erdma_cmdq.c:static void erdma_polling_cmd_completions(struct erdma_cmdq *cmdq)
drivers/infiniband/hw/erdma/erdma_cmdq.c:	 * completions at one time.
drivers/infiniband/hw/erdma/erdma_cmdq.c:		if (erdma_poll_single_cmd_completion(cmdq))
drivers/infiniband/hw/erdma/erdma_cmdq.c:void erdma_cmdq_completion_handler(struct erdma_cmdq *cmdq)
drivers/infiniband/hw/erdma/erdma_cmdq.c:		erdma_polling_cmd_completions(cmdq);
drivers/infiniband/hw/erdma/erdma_cmdq.c:static int erdma_poll_cmd_completion(struct erdma_comp_wait *comp_ctx,
drivers/infiniband/hw/erdma/erdma_cmdq.c:		erdma_polling_cmd_completions(cmdq);
drivers/infiniband/hw/erdma/erdma_cmdq.c:static int erdma_wait_cmd_completion(struct erdma_comp_wait *comp_ctx,
drivers/infiniband/hw/erdma/erdma_cmdq.c:	wait_for_completion_timeout(&comp_ctx->wait_event,
drivers/infiniband/hw/erdma/erdma_cmdq.c:		ret = erdma_wait_cmd_completion(comp_wait, cmdq,
drivers/infiniband/hw/erdma/erdma_cmdq.c:		ret = erdma_poll_cmd_completion(comp_wait, cmdq,
drivers/infiniband/hw/erdma/erdma_eq.c:void erdma_ceq_completion_handler(struct erdma_eq_cb *ceq_cb)
drivers/infiniband/hw/erdma/erdma_eq.c:	erdma_ceq_completion_handler((struct erdma_eq_cb *)data);
drivers/infiniband/hw/erdma/erdma_main.c:	erdma_cmdq_completion_handler(&dev->cmdq);
drivers/infiniband/hw/erdma/erdma_verbs.c:	init_completion(&qp->safe_free);
drivers/infiniband/hw/erdma/erdma_verbs.c:	wait_for_completion(&qp->safe_free);
drivers/infiniband/hw/erdma/erdma_verbs.h:	struct completion safe_free;
drivers/infiniband/hw/hfi1/Kconfig:	sdma completions for unit testing
drivers/infiniband/hw/hfi1/affinity.c:	/* Available CPUs for pinning completion vectors */
drivers/infiniband/hw/hfi1/affinity.c:			  "[%s] Release CPU %d from completion vector %d",
drivers/infiniband/hw/hfi1/affinity.c: * This function creates the table for looking up CPUs for completion vectors.
drivers/infiniband/hw/hfi1/affinity.c:			  "[%s] Completion Vector %d -> CPU %d",
drivers/infiniband/hw/hfi1/affinity.c:	 * If there's only one CPU available for completion vectors, then
drivers/infiniband/hw/hfi1/affinity.c:	 * there will only be one completion vector available. Othewise,
drivers/infiniband/hw/hfi1/affinity.c:	 * the number of completion vector available will be the number of
drivers/infiniband/hw/hfi1/affinity.c:			    "Number of kernel receive queues is too large for completion vector affinity to be effective\n");
drivers/infiniband/hw/hfi1/affinity.c:		 * If the completion vector CPUs available doesn't divide
drivers/infiniband/hw/hfi1/affinity.c:	/* Reserving CPUs for device completion vector */
drivers/infiniband/hw/hfi1/affinity.c:		  "[%s] Completion vector affinity CPU set(s) %*pbl",
drivers/infiniband/hw/hfi1/affinity.c:		/* Clearing CPU in device completion vector cpu mask */
drivers/infiniband/hw/hfi1/affinity.c:		/* Determine completion vector CPUs for the entire node */
drivers/infiniband/hw/hfi1/affinity.c:		 * If there ends up being 0 CPU cores leftover for completion
drivers/infiniband/hw/hfi1/affinity.c:	 * Free device completion vector CPUs to be used by future
drivers/infiniband/hw/hfi1/affinity.c:	 * completion vectors
drivers/infiniband/hw/hfi1/chip.c:	/* wait for completion, alternate: interrupt */
drivers/infiniband/hw/hfi1/chip.c:	init_completion(&dd->user_comp);
drivers/infiniband/hw/hfi1/file_ops.c:		 * using a sub-context that is waiting for this completion.
drivers/infiniband/hw/hfi1/hfi.h:#include <linux/completion.h>
drivers/infiniband/hw/hfi1/hfi.h:	struct completion user_comp;
drivers/infiniband/hw/hfi1/init.c:	wait_for_completion(&dd->user_comp);
drivers/infiniband/hw/hfi1/mad.c: * @in_wc: Work completion data such as source LID, port number, etc.
drivers/infiniband/hw/hfi1/mad.c: * @in_wc: the work completion entry for this packet
drivers/infiniband/hw/hfi1/rc.c:				      RVT_SEND_COMPLETION_ONLY)) {
drivers/infiniband/hw/hfi1/rc.c:				wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/hfi1/rc.c:		} else { /* need to handle delayed completion */
drivers/infiniband/hw/hfi1/rc.c:		trace_hfi1_qp_send_completion(qp, wqe, qp->s_last);
drivers/infiniband/hw/hfi1/rc.c: * Generate a SWQE completion.
drivers/infiniband/hw/hfi1/rc.c:struct rvt_swqe *do_rc_completion(struct rvt_qp *qp,
drivers/infiniband/hw/hfi1/rc.c:	 * completion if the SWQE is being resent until the send
drivers/infiniband/hw/hfi1/rc.c:	trace_hfi1_rc_completion(qp, wqe->lpsn);
drivers/infiniband/hw/hfi1/rc.c:		trace_hfi1_qp_send_completion(qp, wqe, qp->s_last);
drivers/infiniband/hw/hfi1/rc.c:	 * Completion of the TID RDMA WRITE requests are done by the
drivers/infiniband/hw/hfi1/rc.c:		 * we want to generate completion events for everything
drivers/infiniband/hw/hfi1/rc.c:		 * the completion for the read.
drivers/infiniband/hw/hfi1/rc.c:		wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/hfi1/rc.c:		wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/hfi1/rc.c:		 * work completion only for the UD transport (see section
drivers/infiniband/hw/hfi1/rc.c:		/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/hfi1/rc.h:struct rvt_swqe *do_rc_completion(struct rvt_qp *qp, struct rvt_swqe *wqe,
drivers/infiniband/hw/hfi1/sdma.c:	wait_for_completion(&ss->comp);
drivers/infiniband/hw/hfi1/sdma.c:		init_completion(&sde->state.comp);
drivers/infiniband/hw/hfi1/sdma.h:	struct completion    comp;
drivers/infiniband/hw/hfi1/sdma.h: * completion is desired as soon as possible.
drivers/infiniband/hw/hfi1/sdma.h: * Completions of submitted requests can be gotten on selected
drivers/infiniband/hw/hfi1/sdma.h: * txreqs by giving a completion routine callback to sdma_txinit() or
drivers/infiniband/hw/hfi1/sdma.h: * completion is desired as soon as possible.
drivers/infiniband/hw/hfi1/sdma.h: * Completions of submitted requests can be gotten on selected
drivers/infiniband/hw/hfi1/sdma.h: * txreqs by giving a completion routine callback to sdma_txinit() or
drivers/infiniband/hw/hfi1/tid_rdma.c:		wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/hfi1/tid_rdma.c:			wqe = do_rc_completion(qp, wqe,
drivers/infiniband/hw/hfi1/trace_rc.h:	hfi1_rc_template, hfi1_rc_completion,
drivers/infiniband/hw/hfi1/trace_tx.h:TRACE_EVENT(hfi1_sdma_user_completion,
drivers/infiniband/hw/hfi1/trace_tx.h:	    TP_printk("[%s:%u:%u:%u] SDMA completion state %s (%d)",
drivers/infiniband/hw/hfi1/trace_tx.h:	hfi1_qp_send_completion,
drivers/infiniband/hw/hfi1/uc.c:			if (!(wqe->wr.send_flags & RVT_SEND_COMPLETION_ONLY)) {
drivers/infiniband/hw/hfi1/uc.c:		 * work completion only for the UD transport (see section
drivers/infiniband/hw/hfi1/uc.c:		/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/hfi1/ud.c:	/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/hfi1/ud.c:			 * a completion for the loopback packet since
drivers/infiniband/hw/hfi1/ud.c: *     and specifically _not_ the pkey that we attach to the completion,
drivers/infiniband/hw/hfi1/ud.c:	/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/hfi1/user_sdma.c:MODULE_PARM_DESC(sdma_comp_size, "Size of User SDMA completion ring. Default: 128");
drivers/infiniband/hw/hfi1/user_sdma.c:	 * will not wait for send completions.
drivers/infiniband/hw/hfi1/user_sdma.c:	 * If the submitted seqsubmitted == npkts, the completion routine
drivers/infiniband/hw/hfi1/user_sdma.c:	/* If tx completion has reported an error, we are done. */
drivers/infiniband/hw/hfi1/user_sdma.c:		 * Check whether any of the completions have come back
drivers/infiniband/hw/hfi1/user_sdma.c: * user_sdma_txreq_cb() - SDMA tx request completion callback.
drivers/infiniband/hw/hfi1/user_sdma.c:		SDMA_DBG(req, "SDMA completion with error %d",
drivers/infiniband/hw/hfi1/user_sdma.c:	trace_hfi1_sdma_user_completion(pq->dd, pq->ctxt, pq->subctxt,
drivers/infiniband/hw/hfi1/verbs.c:		 "Maximum number of completion queue entries to support");
drivers/infiniband/hw/hfi1/verbs.c:MODULE_PARM_DESC(max_cqs, "Maximum number of completion queues to support");
drivers/infiniband/hw/hfi1/verbs.c:		 * completion event. Only do this for PIO. SDMA has its own
drivers/infiniband/hw/hfi1/verbs.h:#include <linux/completion.h>
drivers/infiniband/hw/hns/hns_roce_cmd.c:	reinit_completion(&context->done);
drivers/infiniband/hw/hns/hns_roce_cmd.c:	if (!wait_for_completion_timeout(&context->done,
drivers/infiniband/hw/hns/hns_roce_cmd.c:		init_completion(&hr_cmd->context[i].done);
drivers/infiniband/hw/hns/hns_roce_cq.c:	wait_for_completion(&hr_cq->free);
drivers/infiniband/hw/hns/hns_roce_cq.c:	init_completion(&hr_cq->free);
drivers/infiniband/hw/hns/hns_roce_cq.c:void hns_roce_cq_completion(struct hns_roce_dev *hr_dev, u32 cqn)
drivers/infiniband/hw/hns/hns_roce_cq.c:		dev_warn(hr_dev->dev, "completion event for bogus CQ 0x%06x\n",
drivers/infiniband/hw/hns/hns_roce_device.h:	struct completion		free;
drivers/infiniband/hw/hns/hns_roce_device.h:	struct completion	free;
drivers/infiniband/hw/hns/hns_roce_device.h:	struct completion	done;
drivers/infiniband/hw/hns/hns_roce_device.h:	struct completion	free;
drivers/infiniband/hw/hns/hns_roce_device.h:void hns_roce_cq_completion(struct hns_roce_dev *hr_dev, u32 cqn);
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		msleep(HNS_ROCE_V2_HW_RST_COMPLETION_WAIT);
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		end -= HNS_ROCE_V2_HW_RST_COMPLETION_WAIT;
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		msleep(HNS_ROCE_V2_HW_RST_COMPLETION_WAIT);
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		end -= HNS_ROCE_V2_HW_RST_COMPLETION_WAIT;
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		/* Completion event interrupt */
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:		hns_roce_cq_completion(hr_dev, cqn);
drivers/infiniband/hw/hns/hns_roce_hw_v2.h:#define HNS_ROCE_V2_HW_RST_COMPLETION_WAIT	20
drivers/infiniband/hw/hns/hns_roce_main.c:		hns_roce_cq_completion(hr_dev, hr_cq->cqn);
drivers/infiniband/hw/hns/hns_roce_qp.c:	init_completion(&hr_qp->free);
drivers/infiniband/hw/hns/hns_roce_qp.c:	wait_for_completion(&hr_qp->free);
drivers/infiniband/hw/hns/hns_roce_srq.c:	wait_for_completion(&srq->free);
drivers/infiniband/hw/hns/hns_roce_srq.c:	init_completion(&srq->free);
drivers/infiniband/hw/irdma/cm.c:			wait_for_completion(&cm_node->establish_comp);
drivers/infiniband/hw/irdma/cm.c:	init_completion(&cm_node->establish_comp);
drivers/infiniband/hw/irdma/cm.h:	struct completion establish_comp;
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_cq_ack - acknowledge completion q
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_cq_init - initialize completion q
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_cq_create - create completion q
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_cq_destroy - destroy completion q
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_cq_modify - modify a Completion Queue
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @count: how many times to try for completion
drivers/infiniband/hw/irdma/ctrl.c: * @info: completion q entry to return
drivers/infiniband/hw/irdma/ctrl.c: * @op_code: cqp opcode for completion
drivers/infiniband/hw/irdma/ctrl.c: * @compl_info: completion q entry to return
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_commit_fpm_val_done - wait for cqp eqe completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @wait_type: poll ccq or cqp registers for cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * irdma_sc_query_fpm_val_done - poll for cqp wqe completion for
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @wait_type: poll ccq or cqp registers for cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @poll_registers: flag to poll register for cqp completion
drivers/infiniband/hw/irdma/ctrl.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/defs.h:/* CQP and iWARP Completion Queue */
drivers/infiniband/hw/irdma/hw.c: * irdma_iwarp_ce_handler - handle iwarp completions
drivers/infiniband/hw/irdma/hw.c: * irdma_puda_ce_handler - handle puda completion events
drivers/infiniband/hw/irdma/hw.c: * @cq: puda completion q for event
drivers/infiniband/hw/irdma/hw.c: * irdma_process_ceq - handle ceq for completions
drivers/infiniband/hw/irdma/hw.c: * @ceq: ceq having cq for completion
drivers/infiniband/hw/irdma/hw.c:		ibdev_dbg(to_ibdev(dev), "ERR: CEQ destroy completion failed %d\n",
drivers/infiniband/hw/irdma/hw.c: * irdma_create_ceq - create completion event queue
drivers/infiniband/hw/irdma/hw.c: * Allocate a list for all device completion event queues
drivers/infiniband/hw/irdma/hw.c: * Allocate a list for all device completion event queues
drivers/infiniband/hw/irdma/hw.c:	enum init_completion_state state = rf->init_state;
drivers/infiniband/hw/irdma/hw.c:		/* Handles processing of CQP completions */
drivers/infiniband/hw/irdma/hw.c: * irdma_cqp_ce_handler - handle cqp completions
drivers/infiniband/hw/irdma/hw.c: * @cq: cq for cqp completions
drivers/infiniband/hw/irdma/hw.c: * cqp_compl_worker - Handle cqp completions
drivers/infiniband/hw/irdma/hw.c: * @cqp_request: qhash cqp completion
drivers/infiniband/hw/irdma/hw.c: * @wait: wait for completion
drivers/infiniband/hw/irdma/hw.c: * @cqp_request: qhash cqp completion
drivers/infiniband/hw/irdma/hw.c: * @wait: flag wait for completion
drivers/infiniband/hw/irdma/hw.c: * @wait: wait for completion
drivers/infiniband/hw/irdma/i40iw_hw.c: * @ceq_id: Completion Event Queue ID
drivers/infiniband/hw/irdma/icrdma_hw.c: * @ceq_id: Completion Event Queue ID
drivers/infiniband/hw/irdma/main.h:enum init_completion_state {
drivers/infiniband/hw/irdma/main.h:	spinlock_t compl_lock; /* protect CQP completion processing */
drivers/infiniband/hw/irdma/main.h:	spinlock_t ce_lock; /* sync cq destroy with cq completion event notification */
drivers/infiniband/hw/irdma/main.h:	enum init_completion_state init_state;
drivers/infiniband/hw/irdma/main.h:	enum init_completion_state init_state;
drivers/infiniband/hw/irdma/puda.c: * irdma_puda_poll_info - poll cq for completion
drivers/infiniband/hw/irdma/puda.c: * @info: info return for successful completion
drivers/infiniband/hw/irdma/puda.c: * irdma_puda_poll_cmpl - processes completion for cq
drivers/infiniband/hw/irdma/puda.c: * @compl_err: return any completion err
drivers/infiniband/hw/irdma/puda.c:		ibdev_dbg(to_ibdev(dev), "PUDA: RQ completion\n");
drivers/infiniband/hw/irdma/puda.c:		ibdev_dbg(to_ibdev(dev), "PUDA: SQ completion\n");
drivers/infiniband/hw/irdma/puda.c:	/* if no wqe available or not from a completion and we have
drivers/infiniband/hw/irdma/puda.c:	/* if we are coming from a completion and have pending buffers
drivers/infiniband/hw/irdma/uda.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/uda.c: * @scratch: u64 saved to be used during cqp completion
drivers/infiniband/hw/irdma/uk.c: * irdma_uk_cq_poll_cmpl - get cq completion info
drivers/infiniband/hw/irdma/uk.c: * @q: completion context
drivers/infiniband/hw/irdma/uk.c: * @signaled: signaled for completion
drivers/infiniband/hw/irdma/utils.c: * completions
drivers/infiniband/hw/irdma/utils.c: * irdma_wait_event - wait for completion
drivers/infiniband/hw/irdma/utils.c:			  "[%s Error][op_code=%d] status=%d waiting=%d completion_err=%d maj=0x%x min=0x%x\n",
drivers/infiniband/hw/irdma/utils.c: * @cqp_request: modify QP completion
drivers/infiniband/hw/irdma/utils.c: * @wait: flag to wait or not for modify qp completion
drivers/infiniband/hw/irdma/utils.c: * @callback_fcn: Callback function on CQP op completion
drivers/infiniband/hw/irdma/utils.c:		  "VERBS: %s: Poll artificially generated completion for QP 0x%X, op %u, wr_id=0x%llx\n",
drivers/infiniband/hw/irdma/utils.c:void irdma_generate_flush_completions(struct irdma_qp *iwqp)
drivers/infiniband/hw/irdma/utils.c:				  "DEV: %s: adding wr_id = 0x%llx SQ Completion to list qp_id=%d\n",
drivers/infiniband/hw/irdma/utils.c:				  "DEV: %s: adding wr_id = 0x%llx RQ Completion to list qp_id=%d, wqe_idx=%d\n",
drivers/infiniband/hw/irdma/verbs.c:	wait_for_completion(&iwqp->free_qp);
drivers/infiniband/hw/irdma/verbs.c:	irdma_generate_flush_completions(iwqp);
drivers/infiniband/hw/irdma/verbs.c:	init_completion(&iwqp->free_qp);
drivers/infiniband/hw/irdma/verbs.c:	wait_for_completion(&iwcq->free_cq);
drivers/infiniband/hw/irdma/verbs.c:	return flags & ~IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION ? -EOPNOTSUPP : 0;
drivers/infiniband/hw/irdma/verbs.c:	init_completion(&iwcq->free_cq);
drivers/infiniband/hw/irdma/verbs.c: * __irdma_poll_cq - poll cq for completion (kernel apps)
drivers/infiniband/hw/irdma/verbs.c: * irdma_poll_cq - poll cq for completion (kernel apps)
drivers/infiniband/hw/irdma/verbs.h:	struct completion free_cq;
drivers/infiniband/hw/irdma/verbs.h:	struct completion free_qp;
drivers/infiniband/hw/irdma/verbs.h:void irdma_generate_flush_completions(struct irdma_qp *iwqp);
drivers/infiniband/hw/mana/mana_ib.h:	struct completion	free;
drivers/infiniband/hw/mana/qp.c:	init_completion(&qp->free);
drivers/infiniband/hw/mana/qp.c:	wait_for_completion(&qp->free);
drivers/infiniband/hw/mlx4/alias_GUID.c:	struct completion	done;
drivers/infiniband/hw/mlx4/alias_GUID.c:	init_completion(&callback_context->done);
drivers/infiniband/hw/mlx4/alias_GUID.c:			wait_for_completion(&cb_ctx->done);
drivers/infiniband/hw/mlx4/cq.c:#define CQ_CREATE_FLAGS_SUPPORTED IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION
drivers/infiniband/hw/mlx4/cq.c:			       IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION),
drivers/infiniband/hw/mlx4/cq.c:	 * simulated FLUSH_ERR completions
drivers/infiniband/hw/mlx4/mad.c:			pr_debug("mlx4_ib: completion error in tunnel: %d."
drivers/infiniband/hw/mlx4/mad.c: * IB MAD completion callback for real SQPs
drivers/infiniband/hw/mlx4/mad.c:			pr_debug("mlx4_ib: completion error in tunnel: %d."
drivers/infiniband/hw/mlx4/qp.c:	struct completion done;
drivers/infiniband/hw/mlx4/qp.c:static void handle_drain_completion(struct ib_cq *cq,
drivers/infiniband/hw/mlx4/qp.c:		while (wait_for_completion_timeout(&sdrain->done, HZ / 10) <= 0)
drivers/infiniband/hw/mlx4/qp.c:	wait_for_completion(&sdrain->done);
drivers/infiniband/hw/mlx4/qp.c:	init_completion(&sdrain.done);
drivers/infiniband/hw/mlx4/qp.c:	handle_drain_completion(cq, &sdrain, dev);
drivers/infiniband/hw/mlx4/qp.c:	init_completion(&rdrain.done);
drivers/infiniband/hw/mlx4/qp.c:	handle_drain_completion(cq, &rdrain, dev);
drivers/infiniband/hw/mlx5/cq.c:		pr_warn("unknown completion status\n");
drivers/infiniband/hw/mlx5/cq.c:		pr_err("Got signature completion error with bad syndrome %04x\n",
drivers/infiniband/hw/mlx5/cq.c:		mlx5_ib_dbg(dev, "polled software generated completion on CQ 0x%x\n",
drivers/infiniband/hw/mlx5/devx.c:			/* CQ completion */
drivers/infiniband/hw/mlx5/gsi.c:static void generate_completions(struct mlx5_ib_qp *mqp)
drivers/infiniband/hw/mlx5/gsi.c:static void handle_single_completion(struct ib_cq *cq, struct ib_wc *wc)
drivers/infiniband/hw/mlx5/gsi.c:	generate_completions(mqp);
drivers/infiniband/hw/mlx5/gsi.c:	gsi_wr->cqe.done = &handle_single_completion;
drivers/infiniband/hw/mlx5/gsi.c:	generate_completions(mqp);
drivers/infiniband/hw/mlx5/main.c:		init_completion(&mpi->unref_comp);
drivers/infiniband/hw/mlx5/main.c:			wait_for_completion(&mpi->unref_comp);
drivers/infiniband/hw/mlx5/mlx5_ib.h:	struct completion	done;
drivers/infiniband/hw/mlx5/mlx5_ib.h:	struct completion unref_comp;
drivers/infiniband/hw/mlx5/mlx5_ib.h:			  IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION));
drivers/infiniband/hw/mlx5/mlx5_ib.h: * 101       X   0  fails (completion is routed to root but root didn't see req)
drivers/infiniband/hw/mlx5/mlx5_ib.h: * 111       1   0  fails (completion is routed to root but root didn't see req)
drivers/infiniband/hw/mlx5/qp.c:	if (cq->create_flags & IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION) {
drivers/infiniband/hw/mlx5/qp.c:	struct completion done;
drivers/infiniband/hw/mlx5/qp.c:static void handle_drain_completion(struct ib_cq *cq,
drivers/infiniband/hw/mlx5/qp.c:		while (wait_for_completion_timeout(&sdrain->done, HZ / 10) <= 0)
drivers/infiniband/hw/mlx5/qp.c:	wait_for_completion(&sdrain->done);
drivers/infiniband/hw/mlx5/qp.c:	init_completion(&sdrain.done);
drivers/infiniband/hw/mlx5/qp.c:	handle_drain_completion(cq, &sdrain, dev);
drivers/infiniband/hw/mlx5/qp.c:	init_completion(&rdrain.done);
drivers/infiniband/hw/mlx5/qp.c:	handle_drain_completion(cq, &rdrain, dev);
drivers/infiniband/hw/mlx5/qpc.c:	init_completion(&qp->common.free);
drivers/infiniband/hw/mlx5/qpc.c:	wait_for_completion(&qp->common.free);
drivers/infiniband/hw/mlx5/qpc.c:	init_completion(&dct->drained);
drivers/infiniband/hw/mlx5/qpc.c:	wait_for_completion(&dct->drained);
drivers/infiniband/hw/mlx5/srq_cmd.c:	init_completion(&srq->common.free);
drivers/infiniband/hw/mlx5/srq_cmd.c:	wait_for_completion(&srq->common.free);
drivers/infiniband/hw/mlx5/umr.c:	init_completion(&context->done);
drivers/infiniband/hw/mlx5/umr.c:		wait_for_completion(&umr_context.done);
drivers/infiniband/hw/mlx5/umr.h:	struct completion done;
drivers/infiniband/hw/mthca/mthca_cmd.c:#include <linux/completion.h>
drivers/infiniband/hw/mthca/mthca_cmd.c:	struct completion done;
drivers/infiniband/hw/mthca/mthca_cmd.c:	init_completion(&context->done);
drivers/infiniband/hw/mthca/mthca_cmd.c:	if (!wait_for_completion_timeout(&context->done, timeout)) {
drivers/infiniband/hw/mthca/mthca_cq.c:void mthca_cq_completion(struct mthca_dev *dev, u32 cqn)
drivers/infiniband/hw/mthca/mthca_cq.c:		mthca_warn(dev, "Completion event for bogus CQ %08x\n", cqn);
drivers/infiniband/hw/mthca/mthca_cq.c:	 * For completions in error, only work request ID, status, vendor error
drivers/infiniband/hw/mthca/mthca_cq.c:		 * WQE addr == base - 1 might be reported in receive completion
drivers/infiniband/hw/mthca/mthca_dev.h:void mthca_cq_completion(struct mthca_dev *dev, u32 cqn);
drivers/infiniband/hw/mthca/mthca_eq.c:			mthca_cq_completion(dev, disarm_cqn);
drivers/infiniband/hw/mthca/mthca_main.c:			  "completion queue table, aborting.\n");
drivers/infiniband/hw/mthca/mthca_provider.h: * completion being polled does not need a reference either.
drivers/infiniband/hw/mthca/mthca_provider.h: * Access because of a completion event should go as follows:
drivers/infiniband/hw/ocrdma/ocrdma.h:	/* syncronizes cq completion handler invoked from multiple context */
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:	/* Alloc completion queue for Mailbox queue */
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:		/* if completion came on sq, rq's cq is buddy cq.
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:		 * if completion came on rq, sq's cq is buddy cq.
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:	/* if there is valid buddy cq, look for its completion handler */
drivers/infiniband/hw/ocrdma/ocrdma_sli.h:	OCRDMA_MAJOR_CODE_COMPLETION    = 0x00,
drivers/infiniband/hw/qedr/main.c:		 * here, only after the completion handler, to ensure that
drivers/infiniband/hw/qedr/qedr.h:#include <linux/completion.h>
drivers/infiniband/hw/qedr/qedr.h:	struct completion iwarp_cm_comp;
drivers/infiniband/hw/qedr/qedr.h:	struct completion qp_rel_comp;
drivers/infiniband/hw/qedr/qedr_hsi_rdma.h:/* rdma completion notification queue element */
drivers/infiniband/hw/qedr/qedr_hsi_rdma.h:/* rdma completion queue element */
drivers/infiniband/hw/qedr/qedr_roce_cm.c:			 * for completion
drivers/infiniband/hw/qedr/verbs.c:	 * in case all the completions are handled in that span. Otherwise
drivers/infiniband/hw/qedr/verbs.c:	 * completion of the event handler because it is invoked from the EQ.
drivers/infiniband/hw/qedr/verbs.c:		init_completion(&qp->iwarp_cm_comp);
drivers/infiniband/hw/qedr/verbs.c:		init_completion(&qp->qp_rel_comp);
drivers/infiniband/hw/qedr/verbs.c:			wait_for_completion(&qp->iwarp_cm_comp);
drivers/infiniband/hw/qedr/verbs.c:		 * complete before continuing. We can use the same completion,
drivers/infiniband/hw/qedr/verbs.c:		 * this completion and it is sequential. In addition,
drivers/infiniband/hw/qedr/verbs.c:		 * means WAIT_FOR_CONNECT is also on and the completion for
drivers/infiniband/hw/qedr/verbs.c:			wait_for_completion(&qp->iwarp_cm_comp);
drivers/infiniband/hw/qedr/verbs.c:		wait_for_completion(&qp->qp_rel_comp);
drivers/infiniband/hw/qedr/verbs.c:	 * soon as we give the doorbell, we could get a completion
drivers/infiniband/hw/qedr/verbs.c:		 * soon as we give the doorbell, we could get a completion
drivers/infiniband/hw/qib/qib.h:#include <linux/completion.h>
drivers/infiniband/hw/qib/qib.h:	struct completion    comp;
drivers/infiniband/hw/qib/qib_common.h:#define QIB_CMD_SDMA_COMPLETE   32      /* sdma completion counter request */
drivers/infiniband/hw/qib/qib_common.h:		 * completion counter
drivers/infiniband/hw/qib/qib_iba6120.c:			  "PCIe completion timeout"),
drivers/infiniband/hw/qib/qib_iba7220.c:			  "PCIe completion timeout"),
drivers/infiniband/hw/qib/qib_mad.c: * @in_wc: the work completion entry for this packet
drivers/infiniband/hw/qib/qib_pcie.c: * Enable PCIe completion and data coalescing, on Intel 5x00 and 7300
drivers/infiniband/hw/qib/qib_rc.c:		} else /* XXX need to handle delayed completion */
drivers/infiniband/hw/qib/qib_rc.c: * Generate a SWQE completion.
drivers/infiniband/hw/qib/qib_rc.c:static struct rvt_swqe *do_rc_completion(struct rvt_qp *qp,
drivers/infiniband/hw/qib/qib_rc.c:	 * completion if the SWQE is being resent until the send
drivers/infiniband/hw/qib/qib_rc.c:		 * we want to generate completion events for everything
drivers/infiniband/hw/qib/qib_rc.c:		 * the completion for the read.
drivers/infiniband/hw/qib/qib_rc.c:		wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/qib/qib_rc.c:		wqe = do_rc_completion(qp, wqe, ibp);
drivers/infiniband/hw/qib/qib_rc.c:		/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/qib/qib_sdma.c:	wait_for_completion(&ss->comp);
drivers/infiniband/hw/qib/qib_sdma.c:	init_completion(&ppd->sdma_state.comp);
drivers/infiniband/hw/qib/qib_uc.c:		/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/qib/qib_ud.c:	/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/qib/qib_ud.c:			 * a completion for the loopback packet since
drivers/infiniband/hw/qib/qib_ud.c:	/* Signal completion event if the solicited bit is set. */
drivers/infiniband/hw/qib/qib_verbs.c:		 "Maximum number of completion queue entries to support");
drivers/infiniband/hw/qib/qib_verbs.c:MODULE_PARM_DESC(max_cqs, "Maximum number of completion queues to support");
drivers/infiniband/hw/qib/qib_verbs.h:#include <linux/completion.h>
drivers/infiniband/hw/vmw_pvrdma/pvrdma.h:	struct completion free;
drivers/infiniband/hw/vmw_pvrdma/pvrdma.h:	struct completion free;
drivers/infiniband/hw/vmw_pvrdma/pvrdma.h:	struct completion free;
drivers/infiniband/hw/vmw_pvrdma/pvrdma.h:	struct completion cmd_done;
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cmd.c:	err = wait_for_completion_interruptible_timeout(&dev->cmd_done,
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cmd.c:			 "completion timeout or interrupted\n");
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cmd.c:	init_completion(&dev->cmd_done);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * pvrdma_req_notify_cq - request notification for a completion queue
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @ibcq: the completion queue
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * pvrdma_create_cq - create completion queue
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @attr: completion queue attributes
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c:			 "overflow pages in completion queue\n");
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c:	init_completion(&cq->free);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c:			 "could not create completion queue, error: %d\n", ret);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c:	wait_for_completion(&cq->free);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * pvrdma_destroy_cq - destroy completion queue
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @cq: the completion queue to destroy.
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c:			 "could not destroy completion queue, error: %d\n",
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * pvrdma_poll_cq - poll for work completion queue entries
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @ibcq: completion queue
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @wc: pointer to work completion array
drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c: * @return: number of polled completion entries
drivers/infiniband/hw/vmw_pvrdma/pvrdma_main.c:	dev_dbg(&dev->pdev->dev, "interrupt x (completion) handler\n");
drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c:		init_completion(&qp->free);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c:	wait_for_completion(&qp->free);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c:	 * the CQEs so there should be no other completions for this QP.
drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c:	init_completion(&srq->free);
drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c:	wait_for_completion(&srq->free);
drivers/infiniband/sw/rdmavt/cq.c: * rvt_cq_enter - add a new entry to the completion queue
drivers/infiniband/sw/rdmavt/cq.c: * @cq: completion queue
drivers/infiniband/sw/rdmavt/cq.c: * @entry: work completion entry to add
drivers/infiniband/sw/rdmavt/cq.c:	 * The completion handler will most likely rearm the notification
drivers/infiniband/sw/rdmavt/cq.c:	 * and poll for all pending entries.  If a new completion entry
drivers/infiniband/sw/rdmavt/cq.c: * rvt_create_cq - create a completion queue
drivers/infiniband/sw/rdmavt/cq.c:	 * Allocate the completion queue entries and head/tail pointers.
drivers/infiniband/sw/rdmavt/cq.c: * rvt_destroy_cq - destroy a completion queue
drivers/infiniband/sw/rdmavt/cq.c: * @ibcq: the completion queue to destroy.
drivers/infiniband/sw/rdmavt/cq.c: * rvt_req_notify_cq - change the notification type for a completion queue
drivers/infiniband/sw/rdmavt/cq.c: * @ibcq: the completion queue
drivers/infiniband/sw/rdmavt/cq.c: * @ibcq: the completion queue
drivers/infiniband/sw/rdmavt/cq.c: * rvt_poll_cq - poll for work completion entries
drivers/infiniband/sw/rdmavt/cq.c: * @ibcq: the completion queue to poll
drivers/infiniband/sw/rdmavt/cq.c: * @entry: pointer to array where work completions are placed
drivers/infiniband/sw/rdmavt/cq.c: * Return: the number of completion entries polled.
drivers/infiniband/sw/rdmavt/cq.c:	/* The kernel can only poll a kernel completion queue */
drivers/infiniband/sw/rdmavt/mad.c: * @in_wc: the work completion entry for this packet
drivers/infiniband/sw/rdmavt/mr.c:	init_completion(&mr->comp);
drivers/infiniband/sw/rdmavt/mr.c:	timeout = wait_for_completion_timeout(&mr->comp, 5 * HZ);
drivers/infiniband/sw/rdmavt/mr.c:	rvt_put_mr(&mr->mr); /* will set completion if last */
drivers/infiniband/sw/rdmavt/qp.c: * completions as per IB 1.2 C10-96.
drivers/infiniband/sw/rdmavt/qp.c: * @err: the receive completion error to signal if a RWQE is active
drivers/infiniband/sw/rdmavt/qp.c:	 * need to have requests with "completion only" flags set posted
drivers/infiniband/sw/rdmavt/qp.c:	 * to the send queue in order to generate completions.
drivers/infiniband/sw/rdmavt/qp.c:			wqe->wr.send_flags |= RVT_SEND_COMPLETION_ONLY;
drivers/infiniband/sw/rdmavt/qp.c:	/* Signal solicited completion event. */
drivers/infiniband/sw/rdmavt/qp.c:	 * completion is generated.
drivers/infiniband/sw/rdmavt/qp.c:	trace_rvt_qp_send_completion(qp, wqe, old_last);
drivers/infiniband/sw/rdmavt/qp.c:		if (!(wqe->wr.send_flags & RVT_SEND_COMPLETION_ONLY)) {
drivers/infiniband/sw/rdmavt/qp.c:	/* Signal completion event if the solicited bit is set. */
drivers/infiniband/sw/rdmavt/trace_tx.h:	rvt_qp_send_completion,
drivers/infiniband/sw/rdmavt/vt.c:	/* Completion queues */
drivers/infiniband/sw/rxe/rxe_comp.c: * IBA Spec. Section 10.7.3.1 SIGNALED COMPLETIONS
drivers/infiniband/sw/rxe/rxe_comp.c: * ...Note that if a completion error occurs, a Work Completion
drivers/infiniband/sw/rxe/rxe_comp.c: * indicator requests an Unsignaled Completion.
drivers/infiniband/sw/rxe/rxe_comp.c:	/* do we need to post a completion */
drivers/infiniband/sw/rxe/rxe_pool.c:	init_completion(&elem->complete);
drivers/infiniband/sw/rxe/rxe_pool.c:		if (!completion_done(&elem->complete) && timeout) {
drivers/infiniband/sw/rxe/rxe_pool.c:			ret = wait_for_completion_timeout(&elem->complete,
drivers/infiniband/sw/rxe/rxe_pool.c:		 * replaces the wait_for_completion call above
drivers/infiniband/sw/rxe/rxe_pool.c:		while (!completion_done(&elem->complete) &&
drivers/infiniband/sw/rxe/rxe_pool.c:		if (WARN_ON(!completion_done(&elem->complete)))
drivers/infiniband/sw/rxe/rxe_pool.h:	struct completion	complete;
drivers/infiniband/sw/rxe/rxe_req.c:	/* update wqe_index for each wqe completion */
drivers/infiniband/sw/siw/siw.h:	struct completion qp_free;
drivers/infiniband/sw/siw/siw_qp.c: * Check if current CQ state qualifies for calling CQ completion
drivers/infiniband/sw/siw/siw_qp.c:	if ((cq_notify & SIW_NOTIFY_NEXT_COMPLETION) ||
drivers/infiniband/sw/siw/siw_qp.c:				siw_dbg_cq(cq, "Call completion handler\n");
drivers/infiniband/sw/siw/siw_qp.c:				siw_dbg_cq(cq, "Call completion handler\n");
drivers/infiniband/sw/siw/siw_qp.c:			 * completion fails?
drivers/infiniband/sw/siw/siw_qp_rx.c: *   o SENDs + RRESPs will need for completion,
drivers/infiniband/sw/siw/siw_qp_rx.c:		int run_completion = 1;
drivers/infiniband/sw/siw/siw_qp_rx.c:					run_completion = 0;
drivers/infiniband/sw/siw/siw_qp_rx.c:				run_completion = 0;
drivers/infiniband/sw/siw/siw_qp_rx.c:			run_completion = 0;
drivers/infiniband/sw/siw/siw_qp_rx.c:			     qp->rx_fpdu->more_ddp_segs) && run_completion)
drivers/infiniband/sw/siw/siw_qp_tx.c:	 * until the work completed. In iWarp, work completion is only
drivers/infiniband/sw/siw/siw_qp_tx.c:		 * o TODO: Implement more precise work completion errors,
drivers/infiniband/sw/siw/siw_verbs.c:	init_completion(&qp->qp_free);
drivers/infiniband/sw/siw/siw_verbs.c:	wait_for_completion(&qp->qp_free);
drivers/infiniband/sw/siw/siw_verbs.c: * Reap CQ entries if available and copy work completion status into
drivers/infiniband/sw/siw/siw_verbs.c: * @wc:		Array of work completions to be filled by siw.
drivers/infiniband/sw/siw/siw_verbs.c:		 * Enable CQ event for next solicited completion.
drivers/infiniband/sw/siw/siw_verbs.c:		 * Enable CQ event for any signalled completion.
drivers/infiniband/ulp/ipoib/ipoib.h:	struct completion done;
drivers/infiniband/ulp/ipoib/ipoib.h: * We use the second option and wait for a completion on the
drivers/infiniband/ulp/ipoib/ipoib.h:	struct completion		flushed;
drivers/infiniband/ulp/ipoib/ipoib.h:	struct completion		deleted;
drivers/infiniband/ulp/ipoib/ipoib.h:	struct completion     done;
drivers/infiniband/ulp/ipoib/ipoib.h:void ipoib_ib_rx_completion(struct ib_cq *cq, void *ctx_ptr);
drivers/infiniband/ulp/ipoib/ipoib.h:void ipoib_ib_tx_completion(struct ib_cq *cq, void *ctx_ptr);
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	 * Current Mellanox HCA firmware won't generate completions
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	ipoib_dbg_data(priv, "cm recv completion: id %d, status: %d\n",
drivers/infiniband/ulp/ipoib/ipoib_cm.c:			ipoib_warn(priv, "cm recv completion event with wrid %d (> %d)\n",
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	 * because it's entirely possible that the completion handler will
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	ipoib_dbg_data(priv, "cm send completion: id %d, status: %d\n",
drivers/infiniband/ulp/ipoib/ipoib_cm.c:		ipoib_warn(priv, "cm send completion event with wrid %d (> %d)\n",
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	ipoib_dbg_data(priv, "recv completion: id %d, status: %d\n",
drivers/infiniband/ulp/ipoib/ipoib_ib.c:		ipoib_warn(priv, "recv completion event with wrid %d (> %d)\n",
drivers/infiniband/ulp/ipoib/ipoib_ib.c: * As the result of a completion error the QP Can be transferred to SQE states.
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	ipoib_dbg_data(priv, "send completion: id %d, status: %d\n",
drivers/infiniband/ulp/ipoib/ipoib_ib.c:		ipoib_warn(priv, "send completion event with wrid %d (> %d)\n",
drivers/infiniband/ulp/ipoib/ipoib_ib.c:void ipoib_ib_rx_completion(struct ib_cq *cq, void *ctx_ptr)
drivers/infiniband/ulp/ipoib/ipoib_ib.c:void ipoib_ib_tx_completion(struct ib_cq *cq, void *ctx_ptr)
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	 * because it's entirely possible that the completion handler will
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	 * We call completion handling routines that expect to be
drivers/infiniband/ulp/ipoib/ipoib_ib.c:			 * Convert any successful completions to flush
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	 * We must make sure there are no more (path) completions
drivers/infiniband/ulp/ipoib/ipoib_main.c:		wait_for_completion(&path->done);
drivers/infiniband/ulp/ipoib/ipoib_main.c:static void path_rec_completion(int status,
drivers/infiniband/ulp/ipoib/ipoib_main.c:	init_completion(&path->done);
drivers/infiniband/ulp/ipoib/ipoib_main.c:				   path_rec_completion,
drivers/infiniband/ulp/ipoib/ipoib_main.c:	init_completion(&priv->ntbl.flushed);
drivers/infiniband/ulp/ipoib/ipoib_main.c:		wait_for_completion(&priv->ntbl.flushed);
drivers/infiniband/ulp/ipoib/ipoib_main.c:	init_completion(&priv->ntbl.deleted);
drivers/infiniband/ulp/ipoib/ipoib_main.c:	wait_for_completion(&priv->ntbl.deleted);
drivers/infiniband/ulp/ipoib/ipoib_multicast.c:#include <linux/completion.h>
drivers/infiniband/ulp/ipoib/ipoib_multicast.c:	ipoib_dbg_mcast(priv, "%sjoin completion for %pI6 (status %d)\n",
drivers/infiniband/ulp/ipoib/ipoib_multicast.c:	init_completion(&mcast->done);
drivers/infiniband/ulp/ipoib/ipoib_multicast.c:			wait_for_completion(&mcast->done);
drivers/infiniband/ulp/ipoib/ipoib_verbs.c:	priv->recv_cq = ib_create_cq(priv->ca, ipoib_ib_rx_completion, NULL,
drivers/infiniband/ulp/ipoib/ipoib_verbs.c:	priv->send_cq = ib_create_cq(priv->ca, ipoib_ib_tx_completion, NULL,
drivers/infiniband/ulp/iser/iscsi_iser.c: * iscsi_iser_recv() - Process a successful recv completion
drivers/infiniband/ulp/iser/iscsi_iser.c: * Notes: In case of data length errors or iscsi PDU completion failures
drivers/infiniband/ulp/iser/iscsi_iser.c:	 * - if no,  the task is recycled at iser_snd_completion
drivers/infiniband/ulp/iser/iscsi_iser.c: * Notes: Here iser intialize (or re-initialize) stop_completion as
drivers/infiniband/ulp/iser/iscsi_iser.c:	reinit_completion(&iser_conn->stop_completion);
drivers/infiniband/ulp/iser/iscsi_iser.c:		complete(&iser_conn->stop_completion);
drivers/infiniband/ulp/iser/iscsi_iser.c: * This routine boils down to waiting for up_completion signaling
drivers/infiniband/ulp/iser/iscsi_iser.c:	rc = wait_for_completion_interruptible_timeout(&iser_conn->up_completion,
drivers/infiniband/ulp/iser/iscsi_iser.c: * completion as we queue a deffered work for iser/RDMA destruction
drivers/infiniband/ulp/iser/iscsi_iser.c:	 * iscsi_conn_stop and flush errors completion before freeing
drivers/infiniband/ulp/iser/iscsi_iser.h: * to have at max for SCSI command. The tx posting & completion handling code  *
drivers/infiniband/ulp/iser/iscsi_iser.h: * @cqe:           completion handler
drivers/infiniband/ulp/iser/iscsi_iser.h: * @cqe:           completion handler
drivers/infiniband/ulp/iser/iscsi_iser.h: * @cqe:           completion handler
drivers/infiniband/ulp/iser/iscsi_iser.h: * @cq:                  Connection completion queue
drivers/infiniband/ulp/iser/iscsi_iser.h: * @cq_size:             The number of max outstanding completions
drivers/infiniband/ulp/iser/iscsi_iser.h: * @reg_cqe:             completion handler
drivers/infiniband/ulp/iser/iscsi_iser.h: * @stop_completion:  conn_stop completion
drivers/infiniband/ulp/iser/iscsi_iser.h: * @ib_completion:    RDMA cleanup completion
drivers/infiniband/ulp/iser/iscsi_iser.h: * @up_completion:    connection establishment completed
drivers/infiniband/ulp/iser/iscsi_iser.h:	struct completion	     stop_completion;
drivers/infiniband/ulp/iser/iscsi_iser.h:	struct completion	     ib_completion;
drivers/infiniband/ulp/iser/iscsi_iser.h:	struct completion	     up_completion;
drivers/infiniband/ulp/iser/iser_verbs.c: * iser_create_device_ib_res - creates Protection Domain (PD), Completion
drivers/infiniband/ulp/iser/iser_verbs.c:	wait_for_completion(&iser_conn->stop_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	wait_for_completion(&iser_conn->ib_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	complete(&iser_conn->up_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	complete(&iser_conn->ib_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	init_completion(&iser_conn->stop_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	init_completion(&iser_conn->ib_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:	init_completion(&iser_conn->up_completion);
drivers/infiniband/ulp/iser/iser_verbs.c:		wait_for_completion_interruptible(&iser_conn->up_completion);
drivers/infiniband/ulp/isert/ib_isert.c:	init_completion(&isert_conn->login_comp);
drivers/infiniband/ulp/isert/ib_isert.c:	init_completion(&isert_conn->login_req_comp);
drivers/infiniband/ulp/isert/ib_isert.c:isert_completion_put(struct iser_tx_desc *tx_desc, struct isert_cmd *isert_cmd,
drivers/infiniband/ulp/isert/ib_isert.c:		isert_completion_put(desc, isert_cmd, device->ib_device, true);
drivers/infiniband/ulp/isert/ib_isert.c:		isert_completion_put(desc, isert_cmd, device->ib_device, true);
drivers/infiniband/ulp/isert/ib_isert.c:		isert_completion_put(&isert_cmd->tx_desc, isert_cmd,
drivers/infiniband/ulp/isert/ib_isert.c:		isert_completion_put(tx_desc, isert_cmd, ib_dev, true);
drivers/infiniband/ulp/isert/ib_isert.c:		isert_completion_put(tx_desc, isert_cmd, ib_dev, false);
drivers/infiniband/ulp/isert/ib_isert.c:	ret = wait_for_completion_interruptible(&isert_conn->login_req_comp);
drivers/infiniband/ulp/isert/ib_isert.c:	reinit_completion(&isert_conn->login_req_comp);
drivers/infiniband/ulp/isert/ib_isert.c:	ret = wait_for_completion_interruptible(&isert_conn->login_comp);
drivers/infiniband/ulp/isert/ib_isert.c:		wait_for_completion_timeout(&conn->conn_logout_comp,
drivers/infiniband/ulp/isert/ib_isert.c:	struct completion comp;
drivers/infiniband/ulp/isert/ib_isert.c:	init_completion(&comp);
drivers/infiniband/ulp/isert/ib_isert.c:	wait_for_completion_interruptible(&comp);
drivers/infiniband/ulp/isert/ib_isert.h:	struct completion	login_comp;
drivers/infiniband/ulp/isert/ib_isert.h:	struct completion	login_req_comp;
drivers/infiniband/ulp/opa_vnic/opa_vnic_vema.c: * @mad_wc:    pointer to mad send work completion information
drivers/infiniband/ulp/opa_vnic/opa_vnic_vema.c: * @mad_wc:    pointer to mad send work completion information
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				wait_for_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		 * post_recv() RDMA write completions of IO reqs (read/write)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		 * post_send() RDMA write completions of IO reqs (read/write)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	reinit_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		 * After completion this request is still useble and can
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		init_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		 * Two (request + registration) completion for send
drivers/infiniband/ulp/rtrs/rtrs-clt.h:	struct completion	inv_comp;
drivers/infiniband/ulp/rtrs/rtrs-srv.c:	init_completion(&srv_path->complete_done);
drivers/infiniband/ulp/rtrs/rtrs-srv.c:		 * post_recv() RDMA write completions of IO reqs (read/write)
drivers/infiniband/ulp/rtrs/rtrs-srv.c:		 * post_send() RDMA write completions of IO reqs (read/write)
drivers/infiniband/ulp/rtrs/rtrs-srv.c:	/* Wait for all completion */
drivers/infiniband/ulp/rtrs/rtrs-srv.c:	wait_for_completion(&srv_path->complete_done);
drivers/infiniband/ulp/rtrs/rtrs-srv.h:	struct completion       complete_done;
drivers/infiniband/ulp/rtrs/rtrs.c:		rtrs_err(con->path, "Creating completion queue failed, errno: %pe\n",
drivers/infiniband/ulp/srp/ib_srp.c:		 "Number of RDMA channels to use for communication with an SRP target. Using more than one channel improves performance if the HCA supports multiple completion vectors. The default value is the minimum of four times the number of online CPU sockets and the number of completion vectors supported by the HCA.");
drivers/infiniband/ulp/srp/ib_srp.c:	init_completion(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:	ret = wait_for_completion_interruptible(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c: * completion handler can access the queue pair while it is
drivers/infiniband/ulp/srp/ib_srp.c:static void srp_path_rec_completion(int status,
drivers/infiniband/ulp/srp/ib_srp.c:	init_completion(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:					       srp_path_rec_completion,
drivers/infiniband/ulp/srp/ib_srp.c:	ret = wait_for_completion_interruptible(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:	init_completion(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:	wait_for_completion_interruptible(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:		init_completion(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:		ret = wait_for_completion_interruptible(&ch->done);
drivers/infiniband/ulp/srp/ib_srp.c:		 * QP. This guarantees that all completion callback function
drivers/infiniband/ulp/srp/ib_srp.c:			     PFX "recv completion, opcode 0x%02x\n", opcode);
drivers/infiniband/ulp/srp/ib_srp.c:	 * it can take before an error completion is generated. See also
drivers/infiniband/ulp/srp/ib_srp.c:	init_completion(&ch->tsk_mgmt_done);
drivers/infiniband/ulp/srp/ib_srp.c:	res = wait_for_completion_timeout(&ch->tsk_mgmt_done,
drivers/infiniband/ulp/srp/ib_srp.h: * @comp_vector: Completion vector used by this RDMA channel.
drivers/infiniband/ulp/srp/ib_srp.h:	struct completion	done;
drivers/infiniband/ulp/srp/ib_srp.h:	struct completion	tsk_mgmt_done;
drivers/infiniband/ulp/srp/ib_srp.h: * @comp_vector: Completion vector used by the first RDMA channel created for
drivers/infiniband/ulp/srpt/ib_srpt.c: * srpt_mad_send_handler - MAD send completion callback
drivers/infiniband/ulp/srpt/ib_srpt.c: * @mad_wc: Work completion reporting that the MAD has been sent.
drivers/infiniband/ulp/srpt/ib_srpt.c: * @mad_wc: Work completion reporting that a MAD has been received.
drivers/infiniband/ulp/srpt/ib_srpt.c:		/* will destroy_ah & free_send_mad in send completion */
drivers/infiniband/ulp/srpt/ib_srpt.c:		 * SRP_RSP sending failed or the SRP_RSP send completion has
drivers/infiniband/ulp/srpt/ib_srpt.c: * srpt_rdma_read_done - RDMA read completion callback
drivers/infiniband/ulp/srpt/ib_srpt.c: * @cq: Completion queue.
drivers/infiniband/ulp/srpt/ib_srpt.c: * @wc: Work completion.
drivers/infiniband/ulp/srpt/ib_srpt.c: * This function must be called from the context in which RDMA completions are
drivers/infiniband/ulp/srpt/ib_srpt.c: * srpt_send_done - send completion callback
drivers/infiniband/ulp/srpt/ib_srpt.c: * @cq: Completion queue.
drivers/infiniband/ulp/srpt/ib_srpt.c: * @wc: Work completion.
drivers/infiniband/ulp/srpt/ib_srpt.c: * makes the initiator send a new request before the send completion for that
drivers/infiniband/ulp/srpt/ib_srpt.c: * if IB retransmission causes generation of the send completion to be
drivers/infiniband/ulp/srpt/ib_srpt.c:		pr_err("IB completion has been received too late for wr_id = %u.\n",
drivers/infiniband/ulp/srpt/ib_srpt.c: * srpt_create_ch_ib - create receive and send completion queues
drivers/infiniband/ulp/srpt/ib_srpt.c:	 * completions, and half R/W contexts to actually do the RDMA
drivers/infiniband/ulp/srpt/ib_srpt.c:	 * both both, as RDMA contexts will also post completions for the
drivers/infiniband/ulp/srpt/ib_srpt.c:	DECLARE_COMPLETION_ONSTACK(closed);
drivers/infiniband/ulp/srpt/ib_srpt.c:	while (wait_for_completion_timeout(&closed, 5 * HZ) == 0)
drivers/infiniband/ulp/srpt/ib_srpt.c: * invoked on the context of the IB completion handler.
drivers/infiniband/ulp/srpt/ib_srpt.c:	DECLARE_COMPLETION_ONSTACK(c);
drivers/infiniband/ulp/srpt/ib_srpt.c:	       wait_for_completion_timeout(&c, 5 * HZ) <= 0) {
drivers/infiniband/ulp/srpt/ib_srpt.h: * @cqe:   Completion queue element.
drivers/infiniband/ulp/srpt/ib_srpt.h: * @rdma_cqe:    RDMA completion queue element.
drivers/infiniband/ulp/srpt/ib_srpt.h: * @CH_DISCONNECTED:  Last completion has been received.
drivers/infiniband/ulp/srpt/ib_srpt.h: * @cq:            IB completion queue for this channel.
drivers/infiniband/ulp/srpt/ib_srpt.h: * @closed:	   Completion object that will be signaled as soon as a new
drivers/infiniband/ulp/srpt/ib_srpt.h:	struct completion	*closed;
drivers/infiniband/ulp/srpt/ib_srpt.h: * @freed_channels: Completion that will be signaled once @refcount becomes 0.
drivers/infiniband/ulp/srpt/ib_srpt.h:	struct completion	*freed_channels;
drivers/input/joystick/iforce/iforce-serio.c:		/* Handle command completion */
drivers/input/joystick/iforce/iforce-usb.c:	 * As long as the urb completion handler is not called, the transmiting
drivers/input/keyboard/hil_kbd.c:#include <linux/completion.h>
drivers/input/keyboard/hil_kbd.c:	struct completion cmd_done;
drivers/input/keyboard/hil_kbd.c:	init_completion(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	error = wait_for_completion_killable(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	reinit_completion(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	error = wait_for_completion_killable(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	reinit_completion(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	error = wait_for_completion_killable(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	reinit_completion(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:	error = wait_for_completion_killable(&dev->cmd_done);
drivers/input/keyboard/hil_kbd.c:		/* No need to wait for completion */
drivers/input/misc/cm109.c:		/* URB completion will resubmit */
drivers/input/misc/ims-pcu.c:#include <linux/completion.h>
drivers/input/misc/ims-pcu.c:	struct completion cmd_done;
drivers/input/misc/ims-pcu.c:	struct completion async_firmware_done;
drivers/input/misc/ims-pcu.c:		 * See if we got command completion.
drivers/input/misc/ims-pcu.c:		 * the data and signal completion.
drivers/input/misc/ims-pcu.c:	init_completion(&pcu->cmd_done);
drivers/input/misc/ims-pcu.c:	    !wait_for_completion_timeout(&pcu->cmd_done,
drivers/input/misc/ims-pcu.c:	wait_for_completion(&pcu->async_firmware_done);
drivers/input/misc/ims-pcu.c:	init_completion(&pcu->cmd_done);
drivers/input/misc/ims-pcu.c:	init_completion(&pcu->async_firmware_done);
drivers/input/misc/iqs269a.c:#include <linux/completion.h>
drivers/input/misc/iqs269a.c:	struct completion ati_done;
drivers/input/misc/iqs269a.c:	 * The following completion signals that ATI has finished, any initial
drivers/input/misc/iqs269a.c:	if (!completion_done(&iqs269->ati_done))
drivers/input/misc/iqs269a.c:			  completion_done(&iqs269->ati_done));
drivers/input/misc/iqs269a.c:	reinit_completion(&iqs269->ati_done);
drivers/input/misc/iqs269a.c:	if (!wait_for_completion_timeout(&iqs269->ati_done,
drivers/input/misc/iqs269a.c:	init_completion(&iqs269->ati_done);
drivers/input/misc/iqs269a.c:	if (!wait_for_completion_timeout(&iqs269->ati_done,
drivers/input/misc/iqs626a.c:#include <linux/completion.h>
drivers/input/misc/iqs626a.c:	struct completion ati_done;
drivers/input/misc/iqs626a.c:	 * The following completion signals that ATI has finished, any initial
drivers/input/misc/iqs626a.c:	init_completion(&iqs626->ati_done);
drivers/input/misc/iqs626a.c:	if (!wait_for_completion_timeout(&iqs626->ati_done,
drivers/input/misc/uinput.c:	struct completion	done;
drivers/input/misc/uinput.c:	init_completion(&request->done);
drivers/input/misc/uinput.c:	if (!wait_for_completion_timeout(&request->done, 30 * HZ)) {
drivers/input/mouse/cyapa.h:	struct completion cmd_ready;
drivers/input/mouse/cyapa_gen5.c:#include <linux/completion.h>
drivers/input/mouse/cyapa_gen5.c:	init_completion(&pip->cmd_ready);
drivers/input/mouse/cyapa_gen5.c:	/* Wait for interrupt to set ready completion */
drivers/input/mouse/cyapa_gen5.c:	init_completion(&pip->cmd_ready);
drivers/input/mouse/cyapa_gen5.c:	timeout = wait_for_completion_timeout(&pip->cmd_ready,
drivers/input/mouse/cyapa_gen6.c:#include <linux/completion.h>
drivers/input/mouse/elan_i2c.h:struct completion;
drivers/input/mouse/elan_i2c.h:				struct completion *reset_done);
drivers/input/mouse/elan_i2c_core.c:#include <linux/completion.h>
drivers/input/mouse/elan_i2c_core.c:	struct completion	fw_completion;
drivers/input/mouse/elan_i2c_core.c:	error = data->ops->finish_fw_update(client, &data->fw_completion);
drivers/input/mouse/elan_i2c_core.c:		complete(&data->fw_completion);
drivers/input/mouse/elan_i2c_core.c:	init_completion(&data->fw_completion);
drivers/input/mouse/elan_i2c_i2c.c:#include <linux/completion.h>
drivers/input/mouse/elan_i2c_i2c.c:				     struct completion *completion)
drivers/input/mouse/elan_i2c_i2c.c:	reinit_completion(completion);
drivers/input/mouse/elan_i2c_i2c.c:	} else if (!wait_for_completion_timeout(completion,
drivers/input/mouse/elan_i2c_smbus.c:				       struct completion *fw_completion)
drivers/input/rmi4/rmi_f34.c:	init_completion(&f34->v5.cmd_done);
drivers/input/rmi4/rmi_f34.c:	if (!wait_for_completion_timeout(&f34->v5.cmd_done,
drivers/input/rmi4/rmi_f34.c:	init_completion(&f34->v5.cmd_done);
drivers/input/rmi4/rmi_f34.h:	struct completion cmd_done;
drivers/input/rmi4/rmi_f34.h:	struct completion cmd_done;
drivers/input/rmi4/rmi_f34v7.c:	if (!wait_for_completion_timeout(&f34->v7.cmd_done, timeout)) {
drivers/input/rmi4/rmi_f34v7.c:	init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:	init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:		init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:		init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:	init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:	init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f34v7.c:	init_completion(&f34->v7.cmd_done);
drivers/input/rmi4/rmi_f54.c:	struct completion cmd_done;
drivers/input/rmi4/rmi_f54.c:	init_completion(&f54->cmd_done);
drivers/input/rmi4/rmi_f54.c:		if (!wait_for_completion_timeout(&f54->cmd_done,
drivers/input/serio/hyperv-keyboard.c:#include <linux/completion.h>
drivers/input/serio/hyperv-keyboard.c:	struct completion wait_event;
drivers/input/serio/hyperv-keyboard.c:	reinit_completion(&kbd_dev->wait_event);
drivers/input/serio/hyperv-keyboard.c:				 VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/input/serio/hyperv-keyboard.c:	if (!wait_for_completion_timeout(&kbd_dev->wait_event, 10 * HZ))
drivers/input/serio/hyperv-keyboard.c:	init_completion(&kbd_dev->wait_event);
drivers/input/serio/i8042.c:static struct completion i8042_aux_irq_delivered;
drivers/input/serio/i8042.c:	init_completion(&i8042_aux_irq_delivered);
drivers/input/serio/i8042.c:	if (wait_for_completion_timeout(&i8042_aux_irq_delivered,
drivers/input/serio/libps2.c: * completion.
drivers/input/serio/libps2.c: * the process waiting for completion of the command. Note that there is a
drivers/input/serio/ps2-gpio.c:#include <linux/completion.h>
drivers/input/serio/ps2-gpio.c:		struct completion complete;
drivers/input/serio/ps2-gpio.c:		if (!wait_for_completion_timeout(&drvdata->tx.complete,
drivers/input/serio/ps2-gpio.c:	init_completion(&drvdata->tx.complete);
drivers/input/serio/sa1111ps2.c: * Completion of ps2 write
drivers/input/tablet/wacom_serial4.c:#include <linux/completion.h>
drivers/input/tablet/wacom_serial4.c:	struct completion cmd_done;
drivers/input/tablet/wacom_serial4.c:	init_completion(&wacom->cmd_done);
drivers/input/tablet/wacom_serial4.c:	u = wait_for_completion_timeout(&wacom->cmd_done, HZ);
drivers/input/touchscreen/atmel_mxt_ts.c:#include <linux/completion.h>
drivers/input/touchscreen/atmel_mxt_ts.c:	struct completion bl_completion;
drivers/input/touchscreen/atmel_mxt_ts.c:	struct completion reset_completion;
drivers/input/touchscreen/atmel_mxt_ts.c:	struct completion crc_completion;
drivers/input/touchscreen/atmel_mxt_ts.c:static int mxt_wait_for_completion(struct mxt_data *data,
drivers/input/touchscreen/atmel_mxt_ts.c:				   struct completion *comp,
drivers/input/touchscreen/atmel_mxt_ts.c:	ret = wait_for_completion_interruptible_timeout(comp, timeout);
drivers/input/touchscreen/atmel_mxt_ts.c:		dev_err(dev, "Wait for completion timed out.\n");
drivers/input/touchscreen/atmel_mxt_ts.c:		ret = mxt_wait_for_completion(data, &data->bl_completion,
drivers/input/touchscreen/atmel_mxt_ts.c:	complete(&data->crc_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:		complete(&data->reset_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:		/* bootloader state transition completion */
drivers/input/touchscreen/atmel_mxt_ts.c:		complete(&data->bl_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	reinit_completion(&data->reset_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	ret = mxt_wait_for_completion(data, &data->reset_completion,
drivers/input/touchscreen/atmel_mxt_ts.c:	reinit_completion(&data->crc_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	mxt_wait_for_completion(data, &data->crc_completion, MXT_CRC_TIMEOUT);
drivers/input/touchscreen/atmel_mxt_ts.c:	reinit_completion(&data->bl_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	ret = mxt_wait_for_completion(data, &data->bl_completion,
drivers/input/touchscreen/atmel_mxt_ts.c:	mxt_wait_for_completion(data, &data->bl_completion, MXT_FW_RESET_TIME);
drivers/input/touchscreen/atmel_mxt_ts.c:	init_completion(&data->bl_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	init_completion(&data->reset_completion);
drivers/input/touchscreen/atmel_mxt_ts.c:	init_completion(&data->crc_completion);
drivers/input/touchscreen/bu21029_ts.c: * INTVL_TIME: waiting time between completion of conversion
drivers/input/touchscreen/cyttsp5.c:	struct completion cmd_done;
drivers/input/touchscreen/cyttsp5.c:	rc = wait_for_completion_interruptible_timeout(&ts->cmd_done,
drivers/input/touchscreen/cyttsp5.c:	rc = wait_for_completion_interruptible_timeout(&ts->cmd_done,
drivers/input/touchscreen/cyttsp5.c:	rc = wait_for_completion_interruptible_timeout(&ts->cmd_done,
drivers/input/touchscreen/cyttsp5.c:	rc = wait_for_completion_interruptible_timeout(&ts->cmd_done,
drivers/input/touchscreen/cyttsp5.c:	init_completion(&ts->cmd_done);
drivers/input/touchscreen/cyttsp_core.c:	/* wait for interrupt to set ready completion */
drivers/input/touchscreen/cyttsp_core.c:	reinit_completion(&ts->bl_ready);
drivers/input/touchscreen/cyttsp_core.c:	if (!wait_for_completion_timeout(&ts->bl_ready,
drivers/input/touchscreen/cyttsp_core.c:	init_completion(&ts->bl_ready);
drivers/input/touchscreen/cyttsp_core.h:	struct completion bl_ready;
drivers/input/touchscreen/elants_i2c.c:	struct completion cmd_done;
drivers/input/touchscreen/elants_i2c.c:	reinit_completion(&ts->cmd_done);
drivers/input/touchscreen/elants_i2c.c:	ret = wait_for_completion_interruptible_timeout(&ts->cmd_done,
drivers/input/touchscreen/elants_i2c.c:	init_completion(&ts->cmd_done);
drivers/input/touchscreen/elo.c:	struct completion cmd_done;
drivers/input/touchscreen/elo.c:	init_completion(&elo->cmd_done);
drivers/input/touchscreen/elo.c:	wait_for_completion_timeout(&elo->cmd_done, HZ);
drivers/input/touchscreen/elo.c:	init_completion(&elo->cmd_done);
drivers/input/touchscreen/exc3000.c:	struct completion wait_event;
drivers/input/touchscreen/exc3000.c:	reinit_completion(&data->wait_event);
drivers/input/touchscreen/exc3000.c:		time_left = wait_for_completion_timeout(&data->wait_event,
drivers/input/touchscreen/exc3000.c:	init_completion(&data->wait_event);
drivers/input/touchscreen/goodix.c:	init_completion(&ts->firmware_loading_complete);
drivers/input/touchscreen/goodix.c:		wait_for_completion(&ts->firmware_loading_complete);
drivers/input/touchscreen/goodix.c:		wait_for_completion(&ts->firmware_loading_complete);
drivers/input/touchscreen/goodix.h:	struct completion firmware_loading_complete;
drivers/input/touchscreen/imx6ul_tsc.c:#include <linux/completion.h>
drivers/input/touchscreen/imx6ul_tsc.c:	struct completion completion;
drivers/input/touchscreen/imx6ul_tsc.c:	reinit_completion(&tsc->completion);
drivers/input/touchscreen/imx6ul_tsc.c:	timeout = wait_for_completion_timeout
drivers/input/touchscreen/imx6ul_tsc.c:			(&tsc->completion, ADC_TIMEOUT);
drivers/input/touchscreen/imx6ul_tsc.c:		complete(&tsc->completion);
drivers/input/touchscreen/imx6ul_tsc.c:	init_completion(&tsc->completion);
drivers/input/touchscreen/stmfts.c:	struct completion cmd_done;
drivers/input/touchscreen/stmfts.c:	reinit_completion(&sdata->cmd_done);
drivers/input/touchscreen/stmfts.c:	if (!wait_for_completion_timeout(&sdata->cmd_done,
drivers/input/touchscreen/stmfts.c:	init_completion(&sdata->cmd_done);
drivers/input/touchscreen/sur40.c:#include <linux/completion.h>
drivers/input/touchscreen/wacom_w8001.c:	struct completion cmd_done;
drivers/input/touchscreen/wacom_w8001.c:	init_completion(&w8001->cmd_done);
drivers/input/touchscreen/wacom_w8001.c:		wait_for_completion_timeout(&w8001->cmd_done, HZ);
drivers/input/touchscreen/wacom_w8001.c:	init_completion(&w8001->cmd_done);
drivers/input/touchscreen/wm831x-ts.c:	/* Make sure the IRQ completion work is quiesced */
drivers/input/touchscreen/zforce_ts.c: * @command_done	completion to wait for the command result
drivers/input/touchscreen/zforce_ts.c:	struct completion	command_done;
drivers/input/touchscreen/zforce_ts.c:	if (wait_for_completion_timeout(&ts->command_done, WAIT_TIMEOUT) == 0)
drivers/input/touchscreen/zforce_ts.c:	init_completion(&ts->command_done);
drivers/input/touchscreen/zforce_ts.c:	if (wait_for_completion_timeout(&ts->command_done, WAIT_TIMEOUT) == 0)
drivers/interconnect/qcom/bcm-voter.c: * @tcs_wait: mask for which buckets require TCS completion
drivers/interconnect/qcom/bcm-voter.c:	 * Set the wait for completion flag on command that need to be completed
drivers/iommu/amd/amd_iommu_types.h:	/* if one, we need to send a completion wait command */
drivers/iommu/amd/amd_iommu_types.h:					     PPR completions */
drivers/iommu/amd/init.c:	 * Re-purpose Exclusion base/limit registers for Completion wait
drivers/iommu/amd/io_pgtable.c:		 * Flush domain TLB(s) and wait for completion. Any Device-Table
drivers/iommu/amd/iommu.c:		pr_alert("Completion-Wait loop timed out\n");
drivers/iommu/amd/iommu.c:static void build_completion_wait(struct iommu_cmd *cmd,
drivers/iommu/amd/iommu.c: * This function queues a completion wait command into the command
drivers/iommu/amd/iommu.c:static int iommu_completion_wait(struct amd_iommu *iommu)
drivers/iommu/amd/iommu.c:	build_completion_wait(&cmd, iommu, data);
drivers/iommu/amd/iommu.c:		 * We need to wait for completion of all commands.
drivers/iommu/amd/iommu.c:		iommu_completion_wait(amd_iommus[i]);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	/* Flush domain TLB(s) and wait for completion */
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/amd/iommu.c:	build_completion_wait(&cmd2, iommu, data);
drivers/iommu/amd/iommu.c:	iommu_completion_wait(iommu);
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c:	"Disable MSI-based polling for CMD_SYNC completion.");
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c:		 * ATC Invalidation Completion timeout. CONS is still pointing
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c: * SYNC completion and freeing up space in the queue before we think that it is
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c: * Wait until the SMMU signals a CMD_SYNC completion MSI.
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c: * - On completion of a CMD_SYNC, there is a control dependency.
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c: *   freeing an IOVA) after completion of the CMD_SYNC.
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c:		 * In order to determine completion of our CMD_SYNC, we must
drivers/iommu/arm/arm-smmu-v3/arm-smmu-v3.c:	 * ATS was enabled at the PCI device before completion of the TLBI.
drivers/iommu/intel/dmar.c:		pr_err("VT-d detected Invalidation Completion Error: SID %llx",
drivers/iommu/intel/dmar.c:		pr_info("Invalidation Completion Error (ICE) cleared\n");
drivers/iommu/intel/dmar.c: * can be part of the submission but it will not be polled for completion.
drivers/iommu/intel/dmar.c:		 * and waiting for completion on this cpu. This is to avoid
drivers/iommu/intel/iommu.c: * invalidation completion before posted writes initiated with translated address
drivers/iommu/intel/iommu.c: * the invalidation completion ordering.
drivers/iommu/intel/iommu.h:#define DMA_FSTS_ICE (1 << 5) /* Invalidation Completion Error */
drivers/iommu/intel/iommu.h:	struct completion prq_complete;
drivers/iommu/intel/iommu.h: * QI_OPT_WAIT_DRAIN - Wait for PRQ drain completion, spec 6.5.2.8.
drivers/iommu/intel/svm.c:	init_completion(&iommu->prq_complete);
drivers/iommu/intel/svm.c:	reinit_completion(&iommu->prq_complete);
drivers/iommu/intel/svm.c:		wait_for_completion(&iommu->prq_complete);
drivers/iommu/intel/svm.c:	reinit_completion(&iommu->prq_complete);
drivers/iommu/intel/svm.c:		wait_for_completion(&iommu->prq_complete);
drivers/iommu/intel/svm.c:	 * are waiting for the completion of this handling.
drivers/iommu/intel/svm.c:	if (!completion_done(&iommu->prq_complete))
drivers/iommu/iommu.c: * requester ID, requests and completions cannot be redirected, and all
drivers/iommu/msm_iommu.c:		 * completion of the tlb sync operation is implicitly
drivers/irqchip/alphascale_asm9260-icoll.h: * indicate the completion of an interrupt on a specific level.
drivers/irqchip/irq-gic-v3-its.c:static int its_wait_for_range_completion(struct its_node *its,
drivers/irqchip/irq-gic-v3-its.c:	if (its_wait_for_range_completion(its, rd_idx, next_cmd))	\
drivers/irqchip/irq-gic-v3.c:/* Wait for completion of a distributor change */
drivers/irqchip/irq-gic-v3.c:/* Wait for completion of a redistributor change */
drivers/isdn/hardware/mISDN/hfcsusb.c:/* control completion routine handling background control cmds */
drivers/isdn/hardware/mISDN/hfcsusb.c:/* receive completion routine for all ISO tx fifos   */
drivers/isdn/hardware/mISDN/hfcsusb.c:					 * completions
drivers/isdn/hardware/mISDN/hfcsusb.c:/* receive completion routine for all interrupt rx fifos */
drivers/isdn/hardware/mISDN/hfcsusb.c:/* transmit completion routine for all ISO tx fifos */
drivers/isdn/hardware/mISDN/hfcsusb.c:						/* signal frame completion */
drivers/isdn/hardware/mISDN/hfcsusb.c:		 * abuse DChannel tx iso completion to trigger NT mode state
drivers/isdn/mISDN/l1oip.h:	struct completion	socket_complete;/* completion of sock thread */
drivers/isdn/mISDN/l1oip_core.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/isdn/mISDN/l1oip_core.c:	/* if we got killed, signal completion */
drivers/isdn/mISDN/l1oip_core.c:		wait_for_completion(&hc->socket_complete);
drivers/isdn/mISDN/l1oip_core.c:	init_completion(&hc->socket_complete);
drivers/isdn/mISDN/stack.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/isdn/mISDN/stack.c:		wait_for_completion(&done);
drivers/isdn/mISDN/stack.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/isdn/mISDN/stack.c:		wait_for_completion(&done);
drivers/leds/leds-powernv.c:	if (rc != OPAL_ASYNC_COMPLETION) {
drivers/leds/trigger/ledtrig-tty.c:#include <linux/completion.h>
drivers/leds/trigger/ledtrig-tty.c:	struct completion sysfs;
drivers/leds/trigger/ledtrig-tty.c:static int ledtrig_tty_wait_for_completion(struct device *dev)
drivers/leds/trigger/ledtrig-tty.c:	ret = wait_for_completion_timeout(&trigger_data->sysfs,
drivers/leds/trigger/ledtrig-tty.c:	int completion;
drivers/leds/trigger/ledtrig-tty.c:	reinit_completion(&trigger_data->sysfs);
drivers/leds/trigger/ledtrig-tty.c:	completion = ledtrig_tty_wait_for_completion(dev);
drivers/leds/trigger/ledtrig-tty.c:	if (completion < 0)
drivers/leds/trigger/ledtrig-tty.c:		return completion;
drivers/leds/trigger/ledtrig-tty.c:	int completion;
drivers/leds/trigger/ledtrig-tty.c:	reinit_completion(&trigger_data->sysfs);
drivers/leds/trigger/ledtrig-tty.c:	completion = ledtrig_tty_wait_for_completion(dev);
drivers/leds/trigger/ledtrig-tty.c:	if (completion < 0)
drivers/leds/trigger/ledtrig-tty.c:		return completion;
drivers/leds/trigger/ledtrig-tty.c:	init_completion(&trigger_data->sysfs);
drivers/macintosh/adb-iop.c: * Completion routine for ADB commands sent to the IOP.
drivers/macintosh/adb.c:#include <linux/completion.h>
drivers/macintosh/adb.c:	struct completion *comp = req->arg;
drivers/macintosh/adb.c:	struct completion comp;
drivers/macintosh/adb.c:	/* Synchronous requests block using an on-stack completion */
drivers/macintosh/adb.c:		init_completion(&comp);
drivers/macintosh/adb.c:		wait_for_completion(&comp);
drivers/macintosh/ams/ams-pmu.c:	complete((struct completion *)req->arg);
drivers/macintosh/ams/ams-pmu.c:	DECLARE_COMPLETION(req_complete);
drivers/macintosh/ams/ams-pmu.c:	wait_for_completion(&req_complete);
drivers/macintosh/ams/ams-pmu.c:	DECLARE_COMPLETION(req_complete);
drivers/macintosh/ams/ams-pmu.c:	wait_for_completion(&req_complete);
drivers/macintosh/smu.c:#include <linux/completion.h>
drivers/macintosh/smu.c:	/* Call command completion handler if any */
drivers/macintosh/smu.c:	struct completion *comp = misc;
drivers/macintosh/smu.c:	/* Call command completion handler if any */
drivers/macintosh/smu.c:static void smu_i2c_low_completion(struct smu_cmd *scmd, void *misc)
drivers/macintosh/smu.c:	cmd->scmd.done = smu_i2c_low_completion;
drivers/macintosh/smu.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/macintosh/smu.c:		wait_for_completion(&comp);
drivers/macintosh/smu.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/macintosh/smu.c:	wait_for_completion(&comp);
drivers/macintosh/via-pmu.c:	/* Wait for completion of async requests */
drivers/macintosh/windfarm_smu_controls.c:#include <linux/completion.h>
drivers/macintosh/windfarm_smu_controls.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/macintosh/windfarm_smu_controls.c:	wait_for_completion(&comp);
drivers/macintosh/windfarm_smu_sensors.c:#include <linux/completion.h>
drivers/macintosh/windfarm_smu_sensors.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/macintosh/windfarm_smu_sensors.c:	wait_for_completion(&comp);
drivers/mailbox/bcm-flexrm-mailbox.c:/* Completion descriptor format */
drivers/mailbox/bcm-flexrm-mailbox.c:/* Completion DME status code */
drivers/mailbox/bcm-flexrm-mailbox.c:/* Completion RM status code */
drivers/mailbox/bcm-flexrm-mailbox.c:static int flexrm_process_completions(struct flexrm_ring *ring)
drivers/mailbox/bcm-flexrm-mailbox.c:	 * Get current completion read and write offset
drivers/mailbox/bcm-flexrm-mailbox.c:	 * Note: We should read completion write pointer at least once
drivers/mailbox/bcm-flexrm-mailbox.c:	 * completion write pointer is read.
drivers/mailbox/bcm-flexrm-mailbox.c:		/* Dequeue next completion descriptor */
drivers/mailbox/bcm-flexrm-mailbox.c:		/* Decode error from completion descriptor */
drivers/mailbox/bcm-flexrm-mailbox.c:			"ring%d got completion desc=0x%lx with error %d\n",
drivers/mailbox/bcm-flexrm-mailbox.c:		/* Determine request id from completion descriptor */
drivers/mailbox/bcm-flexrm-mailbox.c:			"ring%d null msg pointer for completion desc=0x%lx\n",
drivers/mailbox/bcm-flexrm-mailbox.c:		/* Increment number of completions processed */
drivers/mailbox/bcm-flexrm-mailbox.c:	/* We only have MSI for completions so just wakeup IRQ thread */
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Ring related errors will be informed via completion descriptors */
drivers/mailbox/bcm-flexrm-mailbox.c:	flexrm_process_completions(dev_id);
drivers/mailbox/bcm-flexrm-mailbox.c:	int cnt = flexrm_process_completions(chan->con_priv);
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Allocate completion memory */
drivers/mailbox/bcm-flexrm-mailbox.c:			"can't allocate completion memory for ring%d\n",
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Program completion start address */
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Completion read pointer will be same as HW write pointer */
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Free-up completion descriptor ring */
drivers/mailbox/bcm-flexrm-mailbox.c:	/* Create DMA pool for ring completion memory */
drivers/mailbox/mailbox.c:		ret = wait_for_completion_timeout(&chan->tx_complete, wait);
drivers/mailbox/mailbox.c:	init_completion(&chan->tx_complete);
drivers/mailbox/pl320-ipc.c:#include <linux/completion.h>
drivers/mailbox/pl320-ipc.c:static DECLARE_COMPLETION(ipc_completion);
drivers/mailbox/pl320-ipc.c:	init_completion(&ipc_completion);
drivers/mailbox/pl320-ipc.c:	ret = wait_for_completion_timeout(&ipc_completion,
drivers/mailbox/pl320-ipc.c:		complete(&ipc_completion);
drivers/md/dm-bufio.c: * dm-io completion routine. It just calls b->bio.bi_end_io, pretending
drivers/md/dm-builtin.c: *  4. dm_sysfs_exit waits on the completion
drivers/md/dm-builtin.c:	complete(dm_get_completion_from_kobject(kobj));
drivers/md/dm-clone-metadata.c: * e.g., in a hooked overwrite bio's completion routine, and further reduce the
drivers/md/dm-clone-metadata.c: * I/O completion latency.
drivers/md/dm-clone-target.c:	struct bio_list deferred_flush_completions;
drivers/md/dm-clone-target.c:	 * before signaling its completion.
drivers/md/dm-clone-target.c:	bio_list_add(&clone->deferred_flush_completions, bio);
drivers/md/dm-clone-target.c:	struct bio_list bio_completions = BIO_EMPTY_LIST;
drivers/md/dm-clone-target.c:	 * before issuing them or signaling their completion.
drivers/md/dm-clone-target.c:	bio_list_merge_init(&bio_completions,
drivers/md/dm-clone-target.c:			    &clone->deferred_flush_completions);
drivers/md/dm-clone-target.c:	if (bio_list_empty(&bios) && bio_list_empty(&bio_completions) &&
drivers/md/dm-clone-target.c:		bio_list_merge(&bios, &bio_completions);
drivers/md/dm-clone-target.c:	while ((bio = bio_list_pop(&bio_completions)))
drivers/md/dm-clone-target.c:	 *   - Process deferred REQ_FUA completions
drivers/md/dm-clone-target.c:	bio_list_init(&clone->deferred_flush_completions);
drivers/md/dm-core.h:	struct completion completion;
drivers/md/dm-core.h:	/* kobject and completion */
drivers/md/dm-core.h:static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
drivers/md/dm-core.h:	return &container_of(kobj, struct dm_kobject_holder, kobj)->completion;
drivers/md/dm-crypt.c:#include <linux/completion.h>
drivers/md/dm-crypt.c:	struct completion restart;
drivers/md/dm-crypt.c:	init_completion(&ctx->restart);
drivers/md/dm-crypt.c:				if (try_wait_for_completion(&ctx->restart)) {
drivers/md/dm-crypt.c:					 * we don't have to block to wait for completion,
drivers/md/dm-crypt.c:					 * we can't wait for completion without blocking
drivers/md/dm-crypt.c:				wait_for_completion(&ctx->restart);
drivers/md/dm-crypt.c:			reinit_completion(&ctx->restart);
drivers/md/dm-crypt.c:		 * completion function kcryptd_async_done() will be called.
drivers/md/dm-crypt.c: * One of the bios was finished. Check for completion of
drivers/md/dm-crypt.c:	wait_for_completion(&ctx->restart);
drivers/md/dm-crypt.c:	reinit_completion(&ctx->restart);
drivers/md/dm-crypt.c:		/* Wait for completion signaled by kcryptd_async_done() */
drivers/md/dm-crypt.c:		wait_for_completion(&ctx->restart);
drivers/md/dm-crypt.c:		/* Wait for completion signaled by kcryptd_async_done() */
drivers/md/dm-crypt.c:		wait_for_completion(&ctx->restart);
drivers/md/dm-crypt.c:	wait_for_completion(&io->ctx.restart);
drivers/md/dm-crypt.c:	reinit_completion(&io->ctx.restart);
drivers/md/dm-crypt.c:	 * finish the completion and continue in crypt_convert().
drivers/md/dm-crypt.c:		 * irqs_disabled(): the kernel may run some IO completion from the idle thread, but
drivers/md/dm-crypt.c:		 * encryption completion.
drivers/md/dm-era-target.c:	struct completion complete;
drivers/md/dm-era-target.c:	init_completion(&rpc->complete);
drivers/md/dm-era-target.c:	wait_for_completion(&rpc->complete);
drivers/md/dm-integrity.c:	struct completion crypto_backoff;
drivers/md/dm-integrity.c:	struct completion *completion;
drivers/md/dm-integrity.c:struct journal_completion {
drivers/md/dm-integrity.c:	struct completion comp;
drivers/md/dm-integrity.c:	struct journal_completion *comp;
drivers/md/dm-integrity.c:	struct journal_completion *comp = context;
drivers/md/dm-integrity.c:			unsigned int n_sections, struct journal_completion *comp)
drivers/md/dm-integrity.c:	struct journal_completion *comp = data;
drivers/md/dm-integrity.c:static bool do_crypt(bool encrypt, struct skcipher_request *req, struct journal_completion *comp)
drivers/md/dm-integrity.c:		wait_for_completion(&comp->ic->crypto_backoff);
drivers/md/dm-integrity.c:		reinit_completion(&comp->ic->crypto_backoff);
drivers/md/dm-integrity.c:			  unsigned int n_sections, struct journal_completion *comp)
drivers/md/dm-integrity.c:			    unsigned int n_sections, struct journal_completion *comp)
drivers/md/dm-integrity.c:	struct journal_completion *comp = context;
drivers/md/dm-integrity.c:			       struct journal_completion *comp)
drivers/md/dm-integrity.c:		       struct journal_completion *comp)
drivers/md/dm-integrity.c:	struct journal_completion io_comp;
drivers/md/dm-integrity.c:	struct journal_completion crypt_comp_1;
drivers/md/dm-integrity.c:	struct journal_completion crypt_comp_2;
drivers/md/dm-integrity.c:	init_completion(&io_comp.comp);
drivers/md/dm-integrity.c:			init_completion(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:			wait_for_completion_io(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:			init_completion(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:			if (try_wait_for_completion(&crypt_comp_1.comp)) {
drivers/md/dm-integrity.c:				reinit_completion(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:				wait_for_completion_io(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:				init_completion(&crypt_comp_2.comp);
drivers/md/dm-integrity.c:				wait_for_completion_io(&crypt_comp_1.comp);
drivers/md/dm-integrity.c:				wait_for_completion_io(&crypt_comp_2.comp);
drivers/md/dm-integrity.c:	wait_for_completion_io(&io_comp.comp);
drivers/md/dm-integrity.c:	struct completion comp;
drivers/md/dm-integrity.c:		init_completion(&fr.comp);
drivers/md/dm-integrity.c:		wait_for_completion(&fr.comp);
drivers/md/dm-integrity.c:	if (dio->completion)
drivers/md/dm-integrity.c:		complete(dio->completion);
drivers/md/dm-integrity.c:	struct completion read_comp;
drivers/md/dm-integrity.c:		init_completion(&read_comp);
drivers/md/dm-integrity.c:		dio->completion = &read_comp;
drivers/md/dm-integrity.c:		dio->completion = NULL;
drivers/md/dm-integrity.c:		dio->completion = NULL;
drivers/md/dm-integrity.c:		wait_for_completion_io(&read_comp);
drivers/md/dm-integrity.c:	struct journal_completion *comp = io->comp;
drivers/md/dm-integrity.c:	struct journal_completion comp;
drivers/md/dm-integrity.c:	init_completion(&comp.comp);
drivers/md/dm-integrity.c:	wait_for_completion_io(&comp.comp);
drivers/md/dm-integrity.c:			struct journal_completion crypt_comp;
drivers/md/dm-integrity.c:			init_completion(&crypt_comp.comp);
drivers/md/dm-integrity.c:			wait_for_completion(&crypt_comp.comp);
drivers/md/dm-integrity.c:		struct journal_completion comp;
drivers/md/dm-integrity.c:			init_completion(&comp.comp);
drivers/md/dm-integrity.c:				wait_for_completion(&comp.comp);
drivers/md/dm-integrity.c:				init_completion(&comp.comp);
drivers/md/dm-integrity.c:					wait_for_completion(&comp.comp);
drivers/md/dm-integrity.c:	init_completion(&ic->crypto_backoff);
drivers/md/dm-io.c:#include <linux/completion.h>
drivers/md/dm-io.c:	struct completion wait;
drivers/md/dm-io.c:	init_completion(&sio.wait);
drivers/md/dm-io.c:	wait_for_completion_io(&sio.wait);
drivers/md/dm-kcopyd.c: * completion notification.
drivers/md/dm-kcopyd.c:		 * Queue the completion callback to the kcopyd thread.
drivers/md/dm-kcopyd.c:		 * Some callers assume that all the completions are called
drivers/md/dm-kcopyd.c:	/* Wait for completion of all jobs submitted by this client. */
drivers/md/dm-log-userspace-transfer.c:	struct completion complete;
drivers/md/dm-log-userspace-transfer.c:	init_completion(&pkg.complete);
drivers/md/dm-log-userspace-transfer.c:	tmo = wait_for_completion_timeout(&(pkg.complete), DM_ULOG_RETRY_TIMEOUT);
drivers/md/dm-log-writes.c: * order of completion along with the normal writes.  If we didn't do it this
drivers/md/dm-log-writes.c:	struct completion super_done;
drivers/md/dm-log-writes.c:	wait_for_completion_io(&lc->super_done);
drivers/md/dm-log-writes.c:	init_completion(&lc->super_done);
drivers/md/dm-mpath.c:	wait_queue_head_t pg_init_wait;	/* Wait for pg_init completion */
drivers/md/dm-mpath.c:static void multipath_wait_for_pg_init_completion(struct multipath *m)
drivers/md/dm-mpath.c:			multipath_wait_for_pg_init_completion(m);
drivers/md/dm-rq.c: * Partial completion handling for request-based dm
drivers/md/dm-rq.c:	 * Notice the data completion to the upper layer.
drivers/md/dm-rq.c: * Request completion handler for request-based dm
drivers/md/dm-rq.c:	 * because the device may be closed during the request completion
drivers/md/dm-snap.c:	/* A sequence number, it is used for in-order completion. */
drivers/md/dm-snap.c:		 * completion of this exception, and start this one last,
drivers/md/dm-sysfs.c:	wait_for_completion(dm_get_completion_from_kobject(kobj));
drivers/md/dm-table.c:	 * (e.g. request completion process for partial completion.)
drivers/md/dm-thin.c:	struct bio_list deferred_flush_completions;
drivers/md/dm-thin.c:	struct completion can_destroy;
drivers/md/dm-thin.c:	 * before signaling its completion.
drivers/md/dm-thin.c:	bio_list_add(&pool->deferred_flush_completions, bio);
drivers/md/dm-thin.c:	 * will prevent completion until the sub range discards have
drivers/md/dm-thin.c:	struct bio_list bios, bio_completions;
drivers/md/dm-thin.c:	 * before issuing them or signaling their completion.
drivers/md/dm-thin.c:	bio_list_init(&bio_completions);
drivers/md/dm-thin.c:	bio_list_merge(&bio_completions, &pool->deferred_flush_completions);
drivers/md/dm-thin.c:	bio_list_init(&pool->deferred_flush_completions);
drivers/md/dm-thin.c:	if (bio_list_empty(&bios) && bio_list_empty(&bio_completions) &&
drivers/md/dm-thin.c:		bio_list_merge(&bios, &bio_completions);
drivers/md/dm-thin.c:	while ((bio = bio_list_pop(&bio_completions)))
drivers/md/dm-thin.c:	struct completion complete;
drivers/md/dm-thin.c:	init_completion(&pw->complete);
drivers/md/dm-thin.c:	wait_for_completion(&pw->complete);
drivers/md/dm-thin.c:	bio_list_init(&pool->deferred_flush_completions);
drivers/md/dm-thin.c:	wait_for_completion(&tc->can_destroy);
drivers/md/dm-thin.c:	init_completion(&tc->can_destroy);
drivers/md/dm-vdo/Makefile:	completion.o \
drivers/md/dm-vdo/action-manager.c:#include "completion.h"
drivers/md/dm-vdo/action-manager.c:	struct vdo_completion *parent;
drivers/md/dm-vdo/action-manager.c: * @completion: The completion for performing actions.
drivers/md/dm-vdo/action-manager.c:	struct vdo_completion completion;
drivers/md/dm-vdo/action-manager.c:static inline struct action_manager *as_action_manager(struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	vdo_assert_completion_type(completion, VDO_ACTION_COMPLETION);
drivers/md/dm-vdo/action-manager.c:	return container_of(completion, struct action_manager, completion);
drivers/md/dm-vdo/action-manager.c:static void no_preamble(void *context __always_unused, struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	vdo_finish_completion(completion);
drivers/md/dm-vdo/action-manager.c: * @vdo: The vdo used to initialize completions.
drivers/md/dm-vdo/action-manager.c:	vdo_initialize_completion(&manager->completion, vdo, VDO_ACTION_COMPLETION);
drivers/md/dm-vdo/action-manager.c:static void finish_action_callback(struct vdo_completion *completion);
drivers/md/dm-vdo/action-manager.c:static void apply_to_zone(struct vdo_completion *completion);
drivers/md/dm-vdo/action-manager.c:static void preserve_error(struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	if (completion->parent != NULL)
drivers/md/dm-vdo/action-manager.c:		vdo_set_completion_result(completion->parent, completion->result);
drivers/md/dm-vdo/action-manager.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/action-manager.c:	vdo_run_completion(completion);
drivers/md/dm-vdo/action-manager.c:	vdo_prepare_completion_for_requeue(&manager->completion, apply_to_zone,
drivers/md/dm-vdo/action-manager.c:	vdo_prepare_completion_for_requeue(&manager->completion, finish_action_callback,
drivers/md/dm-vdo/action-manager.c:static void apply_to_zone(struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	struct action_manager *manager = as_action_manager(completion);
drivers/md/dm-vdo/action-manager.c:	manager->current_action->zone_action(manager->context, zone, completion);
drivers/md/dm-vdo/action-manager.c:static void handle_preamble_error(struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	completion->callback = finish_action_callback;
drivers/md/dm-vdo/action-manager.c:	preserve_error(completion);
drivers/md/dm-vdo/action-manager.c:			vdo_set_completion_result(action->parent, result);
drivers/md/dm-vdo/action-manager.c:		finish_action_callback(&manager->completion);
drivers/md/dm-vdo/action-manager.c:		vdo_prepare_completion_for_requeue(&manager->completion, apply_to_zone,
drivers/md/dm-vdo/action-manager.c:	action->preamble(manager->context, &manager->completion);
drivers/md/dm-vdo/action-manager.c:static void finish_action_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/action-manager.c:	struct action_manager *manager = as_action_manager(completion);
drivers/md/dm-vdo/action-manager.c:		vdo_continue_completion(action.parent, result);
drivers/md/dm-vdo/action-manager.c:			 struct vdo_completion *parent)
drivers/md/dm-vdo/action-manager.c:			    struct vdo_completion *parent)
drivers/md/dm-vdo/action-manager.c:					 void *context, struct vdo_completion *parent)
drivers/md/dm-vdo/action-manager.c:			vdo_continue_completion(parent, VDO_COMPONENT_BUSY);
drivers/md/dm-vdo/action-manager.h: *     an optional completion to be finished once the conclusion is done
drivers/md/dm-vdo/action-manager.h:				   struct vdo_completion *parent);
drivers/md/dm-vdo/action-manager.h:typedef void (*vdo_action_preamble_fn)(void *context, struct vdo_completion *parent);
drivers/md/dm-vdo/action-manager.h:			 struct vdo_completion *parent);
drivers/md/dm-vdo/action-manager.h:			    struct vdo_completion *parent);
drivers/md/dm-vdo/action-manager.h:					 void *context, struct vdo_completion *parent);
drivers/md/dm-vdo/admin-state.c:#include "completion.h"
drivers/md/dm-vdo/admin-state.c:		vdo_set_completion_result(state->waiter, result);
drivers/md/dm-vdo/admin-state.c:			vdo_launch_completion(vdo_forget(state->waiter));
drivers/md/dm-vdo/admin-state.c: * @waiter A completion to notify when the operation is complete; may be NULL.
drivers/md/dm-vdo/admin-state.c:					struct vdo_completion *waiter,
drivers/md/dm-vdo/admin-state.c:		vdo_continue_completion(waiter, result);
drivers/md/dm-vdo/admin-state.c: * @waiter     A completion to notify when the operation is complete.
drivers/md/dm-vdo/admin-state.c:						struct vdo_completion *waiter,
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to notify of the error; may be NULL.
drivers/md/dm-vdo/admin-state.c:		       struct vdo_completion *waiter)
drivers/md/dm-vdo/admin-state.c:		vdo_continue_completion(waiter, result);
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to finish with an error if the operation is not a drain.
drivers/md/dm-vdo/admin-state.c:						    struct vdo_completion *waiter)
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to notify when the drain is complete.
drivers/md/dm-vdo/admin-state.c:			struct vdo_completion *waiter, vdo_admin_initiator_fn initiator)
drivers/md/dm-vdo/admin-state.c:		vdo_launch_completion(waiter);
drivers/md/dm-vdo/admin-state.c:		vdo_continue_completion(waiter, VDO_INVALID_ADMIN_STATE);
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to finish with an error if the operation is not a load.
drivers/md/dm-vdo/admin-state.c:			       struct vdo_completion *waiter)
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to notify when the load is complete (may be NULL).
drivers/md/dm-vdo/admin-state.c:		       struct vdo_completion *waiter, vdo_admin_initiator_fn initiator)
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to notify if the operation is not a resume operation; may be NULL.
drivers/md/dm-vdo/admin-state.c:						     struct vdo_completion *waiter)
drivers/md/dm-vdo/admin-state.c: * @waiter The completion to notify when the resume is complete (may be NULL).
drivers/md/dm-vdo/admin-state.c:			struct vdo_completion *waiter, vdo_admin_initiator_fn initiator)
drivers/md/dm-vdo/admin-state.c: * @waiter the completion to notify when the operation completes or fails to start; may be NULL.
drivers/md/dm-vdo/admin-state.c:				    struct vdo_completion *waiter,
drivers/md/dm-vdo/admin-state.h:#include "completion.h"
drivers/md/dm-vdo/admin-state.h:	/* A completion waiting on a state change */
drivers/md/dm-vdo/admin-state.h:	struct vdo_completion *waiter;
drivers/md/dm-vdo/admin-state.h:					    struct vdo_completion *waiter);
drivers/md/dm-vdo/admin-state.h:		       struct vdo_completion *waiter, vdo_admin_initiator_fn initiator);
drivers/md/dm-vdo/admin-state.h:			struct vdo_completion *waiter, vdo_admin_initiator_fn initiator);
drivers/md/dm-vdo/admin-state.h:			struct vdo_completion *waiter, vdo_admin_initiator_fn initiator);
drivers/md/dm-vdo/admin-state.h:				    struct vdo_completion *waiter,
drivers/md/dm-vdo/block-map.c:#include "completion.h"
drivers/md/dm-vdo/block-map.c:	struct vdo_completion *completion;
drivers/md/dm-vdo/block-map.c:static inline struct vdo_page_completion *page_completion_from_waiter(struct vdo_waiter *waiter)
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *completion;
drivers/md/dm-vdo/block-map.c:	completion = container_of(waiter, struct vdo_page_completion, waiter);
drivers/md/dm-vdo/block-map.c:	vdo_assert_completion_type(&completion->completion, VDO_PAGE_COMPLETION);
drivers/md/dm-vdo/block-map.c:	return completion;
drivers/md/dm-vdo/block-map.c:		info->vio->completion.callback_thread_id = cache->zone->thread_id;
drivers/md/dm-vdo/block-map.c: * complete_with_page() - Helper to complete the VDO Page Completion request successfully.
drivers/md/dm-vdo/block-map.c: * @vdo_page_comp: The VDO page completion to complete.
drivers/md/dm-vdo/block-map.c:			       struct vdo_page_completion *vdo_page_comp)
drivers/md/dm-vdo/block-map.c:		vdo_fail_completion(&vdo_page_comp->completion, VDO_BAD_PAGE);
drivers/md/dm-vdo/block-map.c:	vdo_finish_completion(&vdo_page_comp->completion);
drivers/md/dm-vdo/block-map.c: * complete_waiter_with_error() - Complete a page completion with an error code.
drivers/md/dm-vdo/block-map.c: * @waiter: The page completion, as a waiter.
drivers/md/dm-vdo/block-map.c:	vdo_fail_completion(&page_completion_from_waiter(waiter)->completion, *result);
drivers/md/dm-vdo/block-map.c: * complete_waiter_with_page() - Complete a page completion with a page.
drivers/md/dm-vdo/block-map.c: * @waiter: The page completion, as a waiter.
drivers/md/dm-vdo/block-map.c:	complete_with_page(page_info, page_completion_from_waiter(waiter));
drivers/md/dm-vdo/block-map.c: * distribute_page_over_waitq() - Complete a waitq of VDO page completions with a page result.
drivers/md/dm-vdo/block-map.c: * Upon completion the waitq will be empty.
drivers/md/dm-vdo/block-map.c:	 * Increment the busy count once for each pending completion so that this page does not
drivers/md/dm-vdo/block-map.c:	 * stop being busy until all completions have been processed.
drivers/md/dm-vdo/block-map.c: * Once triggered, all enqueued completions will get this error. Any future requests will result in
drivers/md/dm-vdo/block-map.c: * validate_completed_page() - Check that a page completion which is being freed to the cache
drivers/md/dm-vdo/block-map.c:static int __must_check validate_completed_page(struct vdo_page_completion *completion,
drivers/md/dm-vdo/block-map.c:	result = VDO_ASSERT(completion->ready, "VDO Page completion not ready");
drivers/md/dm-vdo/block-map.c:	result = VDO_ASSERT(completion->info != NULL,
drivers/md/dm-vdo/block-map.c:			    "VDO Page Completion must be complete");
drivers/md/dm-vdo/block-map.c:	result = VDO_ASSERT(completion->info->pbn == completion->pbn,
drivers/md/dm-vdo/block-map.c:			    "VDO Page Completion pbn must be consistent");
drivers/md/dm-vdo/block-map.c:	result = VDO_ASSERT(is_valid(completion->info),
drivers/md/dm-vdo/block-map.c:			    "VDO Page Completion page must be valid");
drivers/md/dm-vdo/block-map.c:		result = VDO_ASSERT(completion->writable,
drivers/md/dm-vdo/block-map.c:				    "VDO Page Completion must be writable");
drivers/md/dm-vdo/block-map.c:validate_completed_page_or_enter_read_only_mode(struct vdo_page_completion *completion,
drivers/md/dm-vdo/block-map.c:	int result = validate_completed_page(completion, writable);
drivers/md/dm-vdo/block-map.c:	enter_zone_read_only_mode(completion->info->cache->zone, result);
drivers/md/dm-vdo/block-map.c: * @completion: The page read vio.
drivers/md/dm-vdo/block-map.c:static void handle_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	int result = completion->result;
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/block-map.c: * @completion: The vio which has loaded the page. Its parent is the page_info.
drivers/md/dm-vdo/block-map.c:static void page_is_loaded(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c:		vdo_continue_completion(completion, result);
drivers/md/dm-vdo/block-map.c: * @completion: The page load completion.
drivers/md/dm-vdo/block-map.c:static void handle_rebuild_read_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/block-map.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/block-map.c:	page_is_loaded(completion);
drivers/md/dm-vdo/block-map.c:	struct page_info *info = vio->completion.parent;
drivers/md/dm-vdo/block-map.c:static void write_pages(struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.c:static void handle_flush_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/block-map.c:	set_persistent_error(info->cache, "flush failed", completion->result);
drivers/md/dm-vdo/block-map.c:	write_pages(completion);
drivers/md/dm-vdo/block-map.c:	struct page_info *info = vio->completion.parent;
drivers/md/dm-vdo/block-map.c: * completion_needs_page() - Determine whether a given vdo_page_completion (as a waiter) is
drivers/md/dm-vdo/block-map.c: * Return: true if the page completion is for the desired page number.
drivers/md/dm-vdo/block-map.c:static bool completion_needs_page(struct vdo_waiter *waiter, void *context)
drivers/md/dm-vdo/block-map.c:	return (page_completion_from_waiter(waiter)->pbn == *pbn);
drivers/md/dm-vdo/block-map.c: * allocate_free_page() - Allocate a free page to the first completion in the waiting queue, and
drivers/md/dm-vdo/block-map.c: *                        any other completions that match it in page number.
drivers/md/dm-vdo/block-map.c:	pbn = page_completion_from_waiter(oldest_waiter)->pbn;
drivers/md/dm-vdo/block-map.c:	vdo_waitq_dequeue_matching_waiters(&cache->free_waiters, completion_needs_page,
drivers/md/dm-vdo/block-map.c: * If the selected page is not dirty, immediately allocates the page to the oldest completion
drivers/md/dm-vdo/block-map.c: * discard_page_for_completion() - Helper used to trigger a discard so that the completion can get
drivers/md/dm-vdo/block-map.c:static void discard_page_for_completion(struct vdo_page_completion *vdo_page_comp)
drivers/md/dm-vdo/block-map.c: * @completion: The page write vio.
drivers/md/dm-vdo/block-map.c:static void handle_page_write_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	int result = completion->result;
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/block-map.c:static void page_is_written_out(struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.c:	struct page_info *info = vio->completion.parent;
drivers/md/dm-vdo/block-map.c: * @completion: The vio which wrote the page. Its parent is a page_info.
drivers/md/dm-vdo/block-map.c:static void page_is_written_out(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct page_info *info = completion->parent;
drivers/md/dm-vdo/block-map.c: * @flush_completion: The flush vio.
drivers/md/dm-vdo/block-map.c:static void write_pages(struct vdo_completion *flush_completion)
drivers/md/dm-vdo/block-map.c:	struct vdo_page_cache *cache = ((struct page_info *) flush_completion->parent)->cache;
drivers/md/dm-vdo/block-map.c:			struct vdo_completion *completion = &info->vio->completion;
drivers/md/dm-vdo/block-map.c:			vdo_reset_completion(completion);
drivers/md/dm-vdo/block-map.c:			completion->callback = page_is_written_out;
drivers/md/dm-vdo/block-map.c:			completion->error_handler = handle_page_write_error;
drivers/md/dm-vdo/block-map.c:			vdo_fail_completion(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/block-map.c: * vdo_release_page_completion() - Release a VDO Page Completion.
drivers/md/dm-vdo/block-map.c: * The page referenced by this completion (if any) will no longer be held busy by this completion.
drivers/md/dm-vdo/block-map.c: * If a page becomes discardable and there are completions awaiting free pages then a new round of
drivers/md/dm-vdo/block-map.c:void vdo_release_page_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *page_completion = as_vdo_page_completion(completion);
drivers/md/dm-vdo/block-map.c:	if (completion->result == VDO_SUCCESS) {
drivers/md/dm-vdo/block-map.c:		if (!validate_completed_page_or_enter_read_only_mode(page_completion, false))
drivers/md/dm-vdo/block-map.c:		if (--page_completion->info->busy == 0)
drivers/md/dm-vdo/block-map.c:			discard_info = page_completion->info;
drivers/md/dm-vdo/block-map.c:	VDO_ASSERT_LOG_ONLY((page_completion->waiter.next_waiter == NULL),
drivers/md/dm-vdo/block-map.c:	page_completion->info = NULL;
drivers/md/dm-vdo/block-map.c:	cache = page_completion->cache;
drivers/md/dm-vdo/block-map.c: * load_page_for_completion() - Helper function to load a page as described by a VDO Page
drivers/md/dm-vdo/block-map.c: *                              Completion.
drivers/md/dm-vdo/block-map.c:static void load_page_for_completion(struct page_info *info,
drivers/md/dm-vdo/block-map.c:				     struct vdo_page_completion *vdo_page_comp)
drivers/md/dm-vdo/block-map.c: * vdo_get_page() - Initialize a page completion and get a block map page.
drivers/md/dm-vdo/block-map.c: * @page_completion: The vdo_page_completion to initialize.
drivers/md/dm-vdo/block-map.c: * by the completion to be loaded from disk. When the callback is invoked, the page will be
drivers/md/dm-vdo/block-map.c: * resident in the cache and marked busy. All callers must call vdo_release_page_completion()
drivers/md/dm-vdo/block-map.c:void vdo_get_page(struct vdo_page_completion *page_completion,
drivers/md/dm-vdo/block-map.c:	struct vdo_completion *completion = &page_completion->completion;
drivers/md/dm-vdo/block-map.c:	VDO_ASSERT_LOG_ONLY((page_completion->waiter.next_waiter == NULL),
drivers/md/dm-vdo/block-map.c:			    "New page completion was not already on a wait queue");
drivers/md/dm-vdo/block-map.c:	*page_completion = (struct vdo_page_completion) {
drivers/md/dm-vdo/block-map.c:	vdo_initialize_completion(completion, cache->vdo, VDO_PAGE_COMPLETION);
drivers/md/dm-vdo/block-map.c:	vdo_prepare_completion(completion, callback, error_handler,
drivers/md/dm-vdo/block-map.c:	completion->requeue = requeue;
drivers/md/dm-vdo/block-map.c:	if (page_completion->writable && vdo_is_read_only(cache->vdo)) {
drivers/md/dm-vdo/block-map.c:		vdo_fail_completion(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/block-map.c:	if (page_completion->writable)
drivers/md/dm-vdo/block-map.c:	info = find_page(cache, page_completion->pbn);
drivers/md/dm-vdo/block-map.c:		    (is_outgoing(info) && page_completion->writable)) {
drivers/md/dm-vdo/block-map.c:			vdo_waitq_enqueue_waiter(&info->waiting, &page_completion->waiter);
drivers/md/dm-vdo/block-map.c:			complete_with_page(info, page_completion);
drivers/md/dm-vdo/block-map.c:		load_page_for_completion(info, page_completion);
drivers/md/dm-vdo/block-map.c:	discard_page_for_completion(page_completion);
drivers/md/dm-vdo/block-map.c: * @completion: The vdo_page_completion containing the page.
drivers/md/dm-vdo/block-map.c:void vdo_request_page_write(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *vdo_page_comp = as_vdo_page_completion(completion);
drivers/md/dm-vdo/block-map.c: * vdo_get_cached_page() - Get the block map page from a page completion.
drivers/md/dm-vdo/block-map.c: * @completion: A vdo page completion whose callback has been called.
drivers/md/dm-vdo/block-map.c:int vdo_get_cached_page(struct vdo_completion *completion,
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *vpc;
drivers/md/dm-vdo/block-map.c:	vpc = as_vdo_page_completion(completion);
drivers/md/dm-vdo/block-map.c:static void finish_page_write(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/block-map.c:	struct tree_page *page = completion->parent;
drivers/md/dm-vdo/block-map.c:static void handle_write_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	int result = completion->result;
drivers/md/dm-vdo/block-map.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/block-map.c:static void write_initialized_page(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/block-map.c:	struct tree_page *tree_page = completion->parent;
drivers/md/dm-vdo/block-map.c:	struct vdo_completion *completion = &vio->vio.completion;
drivers/md/dm-vdo/block-map.c:	completion->parent = tree_page;
drivers/md/dm-vdo/block-map.c:	completion->callback_thread_id = zone->thread_id;
drivers/md/dm-vdo/block-map.c:		write_initialized_page(completion);
drivers/md/dm-vdo/block-map.c:	data_vio->vio.completion.error_handler = handle_data_vio_error;
drivers/md/dm-vdo/block-map.c:static void finish_block_map_page_load(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = completion->parent;
drivers/md/dm-vdo/block-map.c:static void handle_io_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	int result = completion->result;
drivers/md/dm-vdo/block-map.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = completion->parent;
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = vio->completion.parent;
drivers/md/dm-vdo/block-map.c:	pooled->vio.completion.parent = data_vio;
drivers/md/dm-vdo/block-map.c:static void allocation_failure(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:	if (vdo_requeue_completion_if_needed(completion,
drivers/md/dm-vdo/block-map.c:	abort_lookup(data_vio, completion->result, "allocation");
drivers/md/dm-vdo/block-map.c:static void finish_block_map_allocation(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:static void release_block_map_write_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:static void set_block_map_page_reference_count(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:	completion->callback = release_block_map_write_lock;
drivers/md/dm-vdo/block-map.c:	vdo_modify_reference_count(completion, &data_vio->increment_updater);
drivers/md/dm-vdo/block-map.c:static void journal_block_map_allocation(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:	vdo_add_recovery_journal_entry(completion->vdo->recovery_journal, data_vio);
drivers/md/dm-vdo/block-map.c:static void allocate_block(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/block-map.c:	struct vdo_completion *completion = cursors->completion;
drivers/md/dm-vdo/block-map.c:	vdo_finish_completion(completion);
drivers/md/dm-vdo/block-map.c: * @completion: The VIO doing a read or write.
drivers/md/dm-vdo/block-map.c:static void continue_traversal(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/block-map.c:	traverse(completion->parent);
drivers/md/dm-vdo/block-map.c: * @completion: The VIO doing the read.
drivers/md/dm-vdo/block-map.c:static void finish_traversal_load(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct cursor *cursor = completion->parent;
drivers/md/dm-vdo/block-map.c:	struct cursor *cursor = vio->completion.parent;
drivers/md/dm-vdo/block-map.c:									    cursor->parent->completion);
drivers/md/dm-vdo/block-map.c:	pooled->vio.completion.parent = cursor;
drivers/md/dm-vdo/block-map.c:	pooled->vio.completion.callback_thread_id = cursor->parent->zone->thread_id;
drivers/md/dm-vdo/block-map.c: * @completion: The completion to notify on each traversed PBN, and when traversal completes.
drivers/md/dm-vdo/block-map.c:			 struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:		vdo_fail_completion(completion, result);
drivers/md/dm-vdo/block-map.c:	cursors->completion = completion;
drivers/md/dm-vdo/block-map.c:static void prepare_for_era_advance(void *context, struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/block-map.c:				       struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/block-map.c:		       struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:			 struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:				  struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:	vdo_fail_completion(parent, vdo_resume_if_quiescent(&zone->state));
drivers/md/dm-vdo/block-map.c:void vdo_resume_block_map(struct block_map *map, struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:static void grow_forest(void *context, struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	vdo_finish_completion(completion);
drivers/md/dm-vdo/block-map.c:void vdo_grow_block_map(struct block_map *map, struct vdo_completion *parent)
drivers/md/dm-vdo/block-map.c:/* Release the page completion and then continue the requester. */
drivers/md/dm-vdo/block-map.c:static inline void finish_processing_page(struct vdo_completion *completion, int result)
drivers/md/dm-vdo/block-map.c:	struct vdo_completion *parent = completion->parent;
drivers/md/dm-vdo/block-map.c:	vdo_release_page_completion(completion);
drivers/md/dm-vdo/block-map.c:	vdo_continue_completion(parent, result);
drivers/md/dm-vdo/block-map.c:static void handle_page_error(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	finish_processing_page(completion, completion->result);
drivers/md/dm-vdo/block-map.c:	vdo_get_page(&data_vio->page_completion, zone,
drivers/md/dm-vdo/block-map.c:		     modifiable, &data_vio->vio.completion,
drivers/md/dm-vdo/block-map.c:static void get_mapping_from_fetched_page(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *vpc = as_vdo_page_completion(completion);
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion->parent);
drivers/md/dm-vdo/block-map.c:	if (completion->result != VDO_SUCCESS) {
drivers/md/dm-vdo/block-map.c:		finish_processing_page(completion, completion->result);
drivers/md/dm-vdo/block-map.c:		finish_processing_page(completion, result);
drivers/md/dm-vdo/block-map.c:	finish_processing_page(completion, result);
drivers/md/dm-vdo/block-map.c:static void put_mapping_in_fetched_page(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.c:	struct data_vio *data_vio = as_data_vio(completion->parent);
drivers/md/dm-vdo/block-map.c:	struct vdo_page_completion *vpc;
drivers/md/dm-vdo/block-map.c:	if (completion->result != VDO_SUCCESS) {
drivers/md/dm-vdo/block-map.c:		finish_processing_page(completion, completion->result);
drivers/md/dm-vdo/block-map.c:	vpc = as_vdo_page_completion(completion);
drivers/md/dm-vdo/block-map.c:		finish_processing_page(completion, result);
drivers/md/dm-vdo/block-map.c:	finish_processing_page(completion, VDO_SUCCESS);
drivers/md/dm-vdo/block-map.h:#include "completion.h"
drivers/md/dm-vdo/block-map.h:	/* queue of completions awaiting this item */
drivers/md/dm-vdo/block-map.h: * A completion awaiting a specific page. Also a live reference into the page once completed, until
drivers/md/dm-vdo/block-map.h:struct vdo_page_completion {
drivers/md/dm-vdo/block-map.h:	/* The generic completion */
drivers/md/dm-vdo/block-map.h:	struct vdo_completion completion;
drivers/md/dm-vdo/block-map.h: * @completion: The parent completion of the traversal.
drivers/md/dm-vdo/block-map.h:				     struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.h:static inline struct vdo_page_completion *as_vdo_page_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/block-map.h:	vdo_assert_completion_type(completion, VDO_PAGE_COMPLETION);
drivers/md/dm-vdo/block-map.h:	return container_of(completion, struct vdo_page_completion, completion);
drivers/md/dm-vdo/block-map.h:void vdo_release_page_completion(struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.h:void vdo_get_page(struct vdo_page_completion *page_completion,
drivers/md/dm-vdo/block-map.h:void vdo_request_page_write(struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.h:int __must_check vdo_get_cached_page(struct vdo_completion *completion,
drivers/md/dm-vdo/block-map.h:			 struct vdo_completion *completion);
drivers/md/dm-vdo/block-map.h:			 struct vdo_completion *parent);
drivers/md/dm-vdo/block-map.h:void vdo_resume_block_map(struct block_map *map, struct vdo_completion *parent);
drivers/md/dm-vdo/block-map.h:void vdo_grow_block_map(struct block_map *map, struct vdo_completion *parent);
drivers/md/dm-vdo/completion.c:#include "completion.h"
drivers/md/dm-vdo/completion.c: * DOC: vdo completions.
drivers/md/dm-vdo/completion.c: * vdo_work_queue which holds vdo_completions that are to be run in that zone. A completion may
drivers/md/dm-vdo/completion.c: * At each step of a multi-threaded operation, the completion performing the operation is given a
drivers/md/dm-vdo/completion.c: * callback, error handler, and thread id for the next step. A completion is "run" when it is
drivers/md/dm-vdo/completion.c: * will be invoked. Generally, a completion will not be run directly, but rather will be
drivers/md/dm-vdo/completion.c: * completion's "callback_thread_id". When it is dequeued, it will be on the correct thread, and
drivers/md/dm-vdo/completion.c: * will get run. In some cases, the completion should get queued instead of running immediately,
drivers/md/dm-vdo/completion.c: * the completion's "requeue" field should be set to true. Doing so will skip the current thread
drivers/md/dm-vdo/completion.c: * check and simply enqueue the completion.
drivers/md/dm-vdo/completion.c: * A completion may be "finished," in which case its "complete" field will be set to true before it
drivers/md/dm-vdo/completion.c: * is next run. It is a bug to attempt to set the result or re-finish a finished completion.
drivers/md/dm-vdo/completion.c: * Because a completion's fields are not safe to examine from any thread other than the one on
drivers/md/dm-vdo/completion.c: * which the completion is currently operating, this field is used only to aid in detecting
drivers/md/dm-vdo/completion.c: * A completion must be "reset" before it can be reused after it has been finished. Resetting will
drivers/md/dm-vdo/completion.c:void vdo_initialize_completion(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.c:			       enum vdo_completion_type type)
drivers/md/dm-vdo/completion.c:	memset(completion, 0, sizeof(*completion));
drivers/md/dm-vdo/completion.c:	completion->vdo = vdo;
drivers/md/dm-vdo/completion.c:	completion->type = type;
drivers/md/dm-vdo/completion.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/completion.c:static inline void assert_incomplete(struct vdo_completion *completion)
drivers/md/dm-vdo/completion.c:	VDO_ASSERT_LOG_ONLY(!completion->complete, "completion is not complete");
drivers/md/dm-vdo/completion.c: * vdo_set_completion_result() - Set the result of a completion.
drivers/md/dm-vdo/completion.c:void vdo_set_completion_result(struct vdo_completion *completion, int result)
drivers/md/dm-vdo/completion.c:	assert_incomplete(completion);
drivers/md/dm-vdo/completion.c:	if (completion->result == VDO_SUCCESS)
drivers/md/dm-vdo/completion.c:		completion->result = result;
drivers/md/dm-vdo/completion.c: * vdo_launch_completion_with_priority() - Run or enqueue a completion.
drivers/md/dm-vdo/completion.c: * @priority: The priority at which to enqueue the completion.
drivers/md/dm-vdo/completion.c: * If called on the correct thread (i.e. the one specified in the completion's callback_thread_id
drivers/md/dm-vdo/completion.c: * field) and not marked for requeue, the completion will be run immediately. Otherwise, the
drivers/md/dm-vdo/completion.c: * completion will be enqueued on the specified thread.
drivers/md/dm-vdo/completion.c:void vdo_launch_completion_with_priority(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.c:					 enum vdo_completion_priority priority)
drivers/md/dm-vdo/completion.c:	thread_id_t callback_thread = completion->callback_thread_id;
drivers/md/dm-vdo/completion.c:	if (completion->requeue || (callback_thread != vdo_get_callback_thread_id())) {
drivers/md/dm-vdo/completion.c:		vdo_enqueue_completion(completion, priority);
drivers/md/dm-vdo/completion.c:	vdo_run_completion(completion);
drivers/md/dm-vdo/completion.c:/** vdo_finish_completion() - Mark a completion as complete and then launch it. */
drivers/md/dm-vdo/completion.c:void vdo_finish_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/completion.c:	assert_incomplete(completion);
drivers/md/dm-vdo/completion.c:	completion->complete = true;
drivers/md/dm-vdo/completion.c:	if (completion->callback != NULL)
drivers/md/dm-vdo/completion.c:		vdo_launch_completion(completion);
drivers/md/dm-vdo/completion.c:void vdo_enqueue_completion(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.c:			    enum vdo_completion_priority priority)
drivers/md/dm-vdo/completion.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/completion.c:	thread_id_t thread_id = completion->callback_thread_id;
drivers/md/dm-vdo/completion.c:		       "thread_id %u (completion type %d) is less than thread count %u",
drivers/md/dm-vdo/completion.c:		       thread_id, completion->type,
drivers/md/dm-vdo/completion.c:	completion->requeue = false;
drivers/md/dm-vdo/completion.c:	completion->priority = priority;
drivers/md/dm-vdo/completion.c:	completion->my_queue = NULL;
drivers/md/dm-vdo/completion.c:	vdo_enqueue_work_queue(vdo->threads[thread_id].queue, completion);
drivers/md/dm-vdo/completion.c: * vdo_requeue_completion_if_needed() - Requeue a completion if not called on the specified thread.
drivers/md/dm-vdo/completion.c: * Return: True if the completion was requeued; callers may not access the completion in this case.
drivers/md/dm-vdo/completion.c:bool vdo_requeue_completion_if_needed(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.c:	completion->callback_thread_id = callback_thread_id;
drivers/md/dm-vdo/completion.c:	vdo_enqueue_completion(completion, VDO_WORK_Q_DEFAULT_PRIORITY);
drivers/md/dm-vdo/completion.h:#ifndef VDO_COMPLETION_H
drivers/md/dm-vdo/completion.h:#define VDO_COMPLETION_H
drivers/md/dm-vdo/completion.h: * vdo_run_completion() - Run a completion's callback or error handler on the current thread.
drivers/md/dm-vdo/completion.h:static inline void vdo_run_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/completion.h:	if ((completion->result != VDO_SUCCESS) && (completion->error_handler != NULL)) {
drivers/md/dm-vdo/completion.h:		completion->error_handler(completion);
drivers/md/dm-vdo/completion.h:	completion->callback(completion);
drivers/md/dm-vdo/completion.h:void vdo_set_completion_result(struct vdo_completion *completion, int result);
drivers/md/dm-vdo/completion.h:void vdo_initialize_completion(struct vdo_completion *completion, struct vdo *vdo,
drivers/md/dm-vdo/completion.h:			       enum vdo_completion_type type);
drivers/md/dm-vdo/completion.h: * vdo_reset_completion() - Reset a completion to a clean state, while keeping the type, vdo and
drivers/md/dm-vdo/completion.h:static inline void vdo_reset_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/completion.h:	completion->result = VDO_SUCCESS;
drivers/md/dm-vdo/completion.h:	completion->complete = false;
drivers/md/dm-vdo/completion.h:void vdo_launch_completion_with_priority(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:					 enum vdo_completion_priority priority);
drivers/md/dm-vdo/completion.h: * vdo_launch_completion() - Launch a completion with default priority.
drivers/md/dm-vdo/completion.h:static inline void vdo_launch_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/completion.h:	vdo_launch_completion_with_priority(completion, VDO_WORK_Q_DEFAULT_PRIORITY);
drivers/md/dm-vdo/completion.h: * vdo_continue_completion() - Continue processing a completion.
drivers/md/dm-vdo/completion.h: * Continue processing a completion by setting the current result and calling
drivers/md/dm-vdo/completion.h: * vdo_launch_completion().
drivers/md/dm-vdo/completion.h:static inline void vdo_continue_completion(struct vdo_completion *completion, int result)
drivers/md/dm-vdo/completion.h:	vdo_set_completion_result(completion, result);
drivers/md/dm-vdo/completion.h:	vdo_launch_completion(completion);
drivers/md/dm-vdo/completion.h:void vdo_finish_completion(struct vdo_completion *completion);
drivers/md/dm-vdo/completion.h: * vdo_fail_completion() - Set the result of a completion if it does not already have an error,
drivers/md/dm-vdo/completion.h:static inline void vdo_fail_completion(struct vdo_completion *completion, int result)
drivers/md/dm-vdo/completion.h:	vdo_set_completion_result(completion, result);
drivers/md/dm-vdo/completion.h:	vdo_finish_completion(completion);
drivers/md/dm-vdo/completion.h: * vdo_assert_completion_type() - Assert that a completion is of the correct type.
drivers/md/dm-vdo/completion.h:static inline int vdo_assert_completion_type(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:					     enum vdo_completion_type expected)
drivers/md/dm-vdo/completion.h:	return VDO_ASSERT(expected == completion->type,
drivers/md/dm-vdo/completion.h:			  "completion type should be %u, not %u", expected,
drivers/md/dm-vdo/completion.h:			  completion->type);
drivers/md/dm-vdo/completion.h:static inline void vdo_set_completion_callback(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:	completion->callback = callback;
drivers/md/dm-vdo/completion.h:	completion->callback_thread_id = callback_thread_id;
drivers/md/dm-vdo/completion.h: * vdo_launch_completion_callback() - Set the callback for a completion and launch it immediately.
drivers/md/dm-vdo/completion.h:static inline void vdo_launch_completion_callback(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:	vdo_set_completion_callback(completion, callback, callback_thread_id);
drivers/md/dm-vdo/completion.h:	vdo_launch_completion(completion);
drivers/md/dm-vdo/completion.h: * vdo_prepare_completion() - Prepare a completion for launch.
drivers/md/dm-vdo/completion.h: * Resets the completion, and then sets its callback, error handler, callback thread, and parent.
drivers/md/dm-vdo/completion.h:static inline void vdo_prepare_completion(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:	vdo_reset_completion(completion);
drivers/md/dm-vdo/completion.h:	vdo_set_completion_callback(completion, callback, callback_thread_id);
drivers/md/dm-vdo/completion.h:	completion->error_handler = error_handler;
drivers/md/dm-vdo/completion.h:	completion->parent = parent;
drivers/md/dm-vdo/completion.h: * vdo_prepare_completion_for_requeue() - Prepare a completion for launch ensuring that it will
drivers/md/dm-vdo/completion.h: * Resets the completion, and then sets its callback, error handler, callback thread, and parent.
drivers/md/dm-vdo/completion.h:static inline void vdo_prepare_completion_for_requeue(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:	vdo_prepare_completion(completion, callback, error_handler,
drivers/md/dm-vdo/completion.h:	completion->requeue = true;
drivers/md/dm-vdo/completion.h:void vdo_enqueue_completion(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:			    enum vdo_completion_priority priority);
drivers/md/dm-vdo/completion.h:bool vdo_requeue_completion_if_needed(struct vdo_completion *completion,
drivers/md/dm-vdo/completion.h:#endif /* VDO_COMPLETION_H */
drivers/md/dm-vdo/data-vio.c: *   completion is required for further work to be done by the issuer.
drivers/md/dm-vdo/data-vio.c: * completion will be enqueued on a cpu queue. This obviates the need for the releasing threads to
drivers/md/dm-vdo/data-vio.c: * Whenever the pool's completion is run on a cpu thread, it calls process_release_callback() which
drivers/md/dm-vdo/data-vio.c:	/* Completion for scheduling releases */
drivers/md/dm-vdo/data-vio.c:	struct vdo_completion completion;
drivers/md/dm-vdo/data-vio.c:as_data_vio_pool(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	vdo_assert_completion_type(completion, VDO_DATA_VIO_POOL_COMPLETION);
drivers/md/dm-vdo/data-vio.c:	return container_of(completion, struct data_vio_pool, completion);
drivers/md/dm-vdo/data-vio.c:	int error = vdo_status_to_errno(data_vio->vio.completion.result);
drivers/md/dm-vdo/data-vio.c: * @completion: The data_vio for an external data request as a completion.
drivers/md/dm-vdo/data-vio.c:static void attempt_logical_block_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:		complete_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	struct vdo_completion *completion = &data_vio->vio.completion;
drivers/md/dm-vdo/data-vio.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/data-vio.c:	vdo_enqueue_completion(completion, VDO_DEFAULT_Q_MAP_BIO_PRIORITY);
drivers/md/dm-vdo/data-vio.c:	launch_bio(limiter->pool->completion.vdo, data_vio, bio);
drivers/md/dm-vdo/data-vio.c:	pool->completion.requeue = true;
drivers/md/dm-vdo/data-vio.c:	vdo_launch_completion_with_priority(&pool->completion,
drivers/md/dm-vdo/data-vio.c: * @completion: The pool with data_vios to release.
drivers/md/dm-vdo/data-vio.c:static void process_release_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio_pool *pool = as_data_vio_pool(completion);
drivers/md/dm-vdo/data-vio.c:		data_vio = as_data_vio(container_of(entry, struct vdo_completion,
drivers/md/dm-vdo/data-vio.c:	vdo_initialize_completion(&data_vio->decrement_completion, vdo,
drivers/md/dm-vdo/data-vio.c:				  VDO_DECREMENT_COMPLETION);
drivers/md/dm-vdo/data-vio.c:	vdo_initialize_completion(&pool->completion, vdo, VDO_DATA_VIO_POOL_COMPLETION);
drivers/md/dm-vdo/data-vio.c:	vdo_prepare_completion(&pool->completion, process_release_callback,
drivers/md/dm-vdo/data-vio.c:	launch_bio(pool->completion.vdo, data_vio, bio);
drivers/md/dm-vdo/data-vio.c: * @completion: The completion to notify when the pool has drained.
drivers/md/dm-vdo/data-vio.c:void drain_data_vio_pool(struct data_vio_pool *pool, struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	assert_on_vdo_cpu_thread(completion->vdo, __func__);
drivers/md/dm-vdo/data-vio.c:	vdo_start_draining(&pool->state, VDO_ADMIN_STATE_SUSPENDING, completion,
drivers/md/dm-vdo/data-vio.c: * @completion: The completion to notify when the pool has resumed.
drivers/md/dm-vdo/data-vio.c:void resume_data_vio_pool(struct data_vio_pool *pool, struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	assert_on_vdo_cpu_thread(completion->vdo, __func__);
drivers/md/dm-vdo/data-vio.c:	vdo_continue_completion(completion, vdo_resume_if_quiescent(&pool->state));
drivers/md/dm-vdo/data-vio.c:static void release_allocated_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	next_lock_holder->vio.completion.requeue = true;
drivers/md/dm-vdo/data-vio.c:static void release_logical_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void clean_hash_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	if (completion->result != VDO_SUCCESS) {
drivers/md/dm-vdo/data-vio.c:	struct vdo_completion *completion = &data_vio->vio.completion;
drivers/md/dm-vdo/data-vio.c:	    (completion->result != VDO_SUCCESS)) {
drivers/md/dm-vdo/data-vio.c:		struct data_vio_pool *pool = completion->vdo->data_vio_pool;
drivers/md/dm-vdo/data-vio.c:		vdo_funnel_queue_put(pool->queue, &completion->work_queue_entry_link);
drivers/md/dm-vdo/data-vio.c:	completion->requeue = true;
drivers/md/dm-vdo/data-vio.c:		    (data_vio->vio.completion.result != VDO_READ_ONLY))
drivers/md/dm-vdo/data-vio.c:void complete_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = NULL;
drivers/md/dm-vdo/data-vio.c:static void enter_read_only_mode(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	if (vdo_is_read_only(completion->vdo))
drivers/md/dm-vdo/data-vio.c:	if (completion->result != VDO_READ_ONLY) {
drivers/md/dm-vdo/data-vio.c:		struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:		vdo_log_error_strerror(completion->result,
drivers/md/dm-vdo/data-vio.c:	vdo_enter_read_only_mode(completion->vdo, completion->result);
drivers/md/dm-vdo/data-vio.c:void handle_data_vio_error(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	if ((completion->result == VDO_READ_ONLY) || (data_vio->user_bio == NULL))
drivers/md/dm-vdo/data-vio.c:		enter_read_only_mode(completion);
drivers/md/dm-vdo/data-vio.c:	complete_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	data_vio->vio.completion.error_handler = error_handler;
drivers/md/dm-vdo/data-vio.c: * @completion: The data_vio which has just finished its read.
drivers/md/dm-vdo/data-vio.c:static void modify_for_partial_write(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void complete_read(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:		modify_for_partial_write(completion);
drivers/md/dm-vdo/data-vio.c:	complete_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void complete_zero_read(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:			modify_for_partial_write(completion);
drivers/md/dm-vdo/data-vio.c:	complete_read(completion);
drivers/md/dm-vdo/data-vio.c:static void read_block(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/data-vio.c:reference_count_update_completion_as_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	if (completion->type == VIO_COMPLETION)
drivers/md/dm-vdo/data-vio.c:		return as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	return container_of(completion, struct data_vio, decrement_completion);
drivers/md/dm-vdo/data-vio.c: * update_block_map() - Rendezvous of the data_vio and decrement completions after each has
drivers/md/dm-vdo/data-vio.c: * @completion: The completion of the write in progress.
drivers/md/dm-vdo/data-vio.c:static void update_block_map(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = reference_count_update_completion_as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	completion = &data_vio->vio.completion;
drivers/md/dm-vdo/data-vio.c:	vdo_set_completion_result(completion, data_vio->decrement_completion.result);
drivers/md/dm-vdo/data-vio.c:	if (completion->result != VDO_SUCCESS) {
drivers/md/dm-vdo/data-vio.c:		handle_data_vio_error(completion);
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/data-vio.c:		completion->callback = complete_data_vio;
drivers/md/dm-vdo/data-vio.c:static void decrement_reference_count(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = container_of(completion, struct data_vio,
drivers/md/dm-vdo/data-vio.c:						 decrement_completion);
drivers/md/dm-vdo/data-vio.c:	vdo_set_completion_callback(completion, update_block_map,
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = update_block_map;
drivers/md/dm-vdo/data-vio.c:	vdo_modify_reference_count(completion, &data_vio->decrement_updater);
drivers/md/dm-vdo/data-vio.c:static void increment_reference_count(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = update_block_map;
drivers/md/dm-vdo/data-vio.c:	vdo_modify_reference_count(completion, &data_vio->increment_updater);
drivers/md/dm-vdo/data-vio.c:static void journal_remapping(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:		vdo_set_completion_callback(&data_vio->decrement_completion,
drivers/md/dm-vdo/data-vio.c:	vdo_add_recovery_journal_entry(completion->vdo->recovery_journal, data_vio);
drivers/md/dm-vdo/data-vio.c:static void read_old_block_mapping(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void pack_compressed_data(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void compress_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:static void hash_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	vdo_set_completion_result(&data_vio->vio.completion,
drivers/md/dm-vdo/data-vio.c:static void acknowledge_write_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/data-vio.c:static void allocate_block(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/data-vio.c:static void handle_allocation_error(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:	if (completion->result == VDO_NO_SPACE) {
drivers/md/dm-vdo/data-vio.c:		vdo_reset_completion(completion);
drivers/md/dm-vdo/data-vio.c:		completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/data-vio.c:	handle_data_vio_error(completion);
drivers/md/dm-vdo/data-vio.c:void continue_data_vio_with_block_map_slot(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/data-vio.c:		completion->callback = complete_data_vio;
drivers/md/dm-vdo/data-vio.h:#include "completion.h"
drivers/md/dm-vdo/data-vio.h:	/* The completion to use for fetching block map pages for this vio */
drivers/md/dm-vdo/data-vio.h:	struct vdo_page_completion page_completion;
drivers/md/dm-vdo/data-vio.h:	/* The completion for making reference count decrements */
drivers/md/dm-vdo/data-vio.h:	struct vdo_completion decrement_completion;
drivers/md/dm-vdo/data-vio.h:static inline struct data_vio *as_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/data-vio.h:	return vio_as_data_vio(as_vio(completion));
drivers/md/dm-vdo/data-vio.h:	return data_vio->vio.completion.vdo;
drivers/md/dm-vdo/data-vio.h:void drain_data_vio_pool(struct data_vio_pool *pool, struct vdo_completion *completion);
drivers/md/dm-vdo/data-vio.h:void resume_data_vio_pool(struct data_vio_pool *pool, struct vdo_completion *completion);
drivers/md/dm-vdo/data-vio.h:void complete_data_vio(struct vdo_completion *completion);
drivers/md/dm-vdo/data-vio.h:void handle_data_vio_error(struct vdo_completion *completion);
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_continue_completion(&data_vio->vio.completion, result);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback, journal_thread);
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback, packer_thread);
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion(&data_vio->vio.completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback, cpu_thread);
drivers/md/dm-vdo/data-vio.h:						enum vdo_completion_priority priority)
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion_with_priority(&data_vio->vio.completion, priority);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(&data_vio->vio.completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion_with_priority(&data_vio->vio.completion,
drivers/md/dm-vdo/data-vio.h:	struct vdo_completion *completion = &data_vio->vio.completion;
drivers/md/dm-vdo/data-vio.h:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/data-vio.h:		callback(completion);
drivers/md/dm-vdo/data-vio.h:	vdo_set_completion_callback(completion, callback,
drivers/md/dm-vdo/data-vio.h:	vdo_launch_completion_with_priority(completion, BIO_ACK_Q_ACK_PRIORITY);
drivers/md/dm-vdo/data-vio.h:void continue_data_vio_with_block_map_slot(struct vdo_completion *completion);
drivers/md/dm-vdo/dedupe.c: * timer fires, the hash_zone's completion is enqueued to run in the hash_zone where the zone's
drivers/md/dm-vdo/dedupe.c:#include "completion.h"
drivers/md/dm-vdo/dedupe.c:	struct vdo_completion completion;
drivers/md/dm-vdo/dedupe.c:static inline struct hash_zone *as_hash_zone(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	vdo_assert_completion_type(completion, VDO_HASH_ZONE_COMPLETION);
drivers/md/dm-vdo/dedupe.c:	return container_of(completion, struct hash_zone, completion);
drivers/md/dm-vdo/dedupe.c:static inline struct hash_zones *as_hash_zones(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	vdo_assert_completion_type(completion, VDO_HASH_ZONES_COMPLETION);
drivers/md/dm-vdo/dedupe.c:	return container_of(completion, struct hash_zones, completion);
drivers/md/dm-vdo/dedupe.c:static void unlock_duplicate_pbn(struct vdo_completion *completion);
drivers/md/dm-vdo/dedupe.c:	data_vio->vio.completion.callback = complete_data_vio;
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio acting as the lock's agent.
drivers/md/dm-vdo/dedupe.c:static void finish_unlocking(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio acting as the lock's agent.
drivers/md/dm-vdo/dedupe.c:static void unlock_duplicate_pbn(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:		complete_data_vio(completion);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio that performed the update
drivers/md/dm-vdo/dedupe.c:static void finish_updating(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio used to verify dedupe
drivers/md/dm-vdo/dedupe.c:static void finish_verifying(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:static void verify_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:static void uncompress_and_verify(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:		verify_callback(completion);
drivers/md/dm-vdo/dedupe.c:	vdo_launch_completion_with_priority(&vio->completion, BIO_Q_VERIFY_PRIORITY);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio that attempted to get the read lock.
drivers/md/dm-vdo/dedupe.c:static void finish_locking(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio attempting to acquire the physical block lock on
drivers/md/dm-vdo/dedupe.c:static void lock_duplicate_pbn(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c: * @completion: The completion of the data_vio that performed the query.
drivers/md/dm-vdo/dedupe.c:static void finish_querying(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:void vdo_continue_hash_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:void vdo_acquire_hash_lock(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/dedupe.c:static void change_dedupe_state(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct hash_zones *zones = as_hash_zones(completion);
drivers/md/dm-vdo/dedupe.c:	vdo_initialize_completion(&zones->completion, vdo, VDO_HASH_ZONES_COMPLETION);
drivers/md/dm-vdo/dedupe.c:	vdo_set_completion_callback(&zones->completion, change_dedupe_state,
drivers/md/dm-vdo/dedupe.c:static void timeout_index_operations_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:	struct hash_zone *zone = as_hash_zone(completion);
drivers/md/dm-vdo/dedupe.c:		report_dedupe_timeouts(completion->vdo->hash_zones, timed_out);
drivers/md/dm-vdo/dedupe.c:		vdo_launch_completion(&zone->completion);
drivers/md/dm-vdo/dedupe.c:	vdo_initialize_completion(&zone->completion, vdo, VDO_HASH_ZONE_COMPLETION);
drivers/md/dm-vdo/dedupe.c:	vdo_set_completion_callback(&zone->completion, timeout_index_operations_callback,
drivers/md/dm-vdo/dedupe.c:static void suspend_index(void *context, struct vdo_completion *completion)
drivers/md/dm-vdo/dedupe.c:			   vdo_get_current_manager_operation(zones->manager), completion,
drivers/md/dm-vdo/dedupe.c:			    struct vdo_completion *parent)
drivers/md/dm-vdo/dedupe.c:void vdo_drain_hash_zones(struct hash_zones *zones, struct vdo_completion *parent)
drivers/md/dm-vdo/dedupe.c:		vdo_launch_completion(&zones->completion);
drivers/md/dm-vdo/dedupe.c:static void resume_index(void *context, struct vdo_completion *parent)
drivers/md/dm-vdo/dedupe.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/dedupe.c:			     struct vdo_completion *parent)
drivers/md/dm-vdo/dedupe.c:	vdo_fail_completion(parent, vdo_resume_if_quiescent(&zone->state));
drivers/md/dm-vdo/dedupe.c:void vdo_resume_hash_zones(struct hash_zones *zones, struct vdo_completion *parent)
drivers/md/dm-vdo/dedupe.c:		vdo_launch_completion(parent);
drivers/md/dm-vdo/dedupe.h:	struct vdo_completion completion;
drivers/md/dm-vdo/dedupe.h:void vdo_acquire_hash_lock(struct vdo_completion *completion);
drivers/md/dm-vdo/dedupe.h:void vdo_continue_hash_lock(struct vdo_completion *completion);
drivers/md/dm-vdo/dedupe.h:void vdo_drain_hash_zones(struct hash_zones *zones, struct vdo_completion *parent);
drivers/md/dm-vdo/dedupe.h:void vdo_resume_hash_zones(struct hash_zones *zones, struct vdo_completion *parent);
drivers/md/dm-vdo/dm-vdo-target.c:#include <linux/completion.h>
drivers/md/dm-vdo/dm-vdo-target.c:#include "completion.h"
drivers/md/dm-vdo/dm-vdo-target.c:static struct vdo_completion *prepare_admin_completion(struct vdo *vdo,
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo_completion *completion = &vdo->admin.completion;
drivers/md/dm-vdo/dm-vdo-target.c:	 * We can't use vdo_prepare_completion_for_requeue() here because we don't want to reset
drivers/md/dm-vdo/dm-vdo-target.c:	 * any error in the completion.
drivers/md/dm-vdo/dm-vdo-target.c:	completion->callback = callback;
drivers/md/dm-vdo/dm-vdo-target.c:	completion->error_handler = error_handler;
drivers/md/dm-vdo/dm-vdo-target.c:	completion->callback_thread_id = get_thread_id_for_phase(vdo);
drivers/md/dm-vdo/dm-vdo-target.c:	completion->requeue = true;
drivers/md/dm-vdo/dm-vdo-target.c:	return completion;
drivers/md/dm-vdo/dm-vdo-target.c: *                   completion to run on the thread for the next phase.
drivers/md/dm-vdo/dm-vdo-target.c:	vdo->admin.completion.callback_thread_id = get_thread_id_for_phase(vdo);
drivers/md/dm-vdo/dm-vdo-target.c:	vdo->admin.completion.requeue = true;
drivers/md/dm-vdo/dm-vdo-target.c:	reinit_completion(&admin->callback_sync);
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_reset_completion(&admin->completion);
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_launch_completion(prepare_admin_completion(vdo, callback, error_handler));
drivers/md/dm-vdo/dm-vdo-target.c:	while (wait_for_completion_interruptible(&admin->callback_sync)) {
drivers/md/dm-vdo/dm-vdo-target.c:	result = admin->completion.result;
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin_completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void finish_operation_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo_administrator *admin = &completion->vdo->admin;
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_finish_operation(&admin->state, completion->result);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void pre_load_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_load_super_block(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_continue_completion(completion, decode_vdo(vdo));
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void check_may_grow_physical(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, VDO_RETRY_AFTER_REBUILD);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c:	/* Make a copy completion if there isn't one */
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion
drivers/md/dm-vdo/dm-vdo-target.c:static void write_super_block_for_suspend(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_continue_completion(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_save_components(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The sub-task completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void suspend_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_continue_completion(completion,
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_set_completion_result(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_drain_packer(vdo->packer, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		drain_data_vio_pool(vdo->data_vio_pool, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_drain_hash_zones(vdo->hash_zones, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_drain_flusher(vdo->flusher, completion);
drivers/md/dm-vdo/dm-vdo-target.c:					vdo_get_admin_state_code(state), completion);
drivers/md/dm-vdo/dm-vdo-target.c:				    completion);
drivers/md/dm-vdo/dm-vdo-target.c:					   vdo_get_admin_state_code(state), completion);
drivers/md/dm-vdo/dm-vdo-target.c:				     completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_wait_until_not_entering_read_only_mode(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		if (vdo_is_state_suspending(state) || (completion->result != VDO_SUCCESS)) {
drivers/md/dm-vdo/dm-vdo-target.c:		write_super_block_for_suspend(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The sub-task completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void load_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_allow_read_only_mode_entry(completion);
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_set_completion_result(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_repair(completion);
drivers/md/dm-vdo/dm-vdo-target.c:				    completion, NULL);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_save_components(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c:						   completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_scrub_all_unrecovered_slabs(vdo->depot, completion);
drivers/md/dm-vdo/dm-vdo-target.c:					   completion);
drivers/md/dm-vdo/dm-vdo-target.c:		completion->error_handler = NULL;
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_wait_until_not_entering_read_only_mode(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void handle_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:	if (vdo_requeue_completion_if_needed(completion,
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_log_error_strerror(completion->result, "aborting load");
drivers/md/dm-vdo/dm-vdo-target.c:		load_callback(vdo_forget(completion));
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_log_error_strerror(completion->result,
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_enter_read_only_mode(vdo, completion->result);
drivers/md/dm-vdo/dm-vdo-target.c:	completion->result = VDO_READ_ONLY;
drivers/md/dm-vdo/dm-vdo-target.c:	load_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion
drivers/md/dm-vdo/dm-vdo-target.c:static void write_super_block_for_resume(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_save_components(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_launch_completion(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_continue_completion(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void resume_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c:		write_super_block_for_resume(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_allow_read_only_mode_entry(completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_hash_zones(vdo->hash_zones, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_slab_depot(vdo->depot, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_recovery_journal(vdo->recovery_journal, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_block_map(vdo->block_map, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_logical_zones(vdo->logical_zones, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_packer(vdo->packer, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_resume_flusher(vdo->flusher, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		resume_data_vio_pool(vdo->data_vio_pool, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void grow_logical_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_set_completion_result(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_save_components(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_grow_block_map(vdo->block_map, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_enter_read_only_mode(vdo, completion->result);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void handle_logical_growth_error(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:	grow_logical_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo_completion *completion = context;
drivers/md/dm-vdo/dm-vdo-target.c:	vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c: * @parent: The completion to notify when the copy is complete.
drivers/md/dm-vdo/dm-vdo-target.c:			   struct vdo_completion *parent)
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The admin completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void grow_physical_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_set_completion_result(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/dm-vdo-target.c:			vdo_continue_completion(completion, result);
drivers/md/dm-vdo/dm-vdo-target.c:		copy_partition(vdo, VDO_RECOVERY_JOURNAL_PARTITION, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		copy_partition(vdo, VDO_SLAB_SUMMARY_PARTITION, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_save_components(vdo, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_use_new_slabs(vdo->depot, completion);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_enter_read_only_mode(vdo, completion->result);
drivers/md/dm-vdo/dm-vdo-target.c:		vdo_set_completion_result(completion, UDS_BAD_STATE);
drivers/md/dm-vdo/dm-vdo-target.c:	finish_operation_callback(completion);
drivers/md/dm-vdo/dm-vdo-target.c: * @completion: The sub-task completion.
drivers/md/dm-vdo/dm-vdo-target.c:static void handle_physical_growth_error(struct vdo_completion *completion)
drivers/md/dm-vdo/dm-vdo-target.c:	completion->vdo->admin.phase = GROW_PHYSICAL_PHASE_ERROR;
drivers/md/dm-vdo/dm-vdo-target.c:	grow_physical_callback(completion);
drivers/md/dm-vdo/dump.c: * R => vio completion result not VDO_SUCCESS
drivers/md/dm-vdo/dump.c:	if (data_vio->vio.completion.result != VDO_SUCCESS)
drivers/md/dm-vdo/dump.c:	static char vio_completion_dump_buffer[100 + MAX_VDO_WORK_QUEUE_NAME_LEN];
drivers/md/dm-vdo/dump.c:	vdo_dump_completion_to_buffer(&data_vio->vio.completion,
drivers/md/dm-vdo/dump.c:				      vio_completion_dump_buffer,
drivers/md/dm-vdo/dump.c:				      sizeof(vio_completion_dump_buffer));
drivers/md/dm-vdo/dump.c:		     vio_completion_dump_buffer,
drivers/md/dm-vdo/flush.c:#include "completion.h"
drivers/md/dm-vdo/flush.c:	struct vdo_completion completion;
drivers/md/dm-vdo/flush.c: * as_flusher() - Convert a generic vdo_completion to a flusher.
drivers/md/dm-vdo/flush.c: * @completion: The completion to convert.
drivers/md/dm-vdo/flush.c: * Return: The completion as a flusher.
drivers/md/dm-vdo/flush.c:static struct flusher *as_flusher(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	vdo_assert_completion_type(completion, VDO_FLUSH_NOTIFICATION_COMPLETION);
drivers/md/dm-vdo/flush.c:	return container_of(completion, struct flusher, completion);
drivers/md/dm-vdo/flush.c: * completion_as_vdo_flush() - Convert a generic vdo_completion to a vdo_flush.
drivers/md/dm-vdo/flush.c: * @completion: The completion to convert.
drivers/md/dm-vdo/flush.c: * Return: The completion as a vdo_flush.
drivers/md/dm-vdo/flush.c:static inline struct vdo_flush *completion_as_vdo_flush(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	vdo_assert_completion_type(completion, VDO_FLUSH_COMPLETION);
drivers/md/dm-vdo/flush.c:	return container_of(completion, struct vdo_flush, completion);
drivers/md/dm-vdo/flush.c:		vdo_initialize_completion(&flush->completion, flusher->vdo,
drivers/md/dm-vdo/flush.c:					  VDO_FLUSH_COMPLETION);
drivers/md/dm-vdo/flush.c:	vdo_initialize_completion(&vdo->flusher->completion, vdo,
drivers/md/dm-vdo/flush.c:				  VDO_FLUSH_NOTIFICATION_COMPLETION);
drivers/md/dm-vdo/flush.c: * @completion: The flusher completion.
drivers/md/dm-vdo/flush.c:static void finish_notification(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	struct flusher *flusher = as_flusher(completion);
drivers/md/dm-vdo/flush.c: * @completion: The flusher completion.
drivers/md/dm-vdo/flush.c:static void flush_packer_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	struct flusher *flusher = as_flusher(completion);
drivers/md/dm-vdo/flush.c:	vdo_launch_completion_callback(completion, finish_notification,
drivers/md/dm-vdo/flush.c: * @completion: The flusher as a completion.
drivers/md/dm-vdo/flush.c:static void increment_generation(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	struct flusher *flusher = as_flusher(completion);
drivers/md/dm-vdo/flush.c:		vdo_launch_completion_callback(completion, flush_packer_callback,
drivers/md/dm-vdo/flush.c:	vdo_launch_completion_callback(completion, increment_generation,
drivers/md/dm-vdo/flush.c:	flusher->completion.requeue = true;
drivers/md/dm-vdo/flush.c:	vdo_launch_completion_callback(&flusher->completion, increment_generation,
drivers/md/dm-vdo/flush.c: * @completion: A flush request (as a vdo_completion)
drivers/md/dm-vdo/flush.c:static void flush_vdo(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	struct vdo_flush *flush = completion_as_vdo_flush(completion);
drivers/md/dm-vdo/flush.c:	struct flusher *flusher = completion->vdo->flusher;
drivers/md/dm-vdo/flush.c:	struct vdo_completion *completion = &flush->completion;
drivers/md/dm-vdo/flush.c:	vdo_prepare_completion(completion, flush_vdo, flush_vdo,
drivers/md/dm-vdo/flush.c:			       completion->vdo->thread_config.packer_thread, NULL);
drivers/md/dm-vdo/flush.c:	vdo_enqueue_completion(completion, VDO_DEFAULT_Q_FLUSH_PRIORITY);
drivers/md/dm-vdo/flush.c:	struct flusher *flusher = flush->completion.vdo->flusher;
drivers/md/dm-vdo/flush.c: * @completion: The flush request.
drivers/md/dm-vdo/flush.c:static void vdo_complete_flush_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	struct vdo_flush *flush = completion_as_vdo_flush(completion);
drivers/md/dm-vdo/flush.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/flush.c:	struct vdo_completion *completion = &flush->completion;
drivers/md/dm-vdo/flush.c:	vdo_prepare_completion(completion, vdo_complete_flush_callback,
drivers/md/dm-vdo/flush.c:			       select_bio_queue(completion->vdo->flusher), NULL);
drivers/md/dm-vdo/flush.c:	vdo_enqueue_completion(completion, BIO_Q_FLUSH_PRIORITY);
drivers/md/dm-vdo/flush.c: * @completion: The completion to finish when the flusher has drained.
drivers/md/dm-vdo/flush.c:void vdo_drain_flusher(struct flusher *flusher, struct vdo_completion *completion)
drivers/md/dm-vdo/flush.c:	vdo_start_draining(&flusher->state, VDO_ADMIN_STATE_SUSPENDING, completion,
drivers/md/dm-vdo/flush.c: * @parent: The completion to finish when the flusher has resumed.
drivers/md/dm-vdo/flush.c:void vdo_resume_flusher(struct flusher *flusher, struct vdo_completion *parent)
drivers/md/dm-vdo/flush.c:	vdo_continue_completion(parent, vdo_resume_if_quiescent(&flusher->state));
drivers/md/dm-vdo/flush.h:	/* The completion for enqueueing this flush request. */
drivers/md/dm-vdo/flush.h:	struct vdo_completion completion;
drivers/md/dm-vdo/flush.h:void vdo_drain_flusher(struct flusher *flusher, struct vdo_completion *completion);
drivers/md/dm-vdo/flush.h:void vdo_resume_flusher(struct flusher *flusher, struct vdo_completion *parent);
drivers/md/dm-vdo/funnel-workqueue.c:#include <linux/completion.h>
drivers/md/dm-vdo/funnel-workqueue.c:#include "completion.h"
drivers/md/dm-vdo/funnel-workqueue.c:	struct completion *started;
drivers/md/dm-vdo/funnel-workqueue.c:/* Processing normal completions. */
drivers/md/dm-vdo/funnel-workqueue.c: * Dequeue and return the next waiting completion, if any.
drivers/md/dm-vdo/funnel-workqueue.c: * condition where a high-priority completion can be enqueued followed by a lower-priority one, and
drivers/md/dm-vdo/funnel-workqueue.c:static struct vdo_completion *poll_for_completion(struct simple_work_queue *queue)
drivers/md/dm-vdo/funnel-workqueue.c:			return container_of(link, struct vdo_completion, work_queue_entry_link);
drivers/md/dm-vdo/funnel-workqueue.c:static void enqueue_work_queue_completion(struct simple_work_queue *queue,
drivers/md/dm-vdo/funnel-workqueue.c:					  struct vdo_completion *completion)
drivers/md/dm-vdo/funnel-workqueue.c:	VDO_ASSERT_LOG_ONLY(completion->my_queue == NULL,
drivers/md/dm-vdo/funnel-workqueue.c:			    "completion %px (fn %px) to enqueue (%px) is not already queued (%px)",
drivers/md/dm-vdo/funnel-workqueue.c:			    completion, completion->callback, queue, completion->my_queue);
drivers/md/dm-vdo/funnel-workqueue.c:	if (completion->priority == VDO_WORK_Q_DEFAULT_PRIORITY)
drivers/md/dm-vdo/funnel-workqueue.c:		completion->priority = queue->common.type->default_priority;
drivers/md/dm-vdo/funnel-workqueue.c:	if (VDO_ASSERT(completion->priority <= queue->common.type->max_priority,
drivers/md/dm-vdo/funnel-workqueue.c:		completion->priority = 0;
drivers/md/dm-vdo/funnel-workqueue.c:	completion->my_queue = &queue->common;
drivers/md/dm-vdo/funnel-workqueue.c:	vdo_funnel_queue_put(queue->priority_lists[completion->priority],
drivers/md/dm-vdo/funnel-workqueue.c:			     &completion->work_queue_entry_link);
drivers/md/dm-vdo/funnel-workqueue.c: * Wait for the next completion to process, or until kthread_should_stop indicates that it's time
drivers/md/dm-vdo/funnel-workqueue.c: * If kthread_should_stop says it's time to stop but we have pending completions return a
drivers/md/dm-vdo/funnel-workqueue.c: * completion.
drivers/md/dm-vdo/funnel-workqueue.c:static struct vdo_completion *wait_for_next_completion(struct simple_work_queue *queue)
drivers/md/dm-vdo/funnel-workqueue.c:	struct vdo_completion *completion;
drivers/md/dm-vdo/funnel-workqueue.c:		completion = poll_for_completion(queue);
drivers/md/dm-vdo/funnel-workqueue.c:		if (completion != NULL)
drivers/md/dm-vdo/funnel-workqueue.c:		completion = poll_for_completion(queue);
drivers/md/dm-vdo/funnel-workqueue.c:		if (completion != NULL)
drivers/md/dm-vdo/funnel-workqueue.c:	return completion;
drivers/md/dm-vdo/funnel-workqueue.c:static void process_completion(struct simple_work_queue *queue,
drivers/md/dm-vdo/funnel-workqueue.c:			       struct vdo_completion *completion)
drivers/md/dm-vdo/funnel-workqueue.c:	if (VDO_ASSERT(completion->my_queue == &queue->common,
drivers/md/dm-vdo/funnel-workqueue.c:		       "completion %px from queue %px marked as being in this queue (%px)",
drivers/md/dm-vdo/funnel-workqueue.c:		       completion, queue, completion->my_queue) == VDO_SUCCESS)
drivers/md/dm-vdo/funnel-workqueue.c:		completion->my_queue = NULL;
drivers/md/dm-vdo/funnel-workqueue.c:	vdo_run_completion(completion);
drivers/md/dm-vdo/funnel-workqueue.c:		struct vdo_completion *completion = poll_for_completion(queue);
drivers/md/dm-vdo/funnel-workqueue.c:		if (completion == NULL)
drivers/md/dm-vdo/funnel-workqueue.c:			completion = wait_for_next_completion(queue);
drivers/md/dm-vdo/funnel-workqueue.c:		if (completion == NULL) {
drivers/md/dm-vdo/funnel-workqueue.c:			/* No completions but kthread_should_stop() was triggered. */
drivers/md/dm-vdo/funnel-workqueue.c:		process_completion(queue, completion);
drivers/md/dm-vdo/funnel-workqueue.c:	DECLARE_COMPLETION_ONSTACK(started);
drivers/md/dm-vdo/funnel-workqueue.c:	wait_for_completion(&started);
drivers/md/dm-vdo/funnel-workqueue.c: * vdo_make_work_queue() - Create a work queue; if multiple threads are requested, completions will
drivers/md/dm-vdo/funnel-workqueue.c:/* No enqueueing of completions should be done once this function is called. */
drivers/md/dm-vdo/funnel-workqueue.c: * Write to the buffer some info about the completion, for logging. Since the common use case is
drivers/md/dm-vdo/funnel-workqueue.c: * dumping info about a lot of completions to syslog all at once, the format favors brevity over
drivers/md/dm-vdo/funnel-workqueue.c:void vdo_dump_completion_to_buffer(struct vdo_completion *completion, char *buffer,
drivers/md/dm-vdo/funnel-workqueue.c:			  (completion->my_queue == NULL ? "-" : completion->my_queue->name));
drivers/md/dm-vdo/funnel-workqueue.c:		get_function_name((void *) completion->callback, buffer + current_length,
drivers/md/dm-vdo/funnel-workqueue.c:/* Completion submission */
drivers/md/dm-vdo/funnel-workqueue.c: * If the completion has a timeout that has already passed, the timeout handler function may be
drivers/md/dm-vdo/funnel-workqueue.c:			    struct vdo_completion *completion)
drivers/md/dm-vdo/funnel-workqueue.c:		 * multiple completions and migration between cores, unless the load is so light as
drivers/md/dm-vdo/funnel-workqueue.c:	enqueue_work_queue_completion(simple_queue, completion);
drivers/md/dm-vdo/funnel-workqueue.c:	 * been processing a completion, in which case starting to process another would violate
drivers/md/dm-vdo/funnel-workqueue.h:	enum vdo_completion_priority max_priority;
drivers/md/dm-vdo/funnel-workqueue.h:	enum vdo_completion_priority default_priority;
drivers/md/dm-vdo/funnel-workqueue.h:struct vdo_completion;
drivers/md/dm-vdo/funnel-workqueue.h:void vdo_enqueue_work_queue(struct vdo_work_queue *queue, struct vdo_completion *completion);
drivers/md/dm-vdo/funnel-workqueue.h:void vdo_dump_completion_to_buffer(struct vdo_completion *completion, char *buffer,
drivers/md/dm-vdo/io-submitter.c:	struct atomic_statistics *stats = &vio->completion.vdo->stats;
drivers/md/dm-vdo/io-submitter.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/io-submitter.c:void vdo_submit_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/io-submitter.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/io-submitter.c:	struct io_submitter *submitter = vio->completion.vdo->io_submitter;
drivers/md/dm-vdo/io-submitter.c:static void submit_data_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/io-submitter.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/io-submitter.c:	if (vio->completion.priority != vio_merge->completion.priority)
drivers/md/dm-vdo/io-submitter.c:	 * existing completion.
drivers/md/dm-vdo/io-submitter.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/io-submitter.c:	struct vdo_completion *completion = &vio->completion;
drivers/md/dm-vdo/io-submitter.c:	const struct admin_state_code *code = vdo_get_admin_state(completion->vdo);
drivers/md/dm-vdo/io-submitter.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/io-submitter.c:	completion->error_handler = error_handler;
drivers/md/dm-vdo/io-submitter.c:	vdo_set_completion_callback(completion, vdo_submit_vio,
drivers/md/dm-vdo/io-submitter.c:	vdo_launch_completion_with_priority(completion, get_metadata_priority(vio));
drivers/md/dm-vdo/io-submitter.c: *                     completions.
drivers/md/dm-vdo/io-submitter.h:void vdo_submit_vio(struct vdo_completion *completion);
drivers/md/dm-vdo/logical-zone.c:#include "completion.h"
drivers/md/dm-vdo/logical-zone.c: * as_logical_zone() - Convert a generic vdo_completion to a logical_zone.
drivers/md/dm-vdo/logical-zone.c: * @completion: The completion to convert.
drivers/md/dm-vdo/logical-zone.c: * Return: The completion as a logical_zone.
drivers/md/dm-vdo/logical-zone.c:static struct logical_zone *as_logical_zone(struct vdo_completion *completion)
drivers/md/dm-vdo/logical-zone.c:	vdo_assert_completion_type(completion, VDO_GENERATION_FLUSHED_COMPLETION);
drivers/md/dm-vdo/logical-zone.c:	return container_of(completion, struct logical_zone, completion);
drivers/md/dm-vdo/logical-zone.c:	vdo_initialize_completion(&zone->completion, vdo,
drivers/md/dm-vdo/logical-zone.c:				  VDO_GENERATION_FLUSHED_COMPLETION);
drivers/md/dm-vdo/logical-zone.c:			       struct vdo_completion *parent)
drivers/md/dm-vdo/logical-zone.c:			     struct vdo_completion *parent)
drivers/md/dm-vdo/logical-zone.c:				struct vdo_completion *parent)
drivers/md/dm-vdo/logical-zone.c:	vdo_fail_completion(parent, vdo_resume_if_quiescent(&zone->state));
drivers/md/dm-vdo/logical-zone.c:void vdo_resume_logical_zones(struct logical_zones *zones, struct vdo_completion *parent)
drivers/md/dm-vdo/logical-zone.c:static void attempt_generation_complete_notification(struct vdo_completion *completion);
drivers/md/dm-vdo/logical-zone.c: * @completion: The zone completion.
drivers/md/dm-vdo/logical-zone.c:static void notify_flusher(struct vdo_completion *completion)
drivers/md/dm-vdo/logical-zone.c:	struct logical_zone *zone = as_logical_zone(completion);
drivers/md/dm-vdo/logical-zone.c:	vdo_launch_completion_callback(completion,
drivers/md/dm-vdo/logical-zone.c: * @completion: The zone completion.
drivers/md/dm-vdo/logical-zone.c:static void attempt_generation_complete_notification(struct vdo_completion *completion)
drivers/md/dm-vdo/logical-zone.c:	struct logical_zone *zone = as_logical_zone(completion);
drivers/md/dm-vdo/logical-zone.c:	vdo_launch_completion_callback(&zone->completion, notify_flusher,
drivers/md/dm-vdo/logical-zone.c:	attempt_generation_complete_notification(&zone->completion);
drivers/md/dm-vdo/logical-zone.h:	/* The completion for flush notifications */
drivers/md/dm-vdo/logical-zone.h:	struct vdo_completion completion;
drivers/md/dm-vdo/logical-zone.h:			     struct vdo_completion *completion);
drivers/md/dm-vdo/logical-zone.h:			      struct vdo_completion *parent);
drivers/md/dm-vdo/packer.c:#include "completion.h"
drivers/md/dm-vdo/packer.c: * @completion: The compressed write completion.
drivers/md/dm-vdo/packer.c:static void finish_compressed_write(struct vdo_completion *completion)
drivers/md/dm-vdo/packer.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/packer.c:	completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/packer.c:static void handle_compressed_write_error(struct vdo_completion *completion)
drivers/md/dm-vdo/packer.c:	struct data_vio *agent = as_data_vio(completion);
drivers/md/dm-vdo/packer.c:	if (vdo_requeue_completion_if_needed(completion, allocation->zone->thread_id))
drivers/md/dm-vdo/packer.c:	update_vio_error_stats(as_vio(completion),
drivers/md/dm-vdo/packer.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/packer.c:	completion->error_handler = handle_data_vio_error;
drivers/md/dm-vdo/packer.c:	agent->vio.completion.error_handler = handle_compressed_write_error;
drivers/md/dm-vdo/packer.c: * @completion: The data_vio which needs a lock held by a data_vio in the packer. The data_vio's
drivers/md/dm-vdo/packer.c:void vdo_remove_lock_holder_from_packer(struct vdo_completion *completion)
drivers/md/dm-vdo/packer.c:	struct data_vio *data_vio = as_data_vio(completion);
drivers/md/dm-vdo/packer.c: * @completion: The completion to finish when the packer has drained.
drivers/md/dm-vdo/packer.c:void vdo_drain_packer(struct packer *packer, struct vdo_completion *completion)
drivers/md/dm-vdo/packer.c:	vdo_start_draining(&packer->state, VDO_ADMIN_STATE_SUSPENDING, completion,
drivers/md/dm-vdo/packer.c: * @parent: The completion to finish when the packer has resumed.
drivers/md/dm-vdo/packer.c:void vdo_resume_packer(struct packer *packer, struct vdo_completion *parent)
drivers/md/dm-vdo/packer.c:	vdo_continue_completion(parent, vdo_resume_if_quiescent(&packer->state));
drivers/md/dm-vdo/packer.h:void vdo_remove_lock_holder_from_packer(struct vdo_completion *completion);
drivers/md/dm-vdo/packer.h:void vdo_drain_packer(struct packer *packer, struct vdo_completion *completion);
drivers/md/dm-vdo/packer.h:void vdo_resume_packer(struct packer *packer, struct vdo_completion *parent);
drivers/md/dm-vdo/physical-zone.c:#include "completion.h"
drivers/md/dm-vdo/physical-zone.c:	struct vdo_completion *completion = &data_vio->vio.completion;
drivers/md/dm-vdo/physical-zone.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/physical-zone.c:			vdo_set_completion_result(completion, result);
drivers/md/dm-vdo/physical-zone.c:	completion->callback_thread_id = allocation->zone->thread_id;
drivers/md/dm-vdo/physical-zone.c:	vdo_launch_completion(completion);
drivers/md/dm-vdo/recovery-journal.c:#include "completion.h"
drivers/md/dm-vdo/recovery-journal.c: * completion per lock.
drivers/md/dm-vdo/recovery-journal.c:	vdo_launch_completion(&journal->lock_counter.completion);
drivers/md/dm-vdo/recovery-journal.c:	return vdo_is_read_only(journal->flush_vio->completion.vdo);
drivers/md/dm-vdo/recovery-journal.c: * @parent: The completion to notify in order to acknowledge the notification.
drivers/md/dm-vdo/recovery-journal.c:						      struct vdo_completion *parent)
drivers/md/dm-vdo/recovery-journal.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/recovery-journal.c:	vdo_enter_read_only_mode(journal->flush_vio->completion.vdo, error_code);
drivers/md/dm-vdo/recovery-journal.c: * @completion: The journal's flush VIO.
drivers/md/dm-vdo/recovery-journal.c:static void complete_reaping(struct vdo_completion *completion)
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal *journal = completion->parent;
drivers/md/dm-vdo/recovery-journal.c: * @completion: The journal's flush VIO.
drivers/md/dm-vdo/recovery-journal.c:static void handle_flush_error(struct vdo_completion *completion)
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal *journal = completion->parent;
drivers/md/dm-vdo/recovery-journal.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/recovery-journal.c:	enter_journal_read_only_mode(journal, completion->result);
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal *journal = vio->completion.parent;
drivers/md/dm-vdo/recovery-journal.c: * @completion: The lock counter completion.
drivers/md/dm-vdo/recovery-journal.c:static void reap_recovery_journal_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal *journal = (struct recovery_journal *) completion->parent;
drivers/md/dm-vdo/recovery-journal.c:	vdo_initialize_completion(&counter->completion, vdo,
drivers/md/dm-vdo/recovery-journal.c:				  VDO_LOCK_COUNTER_COMPLETION);
drivers/md/dm-vdo/recovery-journal.c:	vdo_prepare_completion(&counter->completion, reap_recovery_journal_callback,
drivers/md/dm-vdo/recovery-journal.c:	journal->flush_vio->completion.callback_thread_id = journal->thread_id;
drivers/md/dm-vdo/recovery-journal.c:		vdo_launch_completion(&data_vio->decrement_completion);
drivers/md/dm-vdo/recovery-journal.c: * @completion: The completion of the VIO writing this block.
drivers/md/dm-vdo/recovery-journal.c:static void complete_write(struct vdo_completion *completion)
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal_block *block = completion->parent;
drivers/md/dm-vdo/recovery-journal.c:static void handle_write_error(struct vdo_completion *completion)
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal_block *block = completion->parent;
drivers/md/dm-vdo/recovery-journal.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/recovery-journal.c:	vdo_log_error_strerror(completion->result,
drivers/md/dm-vdo/recovery-journal.c:	enter_journal_read_only_mode(journal, completion->result);
drivers/md/dm-vdo/recovery-journal.c:	complete_write(completion);
drivers/md/dm-vdo/recovery-journal.c:	struct recovery_journal_block *block = vio->completion.parent;
drivers/md/dm-vdo/recovery-journal.c: * @parent: The completion to notify once the journal is drained.
drivers/md/dm-vdo/recovery-journal.c:				struct vdo_completion *parent)
drivers/md/dm-vdo/recovery-journal.c: * @parent: The completion to finish once the journal is resumed.
drivers/md/dm-vdo/recovery-journal.c:				 struct vdo_completion *parent)
drivers/md/dm-vdo/recovery-journal.c:	vdo_set_completion_result(parent, vdo_resume_if_quiescent(&journal->state));
drivers/md/dm-vdo/recovery-journal.c:		vdo_continue_completion(parent, VDO_READ_ONLY);
drivers/md/dm-vdo/recovery-journal.c:	vdo_launch_completion(parent);
drivers/md/dm-vdo/recovery-journal.h: * less than the on-disk size. Each in-memory block is also a vdo_completion. Each in-memory block
drivers/md/dm-vdo/recovery-journal.h: * the 'commit_completion' and will be woken the next time a full block has committed. If there is
drivers/md/dm-vdo/recovery-journal.h: * 'reap_completion', and will be woken the next time a journal block is reaped.
drivers/md/dm-vdo/recovery-journal.h:	/* The completion for notifying the owner of a lock release */
drivers/md/dm-vdo/recovery-journal.h:	struct vdo_completion completion;
drivers/md/dm-vdo/recovery-journal.h:				struct vdo_completion *parent);
drivers/md/dm-vdo/recovery-journal.h:				 struct vdo_completion *parent);
drivers/md/dm-vdo/repair.c:#include "completion.h"
drivers/md/dm-vdo/repair.c:struct repair_completion {
drivers/md/dm-vdo/repair.c:	/* The completion header */
drivers/md/dm-vdo/repair.c:	struct vdo_completion completion;
drivers/md/dm-vdo/repair.c:	/* number of page completions */
drivers/md/dm-vdo/repair.c:	 * The page completions used for playing the journal into the block map, and, during
drivers/md/dm-vdo/repair.c:	struct vdo_page_completion page_completions[];
drivers/md/dm-vdo/repair.c:static struct numbered_block_mapping *sort_next_heap_element(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c: * as_repair_completion() - Convert a generic completion to a repair_completion.
drivers/md/dm-vdo/repair.c: * @completion: The completion to convert.
drivers/md/dm-vdo/repair.c: * Return: The repair_completion.
drivers/md/dm-vdo/repair.c:static inline struct repair_completion * __must_check
drivers/md/dm-vdo/repair.c:as_repair_completion(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	vdo_assert_completion_type(completion, VDO_REPAIR_COMPLETION);
drivers/md/dm-vdo/repair.c:	return container_of(completion, struct repair_completion, completion);
drivers/md/dm-vdo/repair.c:static void prepare_repair_completion(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:	struct vdo_completion *completion = &repair->completion;
drivers/md/dm-vdo/repair.c:	const struct thread_config *thread_config = &completion->vdo->thread_config;
drivers/md/dm-vdo/repair.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/repair.c:	vdo_set_completion_callback(completion, callback, thread_id);
drivers/md/dm-vdo/repair.c:static void launch_repair_completion(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, callback, zone_type);
drivers/md/dm-vdo/repair.c:	vdo_launch_completion(&repair->completion);
drivers/md/dm-vdo/repair.c:static void uninitialize_vios(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:static void free_repair_completion(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	repair->completion.vdo->block_map->zones[0].page_cache.rebuilding = false;
drivers/md/dm-vdo/repair.c:static void finish_repair(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct vdo_completion *parent = completion->parent;
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	free_repair_completion(vdo_forget(repair));
drivers/md/dm-vdo/repair.c:		vdo_launch_completion(parent);
drivers/md/dm-vdo/repair.c:	 * Now that we've freed the repair completion and its vast array of journal entries, we
drivers/md/dm-vdo/repair.c:	vdo_continue_completion(parent, vdo_allocate_reference_counters(vdo->depot));
drivers/md/dm-vdo/repair.c: * @completion: The repair completion.
drivers/md/dm-vdo/repair.c:static void abort_repair(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct vdo_completion *parent = completion->parent;
drivers/md/dm-vdo/repair.c:	int result = completion->result;
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	if (vdo_state_requires_read_only_rebuild(completion->vdo->load_state))
drivers/md/dm-vdo/repair.c:	free_repair_completion(vdo_forget(repair));
drivers/md/dm-vdo/repair.c:	vdo_continue_completion(parent, result);
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static bool __must_check abort_on_error(int result, struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	vdo_fail_completion(&repair->completion, result);
drivers/md/dm-vdo/repair.c: * @completion: The repair completion.
drivers/md/dm-vdo/repair.c:static void drain_slab_depot(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, finish_repair, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c:	vdo_drain_slab_depot(vdo->depot, operation, completion);
drivers/md/dm-vdo/repair.c: * @completion: The repair completion.
drivers/md/dm-vdo/repair.c:static void flush_block_map_updates(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	vdo_assert_on_admin_thread(completion->vdo, __func__);
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(as_repair_completion(completion), drain_slab_depot,
drivers/md/dm-vdo/repair.c:	vdo_drain_block_map(completion->vdo->block_map, VDO_ADMIN_STATE_RECOVERING,
drivers/md/dm-vdo/repair.c:			    completion);
drivers/md/dm-vdo/repair.c:static bool fetch_page(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:		       struct vdo_completion *completion);
drivers/md/dm-vdo/repair.c: * @completion: The vdo_page_completion.
drivers/md/dm-vdo/repair.c:static void handle_page_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = completion->parent;
drivers/md/dm-vdo/repair.c:	vdo_set_completion_result(&repair->completion, completion->result);
drivers/md/dm-vdo/repair.c:	vdo_release_page_completion(completion);
drivers/md/dm-vdo/repair.c:	fetch_page(repair, completion);
drivers/md/dm-vdo/repair.c: * @completion: The page_completion for writing the page
drivers/md/dm-vdo/repair.c:static void unmap_entry(struct block_map_page *page, struct vdo_completion *completion,
drivers/md/dm-vdo/repair.c:	vdo_request_page_write(completion);
drivers/md/dm-vdo/repair.c: * @completion: The page_completion for writing the page
drivers/md/dm-vdo/repair.c:					 struct vdo_completion *completion,
drivers/md/dm-vdo/repair.c:			unmap_entry(page, completion, slot);
drivers/md/dm-vdo/repair.c: * @completion: The page_completion for writing the page
drivers/md/dm-vdo/repair.c:static bool process_slot(struct block_map_page *page, struct vdo_completion *completion,
drivers/md/dm-vdo/repair.c:	struct slab_depot *depot = completion->vdo->depot;
drivers/md/dm-vdo/repair.c:		unmap_entry(page, completion, slot);
drivers/md/dm-vdo/repair.c:		unmap_entry(page, completion, slot);
drivers/md/dm-vdo/repair.c:	unmap_entry(page, completion, slot);
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c: * @completion: The page completion holding the page.
drivers/md/dm-vdo/repair.c:static void rebuild_reference_counts_from_page(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:					       struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	result = vdo_get_cached_page(completion, &page);
drivers/md/dm-vdo/repair.c:		vdo_set_completion_result(&repair->completion, result);
drivers/md/dm-vdo/repair.c:		remove_out_of_bounds_entries(page, completion, last_slot);
drivers/md/dm-vdo/repair.c:		if (process_slot(page, completion, slot))
drivers/md/dm-vdo/repair.c: * @completion: The vdo_page_completion for the fetched page.
drivers/md/dm-vdo/repair.c:static void page_loaded(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = completion->parent;
drivers/md/dm-vdo/repair.c:	rebuild_reference_counts_from_page(repair, completion);
drivers/md/dm-vdo/repair.c:	vdo_release_page_completion(completion);
drivers/md/dm-vdo/repair.c:	fetch_page(repair, completion);
drivers/md/dm-vdo/repair.c:static physical_block_number_t get_pbn_to_fetch(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:	if (repair->completion.result != VDO_SUCCESS)
drivers/md/dm-vdo/repair.c:	if (vdo_is_physical_data_block(repair->completion.vdo->depot, pbn))
drivers/md/dm-vdo/repair.c:	vdo_set_completion_result(&repair->completion, VDO_BAD_MAPPING);
drivers/md/dm-vdo/repair.c: * @repair: The repair_completion.
drivers/md/dm-vdo/repair.c: * @completion: The page completion to use.
drivers/md/dm-vdo/repair.c:static bool fetch_page(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:		       struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct vdo_page_completion *page_completion = (struct vdo_page_completion *) completion;
drivers/md/dm-vdo/repair.c:	struct block_map *block_map = repair->completion.vdo->block_map;
drivers/md/dm-vdo/repair.c:		vdo_get_page(page_completion, &block_map->zones[0], pbn, true, repair,
drivers/md/dm-vdo/repair.c:	launch_repair_completion(repair, flush_block_map_updates, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c: * @completion: The repair completion.
drivers/md/dm-vdo/repair.c:static void rebuild_from_leaves(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	struct block_map *map = completion->vdo->block_map;
drivers/md/dm-vdo/repair.c:		if (fetch_page(repair, &repair->page_completions[i].completion)) {
drivers/md/dm-vdo/repair.c: * @completion: The parent completion of the traversal.
drivers/md/dm-vdo/repair.c:static int process_entry(physical_block_number_t pbn, struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	struct slab_depot *depot = completion->vdo->depot;
drivers/md/dm-vdo/repair.c:static void rebuild_reference_counts(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:	 * Completion chaining from page cache hits can lead to stack overflow during the rebuild,
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, rebuild_from_leaves, VDO_ZONE_TYPE_LOGICAL);
drivers/md/dm-vdo/repair.c:	vdo_traverse_forest(vdo->block_map, process_entry, completion);
drivers/md/dm-vdo/repair.c: * @repair: The repair_completion whose points are to be advanced.
drivers/md/dm-vdo/repair.c:static void advance_points(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static struct recovery_journal_entry get_entry(const struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:	sector = get_sector(repair->completion.vdo->recovery_journal,
drivers/md/dm-vdo/repair.c: * @completion: The allocator completion.
drivers/md/dm-vdo/repair.c:static void add_slab_journal_entries(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = completion->parent;
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/repair.c:	vdo_prepare_completion(completion, add_slab_journal_entries,
drivers/md/dm-vdo/repair.c:			       completion->callback_thread_id, repair);
drivers/md/dm-vdo/repair.c:				vdo_fail_completion(completion, result);
drivers/md/dm-vdo/repair.c:						  completion))
drivers/md/dm-vdo/repair.c:	vdo_notify_slab_journals_are_recovered(completion);
drivers/md/dm-vdo/repair.c:	struct vdo_completion *completion = &allocator->completion;
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = context;
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:		vdo_notify_slab_journals_are_recovered(completion);
drivers/md/dm-vdo/repair.c:	completion->parent = repair;
drivers/md/dm-vdo/repair.c:	add_slab_journal_entries(completion);
drivers/md/dm-vdo/repair.c:static void load_slab_depot(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	vdo_assert_on_admin_thread(completion->vdo, __func__);
drivers/md/dm-vdo/repair.c:	if (vdo_state_requires_read_only_rebuild(completion->vdo->load_state)) {
drivers/md/dm-vdo/repair.c:		prepare_repair_completion(repair, rebuild_reference_counts,
drivers/md/dm-vdo/repair.c:		prepare_repair_completion(repair, drain_slab_depot, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c:	vdo_load_slab_depot(completion->vdo->depot, operation, completion, repair);
drivers/md/dm-vdo/repair.c:static void flush_block_map(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	vdo_assert_on_admin_thread(completion->vdo, __func__);
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, load_slab_depot, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c:	operation = (vdo_state_requires_read_only_rebuild(completion->vdo->load_state) ?
drivers/md/dm-vdo/repair.c:	vdo_drain_block_map(completion->vdo->block_map, operation, completion);
drivers/md/dm-vdo/repair.c:static bool finish_if_done(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	if (repair->completion.result != VDO_SUCCESS) {
drivers/md/dm-vdo/repair.c:			struct vdo_page_completion *page_completion =
drivers/md/dm-vdo/repair.c:				&repair->page_completions[i];
drivers/md/dm-vdo/repair.c:			if (page_completion->ready)
drivers/md/dm-vdo/repair.c:				vdo_release_page_completion(&page_completion->completion);
drivers/md/dm-vdo/repair.c:		vdo_launch_completion(&repair->completion);
drivers/md/dm-vdo/repair.c:	launch_repair_completion(repair, flush_block_map, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c:static void abort_block_map_recovery(struct repair_completion *repair, int result)
drivers/md/dm-vdo/repair.c:	vdo_set_completion_result(&repair->completion, result);
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:find_entry_starting_next_page(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:static void recover_ready_pages(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:				struct vdo_completion *completion);
drivers/md/dm-vdo/repair.c:static void block_map_page_loaded(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion->parent);
drivers/md/dm-vdo/repair.c:		recover_ready_pages(repair, completion);
drivers/md/dm-vdo/repair.c:static void handle_block_map_page_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion->parent);
drivers/md/dm-vdo/repair.c:	abort_block_map_recovery(repair, completion->result);
drivers/md/dm-vdo/repair.c:static void fetch_block_map_page(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:				 struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	vdo_get_page(((struct vdo_page_completion *) completion),
drivers/md/dm-vdo/repair.c:		     &repair->completion.vdo->block_map->zones[0], pbn, true,
drivers/md/dm-vdo/repair.c:		     &repair->completion, block_map_page_loaded,
drivers/md/dm-vdo/repair.c:static struct vdo_page_completion *get_next_page_completion(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:							    struct vdo_page_completion *completion)
drivers/md/dm-vdo/repair.c:	completion++;
drivers/md/dm-vdo/repair.c:	if (completion == (&repair->page_completions[repair->page_count]))
drivers/md/dm-vdo/repair.c:		completion = &repair->page_completions[0];
drivers/md/dm-vdo/repair.c:	return completion;
drivers/md/dm-vdo/repair.c:static void recover_ready_pages(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:				struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct vdo_page_completion *page_completion = (struct vdo_page_completion *) completion;
drivers/md/dm-vdo/repair.c:	if (repair->pbn != page_completion->pbn)
drivers/md/dm-vdo/repair.c:	while (page_completion->ready) {
drivers/md/dm-vdo/repair.c:		result = vdo_get_cached_page(completion, &page);
drivers/md/dm-vdo/repair.c:		vdo_request_page_write(completion);
drivers/md/dm-vdo/repair.c:		vdo_release_page_completion(completion);
drivers/md/dm-vdo/repair.c:		fetch_block_map_page(repair, completion);
drivers/md/dm-vdo/repair.c:		page_completion = get_next_page_completion(repair, page_completion);
drivers/md/dm-vdo/repair.c:		completion = &page_completion->completion;
drivers/md/dm-vdo/repair.c:static void recover_block_map(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = as_repair_completion(completion);
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/repair.c:		launch_repair_completion(repair, load_slab_depot, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.c:		fetch_block_map_page(repair, &repair->page_completions[i].completion);
drivers/md/dm-vdo/repair.c:	recover_ready_pages(repair, &repair->page_completions[0].completion);
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static bool find_recovery_journal_head_and_tail(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	struct recovery_journal *journal = repair->completion.vdo->recovery_journal;
drivers/md/dm-vdo/repair.c: *                           sector to the array of numbered mappings in the repair completion,
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static void append_sector_entries(struct repair_completion *repair, char *entries,
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = repair->completion.vdo;
drivers/md/dm-vdo/repair.c:static void extract_entries_from_block(struct repair_completion *repair,
drivers/md/dm-vdo/repair.c:static int parse_journal_for_rebuild(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = repair->completion.vdo;
drivers/md/dm-vdo/repair.c:static int validate_heads(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static int extract_new_mappings(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = repair->completion.vdo;
drivers/md/dm-vdo/repair.c: * @repair: The repair completion.
drivers/md/dm-vdo/repair.c:static noinline int compute_usages(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = repair->completion.vdo;
drivers/md/dm-vdo/repair.c:static int parse_journal_for_recovery(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	struct recovery_journal *journal = repair->completion.vdo->recovery_journal;
drivers/md/dm-vdo/repair.c:			vdo_enter_read_only_mode(repair->completion.vdo,
drivers/md/dm-vdo/repair.c:static int parse_journal(struct repair_completion *repair)
drivers/md/dm-vdo/repair.c:	return (vdo_state_requires_read_only_rebuild(repair->completion.vdo->load_state) ?
drivers/md/dm-vdo/repair.c:static void finish_journal_load(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = completion->parent;
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, recover_block_map, VDO_ZONE_TYPE_LOGICAL);
drivers/md/dm-vdo/repair.c:	vdo_continue_completion(&repair->completion, parse_journal(repair));
drivers/md/dm-vdo/repair.c:static void handle_journal_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair = completion->parent;
drivers/md/dm-vdo/repair.c:	vdo_set_completion_result(&repair->completion, completion->result);
drivers/md/dm-vdo/repair.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/repair.c:	completion->callback(completion);
drivers/md/dm-vdo/repair.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/repair.c: * @parent: The completion to notify when the operation is complete
drivers/md/dm-vdo/repair.c:void vdo_repair(struct vdo_completion *parent)
drivers/md/dm-vdo/repair.c:	struct repair_completion *repair;
drivers/md/dm-vdo/repair.c:	result = vdo_allocate_extended(struct repair_completion, page_count,
drivers/md/dm-vdo/repair.c:				       struct vdo_page_completion, __func__,
drivers/md/dm-vdo/repair.c:		vdo_fail_completion(parent, result);
drivers/md/dm-vdo/repair.c:	vdo_initialize_completion(&repair->completion, vdo, VDO_REPAIR_COMPLETION);
drivers/md/dm-vdo/repair.c:	repair->completion.error_handler = abort_repair;
drivers/md/dm-vdo/repair.c:	repair->completion.parent = parent;
drivers/md/dm-vdo/repair.c:	prepare_repair_completion(repair, finish_repair, VDO_ZONE_TYPE_ADMIN);
drivers/md/dm-vdo/repair.h:void vdo_repair(struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.c:#include "completion.h"
drivers/md/dm-vdo/slab-depot.c: * @completion: The write vio.
drivers/md/dm-vdo/slab-depot.c:static void finish_update(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:		container_of(as_vio(completion), struct slab_summary_block, vio);
drivers/md/dm-vdo/slab-depot.c: * @completion: The write VIO.
drivers/md/dm-vdo/slab-depot.c:static void handle_write_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:		container_of(as_vio(completion), struct slab_summary_block, vio);
drivers/md/dm-vdo/slab-depot.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/slab-depot.c:	vdo_enter_read_only_mode(completion->vdo, completion->result);
drivers/md/dm-vdo/slab-depot.c:	if (vdo_is_read_only(block->vio.completion.vdo)) {
drivers/md/dm-vdo/slab-depot.c: * @completion: The flush vio.
drivers/md/dm-vdo/slab-depot.c:static void complete_reaping(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = completion->parent;
drivers/md/dm-vdo/slab-depot.c:			   vio_as_pooled_vio(as_vio(vdo_forget(completion))));
drivers/md/dm-vdo/slab-depot.c: * @completion: The flush vio.
drivers/md/dm-vdo/slab-depot.c:static void handle_flush_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/slab-depot.c:	vdo_enter_read_only_mode(completion->vdo, completion->result);
drivers/md/dm-vdo/slab-depot.c:	complete_reaping(completion);
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = vio->completion.parent;
drivers/md/dm-vdo/slab-depot.c:	vio->completion.parent = journal;
drivers/md/dm-vdo/slab-depot.c: * @completion: The write vio as a completion.
drivers/md/dm-vdo/slab-depot.c:static void complete_write(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	int result = completion->result;
drivers/md/dm-vdo/slab-depot.c:	struct pooled_vio *pooled = vio_as_pooled_vio(as_vio(completion));
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = completion->parent;
drivers/md/dm-vdo/slab-depot.c:		vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = vio->completion.parent;
drivers/md/dm-vdo/slab-depot.c:	vio->completion.parent = journal;
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to notify when there is space to add the entry if the entry could not be
drivers/md/dm-vdo/slab-depot.c:				  struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c: * @completion: The VIO that just finished writing.
drivers/md/dm-vdo/slab-depot.c:static void finish_reference_block_write(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:	struct reference_block *block = completion->parent;
drivers/md/dm-vdo/slab-depot.c:	if (vdo_is_read_only(completion->vdo)) {
drivers/md/dm-vdo/slab-depot.c:	struct reference_block *block = vio->completion.parent;
drivers/md/dm-vdo/slab-depot.c: * @completion: The VIO doing the I/O as a completion.
drivers/md/dm-vdo/slab-depot.c:static void handle_io_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	int result = completion->result;
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:	struct vdo_slab *slab = ((struct reference_block *) completion->parent)->slab;
drivers/md/dm-vdo/slab-depot.c:	struct vdo_completion *completion = &pooled->vio.completion;
drivers/md/dm-vdo/slab-depot.c:	completion->parent = block;
drivers/md/dm-vdo/slab-depot.c:	completion->callback_thread_id = ((struct block_allocator *) pooled->context)->thread_id;
drivers/md/dm-vdo/slab-depot.c:		vdo_continue_completion(&data_vio->decrement_completion, result);
drivers/md/dm-vdo/slab-depot.c: * @completion: The VIO that just finished reading.
drivers/md/dm-vdo/slab-depot.c:static void finish_reference_block_load(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:	struct reference_block *block = completion->parent;
drivers/md/dm-vdo/slab-depot.c:	struct reference_block *block = vio->completion.parent;
drivers/md/dm-vdo/slab-depot.c:	vio->completion.parent = block;
drivers/md/dm-vdo/slab-depot.c:static void finish_loading_journal(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = completion->parent;
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = vio->completion.parent;
drivers/md/dm-vdo/slab-depot.c:static void handle_load_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	int result = completion->result;
drivers/md/dm-vdo/slab-depot.c:	struct slab_journal *journal = completion->parent;
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:	vio->completion.parent = journal;
drivers/md/dm-vdo/slab-depot.c:	vio->completion.callback_thread_id = slab->allocator->thread_id;
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(vdo_forget(scrubber->vio.completion.parent), result);
drivers/md/dm-vdo/slab-depot.c: * @completion: The slab rebuild completion.
drivers/md/dm-vdo/slab-depot.c:static void slab_scrubbed(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:		container_of(as_vio(completion), struct slab_scrubber, vio);
drivers/md/dm-vdo/slab-depot.c:	vdo_enter_read_only_mode(scrubber->vio.completion.vdo, result);
drivers/md/dm-vdo/slab-depot.c: * @completion: The slab rebuild completion.
drivers/md/dm-vdo/slab-depot.c:static void handle_scrubber_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct vio *vio = as_vio(completion);
drivers/md/dm-vdo/slab-depot.c:			completion->result);
drivers/md/dm-vdo/slab-depot.c: * @completion: The metadata read vio completion.
drivers/md/dm-vdo/slab-depot.c:static void apply_journal_entries(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:		container_of(as_vio(completion), struct slab_scrubber, vio);
drivers/md/dm-vdo/slab-depot.c:	vdo_prepare_completion(completion, slab_scrubbed, handle_scrubber_error,
drivers/md/dm-vdo/slab-depot.c:			       slab->allocator->thread_id, completion->parent);
drivers/md/dm-vdo/slab-depot.c:					completion, initiate_slab_action);
drivers/md/dm-vdo/slab-depot.c: * @completion: The scrubber's vio completion.
drivers/md/dm-vdo/slab-depot.c:static void start_scrubbing(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:		container_of(as_vio(completion), struct slab_scrubber, vio);
drivers/md/dm-vdo/slab-depot.c:		slab_scrubbed(completion);
drivers/md/dm-vdo/slab-depot.c:	struct vdo_completion *completion = &scrubber->vio.completion;
drivers/md/dm-vdo/slab-depot.c:	if (vdo_is_read_only(completion->vdo)) {
drivers/md/dm-vdo/slab-depot.c:	vdo_prepare_completion(completion, start_scrubbing, handle_scrubber_error,
drivers/md/dm-vdo/slab-depot.c:			       slab->allocator->thread_id, completion->parent);
drivers/md/dm-vdo/slab-depot.c:					completion, initiate_slab_action);
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to notify when scrubbing is done, implies high_priority, may be NULL.
drivers/md/dm-vdo/slab-depot.c:static void scrub_slabs(struct block_allocator *allocator, struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	scrubber->vio.completion.parent = parent;
drivers/md/dm-vdo/slab-depot.c:	vdo_continue_completion(&data_vio->decrement_completion, VDO_READ_ONLY);
drivers/md/dm-vdo/slab-depot.c:						     struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/slab-depot.c:void vdo_modify_reference_count(struct vdo_completion *completion,
drivers/md/dm-vdo/slab-depot.c:	struct vdo_slab *slab = vdo_get_slab(completion->vdo->depot, updater->zpbn.pbn);
drivers/md/dm-vdo/slab-depot.c:		vdo_continue_completion(completion, VDO_INVALID_ADMIN_STATE);
drivers/md/dm-vdo/slab-depot.c:	if (vdo_is_read_only(completion->vdo)) {
drivers/md/dm-vdo/slab-depot.c:		vdo_continue_completion(completion, VDO_READ_ONLY);
drivers/md/dm-vdo/slab-depot.c:static void slab_action_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:		actor->callback(completion);
drivers/md/dm-vdo/slab-depot.c:	vdo_reset_completion(completion);
drivers/md/dm-vdo/slab-depot.c:static void handle_operation_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:		vdo_set_completion_result(allocator->state.waiter, completion->result);
drivers/md/dm-vdo/slab-depot.c:	completion->callback(completion);
drivers/md/dm-vdo/slab-depot.c:	vdo_prepare_completion(&allocator->completion, slab_action_callback,
drivers/md/dm-vdo/slab-depot.c:	allocator->completion.requeue = false;
drivers/md/dm-vdo/slab-depot.c:						&allocator->completion,
drivers/md/dm-vdo/slab-depot.c:	slab_action_callback(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:static void finish_loading_allocator(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(&allocator->completion, result);
drivers/md/dm-vdo/slab-depot.c:		vdo_finish_completion(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:		vdo_prepare_completion_for_requeue(&allocator->completion,
drivers/md/dm-vdo/slab-depot.c:			vdo_fail_completion(&allocator->completion,
drivers/md/dm-vdo/slab-depot.c: * @completion The allocator completion
drivers/md/dm-vdo/slab-depot.c:void vdo_notify_slab_journals_are_recovered(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_loading_with_result(&allocator->state, completion->result);
drivers/md/dm-vdo/slab-depot.c:				     struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/slab-depot.c:static void prepare_for_tail_block_commit(void *context, struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/slab-depot.c:	result = allocate_vio_components(allocator->completion.vdo,
drivers/md/dm-vdo/slab-depot.c:	vdo_initialize_completion(&allocator->completion, vdo, VDO_BLOCK_ALLOCATOR_COMPLETION);
drivers/md/dm-vdo/slab-depot.c: * @completion: The vio which was used to write the summary data.
drivers/md/dm-vdo/slab-depot.c:static void finish_combining_zones(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	int result = completion->result;
drivers/md/dm-vdo/slab-depot.c:	struct vdo_completion *parent = completion->parent;
drivers/md/dm-vdo/slab-depot.c:	free_vio(as_vio(vdo_forget(completion)));
drivers/md/dm-vdo/slab-depot.c:	vdo_fail_completion(parent, result);
drivers/md/dm-vdo/slab-depot.c:static void handle_combining_error(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/slab-depot.c:	finish_combining_zones(completion);
drivers/md/dm-vdo/slab-depot.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/slab-depot.c: * @completion: The vio which was used to read the summary data.
drivers/md/dm-vdo/slab-depot.c:static void finish_loading_summary(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct slab_depot *depot = completion->vdo->depot;
drivers/md/dm-vdo/slab-depot.c:	vdo_submit_metadata_vio(as_vio(completion), depot->summary_origin,
drivers/md/dm-vdo/slab-depot.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/slab-depot.c:static void load_slab_summary(void *context, struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(parent, result);
drivers/md/dm-vdo/slab-depot.c:		finish_loading_summary(&vio->completion);
drivers/md/dm-vdo/slab-depot.c:			   struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to notify when the load is complete.
drivers/md/dm-vdo/slab-depot.c:			 struct vdo_completion *parent, void *context)
drivers/md/dm-vdo/slab-depot.c:				struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(parent, result);
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to notify when the operation is complete.
drivers/md/dm-vdo/slab-depot.c:					struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:			       struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_completion(parent);
drivers/md/dm-vdo/slab-depot.c:void vdo_use_new_slabs(struct slab_depot *depot, struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to notify when scrubbing has stopped.
drivers/md/dm-vdo/slab-depot.c:		vdo_finish_completion(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:				   &allocator->completion, NULL);
drivers/md/dm-vdo/slab-depot.c:static void do_drain_step(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:	vdo_prepare_completion_for_requeue(&allocator->completion, do_drain_step,
drivers/md/dm-vdo/slab-depot.c:				   completion, initiate_summary_drain);
drivers/md/dm-vdo/slab-depot.c:		vdo_finish_draining_with_result(&allocator->state, completion->result);
drivers/md/dm-vdo/slab-depot.c:	do_drain_step(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:			    struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to finish when the drain is complete.
drivers/md/dm-vdo/slab-depot.c:			  struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:		vdo_finish_completion(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(&allocator->completion, result);
drivers/md/dm-vdo/slab-depot.c:	vdo_finish_completion(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:static void do_resume_step(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.c:	struct block_allocator *allocator = vdo_as_block_allocator(completion);
drivers/md/dm-vdo/slab-depot.c:	vdo_prepare_completion_for_requeue(&allocator->completion, do_resume_step,
drivers/md/dm-vdo/slab-depot.c:		vdo_fail_completion(completion,
drivers/md/dm-vdo/slab-depot.c:		vdo_finish_resuming_with_result(&allocator->state, completion->result);
drivers/md/dm-vdo/slab-depot.c:	do_resume_step(&allocator->completion);
drivers/md/dm-vdo/slab-depot.c:			     struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c: * @parent: The completion to finish when the depot has resumed.
drivers/md/dm-vdo/slab-depot.c:void vdo_resume_slab_depot(struct slab_depot *depot, struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:		vdo_continue_completion(parent, VDO_READ_ONLY);
drivers/md/dm-vdo/slab-depot.c:					struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.c:	vdo_launch_completion(parent);
drivers/md/dm-vdo/slab-depot.c:				     struct vdo_completion *parent)
drivers/md/dm-vdo/slab-depot.h:#include "completion.h"
drivers/md/dm-vdo/slab-depot.h:	struct vdo_completion completion;
drivers/md/dm-vdo/slab-depot.h:					       struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.h:static inline struct block_allocator *vdo_as_block_allocator(struct vdo_completion *completion)
drivers/md/dm-vdo/slab-depot.h:	vdo_assert_completion_type(completion, VDO_BLOCK_ALLOCATOR_COMPLETION);
drivers/md/dm-vdo/slab-depot.h:	return container_of(completion, struct block_allocator, completion);
drivers/md/dm-vdo/slab-depot.h:void vdo_modify_reference_count(struct vdo_completion *completion,
drivers/md/dm-vdo/slab-depot.h:void vdo_notify_slab_journals_are_recovered(struct vdo_completion *completion);
drivers/md/dm-vdo/slab-depot.h:			 struct vdo_completion *parent, void *context);
drivers/md/dm-vdo/slab-depot.h:					struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.h:void vdo_use_new_slabs(struct slab_depot *depot, struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.h:			  struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.h:void vdo_resume_slab_depot(struct slab_depot *depot, struct vdo_completion *parent);
drivers/md/dm-vdo/slab-depot.h:				     struct vdo_completion *parent);
drivers/md/dm-vdo/thread-utils.c:	struct completion thread_done;
drivers/md/dm-vdo/thread-utils.c:	init_completion(&thread->thread_done);
drivers/md/dm-vdo/thread-utils.c:	while (wait_for_completion_interruptible(&thread->thread_done))
drivers/md/dm-vdo/types.h:enum vdo_completion_type {
drivers/md/dm-vdo/types.h:	/* Keep VDO_UNSET_COMPLETION_TYPE at the top. */
drivers/md/dm-vdo/types.h:	VDO_UNSET_COMPLETION_TYPE,
drivers/md/dm-vdo/types.h:	VDO_ACTION_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_ADMIN_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_BLOCK_ALLOCATOR_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_DATA_VIO_POOL_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_DECREMENT_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_FLUSH_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_FLUSH_NOTIFICATION_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_GENERATION_FLUSHED_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_HASH_ZONE_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_HASH_ZONES_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_LOCK_COUNTER_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_PAGE_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_READ_ONLY_MODE_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_REPAIR_COMPLETION,
drivers/md/dm-vdo/types.h:	VDO_SYNC_COMPLETION,
drivers/md/dm-vdo/types.h:	VIO_COMPLETION,
drivers/md/dm-vdo/types.h:struct vdo_completion;
drivers/md/dm-vdo/types.h: * @completion: The completion of the operation.
drivers/md/dm-vdo/types.h:typedef void (*vdo_action_fn)(struct vdo_completion *completion);
drivers/md/dm-vdo/types.h:enum vdo_completion_priority {
drivers/md/dm-vdo/types.h:	VDO_DEFAULT_Q_COMPLETION_PRIORITY = 1,
drivers/md/dm-vdo/types.h:struct vdo_completion {
drivers/md/dm-vdo/types.h:	/* The type of completion this is */
drivers/md/dm-vdo/types.h:	enum vdo_completion_type type;
drivers/md/dm-vdo/types.h:	 * If true, queue this completion on the next callback invocation, even if it is already
drivers/md/dm-vdo/types.h:	/* The VDO on which this completion operates */
drivers/md/dm-vdo/types.h:	/* The parent object, if any, that spawned this completion */
drivers/md/dm-vdo/types.h:	enum vdo_completion_priority priority;
drivers/md/dm-vdo/types.h:	/* The completion for this vio */
drivers/md/dm-vdo/types.h:	struct vdo_completion completion;
drivers/md/dm-vdo/types.h:	 * are not added to the work queue as separate completions.
drivers/md/dm-vdo/vdo.c: * A read_only_notifier has a single completion which is used to perform read-only notifications,
drivers/md/dm-vdo/vdo.c:#include <linux/completion.h>
drivers/md/dm-vdo/vdo.c:#include "completion.h"
drivers/md/dm-vdo/vdo.c:struct sync_completion {
drivers/md/dm-vdo/vdo.c:	struct vdo_completion vdo_completion;
drivers/md/dm-vdo/vdo.c:	struct completion completion;
drivers/md/dm-vdo/vdo.c:	.default_priority = VDO_DEFAULT_Q_COMPLETION_PRIORITY,
drivers/md/dm-vdo/vdo.c: * config, and completions can be enqueued to the queue and run on the threads comprising this
drivers/md/dm-vdo/vdo.c:	vdo_initialize_completion(&vdo->admin.completion, vdo, VDO_ADMIN_COMPLETION);
drivers/md/dm-vdo/vdo.c:	init_completion(&vdo->admin.callback_sync);
drivers/md/dm-vdo/vdo.c: * @completion: The super block vio.
drivers/md/dm-vdo/vdo.c:static void finish_reading_super_block(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:		container_of(as_vio(completion), struct vdo_super_block, vio);
drivers/md/dm-vdo/vdo.c:	vdo_continue_completion(vdo_forget(completion->parent),
drivers/md/dm-vdo/vdo.c: * @completion: The super block vio.
drivers/md/dm-vdo/vdo.c:static void handle_super_block_read_error(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	vio_record_metadata_io_error(as_vio(completion));
drivers/md/dm-vdo/vdo.c:	finish_reading_super_block(completion);
drivers/md/dm-vdo/vdo.c:	struct vdo_completion *parent = vio->completion.parent;
drivers/md/dm-vdo/vdo.c: * @parent: The completion to notify after loading the super block.
drivers/md/dm-vdo/vdo.c:void vdo_load_super_block(struct vdo *vdo, struct vdo_completion *parent)
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(parent, result);
drivers/md/dm-vdo/vdo.c:	vdo->super_block.vio.completion.parent = parent;
drivers/md/dm-vdo/vdo.c: * @completion: The super block vio.
drivers/md/dm-vdo/vdo.c:static void continue_super_block_parent(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	vdo_continue_completion(vdo_forget(completion->parent), completion->result);
drivers/md/dm-vdo/vdo.c: * @completion: The super block vio.
drivers/md/dm-vdo/vdo.c:static void handle_save_error(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:		container_of(as_vio(completion), struct vdo_super_block, vio);
drivers/md/dm-vdo/vdo.c:	vdo_log_error_strerror(completion->result, "super block save failed");
drivers/md/dm-vdo/vdo.c:	completion->callback(completion);
drivers/md/dm-vdo/vdo.c:	struct vdo_completion *parent = vio->completion.parent;
drivers/md/dm-vdo/vdo.c: * @parent: The completion to notify when the save is complete.
drivers/md/dm-vdo/vdo.c:void vdo_save_components(struct vdo *vdo, struct vdo_completion *parent)
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(parent, VDO_READ_ONLY);
drivers/md/dm-vdo/vdo.c:	if (super_block->vio.completion.parent != NULL) {
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(parent, VDO_COMPONENT_BUSY);
drivers/md/dm-vdo/vdo.c:	super_block->vio.completion.parent = parent;
drivers/md/dm-vdo/vdo.c:	super_block->vio.completion.callback_thread_id = parent->callback_thread_id;
drivers/md/dm-vdo/vdo.c: * @parent: The completion to notify in order to acknowledge the notification.
drivers/md/dm-vdo/vdo.c:static void notify_vdo_of_read_only_mode(void *listener, struct vdo_completion *parent)
drivers/md/dm-vdo/vdo.c:		vdo_finish_completion(parent);
drivers/md/dm-vdo/vdo.c:	vdo_initialize_completion(&notifier->completion, vdo,
drivers/md/dm-vdo/vdo.c:				  VDO_READ_ONLY_MODE_COMPLETION);
drivers/md/dm-vdo/vdo.c: * @parent: The completion to notify when no threads are entering read-only mode.
drivers/md/dm-vdo/vdo.c:void vdo_wait_until_not_entering_read_only_mode(struct vdo_completion *parent)
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(parent, VDO_COMPONENT_BUSY);
drivers/md/dm-vdo/vdo.c:		vdo_launch_completion(parent);
drivers/md/dm-vdo/vdo.c: * as_notifier() - Convert a generic vdo_completion to a read_only_notifier.
drivers/md/dm-vdo/vdo.c: * @completion: The completion to convert.
drivers/md/dm-vdo/vdo.c: * Return: The completion as a read_only_notifier.
drivers/md/dm-vdo/vdo.c:static inline struct read_only_notifier *as_notifier(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	vdo_assert_completion_type(completion, VDO_READ_ONLY_MODE_COMPLETION);
drivers/md/dm-vdo/vdo.c:	return container_of(completion, struct read_only_notifier, completion);
drivers/md/dm-vdo/vdo.c: * @completion: The read-only mode completion.
drivers/md/dm-vdo/vdo.c:static void finish_entering_read_only_mode(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	struct read_only_notifier *notifier = as_notifier(completion);
drivers/md/dm-vdo/vdo.c:	vdo_assert_on_admin_thread(completion->vdo, __func__);
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(vdo_forget(notifier->waiter),
drivers/md/dm-vdo/vdo.c:					completion->result);
drivers/md/dm-vdo/vdo.c: * @completion: The read-only mode completion.
drivers/md/dm-vdo/vdo.c:static void make_thread_read_only(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/vdo.c:	thread_id_t thread_id = completion->callback_thread_id;
drivers/md/dm-vdo/vdo.c:	struct read_only_notifier *notifier = as_notifier(completion);
drivers/md/dm-vdo/vdo.c:	struct read_only_listener *listener = completion->parent;
drivers/md/dm-vdo/vdo.c:		vdo_prepare_completion(completion, make_thread_read_only,
drivers/md/dm-vdo/vdo.c:		listener->notify(listener->listener, completion);
drivers/md/dm-vdo/vdo.c:		vdo_prepare_completion(completion, finish_entering_read_only_mode,
drivers/md/dm-vdo/vdo.c:		vdo_prepare_completion(completion, make_thread_read_only,
drivers/md/dm-vdo/vdo.c:	vdo_launch_completion(completion);
drivers/md/dm-vdo/vdo.c:void vdo_allow_read_only_mode_entry(struct vdo_completion *parent)
drivers/md/dm-vdo/vdo.c:		vdo_continue_completion(parent, VDO_COMPONENT_BUSY);
drivers/md/dm-vdo/vdo.c:		vdo_launch_completion(parent);
drivers/md/dm-vdo/vdo.c:	make_thread_read_only(&notifier->completion);
drivers/md/dm-vdo/vdo.c:	vdo_launch_completion_callback(&notifier->completion, make_thread_read_only, 0);
drivers/md/dm-vdo/vdo.c: * @completion: The sync completion.
drivers/md/dm-vdo/vdo.c:static void complete_synchronous_action(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	vdo_assert_completion_type(completion, VDO_SYNC_COMPLETION);
drivers/md/dm-vdo/vdo.c:	complete(&(container_of(completion, struct sync_completion,
drivers/md/dm-vdo/vdo.c:				vdo_completion)->completion));
drivers/md/dm-vdo/vdo.c: * @parent: The parent of the sync completion (may be NULL).
drivers/md/dm-vdo/vdo.c:	struct sync_completion sync;
drivers/md/dm-vdo/vdo.c:	vdo_initialize_completion(&sync.vdo_completion, vdo, VDO_SYNC_COMPLETION);
drivers/md/dm-vdo/vdo.c:	init_completion(&sync.completion);
drivers/md/dm-vdo/vdo.c:	sync.vdo_completion.parent = parent;
drivers/md/dm-vdo/vdo.c:	vdo_launch_completion_callback(&sync.vdo_completion, action, thread_id);
drivers/md/dm-vdo/vdo.c:	wait_for_completion(&sync.completion);
drivers/md/dm-vdo/vdo.c:	return sync.vdo_completion.result;
drivers/md/dm-vdo/vdo.c: * @completion: The completion.
drivers/md/dm-vdo/vdo.c:static void set_compression_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	struct vdo *vdo = completion->vdo;
drivers/md/dm-vdo/vdo.c:	bool *enable = completion->parent;
drivers/md/dm-vdo/vdo.c:	complete_synchronous_action(completion);
drivers/md/dm-vdo/vdo.c: * @completion: The completion.
drivers/md/dm-vdo/vdo.c:static void vdo_fetch_statistics_callback(struct vdo_completion *completion)
drivers/md/dm-vdo/vdo.c:	get_vdo_statistics(completion->vdo, completion->parent);
drivers/md/dm-vdo/vdo.c:	complete_synchronous_action(completion);
drivers/md/dm-vdo/vdo.c: * vdo_get_callback_thread_id() - Get the id of the callback thread on which a completion is
drivers/md/dm-vdo/vdo.h:#include <linux/completion.h>
drivers/md/dm-vdo/vdo.h: * @parent: The completion to notify in order to acknowledge the notification.
drivers/md/dm-vdo/vdo.h:typedef void (*vdo_read_only_notification_fn)(void *listener, struct vdo_completion *parent);
drivers/md/dm-vdo/vdo.h:	/* The completion for entering read-only mode */
drivers/md/dm-vdo/vdo.h:	struct vdo_completion completion;
drivers/md/dm-vdo/vdo.h:	/* A completion waiting for notifications to be drained or enabled */
drivers/md/dm-vdo/vdo.h:	struct vdo_completion *waiter;
drivers/md/dm-vdo/vdo.h:	struct vdo_completion completion;
drivers/md/dm-vdo/vdo.h:	struct completion callback_sync;
drivers/md/dm-vdo/vdo.h:	struct vdo_completion *completion;
drivers/md/dm-vdo/vdo.h:void vdo_load_super_block(struct vdo *vdo, struct vdo_completion *parent);
drivers/md/dm-vdo/vdo.h:void vdo_save_components(struct vdo *vdo, struct vdo_completion *parent);
drivers/md/dm-vdo/vdo.h:void vdo_wait_until_not_entering_read_only_mode(struct vdo_completion *parent);
drivers/md/dm-vdo/vdo.h:void vdo_allow_read_only_mode_entry(struct vdo_completion *parent);
drivers/md/dm-vdo/vio.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/vio.c:	vio->completion.parent = parent;
drivers/md/dm-vdo/vio.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/vio.c:	struct vdo *vdo = vio->completion.vdo;
drivers/md/dm-vdo/vio.c:	switch (vio->completion.result) {
drivers/md/dm-vdo/vio.c:	vdo_vlog_strerror(priority, vio->completion.result, VDO_LOGGING_MODULE_NAME,
drivers/md/dm-vdo/vio.c:	vio->vio.completion.error_handler = NULL;
drivers/md/dm-vdo/vio.c:	vio->vio.completion.parent = NULL;
drivers/md/dm-vdo/vio.c:	struct atomic_statistics *stats = &vio->completion.vdo->stats;
drivers/md/dm-vdo/vio.c:	atomic64_inc(&vio->completion.vdo->stats.bios_completed);
drivers/md/dm-vdo/vio.h:#include "completion.h"
drivers/md/dm-vdo/vio.h: * as_vio() - Convert a generic vdo_completion to a vio.
drivers/md/dm-vdo/vio.h: * @completion: The completion to convert.
drivers/md/dm-vdo/vio.h: * Return: The completion as a vio.
drivers/md/dm-vdo/vio.h:static inline struct vio *as_vio(struct vdo_completion *completion)
drivers/md/dm-vdo/vio.h:	vdo_assert_completion_type(completion, VIO_COMPLETION);
drivers/md/dm-vdo/vio.h:	return container_of(completion, struct vio, completion);
drivers/md/dm-vdo/vio.h:	return vio->completion.vdo->thread_config.bio_threads[vio->bio_zone];
drivers/md/dm-vdo/vio.h:	vdo_initialize_completion(&vio->completion, vdo, VIO_COMPLETION);
drivers/md/dm-vdo/vio.h:static inline enum vdo_completion_priority get_metadata_priority(struct vio *vio)
drivers/md/dm-vdo/vio.h:		vdo_set_completion_result(&vio->completion, result);
drivers/md/dm-vdo/vio.h:	vdo_enqueue_completion(&vio->completion, VDO_WORK_Q_DEFAULT_PRIORITY);
drivers/md/dm-vdo/vio.h:	vdo_set_completion_callback(&vio->completion, callback, thread);
drivers/md/dm-verity-target.c:	 * Using WQ_HIGHPRI improves throughput and completion latency by
drivers/md/dm-writecache.c:	struct completion c;
drivers/md/dm-writecache.c:		COMPLETION_INITIALIZER_ONSTACK(endio.c),
drivers/md/dm-writecache.c:	wait_for_completion_io(&endio.c);
drivers/md/dm-zone.c: * IO completion callback called from clone_endio().
drivers/md/dm-zoned-metadata.c:	/* Wait for completion */
drivers/md/dm-zoned-target.c: * Target BIO completion.
drivers/md/dm-zoned-target.c: * Completion callback for an internally cloned target BIO. This terminates the
drivers/md/dm.c:	/* one ref is for submission, the other is for completion */
drivers/md/dm.c:		/* tell block layer to poll for completion */
drivers/md/dm.c:	init_completion(&md->kobj_holder.completion);
drivers/md/dm.c:static int dm_wait_for_bios_completion(struct mapped_device *md, unsigned int task_state)
drivers/md/dm.c:static int dm_wait_for_completion(struct mapped_device *md, unsigned int task_state)
drivers/md/dm.c:		return dm_wait_for_bios_completion(md, task_state);
drivers/md/dm.c:	 * We call dm_wait_for_completion to wait for all existing requests
drivers/md/dm.c:	r = dm_wait_for_completion(md, task_state);
drivers/md/dm.c:	dm_wait_for_completion(md, TASK_UNINTERRUPTIBLE);
drivers/md/dm.h:#include <linux/completion.h>
drivers/md/md-bitmap.c:	struct completion *done;
drivers/md/md-bitmap.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/md/md-bitmap.c:	wait_for_completion(&done);
drivers/md/md-cluster.c:	struct completion completion;
drivers/md/md-cluster.c:	struct completion newdisk_completion;
drivers/md/md-cluster.c:		 * cancel the request and reset completion
drivers/md/md-cluster.c:	/* completion is only need to be complete when node join cluster,
drivers/md/md-cluster.c:		complete(&cinfo->completion);
drivers/md/md-cluster.c:	init_completion(&cinfo->newdisk_completion);
drivers/md/md-cluster.c:	if (!wait_for_completion_timeout(&cinfo->newdisk_completion,
drivers/md/md-cluster.c:	init_completion(&cinfo->completion);
drivers/md/md-cluster.c:	wait_for_completion(&cinfo->completion);
drivers/md/md-cluster.c:	complete(&cinfo->newdisk_completion);
drivers/md/md.c:	 * and decrement it on completion, waking up sb_wait
drivers/md/raid1.c: * Update disk head position estimator based on IRQ completion info.
drivers/md/raid10.c: * Update disk head position estimator based on IRQ completion info.
drivers/md/raid10.c: * completion handlers update this position correctly. If there is no
drivers/md/raid5.c:		/* acknowledge completion of a biofill operation */
drivers/md/raid5.c:		break; /* we will be called again upon completion */
drivers/md/raid5.c:		break; /* we will be called again upon completion */
drivers/md/raid5.h: *  Want  -> Clean  - on successful completion of read request
drivers/md/raid5.h: *  Dirty -> Clean  - on successful completion of write request
drivers/media/cec/core/cec-adap.c:	init_completion(&data->c);
drivers/media/cec/core/cec-adap.c:	/* All done if we don't need to block waiting for completion */
drivers/media/cec/core/cec-adap.c:	err = wait_for_completion_killable(&data->c);
drivers/media/cec/core/cec-adap.c:	complete(&adap->config_completion);
drivers/media/cec/core/cec-adap.c:	complete(&adap->config_completion);
drivers/media/cec/core/cec-adap.c:	init_completion(&adap->config_completion);
drivers/media/cec/core/cec-adap.c:		wait_for_completion(&adap->config_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:#include <linux/completion.h>
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:		init_completion(&port->cmd_done);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:		init_completion(&extron->cmd_done);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:	    !wait_for_completion_timeout(port ? &port->cmd_done : &extron->cmd_done, timeout)) {
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:		wait_for_completion_killable_timeout(&extron->edid_completion,
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:			complete(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:		complete(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:	complete(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:	complete(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:	complete(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.c:	init_completion(&extron->edid_completion);
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.h:	struct completion cmd_done;
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.h:	struct completion edid_completion;
drivers/media/cec/usb/extron-da-hd-4k-plus/extron-da-hd-4k-plus.h:	struct completion cmd_done;
drivers/media/cec/usb/pulse8/pulse8-cec.c:#include <linux/completion.h>
drivers/media/cec/usb/pulse8/pulse8-cec.c:	struct completion cmd_done;
drivers/media/cec/usb/pulse8/pulse8-cec.c:	init_completion(&pulse8->cmd_done);
drivers/media/cec/usb/pulse8/pulse8-cec.c:	if (!wait_for_completion_timeout(&pulse8->cmd_done, HZ))
drivers/media/cec/usb/rainshadow/rainshadow-cec.c:#include <linux/completion.h>
drivers/media/cec/usb/rainshadow/rainshadow-cec.c:	struct completion cmd_done;
drivers/media/cec/usb/rainshadow/rainshadow-cec.c:	init_completion(&rain->cmd_done);
drivers/media/cec/usb/rainshadow/rainshadow-cec.c:	if (!wait_for_completion_timeout(&rain->cmd_done, HZ)) {
drivers/media/common/saa7146/saa7146_core.c:			DEB_S("%s: %s timed out while waiting for transfer completion\n",
drivers/media/common/saa7146/saa7146_core.c:			DEB_S("%s: %s timed out while waiting for transfer completion\n",
drivers/media/common/siano/smscoreapi.c:	/* init completion events */
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->version_ex_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->data_download_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->data_validity_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->trigger_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->init_device_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->reload_start_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->resume_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->gpio_configuration_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->gpio_set_level_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->gpio_get_level_done);
drivers/media/common/siano/smscoreapi.c:	init_completion(&dev->ir_init_done);
drivers/media/common/siano/smscoreapi.c:		void *buffer, size_t size, struct completion *completion) {
drivers/media/common/siano/smscoreapi.c:	if (!completion)
drivers/media/common/siano/smscoreapi.c:	init_completion(completion);
drivers/media/common/siano/smscoreapi.c:	return wait_for_completion_timeout(completion,
drivers/media/common/siano/smscoreapi.c:		if (wait_for_completion_timeout(&coredev->resume_done,
drivers/media/common/siano/smscoreapi.h:	struct completion version_ex_done, data_download_done, trigger_done;
drivers/media/common/siano/smscoreapi.h:	struct completion data_validity_done, device_ready_done;
drivers/media/common/siano/smscoreapi.h:	struct completion init_device_done, reload_start_done, resume_done;
drivers/media/common/siano/smscoreapi.h:	struct completion gpio_configuration_done, gpio_set_level_done;
drivers/media/common/siano/smscoreapi.h:	struct completion gpio_get_level_done, ir_init_done;
drivers/media/common/siano/smsdvb-main.c:					struct completion *completion)
drivers/media/common/siano/smsdvb-main.c:	return wait_for_completion_timeout(completion,
drivers/media/common/siano/smsdvb-main.c:	init_completion(&client->tune_done);
drivers/media/common/siano/smsdvb-main.c:	init_completion(&client->stats_done);
drivers/media/common/siano/smsdvb.h:	struct completion       tune_done;
drivers/media/common/siano/smsdvb.h:	struct completion       stats_done;
drivers/media/dvb-frontends/drxk_hard.h:	struct completion fw_wait_load;
drivers/media/dvb-frontends/mt352.c:	 * completion of the read operation is indicated by bit-5 of the
drivers/media/dvb-frontends/stv0367.c:	/*wait for counting completion*/
drivers/media/dvb-frontends/stv0367.c:	/*wait for counting completion*/
drivers/media/i2c/mt9m114.c:		dev_err(&sensor->client->dev, "Command %u completion timeout\n",
drivers/media/i2c/ov2640.c:#define VHYX        0x55 /* Offset and size completion */
drivers/media/i2c/ov2640.c:#define TEST        0x57 /* Horizontal size completion */
drivers/media/i2c/ov2640.c:#define ZMHH        0x5C /* Zoom: Speed and H&W completion */
drivers/media/i2c/ov2640.c:#define SIZEL       0x8C /* Image Size Completion */
drivers/media/i2c/ov5675.c:	 * completion before initiating our first I2C transaction.
drivers/media/pci/bt8xx/bttv-input.c:		/* set timer_end for code completion */
drivers/media/pci/cx18/cx23418.h:/* The MSB of the command code indicates that this is the completion of a
drivers/media/pci/ddbridge/ddbridge-i2c.c:	stat = wait_for_completion_timeout(&i2c->completion, HZ);
drivers/media/pci/ddbridge/ddbridge-i2c.c:	complete(&i2c->completion);
drivers/media/pci/ddbridge/ddbridge-i2c.c:	init_completion(&i2c->completion);
drivers/media/pci/ddbridge/ddbridge-mci.c:	stat = wait_for_completion_timeout(&state->base->completion, HZ);
drivers/media/pci/ddbridge/ddbridge-mci.c:	complete(&base->completion);
drivers/media/pci/ddbridge/ddbridge-mci.c:		init_completion(&base->completion);
drivers/media/pci/ddbridge/ddbridge-mci.h:	struct completion    completion;
drivers/media/pci/ddbridge/ddbridge.h:#include <linux/completion.h>
drivers/media/pci/ddbridge/ddbridge.h:	struct completion      completion;
drivers/media/pci/intel/ipu3/ipu3-cio2.c:	 * Request interrupts for start and completion
drivers/media/pci/intel/ipu3/ipu3-cio2.h: * Interrupt on completion bit, Eg. DMA 0-3 maps to bit 0-3,
drivers/media/pci/intel/ipu6/ipu6-buttress.c:#include <linux/completion.h>
drivers/media/pci/intel/ipu6/ipu6-buttress.c:		reinit_completion(&ipc->send_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.c:			reinit_completion(&ipc->recv_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.c:		tout = wait_for_completion_timeout(&ipc->send_complete,
drivers/media/pci/intel/ipu6/ipu6-buttress.c:		tout = wait_for_completion_timeout(&ipc->recv_complete,
drivers/media/pci/intel/ipu6/ipu6-buttress.c:	init_completion(&b->ish.send_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.c:	init_completion(&b->cse.send_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.c:	init_completion(&b->ish.recv_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.c:	init_completion(&b->cse.recv_complete);
drivers/media/pci/intel/ipu6/ipu6-buttress.h:#include <linux/completion.h>
drivers/media/pci/intel/ipu6/ipu6-buttress.h:	struct completion send_complete;
drivers/media/pci/intel/ipu6/ipu6-buttress.h:	struct completion recv_complete;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:#define IPU6_DWC_DPHY_TEST_IFC_REQ_COMPLETION	0x18
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	u32 completion;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	reg = base + IPU6_DWC_DPHY_TEST_IFC_REQ_COMPLETION;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	ret = readl_poll_timeout(reg, completion, !(completion & BIT(0)),
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	*val = completion >> 8 & 0xff;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	*val = FIELD_GET(GENMASK(15, 8), completion);
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	u32 completion;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	completion = readl(base + IPU6_DWC_DPHY_TEST_IFC_REQ_COMPLETION);
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	reg = base + IPU6_DWC_DPHY_TEST_IFC_REQ_COMPLETION;
drivers/media/pci/intel/ipu6/ipu6-isys-dwc-phy.c:	ret = readl_poll_timeout(reg, completion, !(completion & BIT(0)),
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:#include <linux/completion.h>
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	reinit_completion(&stream->stream_open_completion);
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	tout = wait_for_completion_timeout(&stream->stream_open_completion,
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	reinit_completion(&stream->stream_start_completion);
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	tout = wait_for_completion_timeout(&stream->stream_start_completion,
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	reinit_completion(&stream->stream_close_completion);
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	tout = wait_for_completion_timeout(&stream->stream_close_completion,
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	reinit_completion(&stream->stream_stop_completion);
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	tout = wait_for_completion_timeout(&stream->stream_stop_completion,
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	reinit_completion(&stream->stream_close_completion);
drivers/media/pci/intel/ipu6/ipu6-isys-video.c:	tout = wait_for_completion_timeout(&stream->stream_close_completion,
drivers/media/pci/intel/ipu6/ipu6-isys-video.h:#include <linux/completion.h>
drivers/media/pci/intel/ipu6/ipu6-isys-video.h:	struct completion stream_open_completion;
drivers/media/pci/intel/ipu6/ipu6-isys-video.h:	struct completion stream_close_completion;
drivers/media/pci/intel/ipu6/ipu6-isys-video.h:	struct completion stream_start_completion;
drivers/media/pci/intel/ipu6/ipu6-isys-video.h:	struct completion stream_stop_completion;
drivers/media/pci/intel/ipu6/ipu6-isys.c:#include <linux/completion.h>
drivers/media/pci/intel/ipu6/ipu6-isys.c:		init_completion(&isys->streams[i].stream_open_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		init_completion(&isys->streams[i].stream_close_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		init_completion(&isys->streams[i].stream_start_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		init_completion(&isys->streams[i].stream_stop_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_open_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_close_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_start_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_start_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_stop_completion);
drivers/media/pci/intel/ipu6/ipu6-isys.c:		complete(&stream->stream_stop_completion);
drivers/media/pci/intel/ivsc/mei_ace.c: * executed. The command sending function uses "completion" as the
drivers/media/pci/intel/ivsc/mei_ace.c:#include <linux/completion.h>
drivers/media/pci/intel/ivsc/mei_ace.c:	struct completion cmd_completion;
drivers/media/pci/intel/ivsc/mei_ace.c:	reinit_completion(&ace->cmd_completion);
drivers/media/pci/intel/ivsc/mei_ace.c:	ret = wait_for_completion_killable_timeout(&ace->cmd_completion,
drivers/media/pci/intel/ivsc/mei_ace.c:	ret = wait_for_completion_killable_timeout(&ace->cmd_completion,
drivers/media/pci/intel/ivsc/mei_ace.c:		complete(&ace->cmd_completion);
drivers/media/pci/intel/ivsc/mei_ace.c:		complete(&ace->cmd_completion);
drivers/media/pci/intel/ivsc/mei_ace.c:	init_completion(&ace->cmd_completion);
drivers/media/pci/intel/ivsc/mei_csi.c: * command function uses "completion" as a synchronization mechanism.
drivers/media/pci/intel/ivsc/mei_csi.c:#include <linux/completion.h>
drivers/media/pci/intel/ivsc/mei_csi.c:	struct completion cmd_completion;
drivers/media/pci/intel/ivsc/mei_csi.c:	reinit_completion(&csi->cmd_completion);
drivers/media/pci/intel/ivsc/mei_csi.c:	ret = wait_for_completion_killable_timeout(&csi->cmd_completion,
drivers/media/pci/intel/ivsc/mei_csi.c:		complete(&csi->cmd_completion);
drivers/media/pci/intel/ivsc/mei_csi.c:	init_completion(&csi->cmd_completion);
drivers/media/pci/mantis/mantis_i2c.c:		/* wait for xfer completion */
drivers/media/pci/mantis/mantis_i2c.c:		/* wait for xfer completion */
drivers/media/pci/mantis/mantis_i2c.c:		/* wait for xfer completion */
drivers/media/pci/mantis/mantis_i2c.c:		/* wait for xfer completion */
drivers/media/pci/mantis/mantis_i2c.c:			/* wait for xfer completion */
drivers/media/pci/mantis/mantis_i2c.c:			/* check for xfer completion */
drivers/media/pci/mgb4/mgb4_core.h:	struct completion req_compl;
drivers/media/pci/mgb4/mgb4_dma.c:	if (!wait_for_completion_timeout(&chan->req_compl,
drivers/media/pci/mgb4/mgb4_dma.c:		init_completion(&mgbdev->c2h_chan[i].req_compl);
drivers/media/pci/mgb4/mgb4_dma.c:		init_completion(&mgbdev->h2c_chan[i].req_compl);
drivers/media/pci/netup_unidvb/netup_unidvb_core.c:	/* Adjust PCIe completion timeout. */
drivers/media/pci/solo6x10/solo6x10-p2m.c:	reinit_completion(&p2m_dev->completion);
drivers/media/pci/solo6x10/solo6x10-p2m.c:	time_left = wait_for_completion_timeout(&p2m_dev->completion,
drivers/media/pci/solo6x10/solo6x10-p2m.c:		complete(&p2m_dev->completion);
drivers/media/pci/solo6x10/solo6x10-p2m.c:		complete(&p2m_dev->completion);
drivers/media/pci/solo6x10/solo6x10-p2m.c:		init_completion(&p2m_dev->completion);
drivers/media/pci/solo6x10/solo6x10.h:	struct completion	completion;
drivers/media/platform/allegro-dvt/allegro-core.c:	struct completion init_complete;
drivers/media/platform/allegro-dvt/allegro-core.c:	struct completion completion;
drivers/media/platform/allegro-dvt/allegro-core.c:	time_left = wait_for_completion_timeout(&dev->init_complete,
drivers/media/platform/allegro-dvt/allegro-core.c:	reinit_completion(&dev->init_complete);
drivers/media/platform/allegro-dvt/allegro-core.c:	complete(&channel->completion);
drivers/media/platform/allegro-dvt/allegro-core.c:	complete(&channel->completion);
drivers/media/platform/allegro-dvt/allegro-core.c:		reinit_completion(&channel->completion);
drivers/media/platform/allegro-dvt/allegro-core.c:		time_left = wait_for_completion_timeout(&channel->completion,
drivers/media/platform/allegro-dvt/allegro-core.c:	reinit_completion(&channel->completion);
drivers/media/platform/allegro-dvt/allegro-core.c:	time_left = wait_for_completion_timeout(&channel->completion,
drivers/media/platform/allegro-dvt/allegro-core.c:	init_completion(&channel->completion);
drivers/media/platform/allegro-dvt/allegro-core.c:	init_completion(&dev->init_complete);
drivers/media/platform/amphion/vpu.h:	struct completion cmp;
drivers/media/platform/amphion/vpu_cmds.c:	reinit_completion(&core->cmp);
drivers/media/platform/amphion/vpu_cmds.c:	ret = wait_for_completion_timeout(&core->cmp, VPU_TIMEOUT);
drivers/media/platform/amphion/vpu_cmds.c:	reinit_completion(&core->cmp);
drivers/media/platform/amphion/vpu_cmds.c:	ret = wait_for_completion_timeout(&core->cmp, VPU_TIMEOUT);
drivers/media/platform/amphion/vpu_core.c:	ret = wait_for_completion_timeout(&core->cmp, VPU_TIMEOUT);
drivers/media/platform/amphion/vpu_core.c:	reinit_completion(&core->cmp);
drivers/media/platform/amphion/vpu_core.c:	init_completion(&core->cmp);
drivers/media/platform/atmel/atmel-isi.c:#include <linux/completion.h>
drivers/media/platform/atmel/atmel-isi.c:	struct completion		complete;
drivers/media/platform/atmel/atmel-isi.c:	init_completion(&isi->complete);
drivers/media/platform/atmel/atmel-isi.c:	time_left = wait_for_completion_timeout(&isi->complete,
drivers/media/platform/chips-media/coda/coda-bit.c:		err_vdoa = vdoa_wait_for_completion(ctx->vdoa);
drivers/media/platform/chips-media/coda/coda-bit.c:	complete(&ctx->completion);
drivers/media/platform/chips-media/coda/coda-common.c:	if (!wait_for_completion_timeout(&ctx->completion,
drivers/media/platform/chips-media/coda/coda-common.c:	init_completion(&ctx->completion);
drivers/media/platform/chips-media/coda/coda-jpeg.c:	complete(&ctx->completion);
drivers/media/platform/chips-media/coda/coda.h:	struct completion		completion;
drivers/media/platform/chips-media/coda/imx-vdoa.c:	struct completion	completion;
drivers/media/platform/chips-media/coda/imx-vdoa.c:	complete(&curr_ctx->completion);
drivers/media/platform/chips-media/coda/imx-vdoa.c:int vdoa_wait_for_completion(struct vdoa_ctx *ctx)
drivers/media/platform/chips-media/coda/imx-vdoa.c:	if (!wait_for_completion_timeout(&ctx->completion,
drivers/media/platform/chips-media/coda/imx-vdoa.c:EXPORT_SYMBOL(vdoa_wait_for_completion);
drivers/media/platform/chips-media/coda/imx-vdoa.c:		vdoa_wait_for_completion(vdoa->curr_ctx);
drivers/media/platform/chips-media/coda/imx-vdoa.c:	reinit_completion(&ctx->completion);
drivers/media/platform/chips-media/coda/imx-vdoa.c:	init_completion(&ctx->completion);
drivers/media/platform/chips-media/coda/imx-vdoa.c:		vdoa_wait_for_completion(vdoa->curr_ctx);
drivers/media/platform/chips-media/coda/imx-vdoa.h:int vdoa_wait_for_completion(struct vdoa_ctx *ctx);
drivers/media/platform/chips-media/coda/imx-vdoa.h:static inline int vdoa_wait_for_completion(struct vdoa_ctx *ctx)
drivers/media/platform/chips-media/wave5/wave5-hw.c:	/* waiting for completion of bus transaction */
drivers/media/platform/chips-media/wave5/wave5-hw.c:				/* step2 : waiting for completion of bus transaction */
drivers/media/platform/chips-media/wave5/wave5-hw.c:			/* step2 : waiting for completion of bus transaction */
drivers/media/platform/chips-media/wave5/wave5-hw.c:			/* step2 : waiting for completion of bus transaction */
drivers/media/platform/chips-media/wave5/wave5-hw.c:		/* step2 : waiting for completion of bus transaction */
drivers/media/platform/chips-media/wave5/wave5-vpu-dec.c:	init_completion(&inst->irq_done);
drivers/media/platform/chips-media/wave5/wave5-vpu-enc.c:	init_completion(&inst->irq_done);
drivers/media/platform/chips-media/wave5/wave5-vpu.c:	ret = wait_for_completion_timeout(&inst->irq_done,
drivers/media/platform/chips-media/wave5/wave5-vpu.c:	reinit_completion(&inst->irq_done);
drivers/media/platform/chips-media/wave5/wave5-vpuapi.h:	struct completion irq_done;
drivers/media/platform/marvell/mcam-core.c: * Frame completion handling.
drivers/media/platform/marvell/mcam-core.c: * Frame completion with S/G is trickier.  We can't muck with
drivers/media/platform/marvell/mcam-core.c: * buffer exists at frame completion, the controller is left stopped;
drivers/media/platform/marvell/mcam-core.c:	 * Handle any frame completions.  There really should
drivers/media/platform/mediatek/mdp3/mtk-mdp3-vpu.c:	ret = wait_for_completion_timeout(&vpu->ipi_acked,
drivers/media/platform/mediatek/mdp3/mtk-mdp3-vpu.c:	init_completion(&vpu->ipi_acked);
drivers/media/platform/mediatek/mdp3/mtk-mdp3-vpu.h:	struct completion	ipi_acked;
drivers/media/platform/microchip/microchip-csi2dc.c:	/* prepare async notifier for subdevice completion */
drivers/media/platform/microchip/microchip-isc-base.c:	reinit_completion(&isc->comp);
drivers/media/platform/microchip/microchip-isc-base.c:	if (isc->cur_frm && !wait_for_completion_timeout(&isc->comp, 5 * HZ))
drivers/media/platform/microchip/microchip-isc-base.c:	init_completion(&isc->comp);
drivers/media/platform/microchip/microchip-isc.h: * @comp:		completion reference that signals frame completion
drivers/media/platform/microchip/microchip-isc.h:	struct completion	comp;
drivers/media/platform/nvidia/tegra-vde/h264.c:	reinit_completion(&vde->decode_completion);
drivers/media/platform/nvidia/tegra-vde/h264.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/media/platform/nvidia/tegra-vde/h264.c:			&vde->decode_completion, msecs_to_jiffies(1000));
drivers/media/platform/nvidia/tegra-vde/vde.c:	if (completion_done(&vde->decode_completion))
drivers/media/platform/nvidia/tegra-vde/vde.c:	complete(&vde->decode_completion);
drivers/media/platform/nvidia/tegra-vde/vde.c:	init_completion(&vde->decode_completion);
drivers/media/platform/nvidia/tegra-vde/vde.h:#include <linux/completion.h>
drivers/media/platform/nvidia/tegra-vde/vde.h:	struct completion decode_completion;
drivers/media/platform/nxp/imx7-media-csi.c:#include <linux/completion.h>
drivers/media/platform/nxp/imx7-media-csi.c:	struct completion last_eof_completion;
drivers/media/platform/nxp/imx7-media-csi.c:	init_completion(&csi->last_eof_completion);
drivers/media/platform/nxp/imx7-media-csi.c:	 * and then wait for interrupt handler to mark completion.
drivers/media/platform/nxp/imx7-media-csi.c:	ret = wait_for_completion_timeout(&csi->last_eof_completion,
drivers/media/platform/nxp/imx7-media-csi.c:			complete(&csi->last_eof_completion);
drivers/media/platform/nxp/imx7-media-csi.c:	 * FB1, if the interrupt flag indicating completion of FB2 has been
drivers/media/platform/nxp/imx8-isi/imx8-isi-video.c:	 * can't complete B2 as that would result in out-of-order completion.
drivers/media/platform/qcom/camss/camss-csid-4-1.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-csid-4-1.c:	reinit_completion(&csid->reset_complete);
drivers/media/platform/qcom/camss/camss-csid-4-1.c:	time = wait_for_completion_timeout(&csid->reset_complete,
drivers/media/platform/qcom/camss/camss-csid-4-7.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-csid-4-7.c:	reinit_completion(&csid->reset_complete);
drivers/media/platform/qcom/camss/camss-csid-4-7.c:	time = wait_for_completion_timeout(&csid->reset_complete,
drivers/media/platform/qcom/camss/camss-csid-gen2.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-csid-gen2.c:	reinit_completion(&csid->reset_complete);
drivers/media/platform/qcom/camss/camss-csid-gen2.c:	time = wait_for_completion_timeout(&csid->reset_complete,
drivers/media/platform/qcom/camss/camss-csid.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-csid.c:	init_completion(&csid->reset_complete);
drivers/media/platform/qcom/camss/camss-csid.h:	struct completion reset_complete;
drivers/media/platform/qcom/camss/camss-ispif.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-ispif.c:	reinit_completion(&ispif->reset_complete[vfe_id]);
drivers/media/platform/qcom/camss/camss-ispif.c:	time = wait_for_completion_timeout(&ispif->reset_complete[vfe_id],
drivers/media/platform/qcom/camss/camss-ispif.c:		init_completion(&ispif->reset_complete[i]);
drivers/media/platform/qcom/camss/camss-ispif.h:	struct completion reset_complete[MSM_ISPIF_VFE_NUM];
drivers/media/platform/qcom/camss/camss-vfe-17x.c:	reinit_completion(&output->reg_update);
drivers/media/platform/qcom/camss/camss-vfe-480.c:	reinit_completion(&output->reg_update);
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	reinit_completion(&vfe->halt_complete);
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	time = wait_for_completion_timeout(&vfe->halt_complete,
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	time = wait_for_completion_timeout(&output->sof, msecs_to_jiffies(VFE_NEXT_SOF_MS));
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	time = wait_for_completion_timeout(&output->reg_update, msecs_to_jiffies(VFE_NEXT_SOF_MS));
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	reinit_completion(&output->sof);
drivers/media/platform/qcom/camss/camss-vfe-gen1.c:	reinit_completion(&output->reg_update);
drivers/media/platform/qcom/camss/camss-vfe.c:#include <linux/completion.h>
drivers/media/platform/qcom/camss/camss-vfe.c:	reinit_completion(&vfe->reset_complete);
drivers/media/platform/qcom/camss/camss-vfe.c:	time = wait_for_completion_timeout(&vfe->reset_complete,
drivers/media/platform/qcom/camss/camss-vfe.c:		init_completion(&l->output.sof);
drivers/media/platform/qcom/camss/camss-vfe.c:		init_completion(&l->output.reg_update);
drivers/media/platform/qcom/camss/camss-vfe.c:	init_completion(&vfe->reset_complete);
drivers/media/platform/qcom/camss/camss-vfe.c:	init_completion(&vfe->halt_complete);
drivers/media/platform/qcom/camss/camss-vfe.h:	struct completion sof;
drivers/media/platform/qcom/camss/camss-vfe.h:	struct completion reg_update;
drivers/media/platform/qcom/camss/camss-vfe.h:	struct completion reset_complete;
drivers/media/platform/qcom/camss/camss-vfe.h:	struct completion halt_complete;
drivers/media/platform/qcom/venus/core.h: * @done:	a completion for sync HFI operations
drivers/media/platform/qcom/venus/core.h:	struct completion done;
drivers/media/platform/qcom/venus/core.h: * @done:	a completion for sync HFI operation
drivers/media/platform/qcom/venus/core.h:	struct completion done;
drivers/media/platform/qcom/venus/hfi.c:#include <linux/completion.h>
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&core->done);
drivers/media/platform/qcom/venus/hfi.c:	ret = wait_for_completion_timeout(&core->done, TIMEOUT);
drivers/media/platform/qcom/venus/hfi.c:	ret = wait_for_completion_timeout(&core->done, TIMEOUT);
drivers/media/platform/qcom/venus/hfi.c:	ret = wait_for_completion_timeout(&inst->done, TIMEOUT);
drivers/media/platform/qcom/venus/hfi.c:	init_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	reinit_completion(&inst->done);
drivers/media/platform/qcom/venus/hfi.c:	init_completion(&core->done);
drivers/media/platform/qcom/venus/hfi_venus.c:	struct completion pwr_collapse_prep;
drivers/media/platform/qcom/venus/hfi_venus.c:	struct completion release_resource;
drivers/media/platform/qcom/venus/hfi_venus.c:	init_completion(&hdev->pwr_collapse_prep);
drivers/media/platform/qcom/venus/hfi_venus.c:	ret = wait_for_completion_timeout(&hdev->pwr_collapse_prep, timeout);
drivers/media/platform/renesas/rcar_fdp1.c: * Handles the M2M level after a buffer completion event.
drivers/media/platform/renesas/rcar_jpu.c:		/* ...enable interrupts on transfer completion and d-g error */
drivers/media/platform/renesas/rcar_jpu.c:	/* ...reset JPU after completion */
drivers/media/platform/renesas/vsp1/vsp1_dl.c: * Return a set of flags that indicates display list completion status.
drivers/media/platform/renesas/vsp1/vsp1_dl.c: * completion has been delayed by one frame because the display list commit
drivers/media/platform/renesas/vsp1/vsp1_dl.c:	 * completion marks the end of the writeback capture. Return the
drivers/media/platform/renesas/vsp1/vsp1_drm.c:				       unsigned int completion)
drivers/media/platform/renesas/vsp1/vsp1_drm.c:		unsigned int status = completion
drivers/media/platform/renesas/vsp1/vsp1_drm.c:	if (completion & VSP1_DL_FRAME_END_INTERNAL) {
drivers/media/platform/renesas/vsp1/vsp1_drm.c:	 * completion events.
drivers/media/platform/renesas/vsp1/vsp1_drm.h: * @wait_queue: wait queue to wait for BRx release completion
drivers/media/platform/renesas/vsp1/vsp1_drm.h: * @du_complete: frame completion callback for the DU driver (optional)
drivers/media/platform/renesas/vsp1/vsp1_histo.c:	 * called from the frame completion interrupt handler, which can only
drivers/media/platform/renesas/vsp1/vsp1_pipe.c:	 * Regardless of frame completion we still need to notify the pipe
drivers/media/platform/renesas/vsp1/vsp1_pipe.h: * @wq: wait queue to wait for state change completion
drivers/media/platform/renesas/vsp1/vsp1_pipe.h:	void (*frame_end)(struct vsp1_pipeline *pipe, unsigned int completion);
drivers/media/platform/renesas/vsp1/vsp1_video.c:					  unsigned int completion)
drivers/media/platform/renesas/vsp1/vsp1_video.c:	WARN_ON_ONCE(!(completion & VSP1_DL_FRAME_END_COMPLETED));
drivers/media/platform/samsung/s5p-jpeg/jpeg-regs.h:#define EXYNOS4_IMG_COMPLETION_INT_EN	(1 << 1)
drivers/media/platform/samsung/s5p-mfc/s5p_mfc_common.h: * @queue:		waitqueue for waiting for completion of device commands
drivers/media/platform/samsung/s5p-mfc/s5p_mfc_ctrl.c:	mfc_debug(2, "Will now wait for completion of firmware transfer\n");
drivers/media/platform/samsung/s5p-mfc/s5p_mfc_ctrl.c:	mfc_debug(2, "Ok, now will wait for completion of hardware init\n");
drivers/media/platform/samsung/s5p-mfc/s5p_mfc_ctrl.c:	/* 3. Send MFC wakeup command and wait for completion*/
drivers/media/platform/samsung/s5p-mfc/s5p_mfc_intr.c: * This file contains functions used to wait for command completion.
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-common.c:#include <linux/completion.h>
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:#include <linux/completion.h>
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:		/* wait for idle irq handler to signal completion */
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:		ret = wait_for_completion_timeout(&channel->idle_completion,
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:		reinit_completion(&channel->idle_completion);
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:	/* signal idle completion */
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:			complete(&chan->idle_completion);
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:	init_completion(&tsin->idle_completion);
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.c:	wait_for_completion(&fei->fw_ack);
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.h:	struct completion idle_completion;
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-core.h:	struct completion fw_ack;
drivers/media/platform/st/sti/c8sectpfe/c8sectpfe-dvb.c:#include <linux/completion.h>
drivers/media/platform/st/sti/delta/delta-ipc.c:	init_completion(&ctx->done);
drivers/media/platform/st/sti/delta/delta-ipc.c:	if (!wait_for_completion_timeout
drivers/media/platform/st/sti/delta/delta-ipc.c:	if (!wait_for_completion_timeout
drivers/media/platform/st/sti/delta/delta-ipc.c:	if (!wait_for_completion_timeout
drivers/media/platform/st/sti/delta/delta-ipc.c:	if (!wait_for_completion_timeout
drivers/media/platform/st/sti/delta/delta-ipc.h: *		      after decoding completion on firmware side.
drivers/media/platform/st/sti/delta/delta-ipc.h: *					 after decoding completion.
drivers/media/platform/st/sti/delta/delta-v4l2.c:	 * EOS completion from driver is delayed because
drivers/media/platform/st/sti/delta/delta-v4l2.c:	 * EOS completion is so delayed till next frame_queue() call
drivers/media/platform/st/sti/delta/delta.h: *	Decoding instance is waiting for EOS (End Of Stream) completion.
drivers/media/platform/st/sti/delta/delta.h:	struct completion done;
drivers/media/platform/st/sti/hva/hva-hw.c: * NO_INT_COMPLETION: Time-out on interrupt completion
drivers/media/platform/st/sti/hva/hva-hw.c:	NO_INT_COMPLETION = 0x100,
drivers/media/platform/st/sti/hva/hva-hw.c:	/* initialise completion signal */
drivers/media/platform/st/sti/hva/hva-hw.c:	init_completion(&hva->interrupt);
drivers/media/platform/st/sti/hva/hva-hw.c:	if (!wait_for_completion_timeout(&hva->interrupt,
drivers/media/platform/st/sti/hva/hva-hw.c:		dev_err(dev, "%s     %s: time out on completion\n", ctx->name,
drivers/media/platform/st/sti/hva/hva.h: * @interrupt:           completion interrupt
drivers/media/platform/st/sti/hva/hva.h:	struct completion	interrupt;
drivers/media/platform/st/stm32/stm32-dcmi.c:#include <linux/completion.h>
drivers/media/platform/st/stm32/stm32-dcmi.c:	struct completion		complete;
drivers/media/platform/st/stm32/stm32-dcmi.c:	/* Set completion callback routine for notification */
drivers/media/platform/st/stm32/stm32-dcmi.c:	init_completion(&dcmi->complete);
drivers/media/platform/ti/am437x/am437x-vpfe.c:	init_completion(&vpfe->capture_stop);
drivers/media/platform/ti/am437x/am437x-vpfe.c:	wait_for_completion_timeout(&vpfe->capture_stop,
drivers/media/platform/ti/am437x/am437x-vpfe.h:#include <linux/completion.h>
drivers/media/platform/ti/am437x/am437x-vpfe.h:	struct completion capture_stop;
drivers/media/platform/ti/cal/cal-camerarx.c:	 *    a. Deassert the CSI-2 PHY reset. Do not wait for reset completion
drivers/media/platform/ti/cal/cal.c:	 * Request DMA stop and wait until it completes. If completion times
drivers/media/platform/ti/j721e-csi2rx/j721e-csi2rx.c:	struct completion *drain_complete = param;
drivers/media/platform/ti/j721e-csi2rx/j721e-csi2rx.c:	struct completion drain_complete;
drivers/media/platform/ti/j721e-csi2rx/j721e-csi2rx.c:	init_completion(&drain_complete);
drivers/media/platform/ti/j721e-csi2rx/j721e-csi2rx.c:	if (!wait_for_completion_timeout(&drain_complete,
drivers/media/platform/ti/j721e-csi2rx/j721e-csi2rx.c:		 * ti_csi2rx_drain_dma() might block for completion.
drivers/media/platform/ti/omap/omap_vout_vrfb.c:		pr_err("%s: DMA completion %s status\n", __func__,
drivers/media/platform/ti/vpe/vpdma.c: * submit a list of DMA descriptors to the VPE VPDMA, do not wait for completion
drivers/media/radio/radio-wl1273.c:	struct completion busy;
drivers/media/radio/radio-wl1273.c:	reinit_completion(&radio->busy);
drivers/media/radio/radio-wl1273.c:	t = wait_for_completion_timeout(&radio->busy, msecs_to_jiffies(2000));
drivers/media/radio/radio-wl1273.c:	reinit_completion(&radio->busy);
drivers/media/radio/radio-wl1273.c:	t = wait_for_completion_timeout(&radio->busy, msecs_to_jiffies(1000));
drivers/media/radio/radio-wl1273.c:	reinit_completion(&radio->busy);
drivers/media/radio/radio-wl1273.c:	t = wait_for_completion_timeout(&radio->busy, msecs_to_jiffies(2000));
drivers/media/radio/radio-wl1273.c:	reinit_completion(&radio->busy);
drivers/media/radio/radio-wl1273.c:	wait_for_completion_timeout(&radio->busy, msecs_to_jiffies(1000));
drivers/media/radio/radio-wl1273.c:	reinit_completion(&radio->busy);
drivers/media/radio/radio-wl1273.c:	if (!wait_for_completion_timeout(&radio->busy, msecs_to_jiffies(1000)))
drivers/media/radio/radio-wl1273.c:	init_completion(&radio->busy);
drivers/media/radio/si470x/radio-si470x-common.c:	reinit_completion(&radio->completion);
drivers/media/radio/si470x/radio-si470x-common.c:	time_left = wait_for_completion_timeout(&radio->completion,
drivers/media/radio/si470x/radio-si470x-common.c:	reinit_completion(&radio->completion);
drivers/media/radio/si470x/radio-si470x-common.c:	time_left = wait_for_completion_timeout(&radio->completion,
drivers/media/radio/si470x/radio-si470x-i2c.c:		complete(&radio->completion);
drivers/media/radio/si470x/radio-si470x-i2c.c:	init_completion(&radio->completion);
drivers/media/radio/si470x/radio-si470x-usb.c:		complete(&radio->completion);
drivers/media/radio/si470x/radio-si470x-usb.c:	init_completion(&radio->completion);
drivers/media/radio/si470x/radio-si470x.h:	struct completion completion;
drivers/media/radio/si4713/si4713.c:#include <linux/completion.h>
drivers/media/radio/si4713/si4713.c:			"%s: sending signal to completion work.\n", __func__);
drivers/media/radio/si4713/si4713.c:		if (!wait_for_completion_timeout(&sdev->work,
drivers/media/radio/si4713/si4713.c:	    !wait_for_completion_timeout(&sdev->work, usecs_to_jiffies(usecs) + 1))
drivers/media/radio/si4713/si4713.c:	init_completion(&sdev->work);
drivers/media/radio/si4713/si4713.h:	struct completion work;
drivers/media/radio/wl128x/fmdrv.h:	/* Main task completion handler */
drivers/media/radio/wl128x/fmdrv.h:	struct completion maintask_comp;
drivers/media/radio/wl128x/fmdrv.h:	struct completion *resp_comp;
drivers/media/radio/wl128x/fmdrv_common.c:static struct completion wait_for_fmdrv_reg_comp;
drivers/media/radio/wl128x/fmdrv_common.c:	       fm_cb(skb)->completion ? " " : "*", cmd_hdr->hdr,
drivers/media/radio/wl128x/fmdrv_common.c:		/* Anyone waiting for this with completion handler? */
drivers/media/radio/wl128x/fmdrv_common.c:		fmerr("Response completion handler is not NULL\n");
drivers/media/radio/wl128x/fmdrv_common.c:	fmdev->resp_comp = fm_cb(skb)->completion;
drivers/media/radio/wl128x/fmdrv_common.c:		int payload_len, struct completion *wait_completion)
drivers/media/radio/wl128x/fmdrv_common.c:	fm_cb(skb)->completion = wait_completion;
drivers/media/radio/wl128x/fmdrv_common.c:	init_completion(&fmdev->maintask_comp);
drivers/media/radio/wl128x/fmdrv_common.c:	if (!wait_for_completion_timeout(&fmdev->maintask_comp,
drivers/media/radio/wl128x/fmdrv_common.c:		fmerr("Timeout(%d sec),didn't get regcompletion signal from RX bh work\n",
drivers/media/radio/wl128x/fmdrv_common.c: * Called by ST layer to indicate protocol registration completion
drivers/media/radio/wl128x/fmdrv_common.c:		init_completion(&wait_for_fmdrv_reg_comp);
drivers/media/radio/wl128x/fmdrv_common.c:		fmdbg("%s waiting for ST reg completion signal\n", __func__);
drivers/media/radio/wl128x/fmdrv_common.c:		if (!wait_for_completion_timeout(&wait_for_fmdrv_reg_comp,
drivers/media/radio/wl128x/fmdrv_common.c:			fmerr("Timeout(%d sec), didn't get reg completion signal from ST\n",
drivers/media/radio/wl128x/fmdrv_common.h:	struct completion *completion;
drivers/media/radio/wl128x/fmdrv_rx.c:	init_completion(&fmdev->maintask_comp);
drivers/media/radio/wl128x/fmdrv_rx.c:	timeleft = wait_for_completion_timeout(&fmdev->maintask_comp,
drivers/media/radio/wl128x/fmdrv_rx.c:	init_completion(&fmdev->maintask_comp);
drivers/media/radio/wl128x/fmdrv_rx.c:	timeleft = wait_for_completion_timeout(&fmdev->maintask_comp,
drivers/media/radio/wl128x/fmdrv_tx.c:	init_completion(&fmdev->maintask_comp);
drivers/media/radio/wl128x/fmdrv_tx.c:	timeleft = wait_for_completion_timeout(&fmdev->maintask_comp,
drivers/media/rc/ene_ir.c:	if (wait_for_completion_timeout(&dev->tx_complete, 2 * HZ) == 0) {
drivers/media/rc/ene_ir.c:		init_completion(&dev->tx_complete);
drivers/media/rc/ene_ir.h:	struct completion tx_complete;		/* TX completion */
drivers/media/rc/iguanair.c:#include <linux/completion.h>
drivers/media/rc/iguanair.c:	struct completion completion;
drivers/media/rc/iguanair.c:				complete(&ir->completion);
drivers/media/rc/iguanair.c:				complete(&ir->completion);
drivers/media/rc/iguanair.c:				complete(&ir->completion);
drivers/media/rc/iguanair.c:			complete(&ir->completion);
drivers/media/rc/iguanair.c:		complete(&ir->completion);
drivers/media/rc/iguanair.c:	reinit_completion(&ir->completion);
drivers/media/rc/iguanair.c:	if (wait_for_completion_timeout(&ir->completion, TIMEOUT) == 0)
drivers/media/rc/iguanair.c:	init_completion(&ir->completion);
drivers/media/rc/imon.c:		struct completion finished;	/* wait for write to finish */
drivers/media/rc/imon.c:		int status;			/* status of tx completion */
drivers/media/rc/imon.c:	reinit_completion(&ictx->tx.finished);
drivers/media/rc/imon.c:		retval = wait_for_completion_interruptible(
drivers/media/rc/imon.c:	init_completion(&ictx->tx.finished);
drivers/media/rc/ir_toy.c:#include <linux/completion.h>
drivers/media/rc/ir_toy.c:	struct completion command_done;
drivers/media/rc/ir_toy.c:	init_completion(&irtoy->command_done);
drivers/media/rc/ir_toy.c:	if (!wait_for_completion_timeout(&irtoy->command_done,
drivers/media/rc/mceusb.c:	struct completion tx_done;
drivers/media/rc/mceusb.c:	init_completion(&tx_done);
drivers/media/rc/mceusb.c:	ret_wait = wait_for_completion_timeout(&tx_done, expire);
drivers/media/rc/meson-ir-tx.c:	struct completion completion;
drivers/media/rc/meson-ir-tx.c:	if (completion_done(&ir->completion))
drivers/media/rc/meson-ir-tx.c:		complete(&ir->completion);
drivers/media/rc/meson-ir-tx.c:	reinit_completion(&ir->completion);
drivers/media/rc/meson-ir-tx.c:	if (!wait_for_completion_timeout(&ir->completion,
drivers/media/rc/meson-ir-tx.c:	init_completion(&ir->completion);
drivers/media/rc/mtk-cir.c: * indicating IR receiving completion and then making IRQ fires
drivers/media/rc/mtk-cir.c: * @ok_count:		The count indicating the completion of IR data
drivers/media/rc/mtk-cir.c:	 * indicating end of IR receiving completion
drivers/media/rc/pwm-ir-tx.c:#include <linux/completion.h>
drivers/media/rc/pwm-ir-tx.c:	struct completion tx_done;
drivers/media/rc/pwm-ir-tx.c:	wait_for_completion(&pwm_ir->tx_done);
drivers/media/rc/pwm-ir-tx.c:		init_completion(&pwm_ir->tx_done);
drivers/media/tuners/tda18271-common.c:	msleep(30); /* image low optimization completion */
drivers/media/tuners/tda18271-common.c:	msleep(30); /* image mid optimization completion */
drivers/media/tuners/tda18271-common.c:	msleep(30); /* image high optimization completion */
drivers/media/tuners/tda18271-fe.c:	msleep(60); /* RF tracking filter calibration completion */
drivers/media/usb/au0828/au0828-dvb.c:static void urb_completion(struct urb *purb)
drivers/media/usb/au0828/au0828-dvb.c:				  urb_completion,
drivers/media/usb/au0828/au0828-video.c:		au0828_isocdbg("urb completion error %d.\n", urb->status);
drivers/media/usb/cx231xx/cx231xx-audio.c:		dev_dbg(dev->dev, "urb completion error %d.\n",
drivers/media/usb/cx231xx/cx231xx-audio.c:		dev_dbg(dev->dev, "urb completion error %d.\n",
drivers/media/usb/cx231xx/cx231xx-core.c:		cx231xx_isocdbg("urb completion error %d.\n", urb->status);
drivers/media/usb/cx231xx/cx231xx-core.c:		cx231xx_isocdbg("urb completion error - device is stalled.\n");
drivers/media/usb/cx231xx/cx231xx-core.c:		cx231xx_isocdbg("urb completion error %d.\n", urb->status);
drivers/media/usb/cx231xx/cx231xx-vbi.c:			"urb completion error %d.\n", urb->status);
drivers/media/usb/dvb-usb-v2/usb_urb.c:				"%s: urb completion failed=%d\n",
drivers/media/usb/dvb-usb-v2/usb_urb.c:				"%s: unknown endpoint type in completion handler\n",
drivers/media/usb/dvb-usb/cxusb-analog.c:	/* let URB completion run */
drivers/media/usb/dvb-usb/cxusb-analog.c:	while (completion_done(&cxdev->v4l2_release))
drivers/media/usb/dvb-usb/cxusb-analog.c:	init_completion(&cxdev->v4l2_release);
drivers/media/usb/dvb-usb/cxusb-analog.c:	wait_for_completion(&cxdev->v4l2_release);
drivers/media/usb/dvb-usb/cxusb-analog.c:	wait_for_completion(&cxdev->v4l2_release);
drivers/media/usb/dvb-usb/cxusb.h:#include <linux/completion.h>
drivers/media/usb/dvb-usb/cxusb.h:	struct completion v4l2_release;
drivers/media/usb/dvb-usb/dib0700_core.c:static void dib0700_rc_urb_completion(struct urb *purb)
drivers/media/usb/dvb-usb/dib0700_core.c:					  dib0700_rc_urb_completion, d);
drivers/media/usb/dvb-usb/dib0700_core.c:					  dib0700_rc_urb_completion, d, 1);
drivers/media/usb/dvb-usb/dib0700_devices.c: * at dib0700_rc_urb_completion()
drivers/media/usb/dvb-usb/dib0700_devices.c:		   in the bulk URB completion handler. */
drivers/media/usb/dvb-usb/usb-urb.c:			deb_ts("urb completion error %d.\n", urb->status);
drivers/media/usb/dvb-usb/usb-urb.c:			err("unknown endpoint type in completion handler.");
drivers/media/usb/em28xx/em28xx-audio.c:		dprintk("urb completion error %d.\n", urb->status);
drivers/media/usb/em28xx/em28xx-core.c: * URB completion handler for isoc/bulk transfers
drivers/media/usb/em28xx/em28xx-core.c:		em28xx_isocdbg("urb completion error %d.\n", urb->status);
drivers/media/usb/em28xx/em28xx-i2c.c:	/* wait for completion */
drivers/media/usb/em28xx/em28xx-i2c.c:	/* wait for completion */
drivers/media/usb/em28xx/em28xx-i2c.c:	/* wait for completion */
drivers/media/usb/gspca/conex.c:	/* wait for completion */
drivers/media/usb/gspca/gspca.c:	/* Killing all URBs guarantee that no URB completion
drivers/media/usb/pvrusb2/pvrusb2-hdw-internal.h:	struct completion ctl_done;
drivers/media/usb/pvrusb2/pvrusb2-hdw.c:	init_completion(&hdw->ctl_done);
drivers/media/usb/pvrusb2/pvrusb2-hdw.c:		wait_for_completion(&hdw->ctl_done);
drivers/media/usb/pvrusb2/pvrusb2-io.c:		   completion callback may happen on this buffer.  But it's
drivers/media/usb/pvrusb2/pvrusb2-io.h:/* Retrieve completion code for given ready buffer */
drivers/media/usb/s2255/s2255drv.c:static void read_pipe_completion(struct urb *purb)
drivers/media/usb/s2255/s2255drv.c:			  read_pipe_completion, pipe_info);
drivers/media/usb/s2255/s2255drv.c:			  read_pipe_completion, pipe_info);
drivers/media/usb/uvc/uvc_status.c:			 "Non-zero status (%d) in status completion handler.\n",
drivers/media/usb/uvc/uvc_status.c:	 * The URB completion handler may have queued asynchronous work. This
drivers/media/usb/uvc/uvc_video.c: * Completion handler for video URBs.
drivers/media/usb/uvc/uvc_video.c:			 "Non-zero status (%d) in video completion handler.\n",
drivers/media/usb/uvc/uvc_video.c:	 * after the completion handler returns, any asynchronous workqueues
drivers/media/usb/uvc/uvc_video.c: * completion handler won't try to cancel the queue when we kill the URBs.
drivers/media/usb/uvc/uvcvideo.h:	/* Context data used by the bulk completion handler. */
drivers/media/v4l2-core/v4l2-ctrls-api.c:		 * volatile controls at the time of request completion
drivers/memory/tegra/mc.c:		/* wait for completion of the outstanding DMA requests */
drivers/memory/tegra/tegra210-emc-core.c:		dev_warn(emc->dev, "clock change completion error: %d\n", err);
drivers/memstick/core/memstick.c:		reinit_completion(&host->card->mrq_complete);
drivers/memstick/core/memstick.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/memstick.c:		init_completion(&card->mrq_complete);
drivers/memstick/core/memstick.c:		wait_for_completion(&card->mrq_complete);
drivers/memstick/core/ms_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:		wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:		wait_for_completion(&card->mrq_complete);
drivers/memstick/core/mspro_block.c:	wait_for_completion(&card->mrq_complete);
drivers/memstick/host/r592.c:	reinit_completion(&dev->dma_done);
drivers/memstick/host/r592.c:	/* Wait for DMA completion */
drivers/memstick/host/r592.c:	if (!wait_for_completion_timeout(
drivers/memstick/host/r592.c:	/* Wait for TPC completion */
drivers/memstick/host/r592.c:	init_completion(&dev->dma_done);
drivers/memstick/host/r592.h:	struct completion dma_done;
drivers/memstick/host/rtsx_usb_ms.c:#include <linux/completion.h>
drivers/message/fusion/lsi/mpi_history.txt: *                      Change Event data to indicate completion of internally
drivers/message/fusion/lsi/mpi_history.txt: *  09-16-02  01.02.07  Added flags for confirmed completion.
drivers/message/fusion/lsi/mpi_ioc.h: *                      Change Event data to indicate completion of internally
drivers/message/fusion/lsi/mpi_targ.h: *  09-16-02  01.02.07  Added flags for confirmed completion.
drivers/message/fusion/mptbase.c: *	the protocol-specific details of the MPT request completion.
drivers/message/fusion/mptbase.c:	init_completion(&ioc->internal_cmds.done);
drivers/message/fusion/mptbase.c:	init_completion(&ioc->mptbase_cmds.done);
drivers/message/fusion/mptbase.c:	init_completion(&ioc->taskmgmt_cmds.done);
drivers/message/fusion/mptbase.c: *	upon successful completion.
drivers/message/fusion/mptbase.c:		 * Wait for completion of doorbell handshake reply from the IOC
drivers/message/fusion/mptbase.c:	timeleft = wait_for_completion_timeout(&ioc->mptbase_cmds.done, 10*HZ);
drivers/message/fusion/mptbase.c:	timeleft = wait_for_completion_timeout(&ioc->mptbase_cmds.done,
drivers/message/fusion/mptbase.c:		ioc->wait_on_reset_completion = 1;
drivers/message/fusion/mptbase.c:		ioc->wait_on_reset_completion = 0;
drivers/message/fusion/mptbase.c:	if (ioc->wait_on_reset_completion) {
drivers/message/fusion/mptbase.h:	struct completion	 done;
drivers/message/fusion/mptbase.h:	int			 completion_code;
drivers/message/fusion/mptbase.h:	 * a split completion for a read data, an internal address pointer incorrectly
drivers/message/fusion/mptbase.h:	u8			 wait_on_reset_completion;
drivers/message/fusion/mptbase.h:	int	completion;
drivers/message/fusion/mptctl.c:	ii = wait_for_completion_timeout(&ioc->taskmgmt_cmds.done, timeout*HZ);
drivers/message/fusion/mptctl.c:	timeleft = wait_for_completion_timeout(&iocp->ioctl_cmds.done, HZ*60);
drivers/message/fusion/mptctl.c:	timeleft = wait_for_completion_timeout(&ioc->ioctl_cmds.done,
drivers/message/fusion/mptctl.c:	timeleft = wait_for_completion_timeout(&ioc->ioctl_cmds.done,
drivers/message/fusion/mptctl.c:	init_completion(&ioc->ioctl_cmds.done);
drivers/message/fusion/mptsas.c: * try to send next target reset. This will be called from completion
drivers/message/fusion/mptsas.c: *	Completion for TARGET_RESET after NOT_RESPONDING_EVENT, enable work
drivers/message/fusion/mptsas.c:	timeleft = wait_for_completion_timeout(&ioc->sas_mgmt.done,
drivers/message/fusion/mptsas.c:	timeleft = wait_for_completion_timeout(&ioc->sas_mgmt.done, 10 * HZ);
drivers/message/fusion/mptsas.c:	timeleft = wait_for_completion_timeout(&ioc->sas_mgmt.done, 10 * HZ);
drivers/message/fusion/mptsas.c:	timeleft = wait_for_completion_timeout(&ioc->taskmgmt_cmds.done,
drivers/message/fusion/mptsas.c:	init_completion(&ioc->sas_mgmt.done);
drivers/message/fusion/mptscsih.c:static int	mptscsih_get_completion_code(MPT_ADAPTER *ioc,
drivers/message/fusion/mptscsih.c: *	This routine is called from mpt.c::mpt_interrupt() at the completion
drivers/message/fusion/mptscsih.c:		 * completion done. Cannot touch sc struct. Just free mem.
drivers/message/fusion/mptscsih.c:	wait_for_completion_timeout(&ioc->taskmgmt_cmds.done,
drivers/message/fusion/mptscsih.c: *	This routine is called from mptbase.c::mpt_interrupt() at the completion
drivers/message/fusion/mptscsih.c: *	This routine is called from mpt.c::mpt_interrupt() at the completion
drivers/message/fusion/mptscsih.c: *	Remark: Sets a completion code and (possibly) saves sense data
drivers/message/fusion/mptscsih.c:	ioc->internal_cmds.completion_code = MPT_SCANDV_GOOD;
drivers/message/fusion/mptscsih.c:	ioc->internal_cmds.completion_code =
drivers/message/fusion/mptscsih.c:	    mptscsih_get_completion_code(ioc, req, reply);
drivers/message/fusion/mptscsih.c: *	mptscsih_get_completion_code - get completion code from MPT request
drivers/message/fusion/mptscsih.c:mptscsih_get_completion_code(MPT_ADAPTER *ioc, MPT_FRAME_HDR *req,
drivers/message/fusion/mptscsih.c:	int		 completion_code;
drivers/message/fusion/mptscsih.c:		completion_code = MPT_SCANDV_SELECTION_TIMEOUT;
drivers/message/fusion/mptscsih.c:		completion_code = MPT_SCANDV_DID_RESET;
drivers/message/fusion/mptscsih.c:		completion_code = MPT_SCANDV_BUSY;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_GOOD;
drivers/message/fusion/mptscsih.c:				completion_code = MPT_SCANDV_GOOD;
drivers/message/fusion/mptscsih.c:				completion_code = MPT_SCANDV_SOME_ERROR;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_SENSE;
drivers/message/fusion/mptscsih.c:				completion_code = MPT_SCANDV_ISSUE_SENSE;
drivers/message/fusion/mptscsih.c:				completion_code = MPT_SCANDV_DID_RESET;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_DID_RESET;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_DID_RESET;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_BUSY;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_GOOD;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_DID_RESET;
drivers/message/fusion/mptscsih.c:			completion_code = MPT_SCANDV_SOME_ERROR;
drivers/message/fusion/mptscsih.c:		completion_code = MPT_SCANDV_SOME_ERROR;
drivers/message/fusion/mptscsih.c:	    "  completionCode set to %08xh\n", ioc->name, completion_code));
drivers/message/fusion/mptscsih.c:	return completion_code;
drivers/message/fusion/mptscsih.c: *		 > 0 if command complete but some type of completion error.
drivers/message/fusion/mptscsih.c:	timeleft = wait_for_completion_timeout(&ioc->internal_cmds.done,
drivers/message/fusion/mptscsih.c:	ret = ioc->internal_cmds.completion_code;
drivers/message/fusion/mptspi.c:	timeleft = wait_for_completion_timeout(&ioc->internal_cmds.done, 10*HZ);
drivers/message/fusion/mptspi.c:	ret = ioc->internal_cmds.completion_code;
drivers/mfd/cs42l43-sdw.c:		reinit_completion(&cs42l43->device_attach);
drivers/mfd/cs42l43.c:	reinit_completion(&cs42l43->device_detach);
drivers/mfd/cs42l43.c:		time = wait_for_completion_timeout(&cs42l43->device_detach, timeout);
drivers/mfd/cs42l43.c:		time = wait_for_completion_timeout(&cs42l43->device_attach, timeout);
drivers/mfd/cs42l43.c:			wait_for_completion(&cs42l43->firmware_download);
drivers/mfd/cs42l43.c:	init_completion(&cs42l43->device_attach);
drivers/mfd/cs42l43.c:	init_completion(&cs42l43->device_detach);
drivers/mfd/cs42l43.c:	init_completion(&cs42l43->firmware_download);
drivers/mfd/da9052-core.c:	reinit_completion(&da9052->done);
drivers/mfd/da9052-core.c:	if (!wait_for_completion_timeout(&da9052->done,
drivers/mfd/da9052-core.c:	init_completion(&da9052->done);
drivers/mfd/db8500-prcmu.c:#include <linux/completion.h>
drivers/mfd/db8500-prcmu.c:	struct completion ac_wake_work;
drivers/mfd/db8500-prcmu.c: * @work:	The transaction completion structure.
drivers/mfd/db8500-prcmu.c:	struct completion work;
drivers/mfd/db8500-prcmu.c: * @work:            The transaction completion structure.
drivers/mfd/db8500-prcmu.c:	struct completion work;
drivers/mfd/db8500-prcmu.c:	struct completion sysclk_work;
drivers/mfd/db8500-prcmu.c: * @work:	The transaction completion structure.
drivers/mfd/db8500-prcmu.c:	struct completion work;
drivers/mfd/db8500-prcmu.c: * @work:	The transaction completion structure.
drivers/mfd/db8500-prcmu.c:	struct completion work;
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	if (!wait_for_completion_timeout(&mb2_transfer.work,
drivers/mfd/db8500-prcmu.c:	if (enable && !wait_for_completion_timeout(&mb3_transfer.sysclk_work,
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	if (!wait_for_completion_timeout(&mb5_transfer.work,
drivers/mfd/db8500-prcmu.c:	if (!wait_for_completion_timeout(&mb5_transfer.work,
drivers/mfd/db8500-prcmu.c:	if (!wait_for_completion_timeout(&mb0_transfer.ac_wake_work,
drivers/mfd/db8500-prcmu.c:	if (!wait_for_completion_timeout(&mb0_transfer.ac_wake_work,
drivers/mfd/db8500-prcmu.c:	wait_for_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb0_transfer.ac_wake_work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb1_transfer.work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb2_transfer.work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb3_transfer.sysclk_work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb4_transfer.work);
drivers/mfd/db8500-prcmu.c:	init_completion(&mb5_transfer.work);
drivers/mfd/dln2.c:	/* completion used to wait for a response */
drivers/mfd/dln2.c:	struct completion done;
drivers/mfd/dln2.c:	reinit_completion(&rxc->done);
drivers/mfd/dln2.c:	ret = wait_for_completion_interruptible_timeout(&rxc->done, timeout);
drivers/mfd/dln2.c:			init_completion(&dln2->mod_rx_slots[i].slots[j].done);
drivers/mfd/ezx-pcap.c:	struct completion completion;
drivers/mfd/ezx-pcap.c:	complete(&req->completion);
drivers/mfd/ezx-pcap.c:	init_completion(&sync_data.completion);
drivers/mfd/ezx-pcap.c:	wait_for_completion(&sync_data.completion);
drivers/mfd/iqs62x.c:#include <linux/completion.h>
drivers/mfd/iqs62x.c:		reinit_completion(&iqs62x->ati_done);
drivers/mfd/iqs62x.c:		reinit_completion(&iqs62x->ati_done);
drivers/mfd/iqs62x.c:	} else if (!completion_done(&iqs62x->ati_done)) {
drivers/mfd/iqs62x.c:	if (completion_done(&iqs62x->ati_done)) {
drivers/mfd/iqs62x.c:	if (!wait_for_completion_timeout(&iqs62x->ati_done,
drivers/mfd/iqs62x.c:	init_completion(&iqs62x->ati_done);
drivers/mfd/iqs62x.c:	init_completion(&iqs62x->fw_done);
drivers/mfd/iqs62x.c:	wait_for_completion(&iqs62x->fw_done);
drivers/mfd/iqs62x.c:	wait_for_completion(&iqs62x->fw_done);
drivers/mfd/mc13xxx-core.c:	struct completion done;
drivers/mfd/mc13xxx-core.c:	init_completion(&adcdone_data.done);
drivers/mfd/mc13xxx-core.c:	ret = wait_for_completion_interruptible_timeout(&adcdone_data.done, HZ);
drivers/mfd/pcf50633-adc.c:#include <linux/completion.h>
drivers/mfd/pcf50633-adc.c:	struct completion completion;
drivers/mfd/pcf50633-adc.c:	complete(&req->completion);
drivers/mfd/pcf50633-adc.c:	init_completion(&req.completion);
drivers/mfd/pcf50633-adc.c:	wait_for_completion(&req.completion);
drivers/mfd/qcom_rpm.c:	struct completion ack;
drivers/mfd/qcom_rpm.c:	reinit_completion(&rpm->ack);
drivers/mfd/qcom_rpm.c:	left = wait_for_completion_timeout(&rpm->ack, RPM_REQUEST_TIMEOUT);
drivers/mfd/qcom_rpm.c:	init_completion(&rpm->ack);
drivers/mfd/rave-sp.c: * @received:   Successful reply reception completion
drivers/mfd/rave-sp.c:	struct completion received;
drivers/mfd/rave-sp.c:		.received = COMPLETION_INITIALIZER_ONSTACK(reply.received),
drivers/mfd/rave-sp.c:	if (!wait_for_completion_timeout(&reply.received, HZ)) {
drivers/mfd/si476x-cmd.c:#include <linux/completion.h>
drivers/mfd/si476x-i2c.c: * si476x_core_report_drainer_stop() - mark the completion of the RDS
drivers/mfd/si476x-i2c.c:		/* Unfortunately completions could not be used for
drivers/mfd/stm32-timers.c:		complete(&dma->completion);
drivers/mfd/stm32-timers.c:	reinit_completion(&dma->completion);
drivers/mfd/stm32-timers.c:	err = wait_for_completion_interruptible_timeout(&dma->completion,
drivers/mfd/stm32-timers.c:	init_completion(&ddata->dma.completion);
drivers/mfd/tps6594-core.c:#include <linux/completion.h>
drivers/mfd/tps6594-core.c:/* Completion to synchronize CRC feature enabling on all PMICs */
drivers/mfd/tps6594-core.c:static DECLARE_COMPLETION(tps6594_crc_comp);
drivers/mfd/tps6594-core.c:		ret = wait_for_completion_interruptible_timeout(&tps6594_crc_comp, timeout);
drivers/mfd/twl4030-irq.c: * completion, potentially including some re-ordering, of these requests.
drivers/mfd/twl6040.c:	time_left = wait_for_completion_timeout(&twl6040->ready,
drivers/mfd/twl6040.c:	init_completion(&twl6040->ready);
drivers/mfd/ucb1x00-ts.c:#include <linux/completion.h>
drivers/mfd/wm831x-auxadc.c:	struct completion done;
drivers/mfd/wm831x-auxadc.c:	init_completion(&req->done);
drivers/mfd/wm831x-auxadc.c:	wait_for_completion_timeout(&req->done, msecs_to_jiffies(500));
drivers/mfd/wm8350-core.c:	/* If a late IRQ left the completion signalled then consume
drivers/mfd/wm8350-core.c:	 * the completion. */
drivers/mfd/wm8350-core.c:	try_wait_for_completion(&wm8350->auxadc_done);
drivers/mfd/wm8350-core.c:	/* We ignore the result of the completion and just check for a
drivers/mfd/wm8350-core.c:	wait_for_completion_timeout(&wm8350->auxadc_done, msecs_to_jiffies(5));
drivers/mfd/wm8350-core.c:	init_completion(&wm8350->auxadc_done);
drivers/misc/cardreader/rtsx_pcr.c:	struct completion trans_done;
drivers/misc/cardreader/rtsx_pcr.c:	init_completion(&trans_done);
drivers/misc/cardreader/rtsx_pcr.c:	timeleft = wait_for_completion_interruptible_timeout(
drivers/misc/cardreader/rtsx_pcr.c:	struct completion trans_done;
drivers/misc/cardreader/rtsx_pcr.c:	init_completion(&trans_done);
drivers/misc/cardreader/rtsx_pcr.c:	timeleft = wait_for_completion_interruptible_timeout(
drivers/misc/cardreader/rtsx_pcr.c:	struct completion finish;
drivers/misc/cardreader/rtsx_pcr.c:	init_completion(&finish);
drivers/misc/cardreader/rtsx_pcr.c:	wait_for_completion_interruptible_timeout(&finish,
drivers/misc/cxl/hcalls.c:#define H_CONTROL_CA_FUNCTION_TERMINATE_PROCESS       8 /* terminate the process before completion */
drivers/misc/cxl/hcalls.c: * cxl_h_terminate_process - Terminate the process before completion
drivers/misc/cxl/hcalls.h: * cxl_h_terminate_process - Terminate the process before completion
drivers/misc/fastrpc.c:#include <linux/completion.h>
drivers/misc/fastrpc.c:	struct completion work;
drivers/misc/fastrpc.c:	init_completion(&ctx->work);
drivers/misc/fastrpc.c:		if (!wait_for_completion_timeout(&ctx->work, 10 * HZ))
drivers/misc/fastrpc.c:		err = wait_for_completion_interruptible(&ctx->work);
drivers/misc/genwqe/card_ddcb.c: * A: active DDCB, this is where the code will look for the next completion.
drivers/misc/genwqe/card_ddcb.c: * x: DDCB is enqueued, we are waiting for its completion.
drivers/misc/genwqe/card_ddcb.c:	/* enable DDCB completion irq */
drivers/misc/genwqe/card_ddcb.c:	 * Higher values than 0x102 indicate completion with faults,
drivers/misc/genwqe/card_ddcb.h:	__be64 cmplt_ts_64;	/* Completion Time Stamp. */
drivers/misc/genwqe/card_dev.c:		/* launch an DDCB and wait for completion */
drivers/misc/lattice-ecp3-config.c:	struct completion fw_loaded;
drivers/misc/lattice-ecp3-config.c:	init_completion(&data->fw_loaded);
drivers/misc/lattice-ecp3-config.c:	wait_for_completion(&data->fw_loaded);
drivers/misc/mei/interrupt.c: * @cmpl_list: completion list
drivers/misc/mei/mei_dev.h: * @tx_wait: wait queue for tx completion
drivers/misc/mei/mei_dev.h: * @rx_wait: wait queue for rx completion
drivers/misc/mei/mei_dev.h: * @timer_count:  watchdog timer for operation completion
drivers/misc/mei/mei_dev.h: * @write_waiting_list : write completion list
drivers/misc/nsm.c:	struct completion     cmd_done;
drivers/misc/nsm.c:	init_completion(&nsm->cmd_done);
drivers/misc/nsm.c:	if (!wait_for_completion_io_timeout(&nsm->cmd_done,
drivers/misc/pci_endpoint_test.c:	struct completion irq_raised;
drivers/misc/pci_endpoint_test.c:	val = wait_for_completion_timeout(&test->irq_raised,
drivers/misc/pci_endpoint_test.c:	val = wait_for_completion_timeout(&test->irq_raised,
drivers/misc/pci_endpoint_test.c:	wait_for_completion(&test->irq_raised);
drivers/misc/pci_endpoint_test.c:	wait_for_completion(&test->irq_raised);
drivers/misc/pci_endpoint_test.c:	wait_for_completion(&test->irq_raised);
drivers/misc/pci_endpoint_test.c:	reinit_completion(&test->irq_raised);
drivers/misc/pci_endpoint_test.c:	init_completion(&test->irq_raised);
drivers/misc/sgi-gru/gru_instructions.h: * to complete. Completion status (IDLE or EXCEPTION is returned
drivers/misc/sgi-gru/grufault.c:	struct completion *cmp;
drivers/misc/sgi-gru/grukservices.c: *		  interrupts on completion.
drivers/misc/sgi-gru/grukservices.c: *			  GRU instruction and must wait/check completion.
drivers/misc/sgi-gru/grukservices.c:			struct completion *cmp)
drivers/misc/sgi-gru/grukservices.c:	wait_for_completion(bs->bs_async_wq);
drivers/misc/sgi-gru/grukservices.c:	static DECLARE_COMPLETION(cmp);
drivers/misc/sgi-gru/grukservices.h: * 		cmp	  - completion structure for waiting for
drivers/misc/sgi-gru/grukservices.h: * 			    async completions
drivers/misc/sgi-gru/grukservices.h:				struct completion *cmp);
drivers/misc/sgi-gru/grutables.h:	struct completion	*bs_async_wq;
drivers/misc/sgi-xp/xpc.h:#include <linux/completion.h>
drivers/misc/sgi-xp/xpc.h:	struct completion wdisconnect_wait;    /* wait for channel disconnect */
drivers/misc/sgi-xp/xpc_channel.c:	/* wake those waiting for notify completion */
drivers/misc/sgi-xp/xpc_main.c:static DECLARE_COMPLETION(xpc_hb_checker_exited);
drivers/misc/sgi-xp/xpc_main.c:static DECLARE_COMPLETION(xpc_discovery_exited);
drivers/misc/sgi-xp/xpc_main.c:		init_completion(&ch->wdisconnect_wait);
drivers/misc/sgi-xp/xpc_main.c:		wait_for_completion(&ch->wdisconnect_wait);
drivers/misc/sgi-xp/xpc_main.c:	wait_for_completion(&xpc_discovery_exited);
drivers/misc/sgi-xp/xpc_main.c:	wait_for_completion(&xpc_hb_checker_exited);
drivers/misc/ti-st/st_kim.c:	reinit_completion(&kim_gdata->kim_rcvd);
drivers/misc/ti-st/st_kim.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/misc/ti-st/st_kim.c:	reinit_completion(&kim_gdata->kim_rcvd);
drivers/misc/ti-st/st_kim.c:			 * reinit completion before sending for the
drivers/misc/ti-st/st_kim.c:			reinit_completion(&kim_gdata->kim_rcvd);
drivers/misc/ti-st/st_kim.c:			err = wait_for_completion_interruptible_timeout(
drivers/misc/ti-st/st_kim.c:			reinit_completion(&kim_gdata->kim_rcvd);
drivers/misc/ti-st/st_kim.c: * to signal completion of line discipline installation
drivers/misc/ti-st/st_kim.c:		/* re-initialize the completion */
drivers/misc/ti-st/st_kim.c:		reinit_completion(&kim_gdata->ldisc_installed);
drivers/misc/ti-st/st_kim.c:		err = wait_for_completion_interruptible_timeout(
drivers/misc/ti-st/st_kim.c:	reinit_completion(&kim_gdata->ldisc_installed);
drivers/misc/ti-st/st_kim.c:	err = wait_for_completion_interruptible_timeout(
drivers/misc/ti-st/st_kim.c:	init_completion(&kim_gdata->kim_rcvd);
drivers/misc/ti-st/st_kim.c:	init_completion(&kim_gdata->ldisc_installed);
drivers/misc/tifm_7xx1.c:	DECLARE_COMPLETION_ONSTACK(finish_resume);
drivers/misc/tifm_7xx1.c:		time_left = wait_for_completion_timeout(&finish_resume, HZ);
drivers/misc/vmw_vmci/vmci_doorbell.c:#include <linux/completion.h>
drivers/misc/vmw_vmci/vmci_guest.c: * which is for the completion of a DMA datagram send or receive operation.
drivers/misc/vmw_vmci/vmci_resource.c:#include <linux/completion.h>
drivers/misc/vmw_vmci/vmci_resource.c:	init_completion(&resource->done);
drivers/misc/vmw_vmci/vmci_resource.c:	wait_for_completion(&resource->done);
drivers/misc/vmw_vmci/vmci_resource.h:	struct completion done;
drivers/mmc/core/block.c: * partial completions.
drivers/mmc/core/block.c:	 * Block layer timeouts race with completions which means the normal
drivers/mmc/core/block.c:	 * completion path cannot be used during recovery.
drivers/mmc/core/block.c:	 * Block layer timeouts race with completions which means the normal
drivers/mmc/core/block.c:	 * completion path cannot be used during recovery.
drivers/mmc/core/block.c:static void mmc_blk_mq_poll_completion(struct mmc_queue *mq,
drivers/mmc/core/block.c:	 * Block layer timeouts race with completions which means the normal
drivers/mmc/core/block.c:	 * completion path cannot be used during recovery.
drivers/mmc/core/block.c:	mmc_blk_mq_poll_completion(mq, mq->complete_req);
drivers/mmc/core/block.c:		pr_err("Failed to create mmc completion workqueue");
drivers/mmc/core/core.c:#include <linux/completion.h>
drivers/mmc/core/core.c:	if (mrq->cap_cmd_during_tfr && !completion_done(&mrq->cmd_completion))
drivers/mmc/core/core.c:		complete_all(&mrq->cmd_completion);
drivers/mmc/core/core.c:		 * cmd_completion, so ensure it is reinitialised.
drivers/mmc/core/core.c:		reinit_completion(&mrq->cmd_completion);
drivers/mmc/core/core.c:	init_completion(&mrq->cmd_completion);
drivers/mmc/core/core.c:	complete(&mrq->completion);
drivers/mmc/core/core.c:	if (ongoing_mrq && !completion_done(&ongoing_mrq->cmd_completion))
drivers/mmc/core/core.c:		wait_for_completion(&ongoing_mrq->cmd_completion);
drivers/mmc/core/core.c:	init_completion(&mrq->completion);
drivers/mmc/core/core.c:		complete(&mrq->completion);
drivers/mmc/core/core.c:		wait_for_completion(&mrq->completion);
drivers/mmc/core/core.c:	return completion_done(&mrq->completion);
drivers/mmc/core/core.c: *	mmc_wait_for_req - start a request and wait for completion
drivers/mmc/core/core.c: *	mmc_wait_for_cmd - start a command and wait for completion
drivers/mmc/core/mmc_test.c:	complete(&mrq->completion);
drivers/mmc/core/mmc_test.c:		init_completion(&mrq->completion);
drivers/mmc/core/mmc_test.c:		wait_for_completion(&prev_mrq->completion);
drivers/mmc/host/alcor.c:	 * Upon DMA completion of a single segment (signalled via IRQ), we
drivers/mmc/host/atmel-mci.c:#define	ATMCI_CSTOR			0x001c	/* Completion Signal Timeout[2] */
drivers/mmc/host/atmel-mci.c:#define		ATMCI_CSRCV			BIT(13)		/* CE-ATA Completion Signal Received */
drivers/mmc/host/atmel-mci.c:#define		ATMCI_CSTOE			BIT(23)		/* Completion Signal Time-out Error */
drivers/mmc/host/atmel-mci.c: * @cmd_status: Snapshot of SR taken upon completion of the current
drivers/mmc/host/atmel-mci.c: * @data_status: Snapshot of SR taken upon completion of the current
drivers/mmc/host/atmel-mci.c:		 * completion callback" rule of the dma engine
drivers/mmc/host/bcm2835.c:			/* No busy, so poll for completion */
drivers/mmc/host/cavium.c:	 * For requests the lock is only released after the completion
drivers/mmc/host/cqhci-core.c:	/* No completions allowed during recovery */
drivers/mmc/host/cqhci-core.c:	init_completion(&cq_host->halt_comp);
drivers/mmc/host/cqhci.h:#include <linux/completion.h>
drivers/mmc/host/cqhci.h:/* task completion notification */
drivers/mmc/host/cqhci.h:	struct completion halt_comp;
drivers/mmc/host/davinci_mmc.c:		/* Send clock cycles, poll completion */
drivers/mmc/host/dw_mmc.h: * @cmd_status: Snapshot of SR taken upon completion of the current
drivers/mmc/host/dw_mmc.h: * @data_status: Snapshot of SR taken upon completion of the current
drivers/mmc/host/litex_mmc.c:	struct completion cmd_done;
drivers/mmc/host/litex_mmc.c:		reinit_completion(&host->cmd_done);
drivers/mmc/host/litex_mmc.c:		wait_for_completion(&host->cmd_done);
drivers/mmc/host/litex_mmc.c:	/* Wait for completion of (read or write) DMA transfer */
drivers/mmc/host/litex_mmc.c:	init_completion(&host->cmd_done);
drivers/mmc/host/mmci.c:	 * monitoring DAT0 for busy completion, but there is only one
drivers/mmc/host/mmci.c: * Handle completion of command and data transfers.
drivers/mmc/host/mmci_stm32_sdmmc.c:	 * to wait this completion. Else this request has no busy step.
drivers/mmc/host/mmci_stm32_sdmmc.c:	/* clear the voltage switch completion flag */
drivers/mmc/host/mmci_stm32_sdmmc.c:		/* wait voltage switch completion while 10ms */
drivers/mmc/host/moxart-mmc.c:	struct completion		dma_complete;
drivers/mmc/host/moxart-mmc.c:	struct completion		pio_complete;
drivers/mmc/host/moxart-mmc.c:	wait_for_completion_interruptible_timeout(&host->dma_complete,
drivers/mmc/host/moxart-mmc.c:	init_completion(&host->dma_complete);
drivers/mmc/host/moxart-mmc.c:	init_completion(&host->pio_complete);
drivers/mmc/host/moxart-mmc.c:			wait_for_completion_interruptible_timeout(&host->pio_complete,
drivers/mmc/host/mxs-mmc.c:#include <linux/completion.h>
drivers/mmc/host/omap.c:		/* Send clock cycles, poll completion */
drivers/mmc/host/omap_hsmmc.c: * Notify the core about command completion
drivers/mmc/host/owl-mmc.c:	struct completion sdc_complete;
drivers/mmc/host/owl-mmc.c:	struct completion dma_complete;
drivers/mmc/host/owl-mmc.c:	init_completion(&owl_host->sdc_complete);
drivers/mmc/host/owl-mmc.c:	if (!wait_for_completion_timeout(&owl_host->sdc_complete, timeout)) {
drivers/mmc/host/owl-mmc.c:		init_completion(&owl_host->dma_complete);
drivers/mmc/host/owl-mmc.c:		if (!wait_for_completion_timeout(&owl_host->sdc_complete,
drivers/mmc/host/owl-mmc.c:		if (!wait_for_completion_timeout(&owl_host->dma_complete,
drivers/mmc/host/owl-mmc.c:	init_completion(&owl_host->sdc_complete);
drivers/mmc/host/owl-mmc.c:	if (!wait_for_completion_timeout(&owl_host->sdc_complete, HZ)) {
drivers/mmc/host/renesas_sdhi.h:	struct completion dma_dataend;
drivers/mmc/host/renesas_sdhi_sys_dmac.c:	wait_for_completion(&priv->dma_priv.dma_dataend);
drivers/mmc/host/renesas_sdhi_sys_dmac.c:		reinit_completion(&priv->dma_priv.dma_dataend);
drivers/mmc/host/renesas_sdhi_sys_dmac.c:		reinit_completion(&priv->dma_priv.dma_dataend);
drivers/mmc/host/renesas_sdhi_sys_dmac.c:		init_completion(&priv->dma_priv.dma_dataend);
drivers/mmc/host/sdhci.c:	 * on successful completion (so no Auto-CMD12).
drivers/mmc/host/sdhci.c:	/* Process mrqs ready for immediate completion */
drivers/mmc/host/sdhci.h:	struct workqueue_struct *complete_wq;	/* Request completion wq */
drivers/mmc/host/sdhci.h:	struct work_struct	complete_work;	/* Request completion work */
drivers/mmc/host/sdricoh_cs.c:	/* wait for command completion */
drivers/mmc/host/sh_mmcif.c: * initialises the hardware, installs a timeout handler to handle completion
drivers/mmc/host/sh_mmcif.c: * thread, a DMA completion callback, if DMA is used, a timeout work, and
drivers/mmc/host/sh_mmcif.c: * processing completion, the MMC core is informed and the request processing is
drivers/mmc/host/sh_mmcif.c:#include <linux/completion.h>
drivers/mmc/host/sh_mmcif.c:	bool ccs_enable;		/* Command Completion Signal support */
drivers/mmc/host/sh_mmcif.c:	struct completion	dma_complete;
drivers/mmc/host/sh_mmcif.c:	if (WARN(!mrq || !mrq->data, "%s: NULL data in DMA completion!\n",
drivers/mmc/host/sh_mmcif.c:	 * Completion can be signalled from DMA callback and error, so, have to
drivers/mmc/host/sh_mmcif.c:	init_completion(&host->dma_complete);
drivers/mmc/host/sh_mmcif.c:	time = wait_for_completion_interruptible_timeout(&host->dma_complete,
drivers/mmc/host/sh_mmcif.c:			"Error IRQ while waiting for DMA completion!\n");
drivers/mmc/host/sh_mmcif.c:			"wait_for_completion_...() error %ld!\n", time);
drivers/mmc/host/sunxi-mmc.c:#define SDXC_IDMAC_DES0_DIC	BIT(1)  /* disable interrupt on completion */
drivers/mmc/host/tmio_mmc_core.c:	/* Command completion */
drivers/mmc/host/tmio_mmc_core.c:	/* Data transfer completion */
drivers/mmc/host/toshsd.c:	/* Command completion */
drivers/mmc/host/toshsd.c:	/* Data transfer completion */
drivers/mmc/host/usdhi6rol0.c:	if (WARN(!mrq || !mrq->data, "%s: NULL data in DMA completion for %p!\n",
drivers/mmc/host/usdhi6rol0.c:	/* We have to get a command completion interrupt with DMA too */
drivers/mmc/host/vub300.c:	struct completion command_complete;
drivers/mmc/host/vub300.c:	struct completion irqpoll_complete;
drivers/mmc/host/vub300.c:{				/* urb completion handler - hardirq */
drivers/mmc/host/vub300.c:{				/* urb completion handler - hardirq */
drivers/mmc/host/vub300.c:	init_completion(&vub300->irqpoll_complete);
drivers/mmc/host/vub300.c:	commretval = wait_for_completion_timeout(&vub300->irqpoll_complete,
drivers/mmc/host/vub300.c:{				/* urb completion handler - hardirq */
drivers/mmc/host/vub300.c:{				/* urb completion handler - hardirq */
drivers/mmc/host/vub300.c:			 * the urb completion handler will call
drivers/mmc/host/vub300.c:			 * our completion handler
drivers/mmc/host/vub300.c:static void vub300_usb_bulk_msg_completion(struct urb *urb)
drivers/mmc/host/vub300.c:{				/* urb completion handler - hardirq */
drivers/mmc/host/vub300.c:	complete((struct completion *)urb->context);
drivers/mmc/host/vub300.c:	struct completion done;
drivers/mmc/host/vub300.c:			  vub300_usb_bulk_msg_completion, NULL);
drivers/mmc/host/vub300.c:	init_completion(&done);
drivers/mmc/host/vub300.c:	if (!wait_for_completion_timeout
drivers/mmc/host/vub300.c:		wait_for_completion_timeout(&vub300->command_complete,
drivers/mmc/host/vub300.c:		init_completion(&vub300->command_complete);
drivers/mmc/host/wmt-sdmmc.c:	struct completion cmdcomp;
drivers/mmc/host/wmt-sdmmc.c:	struct completion datacomp;
drivers/mmc/host/wmt-sdmmc.c:	struct completion *comp_cmd;
drivers/mmc/host/wmt-sdmmc.c:	struct completion *comp_dma;
drivers/mmc/host/wmt-sdmmc.c:			init_completion(priv->comp_cmd);
drivers/mmc/host/wmt-sdmmc.c:		if (completion_done(priv->comp_cmd)) {
drivers/mmc/host/wmt-sdmmc.c:			if (completion_done(priv->comp_dma))
drivers/mmc/host/wmt-sdmmc.c:		/* completion is now handled in the regular_isr() */
drivers/mmc/host/wmt-sdmmc.c:		init_completion(priv->comp_cmd);
drivers/mmc/host/wmt-sdmmc.c:		init_completion(priv->comp_dma);
drivers/most/core.c:#include <linux/completion.h>
drivers/most/core.c:	struct completion cleanup;
drivers/most/core.c: * Calls the completion handler of an attached component.
drivers/most/core.c:	if (c->pipe0.refs && c->pipe0.comp->tx_completion)
drivers/most/core.c:		c->pipe0.comp->tx_completion(c->iface, c->channel_id);
drivers/most/core.c:	if (c->pipe1.refs && c->pipe1.comp->tx_completion)
drivers/most/core.c:		c->pipe1.comp->tx_completion(c->iface, c->channel_id);
drivers/most/core.c: * @compl: pointer to completion function
drivers/most/core.c: * most_write_completion - write completion handler
drivers/most/core.c:static void most_write_completion(struct mbo *mbo)
drivers/most/core.c: * most_read_completion - read completion handler
drivers/most/core.c:static void most_read_completion(struct mbo *mbo)
drivers/most/core.c:	if (c->pipe0.refs && c->pipe0.comp->rx_completion &&
drivers/most/core.c:	    c->pipe0.comp->rx_completion(mbo) == 0)
drivers/most/core.c:	if (c->pipe1.refs && c->pipe1.comp->rx_completion &&
drivers/most/core.c:	    c->pipe1.comp->rx_completion(mbo) == 0)
drivers/most/core.c:					   most_read_completion);
drivers/most/core.c:					   most_write_completion);
drivers/most/core.c:	if (wait_for_completion_interruptible(&c->cleanup)) {
drivers/most/core.c:	wait_for_completion(&c->cleanup);
drivers/most/core.c:		init_completion(&c->cleanup);
drivers/most/most_cdev.c: * comp_rx_completion - completion handler for rx channels
drivers/most/most_cdev.c:static int comp_rx_completion(struct mbo *mbo)
drivers/most/most_cdev.c: * comp_tx_completion - completion handler for tx channels
drivers/most/most_cdev.c:static int comp_tx_completion(struct most_interface *iface, int channel_id)
drivers/most/most_cdev.c:		.rx_completion = comp_rx_completion,
drivers/most/most_cdev.c:		.tx_completion = comp_tx_completion,
drivers/most/most_snd.c: * audio_rx_completion - completion handler for rx channels
drivers/most/most_snd.c:static int audio_rx_completion(struct mbo *mbo)
drivers/most/most_snd.c: * audio_tx_completion - completion handler for tx channels
drivers/most/most_snd.c:static int audio_tx_completion(struct most_interface *iface, int channel_id)
drivers/most/most_snd.c:	.rx_completion = audio_rx_completion,
drivers/most/most_snd.c:	.tx_completion = audio_tx_completion,
drivers/most/most_usb.c:#include <linux/completion.h>
drivers/most/most_usb.c: * calls the associated completion function of the core and removes
drivers/most/most_usb.c: * hdm_write_completion - completion function for submitted Tx URBs
drivers/most/most_usb.c: * the completion function.
drivers/most/most_usb.c:static void hdm_write_completion(struct urb *urb)
drivers/most/most_usb.c: * hdm_read_completion - completion function for submitted Rx URBs
drivers/most/most_usb.c: * padding bytes -if necessary- and calls the completion function.
drivers/most/most_usb.c:static void hdm_read_completion(struct urb *urb)
drivers/most/most_usb.c:				  hdm_write_completion,
drivers/most/most_usb.c:				  hdm_read_completion,
drivers/mtd/chips/cfi_cmdset_0001.c:		/* force the completion of any ongoing operation
drivers/mtd/chips/cfi_cmdset_0002.c: * Use status register to poll for Erase/write completion when DQ is not
drivers/mtd/devices/docg3.c: * doc_write_erase_wait_status - wait for write or erase completion
drivers/mtd/devices/powernv_flash.c:	if (rc == OPAL_ASYNC_COMPLETION) {
drivers/mtd/devices/spear_smi.c:/* timeout for command completion */
drivers/mtd/devices/spear_smi.c: * @cmd_complete: queue to wait for command completion of NOR-flash.
drivers/mtd/devices/spear_smi.c:	/* send the completion */
drivers/mtd/devices/st_spi_fsm.c:	dev_err(fsm->dev, "timeout on sequence completion\n");
drivers/mtd/devices/st_spi_fsm.c:	/* Wait for completion */
drivers/mtd/devices/st_spi_fsm.c:	/* Wait for completion */
drivers/mtd/hyperbus/hbmc-am654.c:#include <linux/completion.h>
drivers/mtd/hyperbus/hbmc-am654.c:	struct completion rx_dma_complete;
drivers/mtd/hyperbus/hbmc-am654.c:	reinit_completion(&priv->rx_dma_complete);
drivers/mtd/hyperbus/hbmc-am654.c:	if (!wait_for_completion_timeout(&priv->rx_dma_complete,  msecs_to_jiffies(len + 1000))) {
drivers/mtd/hyperbus/hbmc-am654.c:		dev_err(priv->ctlr->dev, "DMA wait_for_completion_timeout\n");
drivers/mtd/hyperbus/hbmc-am654.c:	init_completion(&priv->rx_dma_complete);
drivers/mtd/nand/ecc-mtk.c:	struct completion done;
drivers/mtd/nand/ecc-mtk.c:		init_completion(&ecc->done);
drivers/mtd/nand/ecc-mtk.c:	ret = wait_for_completion_timeout(&ecc->done, msecs_to_jiffies(500));
drivers/mtd/nand/ecc-mxic.c:	struct completion complete;
drivers/mtd/nand/ecc-mxic.c:static int mxic_ecc_data_xfer_wait_for_completion(struct mxic_ecc_engine *mxic)
drivers/mtd/nand/ecc-mxic.c:		reinit_completion(&mxic->complete);
drivers/mtd/nand/ecc-mxic.c:		ret = wait_for_completion_timeout(&mxic->complete,
drivers/mtd/nand/ecc-mxic.c:		dev_err(mxic->dev, "Timeout on data xfer completion\n");
drivers/mtd/nand/ecc-mxic.c:	/* Wait for completion */
drivers/mtd/nand/ecc-mxic.c:	ret = mxic_ecc_data_xfer_wait_for_completion(mxic);
drivers/mtd/nand/onenand/onenand_base.c:	wait_for_completion(&this->complete);
drivers/mtd/nand/onenand/onenand_base.c:	remain = wait_for_completion_timeout(&this->complete, timeout);
drivers/mtd/nand/onenand/onenand_base.c:	init_completion(&this->complete);
drivers/mtd/nand/onenand/onenand_omap2.c:	struct completion irq_done;
drivers/mtd/nand/onenand/onenand_omap2.c:	struct completion dma_done;
drivers/mtd/nand/onenand/onenand_omap2.c:static void omap2_onenand_dma_complete_func(void *completion)
drivers/mtd/nand/onenand/onenand_omap2.c:	complete(completion);
drivers/mtd/nand/onenand/onenand_omap2.c:		reinit_completion(&c->irq_done);
drivers/mtd/nand/onenand/onenand_omap2.c:			if (!wait_for_completion_io_timeout(&c->irq_done,
drivers/mtd/nand/onenand/onenand_omap2.c:	reinit_completion(&c->dma_done);
drivers/mtd/nand/onenand/onenand_omap2.c:	if (!wait_for_completion_io_timeout(&c->dma_done,
drivers/mtd/nand/onenand/onenand_omap2.c:	init_completion(&c->irq_done);
drivers/mtd/nand/onenand/onenand_omap2.c:	init_completion(&c->dma_done);
drivers/mtd/nand/onenand/onenand_samsung.c:	struct completion	complete;
drivers/mtd/nand/onenand/onenand_samsung.c:	wait_for_completion_timeout(&onenand->complete, msecs_to_jiffies(20));
drivers/mtd/nand/onenand/onenand_samsung.c:			init_completion(&onenand->complete);
drivers/mtd/nand/raw/atmel/nand-controller.c:	struct completion complete;
drivers/mtd/nand/raw/atmel/nand-controller.c:		init_completion(&nc->complete);
drivers/mtd/nand/raw/atmel/nand-controller.c:		ret = wait_for_completion_timeout(&nc->complete,
drivers/mtd/nand/raw/atmel/nand-controller.c:	struct completion *finished = data;
drivers/mtd/nand/raw/atmel/nand-controller.c:	DECLARE_COMPLETION_ONSTACK(finished);
drivers/mtd/nand/raw/atmel/nand-controller.c:	wait_for_completion(&finished);
drivers/mtd/nand/raw/brcmnand/brcmnand.c:#include <linux/completion.h>
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	struct completion	done;
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	struct completion	dma_done;
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	struct completion       edu_done;
drivers/mtd/nand/raw/brcmnand/brcmnand.c:static bool brcmstb_nand_wait_for_completion(struct nand_chip *chip)
drivers/mtd/nand/raw/brcmnand/brcmnand.c:		/* wait for completion interrupt */
drivers/mtd/nand/raw/brcmnand/brcmnand.c:		sts = wait_for_completion_timeout(&ctrl->done, timeo);
drivers/mtd/nand/raw/brcmnand/brcmnand.c:		err = brcmstb_nand_wait_for_completion(chip);
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	if (wait_for_completion_timeout(&ctrl->edu_done, timeo) <= 0) {
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	if (wait_for_completion_timeout(&ctrl->dma_done, timeo) <= 0) {
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	init_completion(&ctrl->done);
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	init_completion(&ctrl->dma_done);
drivers/mtd/nand/raw/brcmnand/brcmnand.c:	init_completion(&ctrl->edu_done);
drivers/mtd/nand/raw/cadence-nand-controller.c: * the completion of descriptor processing.
drivers/mtd/nand/raw/cadence-nand-controller.c:	struct completion complete;
drivers/mtd/nand/raw/cadence-nand-controller.c:	time_left = wait_for_completion_timeout(&cdns_ctrl->complete,
drivers/mtd/nand/raw/cadence-nand-controller.c:	reinit_completion(&cdns_ctrl->complete);
drivers/mtd/nand/raw/cadence-nand-controller.c:	struct completion *finished = data;
drivers/mtd/nand/raw/cadence-nand-controller.c:	DECLARE_COMPLETION_ONSTACK(finished);
drivers/mtd/nand/raw/cadence-nand-controller.c:	wait_for_completion(&finished);
drivers/mtd/nand/raw/cadence-nand-controller.c:	init_completion(&cdns_ctrl->complete);
drivers/mtd/nand/raw/denali.c:#include <linux/completion.h>
drivers/mtd/nand/raw/denali.c:	reinit_completion(&denali->complete);
drivers/mtd/nand/raw/denali.c:	time_left = wait_for_completion_timeout(&denali->complete,
drivers/mtd/nand/raw/denali.c:	init_completion(&denali->complete);
drivers/mtd/nand/raw/denali.h:#include <linux/completion.h>
drivers/mtd/nand/raw/denali.h: * @complete:       completion used to wait for interrupts
drivers/mtd/nand/raw/denali.h:	struct completion complete;
drivers/mtd/nand/raw/fsmc_nand.c:#include <linux/completion.h>
drivers/mtd/nand/raw/fsmc_nand.c: * @dma_access_complete: Completion structure
drivers/mtd/nand/raw/fsmc_nand.c:	struct completion	dma_access_complete;
drivers/mtd/nand/raw/fsmc_nand.c:	wait_for_completion_timeout(&host->dma_access_complete,
drivers/mtd/nand/raw/fsmc_nand.c:		dev_err(host->dev, "wait_for_completion_timeout\n");
drivers/mtd/nand/raw/fsmc_nand.c:		init_completion(&host->dma_access_complete);
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	struct completion *dma_c = &this->dma_done;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	struct completion *dma_completion, *bch_completion;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	dma_completion = &this->dma_done;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	bch_completion = NULL;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	init_completion(dma_completion);
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:		bch_completion = &this->bch_done;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:		init_completion(bch_completion);
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:	to = wait_for_completion_timeout(dma_completion, msecs_to_jiffies(1000));
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c:		to = wait_for_completion_timeout(bch_completion, msecs_to_jiffies(1000));
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h:	struct completion	bch_done;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h:	struct completion	dma_done;
drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h:/* BCH : Status Block Completion Codes */
drivers/mtd/nand/raw/hisi504_nand.c:	struct completion       cmd_complete;
drivers/mtd/nand/raw/hisi504_nand.c:	init_completion(&host->cmd_complete);
drivers/mtd/nand/raw/hisi504_nand.c:	ret = wait_for_completion_timeout(&host->cmd_complete,
drivers/mtd/nand/raw/intel-nand-controller.c:#include <linux/completion.h>
drivers/mtd/nand/raw/intel-nand-controller.c:	struct completion dma_access_complete;
drivers/mtd/nand/raw/intel-nand-controller.c:	struct completion *dma_completion;
drivers/mtd/nand/raw/intel-nand-controller.c:		dma_completion = &ebu_host->dma_access_complete;
drivers/mtd/nand/raw/intel-nand-controller.c:		dma_completion = &ebu_host->dma_access_complete;
drivers/mtd/nand/raw/intel-nand-controller.c:	init_completion(dma_completion);
drivers/mtd/nand/raw/intel-nand-controller.c:	time_left = wait_for_completion_timeout(dma_completion, msecs_to_jiffies(1000));
drivers/mtd/nand/raw/lpc32xx_mlc.c:#include <linux/completion.h>
drivers/mtd/nand/raw/lpc32xx_mlc.c:	struct completion       comp_nand;
drivers/mtd/nand/raw/lpc32xx_mlc.c:	struct completion       comp_controller;
drivers/mtd/nand/raw/lpc32xx_mlc.c:	struct completion	comp_dma;
drivers/mtd/nand/raw/lpc32xx_mlc.c: * wait_for_completion() (DMA setup _not_ included).
drivers/mtd/nand/raw/lpc32xx_mlc.c:	wait_for_completion(&host->comp_nand);
drivers/mtd/nand/raw/lpc32xx_mlc.c:	wait_for_completion(&host->comp_controller);
drivers/mtd/nand/raw/lpc32xx_mlc.c:static void lpc32xx_dma_complete_func(void *completion)
drivers/mtd/nand/raw/lpc32xx_mlc.c:	complete(completion);
drivers/mtd/nand/raw/lpc32xx_mlc.c:	init_completion(&host->comp_dma);
drivers/mtd/nand/raw/lpc32xx_mlc.c:	wait_for_completion_timeout(&host->comp_dma, msecs_to_jiffies(1000));
drivers/mtd/nand/raw/lpc32xx_mlc.c:	init_completion(&host->comp_nand);
drivers/mtd/nand/raw/lpc32xx_mlc.c:	init_completion(&host->comp_controller);
drivers/mtd/nand/raw/lpc32xx_slc.c:	struct completion	comp;
drivers/mtd/nand/raw/lpc32xx_slc.c:static void lpc32xx_dma_complete_func(void *completion)
drivers/mtd/nand/raw/lpc32xx_slc.c:	complete(completion);
drivers/mtd/nand/raw/lpc32xx_slc.c:	init_completion(&host->comp);
drivers/mtd/nand/raw/lpc32xx_slc.c:	wait_for_completion_timeout(&host->comp, msecs_to_jiffies(1000));
drivers/mtd/nand/raw/marvell_nand.c: * @complete:		Completion object to wait for NAND controller events
drivers/mtd/nand/raw/marvell_nand.c:	struct completion complete;
drivers/mtd/nand/raw/marvell_nand.c:		init_completion(&nfc->complete);
drivers/mtd/nand/raw/marvell_nand.c:		ret = wait_for_completion_timeout(&nfc->complete,
drivers/mtd/nand/raw/meson_nand.c:	struct completion completion;
drivers/mtd/nand/raw/meson_nand.c:	reinit_completion(&nfc->completion);
drivers/mtd/nand/raw/meson_nand.c:	if (!wait_for_completion_timeout(&nfc->completion,
drivers/mtd/nand/raw/meson_nand.c:	reinit_completion(&nfc->completion);
drivers/mtd/nand/raw/meson_nand.c:	ret = wait_for_completion_timeout(&nfc->completion,
drivers/mtd/nand/raw/meson_nand.c:	complete(&nfc->completion);
drivers/mtd/nand/raw/meson_nand.c:	init_completion(&nfc->completion);
drivers/mtd/nand/raw/mtk_nand.c:	struct completion done;
drivers/mtd/nand/raw/mtk_nand.c:	init_completion(&nfc->done);
drivers/mtd/nand/raw/mtk_nand.c:	ret = wait_for_completion_timeout(&nfc->done, msecs_to_jiffies(500));
drivers/mtd/nand/raw/mtk_nand.c:	init_completion(&nfc->done);
drivers/mtd/nand/raw/mtk_nand.c:	rc = wait_for_completion_timeout(&nfc->done, msecs_to_jiffies(500));
drivers/mtd/nand/raw/mxc_nand.c:#include <linux/completion.h>
drivers/mtd/nand/raw/mxc_nand.c:	struct completion	op_completion;
drivers/mtd/nand/raw/mxc_nand.c:	complete(&host->op_completion);
drivers/mtd/nand/raw/mxc_nand.c:		reinit_completion(&host->op_completion);
drivers/mtd/nand/raw/mxc_nand.c:		time_left = wait_for_completion_timeout(&host->op_completion, HZ);
drivers/mtd/nand/raw/mxc_nand.c:			dev_dbg(host->dev, "timeout polling for completion\n");
drivers/mtd/nand/raw/mxc_nand.c: * waits for completion. */
drivers/mtd/nand/raw/mxc_nand.c:		/* Reset completion is indicated by NFC_CONFIG2 */
drivers/mtd/nand/raw/mxc_nand.c:	init_completion(&host->op_completion);
drivers/mtd/nand/raw/mxic_nand.c:	struct completion complete;
drivers/mtd/nand/raw/mxic_nand.c:	ret = wait_for_completion_timeout(&nfc->complete,
drivers/mtd/nand/raw/mxic_nand.c:	init_completion(&nfc->complete);
drivers/mtd/nand/raw/nandsim.c:/* Good operation completion status */
drivers/mtd/nand/raw/nandsim.c:/* Operation failed completion status */
drivers/mtd/nand/raw/omap2.c:	struct completion		comp;
drivers/mtd/nand/raw/omap2.c: * omap_nand_dma_callback: callback on the completion of dma transfer
drivers/mtd/nand/raw/omap2.c: * @data: pointer to completion data structure
drivers/mtd/nand/raw/omap2.c:	complete((struct completion *) data);
drivers/mtd/nand/raw/omap2.c:	init_completion(&info->comp);
drivers/mtd/nand/raw/omap2.c:	wait_for_completion(&info->comp);
drivers/mtd/nand/raw/omap2.c:	init_completion(&info->comp);
drivers/mtd/nand/raw/omap2.c:	wait_for_completion(&info->comp);
drivers/mtd/nand/raw/omap2.c:	init_completion(&info->comp);
drivers/mtd/nand/raw/omap2.c:	wait_for_completion(&info->comp);
drivers/mtd/nand/raw/omap_elm.c:	struct completion elm_completion;
drivers/mtd/nand/raw/omap_elm.c: * On completion of processing by elm module, error location status
drivers/mtd/nand/raw/omap_elm.c:	wait_for_completion(&info->elm_completion);
drivers/mtd/nand/raw/omap_elm.c:		complete(&info->elm_completion);
drivers/mtd/nand/raw/omap_elm.c:	init_completion(&info->elm_completion);
drivers/mtd/nand/raw/qcom_nandc.c:#define QPIC_NAND_COMPLETION_TIMEOUT	msecs_to_jiffies(2000)
drivers/mtd/nand/raw/qcom_nandc.c: * @txn_done - completion for NAND transfer.
drivers/mtd/nand/raw/qcom_nandc.c: * @wait_second_completion - wait for second DMA desc completion before making
drivers/mtd/nand/raw/qcom_nandc.c: *			     the NAND transfer completion.
drivers/mtd/nand/raw/qcom_nandc.c:	struct completion txn_done;
drivers/mtd/nand/raw/qcom_nandc.c:	bool wait_second_completion;
drivers/mtd/nand/raw/qcom_nandc.c:	init_completion(&bam_txn->txn_done);
drivers/mtd/nand/raw/qcom_nandc.c:	bam_txn->wait_second_completion = false;
drivers/mtd/nand/raw/qcom_nandc.c:	reinit_completion(&bam_txn->txn_done);
drivers/mtd/nand/raw/qcom_nandc.c:/* Callback for DMA descriptor completion */
drivers/mtd/nand/raw/qcom_nandc.c:	 * (i.e. wait_second_completion is true), then set this to false
drivers/mtd/nand/raw/qcom_nandc.c:	 * and wait for second DMA descriptor completion.
drivers/mtd/nand/raw/qcom_nandc.c:	if (bam_txn->wait_second_completion)
drivers/mtd/nand/raw/qcom_nandc.c:		bam_txn->wait_second_completion = false;
drivers/mtd/nand/raw/qcom_nandc.c:			bam_txn->wait_second_completion = true;
drivers/mtd/nand/raw/qcom_nandc.c:		if (!wait_for_completion_timeout(&bam_txn->txn_done,
drivers/mtd/nand/raw/qcom_nandc.c:						 QPIC_NAND_COMPLETION_TIMEOUT))
drivers/mtd/nand/raw/r852.c:	long timeout = wait_for_completion_timeout(&dev->dma_done,
drivers/mtd/nand/raw/r852.c:	reinit_completion(&dev->dma_done);
drivers/mtd/nand/raw/r852.c:	init_completion(&dev->dma_done);
drivers/mtd/nand/raw/r852.h:#include <linux/completion.h>
drivers/mtd/nand/raw/r852.h:	struct completion dma_done;	/* data transfer done */
drivers/mtd/nand/raw/renesas-nand-controller.c:	struct completion complete;
drivers/mtd/nand/raw/renesas-nand-controller.c:		ret = wait_for_completion_timeout(&rnandc->complete,
drivers/mtd/nand/raw/renesas-nand-controller.c:	reinit_completion(&rnandc->complete);
drivers/mtd/nand/raw/renesas-nand-controller.c:	reinit_completion(&rnandc->complete);
drivers/mtd/nand/raw/renesas-nand-controller.c:	init_completion(&rnandc->complete);
drivers/mtd/nand/raw/rockchip-nand-controller.c:	struct completion done;
drivers/mtd/nand/raw/rockchip-nand-controller.c:	reinit_completion(&nfc->done);
drivers/mtd/nand/raw/rockchip-nand-controller.c:	ret = wait_for_completion_timeout(&nfc->done,
drivers/mtd/nand/raw/rockchip-nand-controller.c:	reinit_completion(&nfc->done);
drivers/mtd/nand/raw/rockchip-nand-controller.c:	ret = wait_for_completion_timeout(&nfc->done,
drivers/mtd/nand/raw/rockchip-nand-controller.c:	init_completion(&nfc->done);
drivers/mtd/nand/raw/sh_flctl.c:#include <linux/completion.h>
drivers/mtd/nand/raw/sh_flctl.c:static void wait_completion(struct sh_flctl *flctl)
drivers/mtd/nand/raw/sh_flctl.c:	init_completion(&flctl->dma_complete);
drivers/mtd/nand/raw/sh_flctl.c:	wait_for_completion_timeout(&flctl->dma_complete,
drivers/mtd/nand/raw/sh_flctl.c:		dev_err(&flctl->pdev->dev, "wait_for_completion_timeout\n");
drivers/mtd/nand/raw/sh_flctl.c:	wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:	wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:	wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:			wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:		wait_completion(flctl);
drivers/mtd/nand/raw/sh_flctl.c:	wait_completion(flctl);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	struct completion complete;
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	struct completion dma_data_complete;
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	struct completion dma_ecc_complete;
drivers/mtd/nand/raw/stm32_fmc2_nand.c:		reinit_completion(&nfc->complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	if (!wait_for_completion_timeout(&nfc->complete,
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	if (!wait_for_completion_timeout(&nfc->complete,
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	complete((struct completion *)arg);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	reinit_completion(&nfc->dma_data_complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	reinit_completion(&nfc->complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:		reinit_completion(&nfc->dma_ecc_complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	if (!wait_for_completion_timeout(&nfc->complete, timeout)) {
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	/* Wait DMA data transfer completion */
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	if (!wait_for_completion_timeout(&nfc->dma_data_complete, timeout)) {
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	/* Wait DMA ECC transfer completion */
drivers/mtd/nand/raw/stm32_fmc2_nand.c:		if (!wait_for_completion_timeout(&nfc->dma_ecc_complete,
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	init_completion(&nfc->dma_data_complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	init_completion(&nfc->dma_ecc_complete);
drivers/mtd/nand/raw/stm32_fmc2_nand.c:	init_completion(&nfc->complete);
drivers/mtd/nand/raw/sunxi_nand.c: * @complete: a completion object used to wait for NAND controller events
drivers/mtd/nand/raw/sunxi_nand.c:	struct completion complete;
drivers/mtd/nand/raw/sunxi_nand.c:		init_completion(&nfc->complete);
drivers/mtd/nand/raw/sunxi_nand.c:		ret = wait_for_completion_timeout(&nfc->complete,
drivers/mtd/nand/raw/tegra_nand.c:#include <linux/completion.h>
drivers/mtd/nand/raw/tegra_nand.c:	struct completion command_complete;
drivers/mtd/nand/raw/tegra_nand.c:	struct completion dma_complete;
drivers/mtd/nand/raw/tegra_nand.c:	reinit_completion(&ctrl->command_complete);
drivers/mtd/nand/raw/tegra_nand.c:	reinit_completion(&ctrl->dma_complete);
drivers/mtd/nand/raw/tegra_nand.c:	ret = wait_for_completion_timeout(&ctrl->command_complete,
drivers/mtd/nand/raw/tegra_nand.c:	ret = wait_for_completion_timeout(&ctrl->command_complete,
drivers/mtd/nand/raw/tegra_nand.c:	ret = wait_for_completion_timeout(&ctrl->dma_complete,
drivers/mtd/nand/raw/tegra_nand.c:	init_completion(&ctrl->command_complete);
drivers/mtd/nand/raw/tegra_nand.c:	init_completion(&ctrl->dma_complete);
drivers/mtd/nand/raw/vf610_nfc.c:	struct completion cmd_done;
drivers/mtd/nand/raw/vf610_nfc.c:	if (!wait_for_completion_timeout(&nfc->cmd_done, timeout))
drivers/mtd/nand/raw/vf610_nfc.c:	init_completion(&nfc->cmd_done);
drivers/mtd/sm_ftl.h:#include <linux/completion.h>
drivers/net/caif/caif_virtio.c: * @rx_napi_complete:	Number of NAPI completions (RX)
drivers/net/can/esd/esdacc.h:	/* (Re-)start and wait for completion of addon detection on the I^2C bus */
drivers/net/can/janz-ican3.c:	struct completion termination_comp;
drivers/net/can/janz-ican3.c:	struct completion buserror_comp;
drivers/net/can/janz-ican3.c:	if (!wait_for_completion_timeout(&mod->buserror_comp, HZ)) {
drivers/net/can/janz-ican3.c:	if (!wait_for_completion_timeout(&mod->termination_comp, HZ)) {
drivers/net/can/janz-ican3.c:	init_completion(&mod->termination_comp);
drivers/net/can/janz-ican3.c:	init_completion(&mod->buserror_comp);
drivers/net/can/kvaser_pciefd.c:	struct completion start_comp, flush_comp;
drivers/net/can/kvaser_pciefd.c:	if (!completion_done(&can->flush_comp))
drivers/net/can/kvaser_pciefd.c:	if (!wait_for_completion_timeout(&can->flush_comp,
drivers/net/can/kvaser_pciefd.c:	if (!wait_for_completion_timeout(&can->start_comp,
drivers/net/can/kvaser_pciefd.c:	if (!completion_done(&can->flush_comp))
drivers/net/can/kvaser_pciefd.c:	if (!wait_for_completion_timeout(&can->flush_comp,
drivers/net/can/kvaser_pciefd.c:		init_completion(&can->start_comp);
drivers/net/can/kvaser_pciefd.c:		init_completion(&can->flush_comp);
drivers/net/can/kvaser_pciefd.c:		if (!completion_done(&can->start_comp))
drivers/net/can/kvaser_pciefd.c:	if (!completion_done(&can->flush_comp))
drivers/net/can/m_can/m_can.h:#include <linux/completion.h>
drivers/net/can/spi/hi311x.c:#include <linux/completion.h>
drivers/net/can/spi/mcp251x.c:#include <linux/completion.h>
drivers/net/can/usb/etas_es58x/es58x_core.h: *	completion. @tx_tail & echo_skb_mask represents the beginning
drivers/net/can/usb/kvaser_usb/kvaser_usb.h:#include <linux/completion.h>
drivers/net/can/usb/kvaser_usb/kvaser_usb.h:	struct completion start_comp, stop_comp, flush_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c:#include <linux/completion.h>
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c: * of URB completions.
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c:	init_completion(&priv->start_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c:	init_completion(&priv->stop_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c:	init_completion(&priv->flush_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_core.c:	init_completion(&priv->get_busparams_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:#include <linux/completion.h>
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	if (completion_done(&priv->start_comp) &&
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	reinit_completion(&priv->get_busparams_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	if (!wait_for_completion_timeout(&priv->get_busparams_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	reinit_completion(&priv->start_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	if (!wait_for_completion_timeout(&priv->start_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	reinit_completion(&priv->stop_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	if (!wait_for_completion_timeout(&priv->stop_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	reinit_completion(&priv->flush_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_hydra.c:	if (!wait_for_completion_timeout(&priv->flush_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:#include <linux/completion.h>
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	if (completion_done(&priv->start_comp) &&
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	reinit_completion(&priv->start_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	if (!wait_for_completion_timeout(&priv->start_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	reinit_completion(&priv->stop_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	if (!wait_for_completion_timeout(&priv->stop_comp,
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	reinit_completion(&priv->get_busparams_comp);
drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c:	if (!wait_for_completion_timeout(&priv->get_busparams_comp,
drivers/net/dsa/lan9303-core.c:static int lan9303_indirect_phy_wait_for_completion(struct lan9303 *chip)
drivers/net/dsa/lan9303-core.c:	ret = lan9303_indirect_phy_wait_for_completion(chip);
drivers/net/dsa/lan9303-core.c:	ret = lan9303_indirect_phy_wait_for_completion(chip);
drivers/net/dsa/lan9303-core.c:	ret = lan9303_indirect_phy_wait_for_completion(chip);
drivers/net/dsa/lan9303-core.c:static int lan9303_switch_wait_for_completion(struct lan9303 *chip)
drivers/net/dsa/lan9303-core.c:	ret = lan9303_switch_wait_for_completion(chip);
drivers/net/dsa/lan9303-core.c:	ret = lan9303_switch_wait_for_completion(chip);
drivers/net/dsa/lan9303-core.c:	ret = lan9303_switch_wait_for_completion(chip);
drivers/net/dsa/microchip/ksz_common.h:	struct completion tstamp_msg_comp;
drivers/net/dsa/microchip/ksz_ptp.c:	ret = wait_for_completion_timeout(&prt->tstamp_msg_comp,
drivers/net/dsa/microchip/ksz_ptp.c:	reinit_completion(&prt->tstamp_msg_comp);
drivers/net/dsa/microchip/ksz_ptp.c:	init_completion(&port->tstamp_msg_comp);
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	ret = wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	ret = wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	ret = wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	ret = wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:		reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:		ret = wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mgmt_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	wait_for_completion_timeout(&mgmt_eth_data->rw_done,
drivers/net/dsa/qca/qca8k-8xxx.c:	reinit_completion(&mib_eth_data->rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	ret = wait_for_completion_timeout(&mib_eth_data->rw_done, QCA8K_ETHERNET_TIMEOUT);
drivers/net/dsa/qca/qca8k-8xxx.c:	init_completion(&priv->mgmt_eth_data.rw_done);
drivers/net/dsa/qca/qca8k-8xxx.c:	init_completion(&priv->mib_eth_data.rw_done);
drivers/net/dsa/qca/qca8k-common.c:	/* wait for completion */
drivers/net/dsa/qca/qca8k-common.c:	/* wait for completion */
drivers/net/dsa/qca/qca8k.h:	struct completion rw_done;
drivers/net/dsa/qca/qca8k.h:	struct completion rw_done;
drivers/net/dsa/realtek/rtl8365mb.c:	/* Poll for completion */
drivers/net/ethernet/3com/3c574_cs.c:static void tc574_wait_for_completion(struct net_device *dev, int cmd);
drivers/net/ethernet/3com/3c574_cs.c:		tc574_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c574_cs.c:		tc574_wait_for_completion(dev, RxReset);
drivers/net/ethernet/3com/3c574_cs.c:static void tc574_wait_for_completion(struct net_device *dev, int cmd)
drivers/net/ethernet/3com/3c574_cs.c:	tc574_wait_for_completion(dev, TotalReset|0x10);
drivers/net/ethernet/3com/3c574_cs.c:	tc574_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c574_cs.c:	tc574_wait_for_completion(dev, RxReset);
drivers/net/ethernet/3com/3c574_cs.c:	tc574_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c574_cs.c:			tc574_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c574_cs.c:					tc574_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c574_cs.c:					tc574_wait_for_completion(dev, RxReset);
drivers/net/ethernet/3com/3c574_cs.c:		tc574_wait_for_completion(dev, RxDiscard);
drivers/net/ethernet/3com/3c589_cs.c:static void tc589_wait_for_completion(struct net_device *dev, int cmd)
drivers/net/ethernet/3com/3c589_cs.c:	tc589_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c589_cs.c:			tc589_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c589_cs.c:					tc589_wait_for_completion(dev, TxReset);
drivers/net/ethernet/3com/3c589_cs.c:					tc589_wait_for_completion(dev, RxReset);
drivers/net/ethernet/3com/3c589_cs.c:		tc589_wait_for_completion(dev, RxDiscard);
drivers/net/ethernet/3com/3c59x.c:an extra interrupt or polling for the completion of each transfer, as well
drivers/net/ethernet/3com/typhoon.c:enum completion_wait_values {
drivers/net/ethernet/3com/typhoon.h: * status:	0 on completion
drivers/net/ethernet/8390/apne.c:	    {0x00,	NE_EN0_IMR},	/* Mask completion irq. */
drivers/net/ethernet/8390/axnet_cs.c:	{0x00,	EN0_IMR},	/* Mask completion irq. */
drivers/net/ethernet/8390/axnet_cs.c: * stack. We also handle transmit completions and wake the transmit path if
drivers/net/ethernet/8390/lib8390.c: * stack. We also handle transmit completions and wake the transmit path if
drivers/net/ethernet/8390/mcf8390.c:			{0x00,	NE_EN0_IMR},	/* Mask completion irq */
drivers/net/ethernet/8390/ne.c:			{0x00,	EN0_IMR},	/* Mask completion irq. */
drivers/net/ethernet/8390/ne2k-pci.c:			/* Mask completion IRQ */
drivers/net/ethernet/8390/pcnet_cs.c:	{0x00,	EN0_IMR},	/* Mask completion irq. */
drivers/net/ethernet/8390/zorro8390.c:			{0x00,	NE_EN0_IMR},	/* Mask completion irq */
drivers/net/ethernet/actions/owl-emac.c:	 * If that's the case, let's force the frame completion by manually
drivers/net/ethernet/actions/owl-emac.h:#define OWL_EMAC_BIT_TDES1_IC			BIT(31)	/* Interrupt on completion */
drivers/net/ethernet/adaptec/starfire.c:/* The completion queues are fixed at 1024 entries i.e. 4K or 8KB. */
drivers/net/ethernet/adaptec/starfire.c:minimum-length padding.  It does not use the completion queue
drivers/net/ethernet/adaptec/starfire.c:should fit in a single descriptor.  The driver does not use the completion
drivers/net/ethernet/adaptec/starfire.c:	CompletionHiAddr=0x500B4, TxCompletionAddr=0x500B8,
drivers/net/ethernet/adaptec/starfire.c:	RxCompletionAddr=0x500BC, RxCompletionQ2Addr=0x500C0,
drivers/net/ethernet/adaptec/starfire.c:	CompletionQConsumerIdx=0x500C4, RxDMACtrl=0x500D0,
drivers/net/ethernet/adaptec/starfire.c:	TxNoDMACompletion=0x08,
drivers/net/ethernet/adaptec/starfire.c:	RxCompletionQ2Enable=0x800000,
drivers/net/ethernet/adaptec/starfire.c:/* Bits in the RxCompletionAddr register */
drivers/net/ethernet/adaptec/starfire.c:/* Bits in the TxCompletionAddr register */
drivers/net/ethernet/adaptec/starfire.c:/* Completion queue entry. */
drivers/net/ethernet/adaptec/starfire.c:	/* Pointers to completion queues (full pages). */
drivers/net/ethernet/adaptec/starfire.c:	writel( (np->queue_mem_dma >> 16) >> 16, ioaddr + CompletionHiAddr);
drivers/net/ethernet/adaptec/starfire.c:	writel(np->tx_done_q_dma, ioaddr + TxCompletionAddr);
drivers/net/ethernet/adaptec/starfire.c:	       ioaddr + RxCompletionAddr);
drivers/net/ethernet/adaptec/starfire.c:	/* Clear the completion rings. */
drivers/net/ethernet/adaptec/starfire.c:				printk(KERN_DEBUG "%s: Tx completion #%d entry %d is %#8.8x.\n",
drivers/net/ethernet/adaptec/starfire.c:		writew(np->tx_done, ioaddr + CompletionQConsumerIdx + 2);
drivers/net/ethernet/adaptec/starfire.c:	writew(np->rx_done, np->base + CompletionQConsumerIdx);
drivers/net/ethernet/agere/et131x.c:	/* Load the completion writeback physical address */
drivers/net/ethernet/agere/et131x.c:	/* Load the completion writeback physical address */
drivers/net/ethernet/agere/et131x.c: * Checks the hardware for available packets, using completion ring
drivers/net/ethernet/agere/et131x.c:	 * the same "wrap" indicator as the current completion indicator
drivers/net/ethernet/agere/et131x.c:		 * request issued by the JAGCore has occurred or a completion is
drivers/net/ethernet/alacritech/slic.h:#define SLIC_MAX_TX_COMPLETIONS		100
drivers/net/ethernet/alacritech/slicoss.c:	/* Limit processing to SLIC_MAX_TX_COMPLETIONS frames to avoid that new
drivers/net/ethernet/alacritech/slicoss.c:	 * completions during processing keeps the loop running endlessly.
drivers/net/ethernet/alacritech/slicoss.c:	} while (frames < SLIC_MAX_TX_COMPLETIONS);
drivers/net/ethernet/altera/altera_msgdma.c:u32 msgdma_tx_completions(struct altera_tse_private *priv)
drivers/net/ethernet/altera/altera_msgdma.h:u32 msgdma_tx_completions(struct altera_tse_private *);
drivers/net/ethernet/altera/altera_sgdma.c:u32 sgdma_tx_completions(struct altera_tse_private *priv)
drivers/net/ethernet/altera/altera_sgdma.h:u32 sgdma_tx_completions(struct altera_tse_private *);
drivers/net/ethernet/altera/altera_tse.h:	u32 (*tx_completions)(struct altera_tse_private *);
drivers/net/ethernet/altera/altera_tse_main.c:	ready = priv->dmaops->tx_completions(priv);
drivers/net/ethernet/altera/altera_tse_main.c:	.tx_completions = sgdma_tx_completions,
drivers/net/ethernet/altera/altera_tse_main.c:	.tx_completions = msgdma_tx_completions,
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:enum ena_admin_aq_completion_status {
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:enum ena_admin_completion_policy_type {
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	/* completion queue entry for each sq descriptor */
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	ENA_ADMIN_COMPLETION_POLICY_DESC            = 0,
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	/* completion queue entry upon request in sq descriptor */
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	ENA_ADMIN_COMPLETION_POLICY_DESC_ON_DEMAND  = 1,
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	ENA_ADMIN_COMPLETION_POLICY_HEAD_ON_DEMAND  = 2,
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	ENA_ADMIN_COMPLETION_POLICY_HEAD            = 3,
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	 * 6:4 : completion_policy - Describing what policy
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	 *    to use for generation completion entry (cqe) in
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	/* associated completion queue id. This CQ must be created prior to SQ
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	 * completion_policy is set to completion_policy_head_on_demand or
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	 * completion_policy_head. Has to be cache aligned
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	/* completion queue depth in # of entries. must be power of 2 */
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	/* Per packet tx completion timeout. value in ms */
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	u16 missing_tx_completion_timeout;
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	u16 missed_tx_completion_count_threshold_to_reset;
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:	u16 admin_completion_tx_timeout;
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:#define ENA_ADMIN_AQ_CREATE_SQ_CMD_COMPLETION_POLICY_SHIFT  4
drivers/net/ethernet/amazon/ena/ena_admin_defs.h:#define ENA_ADMIN_AQ_CREATE_SQ_CMD_COMPLETION_POLICY_MASK   GENMASK(6, 4)
drivers/net/ethernet/amazon/ena/ena_com.c:	struct completion wait_event;
drivers/net/ethernet/amazon/ena/ena_com.c:		netdev_err(admin_queue->ena_dev->net_device, "Completion context is NULL\n");
drivers/net/ethernet/amazon/ena/ena_com.c:		netdev_err(admin_queue->ena_dev->net_device, "Completion context is occupied\n");
drivers/net/ethernet/amazon/ena/ena_com.c:	reinit_completion(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:			init_completion(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:	/* Use the basic completion descriptor for Rx */
drivers/net/ethernet/amazon/ena/ena_com.c:static void ena_com_handle_single_admin_completion(struct ena_com_admin_queue *admin_queue,
drivers/net/ethernet/amazon/ena/ena_com.c:static void ena_com_handle_admin_completion(struct ena_com_admin_queue *admin_queue)
drivers/net/ethernet/amazon/ena/ena_com.c:	/* Go over all the completions */
drivers/net/ethernet/amazon/ena/ena_com.c:		/* Do not read the rest of the completion entry before the
drivers/net/ethernet/amazon/ena/ena_com.c:		ena_com_handle_single_admin_completion(admin_queue, cqe);
drivers/net/ethernet/amazon/ena/ena_com.c:	timeout = jiffies + usecs_to_jiffies(admin_queue->completion_timeout);
drivers/net/ethernet/amazon/ena/ena_com.c:		ena_com_handle_admin_completion(admin_queue);
drivers/net/ethernet/amazon/ena/ena_com.c:				   "Wait for completion (polling) timeout\n");
drivers/net/ethernet/amazon/ena/ena_com.c:			/* ENA didn't have any completion */
drivers/net/ethernet/amazon/ena/ena_com.c:			admin_queue->stats.no_completion++;
drivers/net/ethernet/amazon/ena/ena_com.c:	wait_for_completion_timeout(&comp_ctx->wait_event,
drivers/net/ethernet/amazon/ena/ena_com.c:				    usecs_to_jiffies(admin_queue->completion_timeout));
drivers/net/ethernet/amazon/ena/ena_com.c:	 * 1) No completion (timeout reached)
drivers/net/ethernet/amazon/ena/ena_com.c:	 * 2) There is completion but the device didn't get any msi-x interrupt.
drivers/net/ethernet/amazon/ena/ena_com.c:		ena_com_handle_admin_completion(admin_queue);
drivers/net/ethernet/amazon/ena/ena_com.c:		admin_queue->stats.no_completion++;
drivers/net/ethernet/amazon/ena/ena_com.c:				   "The ena device sent a completion but the driver didn't receive a MSI-X interrupt (cmd %d), autopolling mode is %s\n",
drivers/net/ethernet/amazon/ena/ena_com.c:				   "The ena device didn't send a completion for the admin cmd %d status %d\n",
drivers/net/ethernet/amazon/ena/ena_com.c:		 * This will happen if there is a completion without an interrupt
drivers/net/ethernet/amazon/ena/ena_com.c:/* There are two types to wait for completion.
drivers/net/ethernet/amazon/ena/ena_com.c: * Polling mode - wait until the completion is available.
drivers/net/ethernet/amazon/ena/ena_com.c: * Async mode - wait on wait queue until the completion is ready
drivers/net/ethernet/amazon/ena/ena_com.c: * It is expected that the IRQ called ena_com_handle_admin_completion
drivers/net/ethernet/amazon/ena/ena_com.c: * to mark the completions.
drivers/net/ethernet/amazon/ena/ena_com.c:	struct ena_admin_acq_create_sq_resp_desc cmd_completion;
drivers/net/ethernet/amazon/ena/ena_com.c:	create_cmd.sq_caps_2 |= (ENA_ADMIN_COMPLETION_POLICY_DESC <<
drivers/net/ethernet/amazon/ena/ena_com.c:		ENA_ADMIN_AQ_CREATE_SQ_CMD_COMPLETION_POLICY_SHIFT) &
drivers/net/ethernet/amazon/ena/ena_com.c:		ENA_ADMIN_AQ_CREATE_SQ_CMD_COMPLETION_POLICY_MASK;
drivers/net/ethernet/amazon/ena/ena_com.c:					    (struct ena_admin_acq_entry *)&cmd_completion,
drivers/net/ethernet/amazon/ena/ena_com.c:					    sizeof(cmd_completion));
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq->idx = cmd_completion.sq_idx;
drivers/net/ethernet/amazon/ena/ena_com.c:		(uintptr_t)cmd_completion.sq_doorbell_offset);
drivers/net/ethernet/amazon/ena/ena_com.c:			cmd_completion.llq_descriptors_offset);
drivers/net/ethernet/amazon/ena/ena_com.c:	struct ena_admin_acq_create_cq_resp_desc cmd_completion;
drivers/net/ethernet/amazon/ena/ena_com.c:					    (struct ena_admin_acq_entry *)&cmd_completion,
drivers/net/ethernet/amazon/ena/ena_com.c:					    sizeof(cmd_completion));
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq->idx = cmd_completion.cq_idx;
drivers/net/ethernet/amazon/ena/ena_com.c:		cmd_completion.cq_interrupt_unmask_register_offset);
drivers/net/ethernet/amazon/ena/ena_com.c:	if (cmd_completion.numa_node_register_offset)
drivers/net/ethernet/amazon/ena/ena_com.c:			cmd_completion.numa_node_register_offset);
drivers/net/ethernet/amazon/ena/ena_com.c:void ena_com_wait_for_abort_completion(struct ena_com_dev *ena_dev)
drivers/net/ethernet/amazon/ena/ena_com.c:	ena_com_handle_admin_completion(&ena_dev->admin_queue);
drivers/net/ethernet/amazon/ena/ena_com.c:		ena_dev->admin_queue.completion_timeout = timeout * 100000;
drivers/net/ethernet/amazon/ena/ena_com.c:		ena_dev->admin_queue.completion_timeout = ADMIN_CMD_TIMEOUT_US;
drivers/net/ethernet/amazon/ena/ena_com.h:	u64 no_completion;
drivers/net/ethernet/amazon/ena/ena_com.h:	u32 completion_timeout;
drivers/net/ethernet/amazon/ena/ena_com.h:	/* Indicate if the admin queue should poll for completion */
drivers/net/ethernet/amazon/ena/ena_com.h: * Initialize the admin submission and completion queues.
drivers/net/ethernet/amazon/ena/ena_com.h: * won't send any additional admin completions/aenq.
drivers/net/ethernet/amazon/ena/ena_com.h: * Create the submission and the completion queues.
drivers/net/ethernet/amazon/ena/ena_com.h: * @io_cq - IO completion queue handler.
drivers/net/ethernet/amazon/ena/ena_com.h:/* ena_com_set_admin_polling_mode - Set the admin completion queue polling mode
drivers/net/ethernet/amazon/ena/ena_com.h: * Set the admin completion mode.
drivers/net/ethernet/amazon/ena/ena_com.h: * This method goes over the admin completion queue and wakes up all the pending
drivers/net/ethernet/amazon/ena/ena_com.h: * The caller should then call ena_com_wait_for_abort_completion to make sure
drivers/net/ethernet/amazon/ena/ena_com.h:/* ena_com_wait_for_abort_completion - Wait for admin commands abort.
drivers/net/ethernet/amazon/ena/ena_com.h:void ena_com_wait_for_abort_completion(struct ena_com_dev *ena_dev);
drivers/net/ethernet/amazon/ena/ena_com.h:/* ena_com_create_io_cq - Create io completion queue.
drivers/net/ethernet/amazon/ena/ena_com.h: * @io_cq - io completion queue handler
drivers/net/ethernet/amazon/ena/ena_com.h: * Create IO completion queue.
drivers/net/ethernet/amazon/ena/ena_com.h:/* ena_com_destroy_io_cq - Destroy io completion queue.
drivers/net/ethernet/amazon/ena/ena_com.h: * @io_cq - io completion queue handler
drivers/net/ethernet/amazon/ena/ena_com.h: * Destroy IO completion queue.
drivers/net/ethernet/amazon/ena/ena_com.h: * @cmd_completion: command completion return value.
drivers/net/ethernet/amazon/ena/ena_com.h: * @cmd_comp_size: command completion size.
drivers/net/ethernet/amazon/ena/ena_com.h: * completion.
drivers/net/ethernet/amazon/ena/ena_com.h: * The completion will be copied into cmd_comp.
drivers/net/ethernet/amazon/ena/ena_eth_com.h:	/* When the current completion descriptor phase isn't the same as the
drivers/net/ethernet/amazon/ena/ena_eth_com.h:	 * this completion.
drivers/net/ethernet/amazon/ena/ena_eth_io_defs.h:	 * 28 : comp_req - Indicates whether completion
drivers/net/ethernet/amazon/ena/ena_eth_io_defs.h:	 * 28 : comp_req - Indicates whether completion
drivers/net/ethernet/amazon/ena/ena_ethtool.c:	ENA_STAT_ENA_COM_ENTRY(no_completion),
drivers/net/ethernet/amazon/ena/ena_netdev.c:	/* Req id ring for TX out of order completions */
drivers/net/ethernet/amazon/ena/ena_netdev.c:	 * tx completions.
drivers/net/ethernet/amazon/ena/ena_netdev.c:	/* Enable completion queues interrupt */
drivers/net/ethernet/amazon/ena/ena_netdev.c:		 * next_to_completion and terminates.
drivers/net/ethernet/amazon/ena/ena_netdev.c:	ena_com_wait_for_abort_completion(ena_dev);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	ena_com_wait_for_abort_completion(ena_dev);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	ena_com_wait_for_abort_completion(ena_dev);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	missing_tx_comp_to = jiffies_to_msecs(adapter->missing_tx_completion_to);
drivers/net/ethernet/amazon/ena/ena_netdev.c:			 2 * adapter->missing_tx_completion_to);
drivers/net/ethernet/amazon/ena/ena_netdev.c:			adapter->missing_tx_completion_to);
drivers/net/ethernet/amazon/ena/ena_netdev.c:					2 * adapter->missing_tx_completion_to))
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (unlikely(missed_tx > adapter->missing_tx_completion_threshold)) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:			  "Lost TX completions are above the threshold (%d > %d). Completion transmission timeout: %u.\n",
drivers/net/ethernet/amazon/ena/ena_netdev.c:			  adapter->missing_tx_completion_threshold,
drivers/net/ethernet/amazon/ena/ena_netdev.c:static void check_for_missing_completions(struct ena_adapter *adapter)
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (adapter->missing_tx_completion_to == ENA_HW_HINTS_NO_TIMEOUT)
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (hints->admin_completion_tx_timeout)
drivers/net/ethernet/amazon/ena/ena_netdev.c:		adapter->ena_dev->admin_queue.completion_timeout =
drivers/net/ethernet/amazon/ena/ena_netdev.c:			hints->admin_completion_tx_timeout * 1000;
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (hints->missed_tx_completion_count_threshold_to_reset)
drivers/net/ethernet/amazon/ena/ena_netdev.c:		adapter->missing_tx_completion_threshold =
drivers/net/ethernet/amazon/ena/ena_netdev.c:			hints->missed_tx_completion_count_threshold_to_reset;
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (hints->missing_tx_completion_timeout) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:		if (hints->missing_tx_completion_timeout == ENA_HW_HINTS_NO_TIMEOUT)
drivers/net/ethernet/amazon/ena/ena_netdev.c:			adapter->missing_tx_completion_to = ENA_HW_HINTS_NO_TIMEOUT;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			adapter->missing_tx_completion_to =
drivers/net/ethernet/amazon/ena/ena_netdev.c:				msecs_to_jiffies(hints->missing_tx_completion_timeout);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	check_for_missing_completions(adapter);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	adapter->missing_tx_completion_to = TX_TIMEOUT;
drivers/net/ethernet/amazon/ena/ena_netdev.c:	adapter->missing_tx_completion_threshold = MAX_NUM_OF_TIMEOUTED_PACKETS;
drivers/net/ethernet/amazon/ena/ena_netdev.h:/* The number of tx packet completions that will be handled each NAPI poll
drivers/net/ethernet/amazon/ena/ena_netdev.h:	 * out of order completions
drivers/net/ethernet/amazon/ena/ena_netdev.h:	u32 missing_tx_completion_threshold;
drivers/net/ethernet/amazon/ena/ena_netdev.h:	unsigned long missing_tx_completion_to;
drivers/net/ethernet/amd/pds_core/adminq.c:	struct completion wait_completion;
drivers/net/ethernet/amd/pds_core/adminq.c:	 * for a NotifyQ event and there are no new AdminQ completions.
drivers/net/ethernet/amd/pds_core/adminq.c:	/* Find the first completion to clean,
drivers/net/ethernet/amd/pds_core/adminq.c:		/* Copy out the completion data */
drivers/net/ethernet/amd/pds_core/adminq.c:		complete_all(&q_info->wc->wait_completion);
drivers/net/ethernet/amd/pds_core/adminq.c:	/* Return the interrupt credits, one for each completion */
drivers/net/ethernet/amd/pds_core/adminq.c:		.wait_completion =
drivers/net/ethernet/amd/pds_core/adminq.c:			COMPLETION_INITIALIZER_ONSTACK(wc.wait_completion),
drivers/net/ethernet/amd/pds_core/adminq.c:		remaining = wait_for_completion_timeout(&wc.wait_completion,
drivers/net/ethernet/amd/pds_core/adminq.c:	dev_dbg(pdsc->dev, "read admin queue completion idx %d:\n", index);
drivers/net/ethernet/amd/pds_core/auxbus.c: * Core copies completion data into response buffer
drivers/net/ethernet/amd/xgbe/xgbe-dev.c:	/* Enable MDIO single command completion interrupt */
drivers/net/ethernet/amd/xgbe/xgbe-dev.c:	reinit_completion(&pdata->mdio_complete);
drivers/net/ethernet/amd/xgbe/xgbe-dev.c:	if (!wait_for_completion_timeout(&pdata->mdio_complete, HZ)) {
drivers/net/ethernet/amd/xgbe/xgbe-dev.c:	reinit_completion(&pdata->mdio_complete);
drivers/net/ethernet/amd/xgbe/xgbe-dev.c:	if (!wait_for_completion_timeout(&pdata->mdio_complete, HZ)) {
drivers/net/ethernet/amd/xgbe/xgbe-i2c.c:#include <linux/completion.h>
drivers/net/ethernet/amd/xgbe/xgbe-i2c.c:	reinit_completion(&pdata->i2c_complete);
drivers/net/ethernet/amd/xgbe/xgbe-i2c.c:	if (!wait_for_completion_timeout(&pdata->i2c_complete, HZ)) {
drivers/net/ethernet/amd/xgbe/xgbe-main.c:	init_completion(&pdata->i2c_complete);
drivers/net/ethernet/amd/xgbe/xgbe-main.c:	init_completion(&pdata->mdio_complete);
drivers/net/ethernet/amd/xgbe/xgbe-mdio.c:	dev_dbg(dev, "Auto-Neg Completion Reg (%#06x) = %#06x\n",
drivers/net/ethernet/amd/xgbe/xgbe.h:#include <linux/completion.h>
drivers/net/ethernet/amd/xgbe/xgbe.h:	struct completion mdio_complete;
drivers/net/ethernet/amd/xgbe/xgbe.h:	struct completion i2c_complete;
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:static int xgene_enet_tx_completion(struct xgene_enet_desc_ring *cp_ring,
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:		netdev_err(cp_ring->ndev, "completion skb is NULL\n");
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:	bool is_completion;
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:		is_completion = false;
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:			ret = xgene_enet_tx_completion(ring, raw_desc);
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:			is_completion = true;
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:		if (is_completion)
drivers/net/ethernet/apm/xgene/xgene_enet_main.c:			/* allocate tx completion descriptor ring */
drivers/net/ethernet/broadcom/b44.h:#define DESC_CTRL_IOC	0x20000000 /* Interrupt On Completion */
drivers/net/ethernet/broadcom/bcmsysport.c:/* Reclaim queued SKBs for transmission completion, lockless version */
drivers/net/ethernet/broadcom/bcmsysport.c:	/* Poll for RMDA disabling completion */
drivers/net/ethernet/broadcom/bcmsysport.c:	/* Poll for TMDA disabling completion */
drivers/net/ethernet/broadcom/bnx2.c:		/* partial BD completions possible with TSO packets */
drivers/net/ethernet/broadcom/bnx2.c:	/* Initialize the Completion Processor. */
drivers/net/ethernet/broadcom/bnx2.c:	/* Wait for completion. */
drivers/net/ethernet/broadcom/bnx2.c:	/* Wait for completion. */
drivers/net/ethernet/broadcom/bnx2.c:	/* Wait for completion. */
drivers/net/ethernet/broadcom/bnx2.h:		#define STATUS_ATTN_BITS_COMPLETION_ABORT	(1L<<16)
drivers/net/ethernet/broadcom/bnx2.h:	u16 status_completion_producer_index;
drivers/net/ethernet/broadcom/bnx2.h:	u16 status_completion_producer_index;
drivers/net/ethernet/broadcom/bnx2.h:	u16 status_completion_producer_index;
drivers/net/ethernet/broadcom/bnx2.h:	u16 status_completion_producer_index;
drivers/net/ethernet/broadcom/bnx2.h:#define BNX2_MISC_ENABLE_STATUS_BITS_COMPLETION_ENABLE	 (1L<<18)
drivers/net/ethernet/broadcom/bnx2.h:#define BNX2_MISC_ENABLE_SET_BITS_COMPLETION_ENABLE	 (1L<<18)
drivers/net/ethernet/broadcom/bnx2.h:#define BNX2_MISC_ENABLE_CLR_BITS_COMPLETION_ENABLE	 (1L<<18)
drivers/net/ethernet/broadcom/bnx2.h:#define BNX2_MISC_LFSR_MASK_BITS_COMPLETION_ENABLE	 (1L<<18)
drivers/net/ethernet/broadcom/bnx2_fw.h:/* Initialized Values for the Completion Processor. */
drivers/net/ethernet/broadcom/bnx2x/bnx2x.h:/* EQ completions */
drivers/net/ethernet/broadcom/bnx2x/bnx2x.h:/* FCoE L2 connection completions */
drivers/net/ethernet/broadcom/bnx2x/bnx2x.h:	 * completions in the default status block.
drivers/net/ethernet/broadcom/bnx2x/bnx2x.h: * @wait_for_comp:	if 'true' block until completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x.h:/* E2 and onward - PCI error handling in the completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c:	/* Wait for completion of requested */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c:	 * as we don't want a true completion to disrupt us in the middle.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h: * bnx2x_sp_event - handle ramrods completion.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h:		BNX2X_ERR("Filtering completion timed out. sp_state 0x%lx, mask 0x%lx\n",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_ethtool.c:	/* wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_ethtool.c:	/* wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_link.c:	/* Poll for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_link.c:	/* Poll for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* fill in the completion parameters */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:/* issue a dmae command over the init-channel and wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* reset completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* issue the command and wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* issue the command and wait for completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		DP(BNX2X_MSG_SP, "At timeout completion address contained %x\n",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* Zero completion for next FLR */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		 * an unexpected completion.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* no need to wait for RAMROD completion, so don't
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		DP(BNX2X_MSG_SP, "Got SETUP_MAC completions\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		DP(BNX2X_MSG_SP, "Got SETUP_VLAN completions\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		DP(BNX2X_MSG_SP, "Got SETUP_MCAST completions\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:		/* clear pending completion bit */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:			   "got set_timesync ramrod completion\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:			/* Handle EQ completions */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* Suspend Tx switching to the PF. Completion of this ramrod
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* Wait for completion of requested */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* We want to wait for completion in this context */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* We want to wait for completion in this context */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	 * received completion for the transaction the state is TX_STOPPED.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	 * State will return to STARTED after completion of TX_STOPPED-->STARTED
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	 * a race between the completion code and this code.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	 * Completions for ramrods are collected in a synchronous way
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c: * This function will wait until the ramrod completion returns.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:/* count denotes the number of new completions we have seen */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	/* first we tell CNIC and only then we count this as a completion */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:	ctl.cmd = CNIC_CTL_COMPLETION_CMD;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c: * Completion should be checked outside.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:			BNX2X_ERR("rx_mode completion timed out!\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c:			BNX2X_ERR("rx_mode completion timed out!\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #0 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #1 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #2 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #3 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 13] The start address in the internal RAM for the completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * 4.Completion function=0; 5.Error handling=0 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * an uncorrectable error. Bit 4 - Completion with Configuration Request
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * Bit 6 - Completion with pcie_rx_err of 0000; CMPL_STATUS of non-zero; and
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * pcie_rx_last not asserted. Bit 7 - Completion with pcie_rx_err of 1010;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * VF_VALID. [9:4] - VFID. [11:10] - Error Code - 0 - Indicates Completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * if there was a completion error since the last time this register was
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [R 18] Details of first ATS Translation Completion request received with
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * 0 - Indicates Completion Timeout of a User Tx non-posted request. 1 -
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * completion error since the last time this register was cleared. */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * completion did not return yet. 1 - tag is unused. Same functionality as
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * that there was a completion with uncorrectable error for the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * indicates that there was a completion with uncorrectable error for the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * indicates that there was a completion with uncorrectable error for the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * indicates that there was a completion with uncorrectable error for the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h: * indicates that there was a completion with uncorrectable error for the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:   not finish yet (not all completions have arrived for it) */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [R 5] Number of entries in the ufifo; his fifo has l2p completions */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #0 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #1 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #2 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #3 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 13] The start address in the internal RAM for the completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #0 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #1 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #2 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #3 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 13] The start address in the internal RAM for the completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #0 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #1 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #2 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 16] The maximum value of the completion counter #3 */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [RW 13] The start address in the internal RAM for the completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:/* [W 17] Generate an operation after completion; bit-16 is
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 24) /* Unexpected Completion Status Status in function 4, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 14) /* Unexpected Completion Status Status in function 3, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 4) /* Unexpected Completion Status Status for Function 2, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 24) /* Unexpected Completion Status Status in function 7, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 14) /* Unexpected Completion Status Status in function 6, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_reg.h:	(1 << 4) /* Unexpected Completion Status Status for Function 5, \
drivers/net/ethernet/broadcom/bnx2x/bnx2x_self_test.c:	"PGLUE_B: Completion received with error. (2:0) - PFID. (3) - VF_VALID. (9:4) - VFID. (11:10) - Error code : 0 - Completion Timeout; 1 - Unsupported Request; 2 - Completer Abort. (12) - valid bit",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_self_test.c:	"PGLUE_B: ATS TCPL received with error. (2:0) - PFID. (3) - VF_VALID. (9:4) - VFID. (11:10) - Error code : 0 - Completion Timeout ; 1 - Unsupported Request; 2 - Completer Abort. (16:12) - OTB Entry ID. (17) - valid bit",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_self_test.c:	"PXP2: Completion received with error. Error details register is not 0. (15:0) - ECHO. (28:16) - Sub Request length plus start_offset_2_0 minus 1",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_self_test.c:	"PXP2: Completion received with error. Error details 2nd register is not 0. (4:0) - VQ ID. (8:5) - client ID. (9) - valid bit",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	 * which also implies there won't be any completion to clear the
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:		 * completions and we may dismiss the pending list.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * @cqe:	completion element
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	/* Ramrod completion is pending */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	/* Wait for a ramrod completion if was requested */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:		/* Ramrod completion is pending */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:		/* Ramrod completion is pending */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:		/* Wait for a ramrod completion if was requested */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * code in case of failure, positive (EBUSY) value if there is a completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * Checks that the arrived completion is expected.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * that will be used in the completion flow to set the `state'
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	/* Forget all pending for completion commands if a driver only state
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * Checks that the arrived completion is expected.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	 * legal completion.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: * that will be used in the completion flow to set the `state'
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:	/* Forget all pending for completion commands if a driver only state
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:		 * if not pending for function_stop ramrod completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c: *         (EBUSY) value if there is a completion to that is
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c:			BNX2X_ERR("timeout waiting for previous ramrod completion\n");
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	/* Commands pending for an completion. */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 *         if there are pending for completion commands,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 * Should be called on a completion arrival.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 * @param cqe Completion element we are handling
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 *         completion commands. Positive value if there are
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 *         pending for execution or for completion commands.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 * Wait for completion of all commands. Don't schedule new ones,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h:	 * just wait. It assumes that the completion code will schedule
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h: * Return: 0 - if operation was successful and there is no pending completions,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h: *         positive number - if there are pending completions,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h: * Return: 0 is operation was successful and there are no pending completions,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h: *         completions.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sriov.c:	 * and set-mac completion
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sriov.c:		BNX2X_ERR("EQ completion for unknown VF, cid %d, abs_vfid %d\n",
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		/* vf doesn't collect HW statistics, and doesn't get completions
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	 * (statistics) ramrod completion.
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	/* issue the command and wait for completion */
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	netdev_err(bp->dev, "Invalid Tx completion (ring:%d tx_hw_cons:%u cons:%u prod:%u curr:%u)",
drivers/net/ethernet/broadcom/bnxt/bnxt.c: * -EBUSY  - completion ring does not have all the agg buffers yet
drivers/net/ethernet/broadcom/bnxt/bnxt.c:/* In netpoll mode, if we are using a combined completion ring, we need to
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			else if (rc == -EBUSY)	/* partial completion */
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	/* ACK completion ring before freeing tx ring and producing new
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	 * buffers in rx/agg rings to prevent overflowing the completion
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			else if (rc == -EBUSY)	/* partial completion */
drivers/net/ethernet/broadcom/bnxt/bnxt.c:				   "Invalid completion received on special ring\n");
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	/* MAX TPA needs to be added because TPA_START completions are
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	 * immediately recycled, so the TPA completions are not bound by
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	/* RX and TPA completions are 32-byte, all others are 16-byte */
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		netdev_warn(bp->dev, "completion ring size %d reduced to %d.\n",
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		/* Association of transmit ring with completion ring */
drivers/net/ethernet/broadcom/bnxt/bnxt.c:				netdev_warn(bp->dev, "Failed to set async event completion ring.\n");
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	/* The completion rings are about to be freed.  After that the
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	 * 1 coal_buf x bufs_per_record = 1 completion record.
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	 * 1 coal_buf x bufs_per_record = 1 completion record.
drivers/net/ethernet/broadcom/bnxt/bnxt.h:	/* grp_info indexed by completion ring index */
drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c: * request’s target and completion ring are initialized to default values and
drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c: * hwrm_req_timeout() - Set the completion timeout for the request.
drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c:			netdev_err(bp->dev, "Ring completions not supported for KONG commands, req_type = %d\n",
drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c:			/* Abort the wait for completion if the FW health
drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c:			/* Abort the wait for completion if the FW health
drivers/net/ethernet/broadcom/bnxt/bnxt_ptp.c:				   "timestamp completion error 0x%x 0x%x\n",
drivers/net/ethernet/broadcom/cnic.c:static void cnic_spq_completion(struct cnic_dev *dev, int cmd, u32 count)
drivers/net/ethernet/broadcom/cnic.c:		kcqe.completion_status =
drivers/net/ethernet/broadcom/cnic.c:			ISCSI_KCQE_COMPLETION_STATUS_ISCSI_NOT_SUPPORTED;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = ISCSI_KCQE_COMPLETION_STATUS_SUCCESS;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = ISCSI_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE;
drivers/net/ethernet/broadcom/cnic.c:		kcqe.completion_status =
drivers/net/ethernet/broadcom/cnic.c:			ISCSI_KCQE_COMPLETION_STATUS_CID_BUSY;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = ISCSI_KCQE_COMPLETION_STATUS_SUCCESS;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = ISCSI_KCQE_COMPLETION_STATUS_SUCCESS;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = FCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.completion_status = FCOE_KCQE_COMPLETION_STATUS_ERROR;
drivers/net/ethernet/broadcom/cnic.c:			kcqe.completion_status = 0;
drivers/net/ethernet/broadcom/cnic.c:		kcqe.kcqe_info1 = FCOE_KCQE_COMPLETION_STATUS_PARITY_ERROR;
drivers/net/ethernet/broadcom/cnic.c:		kcqe.kcqe_info1 = ISCSI_KCQE_COMPLETION_STATUS_PARITY_ERR;
drivers/net/ethernet/broadcom/cnic.c:		l4kcqe->status = L4_KCQE_COMPLETION_STATUS_PARITY_ERROR;
drivers/net/ethernet/broadcom/cnic.c:			/* Possibly bnx2x parity error, send completion
drivers/net/ethernet/broadcom/cnic.c:			/* Possibly bnx2x parity error, send completion
drivers/net/ethernet/broadcom/cnic.c:		if (unlikely(kcqe_op_flag & KCQE_RAMROD_COMPLETION))
drivers/net/ethernet/broadcom/cnic.c:			if (unlikely(next_op & KCQE_RAMROD_COMPLETION))
drivers/net/ethernet/broadcom/cnic.c:		cnic_spq_completion(dev, DRV_CTL_RET_L5_SPQ_CREDIT_CMD, comp);
drivers/net/ethernet/broadcom/cnic.c:static int cnic_l2_completion(struct cnic_local *cp)
drivers/net/ethernet/broadcom/cnic.c:			comp = cnic_l2_completion(cp);
drivers/net/ethernet/broadcom/cnic.c:	case CNIC_CTL_COMPLETION_CMD: {
drivers/net/ethernet/broadcom/cnic.c:		struct cnic_ctl_completion *comp = &info->data.comp;
drivers/net/ethernet/broadcom/cnic.c:	if (kcqe->status == L4_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAIL) {
drivers/net/ethernet/broadcom/cnic.c:			 L4_KCQE_COMPLETION_STATUS_PARITY_ERROR)
drivers/net/ethernet/broadcom/cnic.c:		if (l4kcqe->status == 0 && l5kcqe->completion_status == 0)
drivers/net/ethernet/broadcom/cnic.c:		netdev_warn(dev->netdev, "RAMROD CLOSE compl with status 0x%x completion status 0x%x\n",
drivers/net/ethernet/broadcom/cnic.c:			    l4kcqe->status, l5kcqe->completion_status);
drivers/net/ethernet/broadcom/cnic.c:		if (l4kcqe->status == L4_KCQE_COMPLETION_STATUS_PARITY_ERROR)
drivers/net/ethernet/broadcom/cnic.c:		while (cp->status_blk.bnx2->status_completion_producer_index &&
drivers/net/ethernet/broadcom/cnic.c:		if (cp->status_blk.bnx2->status_completion_producer_index) {
drivers/net/ethernet/broadcom/cnic.c:		while (sblk->status_completion_producer_index && i < 10) {
drivers/net/ethernet/broadcom/cnic.c:		if (sblk->status_completion_producer_index)
drivers/net/ethernet/broadcom/cnic.c:		&sblk->status_completion_producer_index;
drivers/net/ethernet/broadcom/cnic.c:			&msblk->status_completion_producer_index;
drivers/net/ethernet/broadcom/cnic.c:		cnic_spq_completion(dev, DRV_CTL_RET_L2_SPQ_CREDIT_CMD, 1);
drivers/net/ethernet/broadcom/cnic.c:		cnic_spq_completion(dev, DRV_CTL_RET_L2_SPQ_CREDIT_CMD, 1);
drivers/net/ethernet/broadcom/cnic_defs.h:/* KCQ (kernel completion queue) response op codes */
drivers/net/ethernet/broadcom/cnic_defs.h:/* KCQ (kernel completion queue) completion status */
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_SUCCESS           (0)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_NIC_ERROR         (4)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_PARITY_ERROR	    (0x81)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_TIMEOUT           (0x93)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAIL    (0x83)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQE_COMPLETION_STATUS_OFFLOADED_PG      (0x89)
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQ_RAMROD_COMPLETION (0x1<<3) /* Everest only */
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQ_RAMROD_COMPLETION_SHIFT 3
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQ_RAMROD_COMPLETION (0x1<<3) /* Everest only */
drivers/net/ethernet/broadcom/cnic_defs.h:#define L4_KCQ_RAMROD_COMPLETION_SHIFT 3
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF (0x3<<6)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_SHIFT 6
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF (0x3<<6)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_SHIFT 6
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_EN (0x1<<1)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_EN_SHIFT 1
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_EN (0x1<<1)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_FCOE_AG_CONTEXT_COMPLETION_CF_EN_SHIFT 1
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF (0x3<<6)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_SHIFT 6
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF (0x3<<6)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_SHIFT 6
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_EN (0x1<<1)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_EN_SHIFT 1
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_EN (0x1<<1)
drivers/net/ethernet/broadcom/cnic_defs.h:#define USTORM_ISCSI_AG_CONTEXT_COMPLETION_CF_EN_SHIFT 1
drivers/net/ethernet/broadcom/cnic_defs.h:	u32 completion_seq;
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_ISCSI_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK (0x1<<10)
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_ISCSI_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK_SHIFT 10
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_ISCSI_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK (0x1<<10)
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_ISCSI_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK_SHIFT 10
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_L5CM_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK (0x1<<10)
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_L5CM_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK_SHIFT 10
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_L5CM_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK (0x1<<10)
drivers/net/ethernet/broadcom/cnic_defs.h:#define __XSTORM_L5CM_AG_CONTEXT_COMPLETION_SEQ_DECISION_MASK_SHIFT 10
drivers/net/ethernet/broadcom/cnic_defs.h:	u32 completion_seq;
drivers/net/ethernet/broadcom/cnic_defs.h: * Completion information $$KEEP_ENDIANNESS$$
drivers/net/ethernet/broadcom/cnic_defs.h:	__le32 completion_status;
drivers/net/ethernet/broadcom/cnic_defs.h:#define FCOE_KCQE_RAMROD_COMPLETION (0x1<<3)
drivers/net/ethernet/broadcom/cnic_defs.h:#define FCOE_KCQE_RAMROD_COMPLETION_SHIFT 3
drivers/net/ethernet/broadcom/cnic_defs.h: * CQ DB CQ producer and pending completion counter
drivers/net/ethernet/broadcom/cnic_defs.h: * CQ DB pending completion ITT array
drivers/net/ethernet/broadcom/cnic_if.h:		#define KCQE_RAMROD_COMPLETION		(0x1<<27) /* Everest */
drivers/net/ethernet/broadcom/cnic_if.h:#define CNIC_CTL_COMPLETION_CMD		3
drivers/net/ethernet/broadcom/cnic_if.h:struct cnic_ctl_completion {
drivers/net/ethernet/broadcom/cnic_if.h:		struct cnic_ctl_completion comp;
drivers/net/ethernet/broadcom/tg3.c:	       MAC_STATUS_MI_COMPLETION |
drivers/net/ethernet/broadcom/tg3.c: * is bogus tx completions. We try to recover by setting the
drivers/net/ethernet/broadcom/tg3.c:				      MAC_STATUS_MI_COMPLETION |
drivers/net/ethernet/broadcom/tg3.c:	/* run TX completion thread */
drivers/net/ethernet/broadcom/tg3.h:#define  MAC_STATUS_MI_COMPLETION	 0x00400000
drivers/net/ethernet/broadcom/tg3.h:#define  MAC_EVENT_MI_COMPLETION	 0x00400000
drivers/net/ethernet/broadcom/tg3.h:/* Send data completion control registers */
drivers/net/ethernet/broadcom/tg3.h:/* Send BD completion control registers */
drivers/net/ethernet/broadcom/tg3.h:/* Receive Data Completion Control */
drivers/net/ethernet/broadcom/tg3.h:/* Receive BD Completion Control Registers */
drivers/net/ethernet/broadcom/tg3.h:/* DMA completion registers */
drivers/net/ethernet/brocade/bna/bfa_ioc.c:/* IOC disable completion entry. */
drivers/net/ethernet/brocade/bna/bfa_ioc.c:/* Notify enable completion callback */
drivers/net/ethernet/brocade/bna/bfa_ioc.c:/* IOC disable completion entry. */
drivers/net/ethernet/brocade/bna/bfa_ioc.c:	 * just wait for an initialization completion interrupt.
drivers/net/ethernet/brocade/bna/bfa_ioc.c:	 * Provide enable completion callback and AEN notification.
drivers/net/ethernet/brocade/bna/bfi.h:	BFI_MC_IOIM_IOCOM	= 17,	/*!< good IO completion		    */
drivers/net/ethernet/brocade/bna/bfi_enet.h:	BFI_ENET_CMD_WAITING	= 6,	/* !< Waiting for completion */
drivers/net/ethernet/brocade/bna/bfi_enet.h: * On the completion queue.  RxQ ID = even is for large/data buffer queues
drivers/net/ethernet/brocade/bna/bna_hw_defs.h: * Completion Q defines
drivers/net/ethernet/brocade/bna/bna_hw_defs.h: * Bit 31 is set in every end of frame completion
drivers/net/ethernet/brocade/bna/bna_types.h:/* Completion control structure */
drivers/net/ethernet/brocade/bna/bnad.c: * Reinitialize completions in CQ, once Rx is taken down
drivers/net/ethernet/brocade/bna/bnad.c: * bnad_txcmpl_process : Frees the Tx bufs on Tx completion
drivers/net/ethernet/brocade/bna/bnad.c:/* MSIX Tx Completion Handler */
drivers/net/ethernet/brocade/bna/bnad.c:		 * the other fields of completion entry. Hence, do not load
drivers/net/ethernet/brocade/bna/bnad.c:		 * other fields of completion entry *before* the 'valid' is
drivers/net/ethernet/brocade/bna/bnad.c:		 * in reading stale values in completion entry.
drivers/net/ethernet/brocade/bna/bnad.c:		/* Check all the completions for this frame.
drivers/net/ethernet/brocade/bna/bnad.c:				 * after writing the other fields of completion
drivers/net/ethernet/brocade/bna/bnad.c:				 * completion entry *before* the 'valid' is
drivers/net/ethernet/brocade/bna/bnad.c:				 * stale values in completion entry.
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.ioc_comp_status = BNA_CB_SUCCESS;
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.ioc_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.ioc_comp_status = BNA_CB_FAIL;
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.ioc_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.ioc_comp_status = BNA_CB_SUCCESS;
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.ioc_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.enet_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.tx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.rx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.mcast_comp_status = BNA_CB_SUCCESS;
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.mcast_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.mtu_comp_status = BNA_CB_SUCCESS;
drivers/net/ethernet/brocade/bna/bnad.c:	complete(&bnad->bnad_completions.mtu_comp);
drivers/net/ethernet/brocade/bna/bnad.c:bnad_cb_completion(void *arg, enum bfa_status status)
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.tx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion(&bnad->bnad_completions.tx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.rx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion(&bnad->bnad_completions.rx_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.mcast_comp);
drivers/net/ethernet/brocade/bna/bnad.c:		wait_for_completion(&bnad->bnad_completions.mcast_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	if (bnad->bnad_completions.mcast_comp_status != BNA_CB_SUCCESS)
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.ioc_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion_timeout(&bnad->bnad_completions.ioc_comp,
drivers/net/ethernet/brocade/bna/bnad.c:	err = bnad->bnad_completions.ioc_comp_status;
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.ioc_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	bnad->bnad_completions.ioc_comp_status = BNA_CB_WAITING;
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion_timeout(&bnad->bnad_completions.ioc_comp,
drivers/net/ethernet/brocade/bna/bnad.c:	err = bnad->bnad_completions.ioc_comp_status;
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.enet_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion(&bnad->bnad_completions.enet_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	init_completion(&bnad->bnad_completions.mtu_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	wait_for_completion(&bnad->bnad_completions.mtu_comp);
drivers/net/ethernet/brocade/bna/bnad.c:	return bnad->bnad_completions.mtu_comp_status;
drivers/net/ethernet/brocade/bna/bnad.c:		 * to explicitly process completions here
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	comp;
drivers/net/ethernet/brocade/bna/bnad.h:struct bnad_completion {
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	ioc_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	ucast_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	mcast_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	tx_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	rx_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	stats_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	enet_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct completion	mtu_comp;
drivers/net/ethernet/brocade/bna/bnad.h:	struct bnad_completion bnad_completions;
drivers/net/ethernet/brocade/bna/bnad.h:void bnad_cb_completion(void *arg, enum bfa_status status);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:	init_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:	reinit_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_debugfs.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	init_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	init_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	init_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	init_completion(&fcomp.comp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:				bnad_cb_completion, &fcomp);
drivers/net/ethernet/brocade/bna/bnad_ethtool.c:	wait_for_completion(&fcomp.comp);
drivers/net/ethernet/cadence/macb_main.c:		/* Packet completions only seem to propagate to raise
drivers/net/ethernet/cadence/macb_main.c:		/* Packet completions only seem to propagate to raise
drivers/net/ethernet/calxeda/xgmac.c:	/* Ensure tx_head update is visible to tx completion */
drivers/net/ethernet/calxeda/xgmac.c:		/* Ensure netif_stop_queue is visible to tx completion */
drivers/net/ethernet/calxeda/xgmac.c: *   Also it runs the TX completion thread
drivers/net/ethernet/cavium/liquidio/lio_core.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_core.c:void octeon_report_tx_completion_to_bql(void *txq, unsigned int pkts_compl,
drivers/net/ethernet/cavium/liquidio/lio_core.c:void octeon_update_tx_completion_counters(void *buf, int reqtype,
drivers/net/ethernet/cavium/liquidio/lio_core.c:void liquidio_link_ctrl_cmd_completion(void *nctrl_ptr)
drivers/net/ethernet/cavium/liquidio/lio_core.c:EXPORT_SYMBOL_GPL(liquidio_link_ctrl_cmd_completion);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	ret = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:		wait_for_sc_completion_timeout(oct_dev, sc,
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	retval = wait_for_sc_completion_timeout(oct_dev, sc,
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:		retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:		retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_core.c:	retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:		retval = wait_for_sc_completion_timeout(oct_dev, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	retval = wait_for_sc_completion_timeout(oct_dev, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	retval = wait_for_sc_completion_timeout(oct_dev, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	struct completion init;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	struct completion started;
drivers/net/ethernet/cavium/liquidio/lio_main.c:static struct completion first_stage;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&hs->init);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&hs->started);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:		nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_completion(&first_stage);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	wait_for_completion_timeout(&first_stage, msecs_to_jiffies(1000));
drivers/net/ethernet/cavium/liquidio/lio_main.c:			wait_for_completion(&hs->init);
drivers/net/ethernet/cavium/liquidio/lio_main.c:			wait_for_completion_timeout(&hs->started,
drivers/net/ethernet/cavium/liquidio/lio_main.c:		init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		retval = wait_for_sc_completion_timeout(octeon_dev, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:		retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:	nctrl.cb_fn = liquidio_link_ctrl_cmd_completion;
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:		init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_vf_main.c:		retval = wait_for_sc_completion_timeout(octeon_dev, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_vf_rep.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/lio_vf_rep.c:	err = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/lio_vf_rep.h:	struct completion complete;
drivers/net/ethernet/cavium/liquidio/octeon_iq.h:#define COMPLETION_WORD_INIT    0xffffffffffffffffULL
drivers/net/ethernet/cavium/liquidio/octeon_iq.h:	struct completion complete;
drivers/net/ethernet/cavium/liquidio/octeon_mailbox.c: * Writes back the acknowldgement inidcating completion of read
drivers/net/ethernet/cavium/liquidio/octeon_main.h:void octeon_update_tx_completion_counters(void *buf, int reqtype,
drivers/net/ethernet/cavium/liquidio/octeon_main.h:void octeon_report_tx_completion_to_bql(void *txq, unsigned int pkts_compl,
drivers/net/ethernet/cavium/liquidio/octeon_main.h:wait_for_sc_completion_timeout(struct octeon_device *oct_dev,
drivers/net/ethernet/cavium/liquidio/octeon_main.h:		wait_for_completion_interruptible_timeout(&sc->complete,
drivers/net/ethernet/cavium/liquidio/octeon_network.h:	struct completion complete;
drivers/net/ethernet/cavium/liquidio/octeon_network.h: * \brief Link control command completion callback
drivers/net/ethernet/cavium/liquidio/octeon_network.h:void liquidio_link_ctrl_cmd_completion(void *nctrl_ptr);
drivers/net/ethernet/cavium/liquidio/octeon_nic.c:	*sc->status_word = COMPLETION_WORD_INIT;
drivers/net/ethernet/cavium/liquidio/octeon_nic.c:	init_completion(&sc->complete);
drivers/net/ethernet/cavium/liquidio/octeon_nic.c:	retval = wait_for_sc_completion_timeout(oct, sc, 0);
drivers/net/ethernet/cavium/liquidio/request_manager.c:		octeon_update_tx_completion_counters(buf, reqtype, &pkts_compl,
drivers/net/ethernet/cavium/liquidio/request_manager.c:		octeon_report_tx_completion_to_bql(iq->app_ctx, pkts_compl,
drivers/net/ethernet/cavium/liquidio/request_manager.c:	 * for cases where there are no IQ completion interrupts.
drivers/net/ethernet/cavium/liquidio/request_manager.c:			*sc->status_word = COMPLETION_WORD_INIT;
drivers/net/ethernet/cavium/liquidio/request_manager.c:			*sc->status_word = COMPLETION_WORD_INIT;
drivers/net/ethernet/cavium/liquidio/request_manager.c:			if (*sc->status_word == COMPLETION_WORD_INIT) {
drivers/net/ethernet/cavium/liquidio/response_manager.c:static void oct_poll_req_completion(struct work_struct *work);
drivers/net/ethernet/cavium/liquidio/response_manager.c:	INIT_DELAYED_WORK(&cwq->wk.work, oct_poll_req_completion);
drivers/net/ethernet/cavium/liquidio/response_manager.c:		if (status64 != COMPLETION_WORD_INIT) {
drivers/net/ethernet/cavium/liquidio/response_manager.c:static void oct_poll_req_completion(struct work_struct *work)
drivers/net/ethernet/cavium/thunder/nic.h:	u8	cq_idx;		/* Completion queue index */
drivers/net/ethernet/cavium/thunder/nic.h:	 * two entries to the completion queue.  First is the regular
drivers/net/ethernet/cavium/thunder/nic.h:	 * each time it receives the entry on the completion queue saying
drivers/net/ethernet/cavium/thunder/nicvf_ethtool.c:	/* All completion queue's registers */
drivers/net/ethernet/cavium/thunder/nicvf_main.c:	/* Enable completion queue interrupt */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:/* Initialize completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Disable completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Reset completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:/* Configures completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Reset completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Set completion queue base address */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Enable Completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Free completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Alloc completion queue */
drivers/net/ethernet/cavium/thunder/nicvf_queues.c:	/* Dummy descriptors to get TSO pkt completion notification */
drivers/net/ethernet/cavium/thunder/q_struct.h:/* Completion queue entry types */
drivers/net/ethernet/chelsio/cxgb/subr.c: *	@reg: the register to check for completion
drivers/net/ethernet/chelsio/cxgb/subr.c: *	@mask: a single-bit field within @reg that indicates completion
drivers/net/ethernet/chelsio/cxgb3/cxgb3_ctl_defs.h: * Structure used to request an operation on an RDMA completion queue.
drivers/net/ethernet/chelsio/cxgb3/cxgb3_ctl_defs.h: * Structure used to setup RDMA completion queues.
drivers/net/ethernet/chelsio/cxgb3/firmware_exports.h: * Ingress Traffic (e.g. DMA completion credit)  for TUNNEL Queue[i] is sent
drivers/net/ethernet/chelsio/cxgb3/mc5.c: * Issue a command to the TCAM and wait for its completion.  The address and
drivers/net/ethernet/chelsio/cxgb3/sge.c:	 * We do not use Tx completion interrupts to free DMAd Tx packets.
drivers/net/ethernet/chelsio/cxgb3/sge.c: *	indications and completion credits for the queue set's Tx queues.
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	@reg: the register to check for completion
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	@mask: a single-bit field within @reg that indicates completion
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	@valp: where to store the value of the register at completion time
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	at the time it indicated completion is stored there.  Returns 0 if the
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c:		{F_SPLCMPDIS, "PCI split completion discarded", -1, 1},
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c:		{F_UNXSPLCMP, "PCI unexpected split completion error", -1, 1},
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c:		{F_RCVSPLCMPERR, "PCI received split completion error", -1,
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c:		 "PCI unexpected split completion DMA read error", -1, 1},
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c:		 "PCI unexpected split completion DMA command error", -1, 1},
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	t3_sge_init_cqcntxt - initialize an SGE completion queue context
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	@credits: completion queue credits
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	Initialize an SGE completion queue context and make it ready for use.
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	t3_sge_disable_cqcntxt - disable an SGE completion queue
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	@id: the completion queue context id
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	Disable an SGE completion queue.  The caller is responsible for
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	t3_sge_cqcntxt_op - perform an operation on a completion queue context
drivers/net/ethernet/chelsio/cxgb3/t3_hw.c: *	Perform the selected operation on an SGE completion queue context.
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	struct completion completion;
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	struct sk_buff *skb; /* SKB to free after getting completion */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	u16 nciq;		/* # of completion queues */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	spinlock_t lock; /* Per queue lock to synchronize completions */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	u32 ncompl; /* # of completions posted */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	u32 last_compl; /* # of credits consumed since last completion req */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	struct completion completion; /* completion for FLOWC rendezvous */
drivers/net/ethernet/chelsio/cxgb4/cxgb4.h:	struct filter_ctx *ctx; /* Caller's completion hook */
drivers/net/ethernet/chelsio/cxgb4/cxgb4_debugfs.c:	seq_printf(seq, "Completion: %10u \n",
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c: * it till we get a reply from the firmware on the completion status of the
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c: * filter specification in order to facilitate signaling completion of the
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c: * facilitate signaling completion of the operation.
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	/* If the caller has passed in a Completion Context then we need to
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	 * mark it as a successful completion so they don't stall waiting
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:		complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	init_completion(&ctx.completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	ret = wait_for_completion_timeout(&ctx.completion, 10 * HZ);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	init_completion(&ctx.completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	ret = wait_for_completion_timeout(&ctx.completion, 10 * HZ);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:		complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:		complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:			complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c:	init_completion(&ctx.completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c:	ret = wait_for_completion_timeout(&ctx.completion, 10 * HZ);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:		/* Allocate Rxqs for receiving ETHOFLD Tx completions */
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:	init_completion(&eosw_txq->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:	ret = wait_for_completion_timeout(&eosw_txq->completion,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:	/* If we're shutting down, interrupts are disabled and no completions
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:	 * come back. So, skip waiting for completions in this scenario.
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:		init_completion(&eosw_txq->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_mqprio.c:		wait_for_completion_timeout(&eosw_txq->completion,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_uld.c:	/* Tell uP to route control queue completions to rdma rspq */
drivers/net/ethernet/chelsio/cxgb4/cxgb4_uld.h: * cxgb4_del_filter() to wait for an asynchronous completion.
drivers/net/ethernet/chelsio/cxgb4/cxgb4_uld.h:	struct completion completion;	/* completion rendezvous */
drivers/net/ethernet/chelsio/cxgb4/sge.c:		 * completion notifications to us and we mostly perform TX
drivers/net/ethernet/chelsio/cxgb4/sge.c:		complete(&eosw_txq->completion);
drivers/net/ethernet/chelsio/cxgb4/sge.c:	init_completion(&lb->completion);
drivers/net/ethernet/chelsio/cxgb4/sge.c:	ret = wait_for_completion_timeout(&lb->completion, 10 * HZ);
drivers/net/ethernet/chelsio/cxgb4/sge.c: *	t4_tx_completion_handler - handle CPL_SGE_EGR_UPDATE messages
drivers/net/ethernet/chelsio/cxgb4/sge.c: *	of TX Data outstanding before receiving DMA Completions.
drivers/net/ethernet/chelsio/cxgb4/sge.c:static void t4_tx_completion_handler(struct sge_rspq *rspq,
drivers/net/ethernet/chelsio/cxgb4/sge.c:	complete(&lb->completion);
drivers/net/ethernet/chelsio/cxgb4/sge.c:		t4_tx_completion_handler(q, rsp, si);
drivers/net/ethernet/chelsio/cxgb4/sge.c:	/* There may be some packets waiting for completions. So,
drivers/net/ethernet/chelsio/cxgb4/sge.c:/* cxgb4_ethofld_rx_handler - Process ETHOFLD Tx completions
drivers/net/ethernet/chelsio/cxgb4/sge.c: * Process a ETHOFLD Tx completion. Increment the cidx here, but
drivers/net/ethernet/chelsio/cxgb4/sge.c:				complete(&eosw_txq->completion);
drivers/net/ethernet/chelsio/cxgb4/sge.c:		 * if there were packets waiting for completion.
drivers/net/ethernet/chelsio/cxgb4/srq.c:	init_completion(&s->comp);
drivers/net/ethernet/chelsio/cxgb4/srq.c:	rc = wait_for_completion_timeout(&s->comp, SRQ_WAIT_TO);
drivers/net/ethernet/chelsio/cxgb4/srq.h:	struct completion comp;
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@reg: the register to check for completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@mask: a single-bit field within @reg that indicates completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@valp: where to store the value of the register at completion time
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	at the time it indicated completion is stored there.  Returns 0 if the
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		{ RCCP_F, "Rx completions control array parity error", -1, 1 },
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		{ PIOCPLPERR_F, "PCI PIO completion FIFO parity error", -1, 1 },
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		{ RXCPLPERR_F, "PCI Rx completion parity error", -1, 1 },
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		{ UNXSPLCPLERR_F, "PCI unexpected split completion error",
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		{ PIOCPLGRPPERR_F, "PCI PIO completion Group FIFO parity error",
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		"IDMA_FL_SEND_COMPLETION_TO_IMSG",
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		"IDMA_FL_SEND_COMPLETION_TO_IMSG",
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:		"IDMA_FL_SEND_COMPLETION_TO_IMSG",
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@sleep_ok: if true, we may sleep awaiting mbox cmd completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *	@sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c:	/* Set PCIe completion timeout to 4 seconds. */
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: *      @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4_hw.c: * @sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h:/* completion flag (hi) - firmware generates a cpl_fw6_ack */
drivers/net/ethernet/chelsio/cxgb4vf/cxgb4vf_main.c:	 * notifications of TX DMA completions.
drivers/net/ethernet/chelsio/cxgb4vf/sge.c:		 * completion notifications to us and we mostly perform TX
drivers/net/ethernet/chelsio/cxgb4vf/t4vf_hw.c: *	@sleep_ok: if true we may sleep while awaiting command completion
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	init_completion(&tx_info->completion);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	wait_for_completion_timeout(&tx_info->completion, 30 * HZ);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	reinit_completion(&tx_info->completion);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	wait_for_completion_timeout(&tx_info->completion, 30 * HZ);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	complete(&tx_info->completion);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	complete(&tx_info->completion);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.h:	struct completion completion;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls.h:	ULPCB_FLAG_COMPL     = 1 << 4,	/* request WR completion */
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:		unsigned int completion = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:				completion = 1;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:						credits_needed, completion);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:			if (completion)
drivers/net/ethernet/cirrus/cs89x0.c:	 * it runs like a dog.  We just return and wait for the Tx completion
drivers/net/ethernet/cisco/enic/cq_desc.h: * Completion queue descriptor types
drivers/net/ethernet/cisco/enic/cq_desc.h:/* Completion queue descriptor: 16B
drivers/net/ethernet/cisco/enic/cq_desc.h: * All completion queues have this basic layout.  The
drivers/net/ethernet/cisco/enic/cq_desc.h: * type_specfic area is unique for each completion
drivers/net/ethernet/cisco/enic/cq_enet_desc.h:/* Ethernet completion queue descriptor: 16B */
drivers/net/ethernet/cisco/enic/cq_enet_desc.h:/* Completion queue descriptor: Ethernet receive queue, 16B */
drivers/net/ethernet/cisco/enic/enic.h:	u64 cq_work;		/* Tx completions processed */
drivers/net/ethernet/cisco/enic/enic.h:	/* completion queue cache line section */
drivers/net/ethernet/cisco/enic/enic_main.c:	 * cycle.  An intr event is the completion of a
drivers/net/ethernet/cisco/enic/enic_main.c:	 * cycle.  An intr event is the completion of a
drivers/net/ethernet/cisco/enic/vnic_cq.h:/* Completion queue control */
drivers/net/ethernet/cisco/enic/vnic_resource.h:	RES_TYPE_CQ,			/* Completion queues */
drivers/net/ethernet/cisco/enic/vnic_resource.h:	RES_TYPE_MQ_CQ,			/* MQ Completion queues */
drivers/net/ethernet/cisco/enic/vnic_wq.h:	uint8_t cq_entry; /* Gets completion event from hw */
drivers/net/ethernet/cortina/gemini.c:	/* Racing with MIB and TX completion interrupts */
drivers/net/ethernet/dec/tulip/interrupt.c:         /* The last op happens after poll completion. Which means the following:
drivers/net/ethernet/emulex/benet/be.h:	u8 status;		/* Completion status */
drivers/net/ethernet/emulex/benet/be.h:	u32 rx_compl_err;	/* completions with err set */
drivers/net/ethernet/emulex/benet/be.h:	struct completion et_cmd_compl;
drivers/net/ethernet/emulex/benet/be_cmds.c:/* Notify MCC requests and wait for completion */
drivers/net/ethernet/emulex/benet/be_cmds.c: * Polls on the mbox doorbell till a command completion (or a timeout) occurs
drivers/net/ethernet/emulex/benet/be_cmds.c:		dev_err(&adapter->pdev->dev, "invalid mailbox completion\n");
drivers/net/ethernet/emulex/benet/be_cmds.c:	if (!wait_for_completion_timeout(&adapter->et_cmd_compl,
drivers/net/ethernet/emulex/benet/be_cmds.c:	if (!wait_for_completion_timeout(&adapter->et_cmd_compl,
drivers/net/ethernet/emulex/benet/be_cmds.c:	if (!wait_for_completion_timeout(&adapter->et_cmd_compl,
drivers/net/ethernet/emulex/benet/be_cmds.c:	wait_for_completion(&adapter->et_cmd_compl);
drivers/net/ethernet/emulex/benet/be_cmds.h:/* Completion Status */
drivers/net/ethernet/emulex/benet/be_hw.h: * complete. Upon completion, the MAILBOX will contain a valid completion
drivers/net/ethernet/emulex/benet/be_main.c:	 * and set event, completion, vlan bits accordingly
drivers/net/ethernet/emulex/benet/be_main.c:/* Throwaway the data in the Rx completion */
drivers/net/ethernet/emulex/benet/be_main.c:	/* Copy data in the first descriptor of this completion */
drivers/net/ethernet/emulex/benet/be_main.c:	/* More frags present for this completion */
drivers/net/ethernet/emulex/benet/be_main.c:/* Process the RX completion indicated by rxcp when GRO is disabled */
drivers/net/ethernet/emulex/benet/be_main.c:/* Process the RX completion indicated by rxcp when GRO is enabled */
drivers/net/ethernet/emulex/benet/be_main.c:	/* Consume pending rx completions.
drivers/net/ethernet/emulex/benet/be_main.c:	 * Wait for the flush completion (identified by zero num_rcvd)
drivers/net/ethernet/emulex/benet/be_main.c:	/* Use the default EQ for MCC completions */
drivers/net/ethernet/emulex/benet/be_main.c:	 * completions of the last RXQ (default one) are also processed
drivers/net/ethernet/emulex/benet/be_main.c:	/* Wait for all pending tx completions to arrive so that
drivers/net/ethernet/emulex/benet/be_main.c:	 * mcc completions
drivers/net/ethernet/emulex/benet/be_main.c:	init_completion(&adapter->et_cmd_compl);
drivers/net/ethernet/ezchip/Kconfig:	  Device supports interrupts for RX and TX(completion).
drivers/net/ethernet/ezchip/nps_enet.c: * We got one for RX and the other for TX (completion).
drivers/net/ethernet/faraday/ftgmac100.c:	/* Handle TX completions */
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/dpaa2/dpsw.c: * Return:	Completion status. '0' on Success; Error code otherwise.
drivers/net/ethernet/freescale/enetc/enetc_hw.h:/* Command completion status */
drivers/net/ethernet/freescale/fman/fman.c:		/* Wait for reset completion */
drivers/net/ethernet/freescale/fman/fman.c:		/* Wait for reset completion */
drivers/net/ethernet/freescale/fman/fman_mac.h:	/* 10GEC MDIO command completion interrupt */
drivers/net/ethernet/freescale/fman/fman_mac.h:	/* dTSEC MII management read completion */
drivers/net/ethernet/freescale/fman/fman_mac.h:	/* dTSEC MII management write completion */
drivers/net/ethernet/freescale/gianfar.c:	/* Store incomplete frames for completion */
drivers/net/ethernet/freescale/gianfar.c:	/* run Tx cleanup to completion */
drivers/net/ethernet/freescale/gianfar.c:	/* Check for transmit completion */
drivers/net/ethernet/freescale/ucc_geth.c:	/* Stop NAPI, and possibly wait for its completion. */
drivers/net/ethernet/fungible/funcore/fun_dev.c:	fun_admin_callback_t cb;  /* callback to invoke on completion */
drivers/net/ethernet/fungible/funcore/fun_dev.c:	struct completion compl;
drivers/net/ethernet/fungible/funcore/fun_dev.c: * any waiting or timeout. Upon command completion the callback @cb is called.
drivers/net/ethernet/fungible/funcore/fun_dev.c: * completion is racing with this call.
drivers/net/ethernet/fungible/funcore/fun_dev.c: * command response to the caller's buffer and signals completion.
drivers/net/ethernet/fungible/funcore/fun_dev.c:		.compl = COMPLETION_INITIALIZER_ONSTACK(ctx.compl),
drivers/net/ethernet/fungible/funcore/fun_dev.c:	jiffies_left = wait_for_completion_timeout(&ctx.compl,
drivers/net/ethernet/fungible/funcore/fun_dev.c:		wait_for_completion(&ctx.compl);
drivers/net/ethernet/fungible/funcore/fun_queue.c:	/* For scattered completions gather the fragments into one buffer. */
drivers/net/ethernet/fungible/funeth/funeth_rx.c:/* A CQE contains a fixed completion structure along with optional metadata and
drivers/net/ethernet/google/gve/gve.h: * Each RX (completion) queue has a corresponding buffer queue.
drivers/net/ethernet/google/gve/gve.h:/* RX completion queue to receive packets from HW. */
drivers/net/ethernet/google/gve/gve.h:	/* Pointer into desc_ring where the next completion descriptor will be
drivers/net/ethernet/google/gve/gve.h:	/* Packet is expecting a regular data completion or miss completion */
drivers/net/ethernet/google/gve/gve.h:	/* Packet has received a miss completion and is expecting a
drivers/net/ethernet/google/gve/gve.h:	 * re-injection completion.
drivers/net/ethernet/google/gve/gve.h:	/* No valid completion received within the specified timeout. */
drivers/net/ethernet/google/gve/gve.h:	 * Used for tracking either outstanding miss completions or prematurely
drivers/net/ethernet/google/gve/gve.h:	/* If packet is an outstanding miss completion, then the packet is
drivers/net/ethernet/google/gve/gve.h:	 * freed if the corresponding re-injection completion is not received
drivers/net/ethernet/google/gve/gve.h:			 * completion handling path
drivers/net/ethernet/google/gve/gve.h:				* completion handling path
drivers/net/ethernet/google/gve/gve.h:			 * This is the producer list, owned by the completion
drivers/net/ethernet/google/gve/gve.h:			 * completion but not a corresponding reinjection.
drivers/net/ethernet/google/gve/gve.h:			struct gve_index_list miss_completions;
drivers/net/ethernet/google/gve/gve.h:			 * before receiving a valid completion because they
drivers/net/ethernet/google/gve/gve.h:			struct gve_index_list timed_out_completions;
drivers/net/ethernet/google/gve/gve.h:				 * This is the producer list, owned by the completion
drivers/net/ethernet/google/gve/gve.h:	 * out-of-order completions. Set it to two times of ring size.
drivers/net/ethernet/google/gve/gve_adminq.h:	TX_LAST_COMPLETION_PROCESSED	= 5,
drivers/net/ethernet/google/gve/gve_desc_dqo.h:	/* If set, will generate a descriptor completion for this descriptor. */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:	/* The TX completion associated with this packet will contain this tag.
drivers/net/ethernet/google/gve/gve_desc_dqo.h:/* TX completion descriptor */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:	 * completion.
drivers/net/ethernet/google/gve/gve_desc_dqo.h:		/* For descriptor completions, this is the last index fetched
drivers/net/ethernet/google/gve/gve_desc_dqo.h:		/* For packet completions, this is the completion tag set on the
drivers/net/ethernet/google/gve/gve_desc_dqo.h:		__le16 completion_tag;
drivers/net/ethernet/google/gve/gve_desc_dqo.h:#define GVE_COMPL_TYPE_DQO_PKT 0x2 /* Packet completion */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:#define GVE_COMPL_TYPE_DQO_DESC 0x4 /* Descriptor completion */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:#define GVE_COMPL_TYPE_DQO_MISS 0x1 /* Miss path completion */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:#define GVE_COMPL_TYPE_DQO_REINJECTION 0x3 /* Re-injection completion */
drivers/net/ethernet/google/gve/gve_desc_dqo.h:/* The most significant bit in the completion tag can change the completion
drivers/net/ethernet/google/gve/gve_desc_dqo.h: * type from packet completion to miss path completion.
drivers/net/ethernet/google/gve/gve_desc_dqo.h:	__le16 buf_id; /* ID returned in Rx completion descriptor */
drivers/net/ethernet/google/gve/gve_dqo.h:/* Timeout in seconds to wait for a reinjection completion after receiving
drivers/net/ethernet/google/gve/gve_dqo.h: * its corresponding miss completion.
drivers/net/ethernet/google/gve/gve_dqo.h:/* Timeout in seconds to deallocate the completion tag for a packet that was
drivers/net/ethernet/google/gve/gve_dqo.h: * prematurely freed for not receiving a valid completion. This should be large
drivers/net/ethernet/google/gve/gve_dqo.h: * completion after this interval.
drivers/net/ethernet/google/gve/gve_main.c:	/* Check to see if there are missed completions, which will allow us to
drivers/net/ethernet/google/gve/gve_main.c:			u32 last_completion = 0;
drivers/net/ethernet/google/gve/gve_main.c:				last_completion = priv->tx[idx].done;
drivers/net/ethernet/google/gve/gve_main.c:				.stat_name = cpu_to_be32(TX_LAST_COMPLETION_PROCESSED),
drivers/net/ethernet/google/gve/gve_main.c:				.value = cpu_to_be64(last_completion),
drivers/net/ethernet/google/gve/gve_rx_dqo.c:				       const u32 completion_queue_slots)
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	/* Set completion queue state */
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	rx->dqo.complq.num_free_slots = completion_queue_slots;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	rx->dqo.complq.mask = completion_queue_slots - 1;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	const u32 completion_queue_slots = priv->rx_desc_cnt;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	/* Reset completion queue */
drivers/net/ethernet/google/gve/gve_rx_dqo.c:			completion_queue_slots;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:				   completion_queue_slots);
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	size_t completion_queue_slots;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	completion_queue_slots = rx->dqo.complq.mask + 1;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:			completion_queue_slots;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	const u32 completion_queue_slots = cfg->ring_size;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:	/* Allocate RX completion queue */
drivers/net/ethernet/google/gve/gve_rx_dqo.c:		completion_queue_slots;
drivers/net/ethernet/google/gve/gve_rx_dqo.c:				   completion_queue_slots);
drivers/net/ethernet/google/gve/gve_rx_dqo.c:		/* Receiving a completion means we have space to post another
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	 * completion handler.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	/* Check completion handler's list. */
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	 * completion handler.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	 * descriptors which maybe written to the completion queue.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	 * completion queue.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	/* Reserve space for descriptor completions, which will be reported at
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	/* Each packet may have at most 2 buffer completions if it receives both
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	 * a miss and reinjection completion.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	tx->dqo_compl.miss_completions.head = -1;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	tx->dqo_compl.miss_completions.tail = -1;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	tx->dqo_compl.timed_out_completions.head = -1;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	tx->dqo_compl.timed_out_completions.tail = -1;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:				      s16 completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					 completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					 completion_tag, is_eop, is_gso);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:				   s16 completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					 completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	s16 completion_tag;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	completion_tag = pkt - tx->dqo.pending_packets;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					    completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					       completion_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	/* Request a descriptor completion on the last descriptor of the
drivers/net/ethernet/google/gve/gve_tx_dqo.c:/* Completion types and expected behavior:
drivers/net/ethernet/google/gve/gve_tx_dqo.c:static void gve_handle_packet_completion(struct gve_priv *priv,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		net_err_ratelimited("%s: Invalid TX completion tag: %d\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			net_err_ratelimited("%s: Re-injection completion: %d received after timeout.\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:					 &tx->dqo_compl.timed_out_completions,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			/* No outstanding miss completion but packet allocated
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			 * implies packet receives a re-injection completion
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			 * without a prior miss completion. Return without
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			net_err_ratelimited("%s: Re-injection completion received without corresponding miss completion: %d\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		remove_from_list(tx, &tx->dqo_compl.miss_completions,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		/* Packet is allocated but not a pending data completion. */
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			net_err_ratelimited("%s: No pending data completion: %d\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:static void gve_handle_miss_completion(struct gve_priv *priv,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		net_err_ratelimited("%s: Invalid TX completion tag: %d\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		net_err_ratelimited("%s: Unexpected packet state: %d for completion tag : %d\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	add_to_list(tx, &tx->dqo_compl.miss_completions, pending_packet);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:static void remove_miss_completions(struct gve_priv *priv,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	next_index = tx->dqo_compl.miss_completions.head;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		remove_from_list(tx, &tx->dqo_compl.miss_completions,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		 * the completion tag is not freed to ensure that the driver
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		 * completion is received later.
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		net_err_ratelimited("%s: No reinjection completion was received for: %d.\n",
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		add_to_list(tx, &tx->dqo_compl.timed_out_completions,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:static void remove_timed_out_completions(struct gve_priv *priv,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	next_index = tx->dqo_compl.timed_out_completions.head;
drivers/net/ethernet/google/gve/gve_tx_dqo.c:		remove_from_list(tx, &tx->dqo_compl.timed_out_completions,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			u16 compl_tag = le16_to_cpu(compl_desc->completion_tag);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:				gve_handle_miss_completion(priv, tx, compl_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:				gve_handle_packet_completion(priv, tx, !!napi,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			u16 compl_tag = le16_to_cpu(compl_desc->completion_tag);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			gve_handle_miss_completion(priv, tx, compl_tag,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			u16 compl_tag = le16_to_cpu(compl_desc->completion_tag);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:			gve_handle_packet_completion(priv, tx, !!napi,
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	remove_miss_completions(priv, tx);
drivers/net/ethernet/google/gve/gve_tx_dqo.c:	remove_timed_out_completions(priv, tx);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	/* hardware completion status should be available by this time */
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	/* check if VF could successfully fetch the hardware reset completion
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:			"failed to fetch H/W reset completion status\n");
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		 * completed the reset sequence. On hardware reset completion,
drivers/net/ethernet/huawei/hinic/hinic_hw_api_cmd.c:		/* wait for CI to be updated - sign for completion */
drivers/net/ethernet/huawei/hinic/hinic_hw_api_cmd.c: * wait_for_api_cmd_completion - wait for command to complete
drivers/net/ethernet/huawei/hinic/hinic_hw_api_cmd.c:static int wait_for_api_cmd_completion(struct hinic_api_cmd_chain *chain)
drivers/net/ethernet/huawei/hinic/hinic_hw_api_cmd.c:	err = wait_for_api_cmd_completion(chain);
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:#include <linux/completion.h>
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:enum completion_format {
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:enum completion_request {
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:static void cmdq_set_sge_completion(struct hinic_cmdq_completion *completion,
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	struct hinic_sge_resp *sge_resp = &completion->sge_resp;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:				  enum completion_format complete_format,
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	enum completion_format complete_format;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:		cmdq_set_sge_completion(&wqe_lcmd->completion, buf_out);
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:		wqe_lcmd->completion.direct_resp = 0;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	enum completion_format complete_format;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:		cmdq_set_sge_completion(&wqe_scmd->completion, buf_out);
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:		wqe_scmd->completion.direct_resp = 0;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	struct completion done;
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	init_completion(&done);
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	if (!wait_for_completion_timeout(&done,
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:	smp_rmb();      /* read error code after completion */
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c:		*resp = cpu_to_be64(wqe_lcmd->completion.direct_resp);
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c: * cmdq_arm_ceq_handler - cmdq completion event handler for arm command
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c: * cmdq_sync_cmd_handler - cmdq completion event handler for sync command
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.c: * cmdq_ceq_handler - cmdq completion event handler
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.h:#include <linux/completion.h>
drivers/net/ethernet/huawei/hinic/hinic_hw_cmdq.h:	struct completion       **done;
drivers/net/ethernet/huawei/hinic/hinic_hw_eqs.c: * @ceqs: pointer to Completion eqs part of the chip
drivers/net/ethernet/huawei/hinic/hinic_hw_eqs.c: * @ceqs: pointer to Completion eqs part of the chip
drivers/net/ethernet/huawei/hinic/hinic_hw_eqs.c: * @eq: the Completion Event Queue that received the event
drivers/net/ethernet/huawei/hinic/hinic_hw_eqs.c: * @data: the Completion Event Queue that collected the event
drivers/net/ethernet/huawei/hinic/hinic_hw_io.c: * @num_ceqs: number completion event queues
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:#include <linux/completion.h>
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:wait_for_mbox_seg_completion(struct hinic_mbox_func_to_func *func_to_func,
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:	struct completion *done = &send_mbox->send_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:		if (!wait_for_completion_timeout(done, jif)) {
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:	struct completion *done = &send_mbox->send_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:		init_completion(done);
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:	if (wait_for_mbox_seg_completion(func_to_func, poll, &wb_status))
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:	init_completion(&mbox_for_resp->recv_done);
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.c:	if (!wait_for_completion_timeout(&mbox_for_resp->recv_done, timeo)) {
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.h:	struct completion	recv_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_mbox.h:	struct completion	send_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.c:#include <linux/completion.h>
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.c:	struct completion *recv_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.c:	init_completion(recv_done);
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.c:	if (!wait_for_completion_timeout(recv_done, timeo)) {
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.c:	smp_rmb();      /* verify reading after completion */
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.h:#include <linux/completion.h>
drivers/net/ethernet/huawei/hinic/hinic_hw_mgmt.h:	struct completion       recv_done;
drivers/net/ethernet/huawei/hinic/hinic_hw_qp.c:enum rq_completion_fmt {
drivers/net/ethernet/huawei/hinic/hinic_hw_qp.c: * alloc_rq_cqe - allocate rq completion queue elements
drivers/net/ethernet/huawei/hinic/hinic_hw_qp.c: * free_rq_cqe - free rq completion queue elements
drivers/net/ethernet/huawei/hinic/hinic_hw_wqe.h:struct hinic_cmdq_completion {
drivers/net/ethernet/huawei/hinic/hinic_hw_wqe.h:	struct hinic_cmdq_completion    completion;
drivers/net/ethernet/huawei/hinic/hinic_hw_wqe.h:	struct hinic_cmdq_completion    completion;
drivers/net/ethernet/ibm/ehea/ehea.h:/* Send completion signaling */
drivers/net/ethernet/ibm/ehea/ehea.h: * Completion Queue attributes
drivers/net/ethernet/ibm/ehea/ehea.h: * Completion Queue
drivers/net/ethernet/ibm/ehea/ehea_main.c:		swqe->tx_control |= EHEA_SWQE_SIGNALLED_COMPLETION;
drivers/net/ethernet/ibm/ehea/ehea_main.c:			pr_err("Bad send completion status=0x%04X\n",
drivers/net/ethernet/ibm/ehea/ehea_main.c:			swqe->tx_control |= EHEA_SWQE_SIGNALLED_COMPLETION;
drivers/net/ethernet/ibm/ehea/ehea_main.c:		swqe->tx_control |= EHEA_SWQE_SIGNALLED_COMPLETION;
drivers/net/ethernet/ibm/ehea/ehea_qmr.h: * CQE  - Completion Queue Entry
drivers/net/ethernet/ibm/ehea/ehea_qmr.h:#define EHEA_SWQE_SIGNALLED_COMPLETION  0x0800
drivers/net/ethernet/ibm/ibmvnic.c:#include <linux/completion.h>
drivers/net/ethernet/ibm/ibmvnic.c: * ibmvnic_wait_for_completion - Check device state and wait for completion
drivers/net/ethernet/ibm/ibmvnic.c: * @comp_done: completion structure to wait for
drivers/net/ethernet/ibm/ibmvnic.c: * Wait for a completion signal or until the timeout limit is reached
drivers/net/ethernet/ibm/ibmvnic.c:static int ibmvnic_wait_for_completion(struct ibmvnic_adapter *adapter,
drivers/net/ethernet/ibm/ibmvnic.c:				       struct completion *comp_done,
drivers/net/ethernet/ibm/ibmvnic.c:		if (wait_for_completion_timeout(comp_done, div_timeout))
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->fw_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c:		reinit_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:		if (!wait_for_completion_timeout(&adapter->init_done,
drivers/net/ethernet/ibm/ibmvnic.c:			reinit_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:			if (!wait_for_completion_timeout(&adapter->init_done,
drivers/net/ethernet/ibm/ibmvnic.c:		reinit_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:		if (!wait_for_completion_timeout(&adapter->init_done,
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->fw_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->fw_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->fw_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c: * Initialize the init_done completion and return code values. We
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:	if (!wait_for_completion_timeout(&adapter->init_done, timeout)) {
drivers/net/ethernet/ibm/ibmvnic.c:	    !wait_for_completion_timeout(&adapter->probe_done, timeout)) {
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->reset_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->reset_done, 60000);
drivers/net/ethernet/ibm/ibmvnic.c:		reinit_completion(&adapter->reset_done);
drivers/net/ethernet/ibm/ibmvnic.c:		rc = ibmvnic_wait_for_completion(adapter, &adapter->reset_done,
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->stats_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->stats_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c:					    "TX completion received with NULL socket buffer\n");
drivers/net/ethernet/ibm/ibmvnic.c:	reinit_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	rc = ibmvnic_wait_for_completion(adapter, &adapter->fw_done, 10000);
drivers/net/ethernet/ibm/ibmvnic.c:			if (!completion_done(&adapter->init_done)) {
drivers/net/ethernet/ibm/ibmvnic.c:		if (!completion_done(&adapter->fw_done)) {
drivers/net/ethernet/ibm/ibmvnic.c:		if (!completion_done(&adapter->init_done)) {
drivers/net/ethernet/ibm/ibmvnic.c:		if (!completion_done(&adapter->stats_done))
drivers/net/ethernet/ibm/ibmvnic.c:	if (!wait_for_completion_timeout(&adapter->init_done, timeout)) {
drivers/net/ethernet/ibm/ibmvnic.c:			 * awaiting completion.
drivers/net/ethernet/ibm/ibmvnic.c:	init_completion(&adapter->probe_done);
drivers/net/ethernet/ibm/ibmvnic.c:	init_completion(&adapter->init_done);
drivers/net/ethernet/ibm/ibmvnic.c:	init_completion(&adapter->fw_done);
drivers/net/ethernet/ibm/ibmvnic.c:	init_completion(&adapter->reset_done);
drivers/net/ethernet/ibm/ibmvnic.c:	init_completion(&adapter->stats_done);
drivers/net/ethernet/ibm/ibmvnic.h:	struct completion stats_done;
drivers/net/ethernet/ibm/ibmvnic.h:	struct completion probe_done;
drivers/net/ethernet/ibm/ibmvnic.h:	struct completion init_done;
drivers/net/ethernet/ibm/ibmvnic.h:	struct completion fw_done;
drivers/net/ethernet/ibm/ibmvnic.h:	struct completion reset_done;
drivers/net/ethernet/intel/e100.c: *	is the next CB to check for completion; cb_to_send is the first
drivers/net/ethernet/intel/e100.c: *	mapped shared memory, and completion status is contained within
drivers/net/ethernet/intel/e100.c:	/* no interrupt for every tx completion, delay = 256us if not 557 */
drivers/net/ethernet/intel/e100.c:	/* wait for completion */
drivers/net/ethernet/intel/e1000/e1000_hw.h:#define E1000_STATUS_LAN_INIT_DONE 0x00000200	/* Lan Init Completion
drivers/net/ethernet/intel/e1000e/82571.c: *  poll for completion.
drivers/net/ethernet/intel/e1000e/82571.c:	 * Need to wait for Phy configuration completion before accessing
drivers/net/ethernet/intel/e1000e/82571.c:		 * completions are occurring, particularly with ASPM enabled.
drivers/net/ethernet/intel/e1000e/defines.h:#define E1000_STATUS_LAN_INIT_DONE 0x00000200   /* Lan Init Completion by NVM */
drivers/net/ethernet/intel/e1000e/ich8lan.c: *  When K1 is enabled for 1Gbps, the MAC can miss 2 DMA completion indications
drivers/net/ethernet/intel/e1000e/ich8lan.c: *  e1000_lan_init_done_ich8lan - Check for PHY config completion
drivers/net/ethernet/intel/e1000e/ich8lan.c: *  @timeout: maximum time to wait for completion
drivers/net/ethernet/intel/e1000e/ich8lan.c: *  This function starts a flash cycle and waits for its completion.
drivers/net/ethernet/intel/e1000e/ich8lan.c: *  Read appropriate register for the config done bit for completion status
drivers/net/ethernet/intel/e1000e/mac.c: *  e1000e_get_auto_rd_done - Check for auto read completion
drivers/net/ethernet/intel/e1000e/nvm.c: *  e1000e_poll_eerd_eewr_done - Poll for EEPROM read/write completion
drivers/net/ethernet/intel/e1000e/nvm.c: *  Polls the EEPROM status bit for either read or write completion based
drivers/net/ethernet/intel/e1000e/phy.c: *  successful completion, else return corresponding error code.
drivers/net/ethernet/intel/e1000e/phy.c: *  e1000_wait_autoneg - Wait for auto-neg completion
drivers/net/ethernet/intel/fm10k/fm10k_iov.c:	/* Mask the completion abort bit in the ERR_UNCOR_MASK register,
drivers/net/ethernet/intel/fm10k/fm10k_main.c:	/* place incomplete frames back on ring for completion */
drivers/net/ethernet/intel/fm10k/fm10k_main.c:	 * run the check_tx_hang logic with a transmit completion
drivers/net/ethernet/intel/i40e/i40e_adminq.c:	 * in case of asynchronous completions
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * - _completion for direct return data
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_get_wake_reason_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_get_wake_reason_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: *     uses the same completion and data structure as Add VSI
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_get_update_vsi_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_get_update_vsi_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_update_pv_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_update_pv_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_get_pv_params_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_get_pv_params_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_veb_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_veb_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_get_veb_parameters_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_get_veb_parameters_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_remove_macvlan_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_remove_macvlan_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_remove_vlan_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * Uses generic i40e_aqc_add_remove_tag_completion for completion
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_remove_tag_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_remove_tag_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * Uses generic i40e_aqc_add_remove_tag_completion for completion
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_remove_mcast_etag_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_remove_mcast_etag_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_update_tag_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_update_tag_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * and the generic direct completion structure
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_remove_control_packet_filter_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_remove_control_packet_filter_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * and the generic indirect completion structure
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_remove_cloud_filters_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_remove_cloud_filters_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h: * and the generic indirect completion structure
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_delete_mirror_rule_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_delete_mirror_rule_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:/* Add Udp Tunnel command and completion (direct 0x0B00) */
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_add_udp_tunnel_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_add_udp_tunnel_completion);
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:struct i40e_aqc_del_udp_tunnel_completion {
drivers/net/ethernet/intel/i40e/i40e_adminq_cmd.h:I40E_CHECK_CMD_LENGTH(i40e_aqc_del_udp_tunnel_completion);
drivers/net/ethernet/intel/i40e/i40e_common.c: * i40e_poll_globr - Poll for Global Reset completion
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_get_update_vsi_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_add_get_update_vsi_completion *)
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_get_update_vsi_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_add_get_update_vsi_completion *)
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_get_update_vsi_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_add_get_update_vsi_completion *)
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_veb_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_add_veb_completion *)&desc.params.raw;
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_get_veb_parameters_completion *cmd_resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_get_veb_parameters_completion *)
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_delete_mirror_rule_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:	(struct i40e_aqc_add_delete_mirror_rule_completion *)&desc.params.raw;
drivers/net/ethernet/intel/i40e/i40e_common.c:	/* The completion specifies the maximum time in ms that the driver
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_del_udp_tunnel_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_del_udp_tunnel_completion *)&desc.params.raw;
drivers/net/ethernet/intel/i40e/i40e_common.c:	struct i40e_aqc_add_remove_control_packet_filter_completion *resp =
drivers/net/ethernet/intel/i40e/i40e_common.c:		(struct i40e_aqc_add_remove_control_packet_filter_completion *)
drivers/net/ethernet/intel/i40e/i40e_main.c: * i40e_control_wait_tx_q - Start/stop Tx queue and wait for completion
drivers/net/ethernet/intel/i40e/i40e_nvm.c: * on ARQ completion event reception by caller.
drivers/net/ethernet/intel/i40e/i40e_txrx.c:	 * completion. In the event of an error adding the buffer to the FDIR
drivers/net/ethernet/intel/i40e/i40e_type.h:	struct i40e_aqc_get_veb_parameters_completion info;
drivers/net/ethernet/intel/iavf/iavf.h:void iavf_virtchnl_completion(struct iavf_adapter *adapter,
drivers/net/ethernet/intel/iavf/iavf_adminq.c:	 * in case of asynchronous completions
drivers/net/ethernet/intel/iavf/iavf_adminq_cmd.h: * - _completion for direct return data
drivers/net/ethernet/intel/iavf/iavf_adminq_cmd.h:struct iavf_aqc_get_veb_parameters_completion {
drivers/net/ethernet/intel/iavf/iavf_adminq_cmd.h:IAVF_CHECK_CMD_LENGTH(iavf_aqc_get_veb_parameters_completion);
drivers/net/ethernet/intel/iavf/iavf_common.c: * completion before returning.
drivers/net/ethernet/intel/iavf/iavf_main.c:		iavf_virtchnl_completion(adapter, v_op, v_ret, event.msg_buf,
drivers/net/ethernet/intel/iavf/iavf_main.c:	 * iavf_virtchnl_completion() after we get confirmation from the PF
drivers/net/ethernet/intel/iavf/iavf_main.c:	 * returning. State change occurs in iavf_virtchnl_completion() after
drivers/net/ethernet/intel/iavf/iavf_virtchnl.c: * iavf_virtchnl_completion
drivers/net/ethernet/intel/iavf/iavf_virtchnl.c: * Asynchronous completion function for admin queue messages. Rather than busy
drivers/net/ethernet/intel/iavf/iavf_virtchnl.c:void iavf_virtchnl_completion(struct iavf_adapter *adapter,
drivers/net/ethernet/intel/ice/ice_adminq_cmd.h:	/* Upon successful completion, FW writes this value and driver is
drivers/net/ethernet/intel/ice/ice_common.c: * NOTE: Upon successful completion of this command, MAC address information
drivers/net/ethernet/intel/ice/ice_common.c: * for its completion and then issues the PF reset
drivers/net/ethernet/intel/ice/ice_common.c:		/* data read comes back in completion, so shorten the struct by
drivers/net/ethernet/intel/ice/ice_common.c:	/* The completion specifies the maximum time in ms that the driver
drivers/net/ethernet/intel/ice/ice_common.c: * Completion queue ID if the queue uses Completion queue, Quanta profile,
drivers/net/ethernet/intel/ice/ice_controlq.c:	 * for completion.
drivers/net/ethernet/intel/ice/ice_controlq.c:	 * called in a separate thread in case of asynchronous completions.
drivers/net/ethernet/intel/ice/ice_dcb_lib.c: * and CHNL need to be brought down. Following completion of DCB configuration
drivers/net/ethernet/intel/ice/ice_fw_update.c: * ice_write_one_nvm_block - Write an NVM block and await completion response
drivers/net/ethernet/intel/ice/ice_fw_update.c: * Write a block of data to a flash module, and await for the completion
drivers/net/ethernet/intel/ice/ice_fw_update.c:	u16 completion_module, completion_retval;
drivers/net/ethernet/intel/ice/ice_fw_update.c:	u32 completion_offset;
drivers/net/ethernet/intel/ice/ice_fw_update.c:	/* In most cases, firmware reports a write completion within a few
drivers/net/ethernet/intel/ice/ice_fw_update.c:	 * milliseconds. However, it has been observed that a completion might
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_module = le16_to_cpu(desc->params.nvm.module_typeid);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_retval = le16_to_cpu(desc->retval);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_offset = le16_to_cpu(desc->params.nvm.offset_low);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_offset |= desc->params.nvm.offset_high << 16;
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_module != module) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:		dev_err(dev, "Unexpected module_typeid in write completion: got 0x%x, expected 0x%x\n",
drivers/net/ethernet/intel/ice/ice_fw_update.c:			completion_module, module);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_offset != offset) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:		dev_err(dev, "Unexpected offset in write completion: got %u, expected %u\n",
drivers/net/ethernet/intel/ice/ice_fw_update.c:			completion_offset, offset);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_retval) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:			ice_aq_str((enum ice_aq_err)completion_retval));
drivers/net/ethernet/intel/ice/ice_fw_update.c: * ice_erase_nvm_module - Erase an NVM module and await firmware completion
drivers/net/ethernet/intel/ice/ice_fw_update.c: * a completion response message from firmware.
drivers/net/ethernet/intel/ice/ice_fw_update.c:	u16 completion_module, completion_retval;
drivers/net/ethernet/intel/ice/ice_fw_update.c:		dev_err(dev, "Timed out waiting for firmware to respond with erase completion for %s (module 0x%02x), err %d\n",
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_module = le16_to_cpu(desc->params.nvm.module_typeid);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_retval = le16_to_cpu(desc->retval);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_module != module) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:		dev_err(dev, "Unexpected module_typeid in erase completion for %s: got 0x%x, expected 0x%x\n",
drivers/net/ethernet/intel/ice/ice_fw_update.c:			component, completion_module, module);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_retval) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:			ice_aq_str((enum ice_aq_err)completion_retval));
drivers/net/ethernet/intel/ice/ice_fw_update.c:	u16 completion_retval;
drivers/net/ethernet/intel/ice/ice_fw_update.c:	completion_retval = le16_to_cpu(task.event.desc.retval);
drivers/net/ethernet/intel/ice/ice_fw_update.c:	if (completion_retval) {
drivers/net/ethernet/intel/ice/ice_fw_update.c:			ice_aq_str((enum ice_aq_err)completion_retval));
drivers/net/ethernet/intel/ice/ice_lib.c:	/* queue index on which FD filter completion is reported */
drivers/net/ethernet/intel/ice/ice_lib.c: * completion of package download, this function will configure default RSS
drivers/net/ethernet/intel/ice/ice_main.c: * Prepares to wait for a specific AdminQ completion event on the ARQ for
drivers/net/ethernet/intel/ice/ice_main.c: * Waits for a specific AdminQ completion event on the ARQ for a given PF. The
drivers/net/ethernet/intel/ice/ice_main.c:	/* Stop watchdog tasks until resume completion.
drivers/net/ethernet/intel/ice/ice_txrx.c:		/* Set the writeback on ITR so partial completions of
drivers/net/ethernet/intel/ice/ice_txrx.h: * enum ice_tx_buf_type - type of &ice_tx_buf to act on Tx completion
drivers/net/ethernet/intel/ice/ice_vf_lib.c:	 * enabled. This is needed for successful completion of VFR.
drivers/net/ethernet/intel/idpf/Kconfig:	  completion and fill queues. Only enable if you have hardware which
drivers/net/ethernet/intel/idpf/idpf.h: * @max_complq: In splitq, maximum number of completion queues supported
drivers/net/ethernet/intel/idpf/idpf.h: * @num_complq: Number of allocated completion queues
drivers/net/ethernet/intel/idpf/idpf.h: * @complq_desc_count: Completion queue descriptor count
drivers/net/ethernet/intel/idpf/idpf.h: * @compln_clean_budget: Work budget for completion clean
drivers/net/ethernet/intel/idpf/idpf.h: * @avail_complq: Available completion queues
drivers/net/ethernet/intel/idpf/idpf_controlq.c: * the completion for that message has been cleaned.
drivers/net/ethernet/intel/idpf/idpf_ethtool.c:	/* Since we adjusted the RX completion queue count, the RX buffer queue
drivers/net/ethernet/intel/idpf/idpf_lan_txrx.h:/* TX Completion Descriptor Completion Types */
drivers/net/ethernet/intel/idpf/idpf_lan_txrx.h:/* Descriptor completion type 1 is reserved */
drivers/net/ethernet/intel/idpf/idpf_lan_txrx.h:/* Descriptor completion type 3 is reserved */
drivers/net/ethernet/intel/idpf/idpf_lan_txrx.h:		__le16 compl_tag; /* Completion tag */
drivers/net/ethernet/intel/idpf/idpf_lan_txrx.h:}; /* writeback used with completion queues */
drivers/net/ethernet/intel/idpf/idpf_singleq_txrx.c: * @rx_q: Rx completion queue
drivers/net/ethernet/intel/idpf/idpf_singleq_txrx.c: * @rx_q: Rx completion queue
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_compl_desc_rel - Free completion resources per queue
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * @complq: completion queue
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * Free all completion software resources.
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	/* Initialize tx buf stack for out-of-order completions if
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_compl_desc_alloc - allocate completion descriptors
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * @complq: completion queue to set up
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	 * completion queues will be same
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		/* Setup completion queues */
drivers/net/ethernet/intel/idpf/idpf_txrx.c:				"Allocation for Tx Completion Queue %u failed\n",
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	 * completion queues. So check if all queues received marker packets
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		/* If we're still waiting on any other TXQ marker completions,
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * out of order completions
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * @compl_tag: completion tag of packet to clean (from completion descriptor)
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	/* Buffer completion */
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * Separate packet completion events will be reported on the completion queue,
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * @compl_tag: completion tag of packet to clean (from completion descriptor)
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * Cleans all buffers associated with the input completion tag either from the
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * this completion tag.
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	 * completion, which means we can stash the buffers starting from
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_tx_handle_rs_completion - clean a single packet and all of its buffers
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * @desc: pointer to completion queue descriptor to extract completion
drivers/net/ethernet/intel/idpf/idpf_txrx.c:static void idpf_tx_handle_rs_completion(struct idpf_tx_queue *txq,
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_tx_clean_complq - Reclaim resources on completion queue
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		u8 ctype;	/* completion type */
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		/* Determine completion type */
drivers/net/ethernet/intel/idpf/idpf_txrx.c:			idpf_tx_handle_rs_completion(tx_q, tx_desc,
drivers/net/ethernet/intel/idpf/idpf_txrx.c:				   "Unknown TX completion type: %d\n", ctype);
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		complq->num_completions++;
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	/* If there are too many outstanding completions expected on the
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	 * completion queue, stop the TX queue to give the device some time to
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	 * the queue to wait for more completions
drivers/net/ethernet/intel/idpf/idpf_txrx.c:			 * completion tag as the current packet. Then when the
drivers/net/ethernet/intel/idpf/idpf_txrx.c:	tx_q->txq_grp->num_completions_pending++;
drivers/net/ethernet/intel/idpf/idpf_txrx.c:		 * stashed during RS completion cleaning. MIN_GAP is set to
drivers/net/ethernet/intel/idpf/idpf_txrx.c:			tx_q->txq_grp->num_completions_pending++;
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_tx_splitq_clean_all- Clean completion queues
drivers/net/ethernet/intel/idpf/idpf_txrx.c: * idpf_rx_splitq_clean_all- Clean completion queues
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * given RX completion queue has descriptors. This includes _ALL_ buffer
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * If you give hardware more buffers than completion descriptors what will
drivers/net/ethernet/intel/idpf/idpf_txrx.h:/* Determine the absolute number of completions pending, i.e. the number of
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * completions that are expected to arrive on the TX completion queue.
drivers/net/ethernet/intel/idpf/idpf_txrx.h:	(((txq)->num_completions_pending >= (txq)->complq->num_completions ? \
drivers/net/ethernet/intel/idpf/idpf_txrx.h:	(txq)->num_completions_pending - (txq)->complq->num_completions)
drivers/net/ethernet/intel/idpf/idpf_txrx.h:/* Adjust the generation for the completion tag and wrap if necessary */
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * struct idpf_buf_lifo - LIFO for managing OOO completions
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @compl_tag: Associated tag for completion
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @__IDPF_Q_SW_MARKER: Used to indicate TX queue marker completions
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @num_complq: number of completion queues
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @complq: array of completion queues
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *	       buffer completions. See struct idpf_buf_lifo
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @compl_tag_gen_s: Completion tag generation bit
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *	The format of the completion tag will change based on the TXQ
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *	completion tag will be formatted as below:
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *	the completion tag will be formatted as below:
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @cleaned_bytes: Splitq only, TXQ only: When a TX completion is received on
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		   the TX completion queue, it can be for any TXQ associated
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		   with that completion queue. This means we can clean up to
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		   N TXQs during a single call to clean the completion queue.
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		   that single call to clean the completion queue. By doing so,
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @compl_tag_bufid_m: Completion tag buffer id mask
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @compl_tag_cur_gen: Used to keep track of current completion tag generation
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * struct idpf_compl_queue - software structure representing a completion queue
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @comp: completion descriptor array
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @num_completions: Only relevant for TX completion queue. It tracks the
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		     number of completions received to compare against the
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *		     number of completions pending, as accumulated by the
drivers/net/ethernet/intel/idpf/idpf_txrx.h:	aligned_u64 num_completions;
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @complq: Associated completion queue pointer, split queue only
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * @num_completions_pending: Total number of completions pending for the
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *			     completion queue, acculumated for all TX queues
drivers/net/ethernet/intel/idpf/idpf_txrx.h: *			     associated with that completion queue.
drivers/net/ethernet/intel/idpf/idpf_txrx.h: * complq. In splitq a single complq is responsible for handling completions
drivers/net/ethernet/intel/idpf/idpf_txrx.h:	aligned_u64 num_completions_pending;
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c: *	       available, uses kernel completion API
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c: *	   completion's lock.
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:	struct completion completed;
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c: * @async: send message asynchronously, will not wait on completion
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c: * We are reusing the completion lock to serialize the accesses to the
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:		init_completion(&xn->completed);
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:		reinit_completion(&xn->completed);
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:	wait_for_completion_timeout(&xn->completed,
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:	 * wait_for_completion_timeout returns. This should be non-issue
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:		qi[k].type = cpu_to_le32(VIRTCHNL2_QUEUE_TYPE_TX_COMPLETION);
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:		qc[k].type = cpu_to_le32(VIRTCHNL2_QUEUE_TYPE_TX_COMPLETION);
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c: * @num_complq: number of transmit completion queues
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:	case VIRTCHNL2_QUEUE_TYPE_TX_COMPLETION:
drivers/net/ethernet/intel/idpf/idpf_virtchnl.c:	q_type = VIRTCHNL2_QUEUE_TYPE_TX_COMPLETION;
drivers/net/ethernet/intel/idpf/virtchnl2.h: * completions to software and by software to post buffers to hardware.
drivers/net/ethernet/intel/idpf/virtchnl2.h: * In the split queue model, hardware uses transmit completion queues to post
drivers/net/ethernet/intel/idpf/virtchnl2.h: * descriptor/buffer completions to software, while software uses transmit
drivers/net/ethernet/intel/idpf/virtchnl2.h: * Likewise, hardware posts descriptor completions to the receive descriptor
drivers/net/ethernet/intel/idpf/virtchnl2.h: *				    completions where descriptors and buffers
drivers/net/ethernet/intel/idpf/virtchnl2.h: * TX_COMPLETION and RX_BUFFER. In split queue model, receive  corresponds to
drivers/net/ethernet/intel/idpf/virtchnl2.h: * the queue where hardware posts completions.
drivers/net/ethernet/intel/idpf/virtchnl2.h:	VIRTCHNL2_QUEUE_TYPE_TX_COMPLETION	= 2,
drivers/net/ethernet/intel/idpf/virtchnl2.h: * @max_tx_complq: Maximum number of supported completion queues.
drivers/net/ethernet/intel/idpf/virtchnl2.h: *		       completion queue.
drivers/net/ethernet/intel/idpf/virtchnl2.h: * @qflags: Applicable only for receive completion queues.
drivers/net/ethernet/intel/idpf/virtchnl2.h: * @num_tx_complq: Number of Tx completion queues.
drivers/net/ethernet/intel/igb/e1000_82575.c:static s32  igb_set_pcie_completion_timeout(struct e1000_hw *hw);
drivers/net/ethernet/intel/igb/e1000_82575.c: *  completion status.  NOTE: silicon which is EEPROM-less will fail trying
drivers/net/ethernet/intel/igb/e1000_82575.c:	/* flush the write to verify completion */
drivers/net/ethernet/intel/igb/e1000_82575.c:		/* flush the write to verify completion */
drivers/net/ethernet/intel/igb/e1000_82575.c:	/* set the completion timeout for interface */
drivers/net/ethernet/intel/igb/e1000_82575.c:	ret_val = igb_set_pcie_completion_timeout(hw);
drivers/net/ethernet/intel/igb/e1000_82575.c:		hw_dbg("PCI-E Set completion timeout has failed.\n");
drivers/net/ethernet/intel/igb/e1000_82575.c: *  igb_set_pcie_completion_timeout - set pci-e completion timeout
drivers/net/ethernet/intel/igb/e1000_82575.c:static s32 igb_set_pcie_completion_timeout(struct e1000_hw *hw)
drivers/net/ethernet/intel/igb/e1000_82575.c:	 * directly in order to set the completion timeout value for
drivers/net/ethernet/intel/igb/e1000_82575.c:	/* disable completion timeout resend */
drivers/net/ethernet/intel/igb/e1000_i210.c: *  completion status.  NOTE: silicon which is EEPROM-less will fail trying
drivers/net/ethernet/intel/igb/e1000_mac.c: *  igb_get_auto_rd_done - Check for auto read completion
drivers/net/ethernet/intel/igb/e1000_mac.c: *  completion.
drivers/net/ethernet/intel/igb/e1000_nvm.c: *  igb_poll_eerd_eewr_done - Poll for EEPROM read/write completion
drivers/net/ethernet/intel/igb/e1000_nvm.c: *  Polls the EEPROM status bit for either read or write completion based
drivers/net/ethernet/intel/igb/e1000_phy.c: *  successful completion, else return corresponding error code.
drivers/net/ethernet/intel/igb/e1000_phy.c: *  igb_wait_autoneg - Wait for auto-neg completion
drivers/net/ethernet/intel/igb/igb_main.c:	/* place incomplete frames back on ring for completion */
drivers/net/ethernet/intel/igbvf/vf.c:		/* notify PF of VF reset completion */
drivers/net/ethernet/intel/igc/igc_defines.h:#define IGC_PHY_RST_COMP	0x0100 /* Internal PHY reset completion */
drivers/net/ethernet/intel/igc/igc_mac.c: * igc_get_auto_rd_done - Check for auto read completion
drivers/net/ethernet/intel/igc/igc_main.c:	/* place incomplete frames back on ring for completion */
drivers/net/ethernet/intel/igc/igc_main.c:		/* Hold the transmit completion until timestamp is ready */
drivers/net/ethernet/intel/igc/igc_main.c:		/* Hold the completions while there's a pending tx hardware
drivers/net/ethernet/intel/igc/igc_nvm.c: * igc_poll_eerd_eewr_done - Poll for EEPROM read/write completion
drivers/net/ethernet/intel/igc/igc_nvm.c: * Polls the EEPROM status bit for either read or write completion based
drivers/net/ethernet/intel/igc/igc_phy.c:	/* SW should guarantee 100us for the completion of the PHY reset */
drivers/net/ethernet/intel/igc/igc_phy.c: * igc_wait_autoneg - Wait for auto-neg completion
drivers/net/ethernet/intel/igc/igc_ptp.c:		/* Release the transmit completion */
drivers/net/ethernet/intel/igc/igc_ptp.c:		/* Trigger txrx interrupt for transmit completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c: *  ixgbe_set_pcie_completion_timeout - set pci-e completion timeout
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c:static void ixgbe_set_pcie_completion_timeout(struct ixgbe_hw *hw)
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c:	 * directly in order to set the completion timeout value for
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c:	/* disable completion timeout resend */
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c: *  Then set pcie completion timeout
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c:	/* set the completion timeout for interface */
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c:	ixgbe_set_pcie_completion_timeout(hw);
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c:	/* write hashes and fdirctrl register, poll for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c:	/* write hashes and fdirctrl register, poll for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c: * ixgbe_pcie_timeout_poll - Return number of times to poll for completion
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c: *  completion timeout, in units of 100 microsec.  Never return less than
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c:	 * remaining completions from the PCIe bus to trickle in, and then reset
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c: *  @timeout: time in ms to wait for command completion
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c:	/* Check command successful completion. */
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c: *  @timeout: time in ms to wait for command completion
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c:	/* wait for a last completion before clearing buffers */
drivers/net/ethernet/intel/ixgbe/ixgbe_common.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	 * run the check_tx_hang logic with a transmit completion
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:		/* place incomplete frames back on ring for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:static unsigned long ixgbe_get_completion_timeout(struct ixgbe_adapter *adapter)
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	 * though completion timeout is not supported and support 32ms.
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	delay_interval = ixgbe_get_completion_timeout(adapter) / 100;
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	delay_interval = ixgbe_get_completion_timeout(adapter) / 100;
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	delay_interval = ixgbe_get_completion_timeout(adapter) / 100;
drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:	delay_interval = ixgbe_get_completion_timeout(adapter) / 100;
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c: *  ixgbe_msca_cmd - Write the command register and poll for completion/timeout
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c: *  Restart autonegotiation and PHY and waits for completion.
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c:	/* Restart PHY autonegotiation and wait for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c: *	Restart autonegotiation and PHY and waits for completion.
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c:	/* Restart PHY autonegotiation and wait for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_phy.c:	/* reset the PHY and poll for completion */
drivers/net/ethernet/intel/ixgbe/ixgbe_x540.c: *  @autoneg_wait_to_complete: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c:	/* Record completion for next time. */
drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c: * ixgbe_iosf_wait - Wait for IOSF command completion
drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c: * @autoneg_wait: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c: * @autoneg_wait: true when waiting for completion is needed
drivers/net/ethernet/intel/ixgbevf/ixgbevf_main.c:	/* place incomplete frames back on ring for completion */
drivers/net/ethernet/marvell/mv643xx_eth.c:		 * which will free the skb on TX completion.
drivers/net/ethernet/marvell/mvmdio.c:	 * but also reflects SMI completion), use that to wait for
drivers/net/ethernet/marvell/mvmdio.c:	 * SMI access completion instead of polling the SMI busy bit.
drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c: * (migration disabled) and from the TX completion tasklet (migration
drivers/net/ethernet/marvell/octeon_ep/octep_main.c:	tx_pending = octep_iq_process_completions(ioq_vector->iq, budget);
drivers/net/ethernet/marvell/octeon_ep/octep_main.c:	/* need more polling if tx completion processing is still pending or
drivers/net/ethernet/marvell/octeon_ep/octep_main.c:	 * from iq_process_completion in other cpus
drivers/net/ethernet/marvell/octeon_ep/octep_main.h:int octep_iq_process_completions(struct octep_iq *iq, u16 budget);
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c: * octep_iq_process_completions() - Process Tx queue completions.
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c: * @budget: max number of completions to be processed in one invocation.
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c:int octep_iq_process_completions(struct octep_iq *iq, u16 budget)
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c: * octep_iq_free_pending() - Free Tx buffers for pending completions.
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c: * Free the buffers in Tx queue descriptors pending completion and
drivers/net/ethernet/marvell/octeon_ep/octep_tx.c:	/* allocate memory to manage Tx packets pending completion */
drivers/net/ethernet/marvell/octeon_ep/octep_tx.h:	/* Info of Tx buffers pending completion. */
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_main.c:	tx_pending = octep_vf_iq_process_completions(ioq_vector->iq, 64);
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_main.c:	/* need more polling if tx completion processing is still pending or
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_main.c:		  * iq_process_completion in other cpus
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_main.h:int octep_vf_iq_process_completions(struct octep_vf_iq *iq, u16 budget);
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c: * octep_vf_iq_process_completions() - Process Tx queue completions.
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c: * @budget: max number of completions to be processed in one invocation.
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c:int octep_vf_iq_process_completions(struct octep_vf_iq *iq, u16 budget)
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c: * octep_vf_iq_free_pending() - Free Tx buffers for pending completions.
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c: * Free the buffers in Tx queue descriptors pending completion and
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.c:	/* allocate memory to manage Tx packets pending completion */
drivers/net/ethernet/marvell/octeon_ep_vf/octep_vf_tx.h:	/* Info of Tx buffers pending completion. */
drivers/net/ethernet/marvell/octeontx2/af/cgx.c:		/* Release thread waiting for completion  */
drivers/net/ethernet/marvell/octeontx2/af/lmac_common.h: * @wq_cmd_cmplt:	waitq to keep the process blocked until cmd completion
drivers/net/ethernet/marvell/octeontx2/af/mbox.h:	u32 cq_cnt;   /* No of completion queues */
drivers/net/ethernet/marvell/octeontx2/af/rvu.h:	/* HW requires read back of RVU_AF_BAR2_SEL register to make sure completion of
drivers/net/ethernet/marvell/octeontx2/af/rvu_cn10k.c:	 * early completion for ordered LMTST.
drivers/net/ethernet/marvell/octeontx2/af/rvu_cn10k.c:		/* Disable early completion for Ordered LMTSTs. */
drivers/net/ethernet/marvell/octeontx2/af/rvu_struct.h:/* NPA admin queue completion enumeration */
drivers/net/ethernet/marvell/octeontx2/af/rvu_struct.h:/* NIX admin queue completion status */
drivers/net/ethernet/marvell/octeontx2/af/rvu_struct.h:/* NIX Completion queue context structure */
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	/* Initialize completion queues */
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:			   "Completion event size must be 128 or 512");
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	 * Completion interrupts behave in a level-triggered interrupt
drivers/net/ethernet/marvell/sky2.c: *  1. The hardware will tell us about partial completion of multi-part
drivers/net/ethernet/mediatek/mtk_star_emac.c:/* Wait for the completion of any previous command - CMD_START bit must be
drivers/net/ethernet/mellanox/mlx4/catas.c:	mlx4_cmd_wake_completions(dev);
drivers/net/ethernet/mellanox/mlx4/cmd.c:	struct completion	done;
drivers/net/ethernet/mellanox/mlx4/cmd.c:	reinit_completion(&context->done);
drivers/net/ethernet/mellanox/mlx4/cmd.c:	if (!wait_for_completion_timeout(&context->done,
drivers/net/ethernet/mellanox/mlx4/cmd.c:	reinit_completion(&context->done);
drivers/net/ethernet/mellanox/mlx4/cmd.c:			wait_for_completion_interruptible_timeout(&context->done,
drivers/net/ethernet/mellanox/mlx4/cmd.c:		ret_wait = (long)wait_for_completion_timeout(&context->done,
drivers/net/ethernet/mellanox/mlx4/cmd.c:				mlx4_warn(dev, "Failed to generate command completion eqe for slave %d\n",
drivers/net/ethernet/mellanox/mlx4/cmd.c:		 * cmd contexts to allow simulating completions
drivers/net/ethernet/mellanox/mlx4/cmd.c:		init_completion(&priv->cmd.context[i].done);
drivers/net/ethernet/mellanox/mlx4/cmd.c:void mlx4_cmd_wake_completions(struct mlx4_dev *dev)
drivers/net/ethernet/mellanox/mlx4/cq.c:	 * while migrating a CQ, completions on the old EQs could
drivers/net/ethernet/mellanox/mlx4/cq.c:void mlx4_cq_completion(struct mlx4_dev *dev, u32 cqn)
drivers/net/ethernet/mellanox/mlx4/cq.c:		mlx4_dbg(dev, "Completion event for bogus CQ %08x\n", cqn);
drivers/net/ethernet/mellanox/mlx4/cq.c:	init_completion(&cq->free);
drivers/net/ethernet/mellanox/mlx4/cq.c:	wait_for_completion(&cq->free);
drivers/net/ethernet/mellanox/mlx4/en_netdev.c:				/* Arm CQ for TX completions */
drivers/net/ethernet/mellanox/mlx4/en_netdev.c:	/* Process all completions if exist to prevent
drivers/net/ethernet/mellanox/mlx4/en_selftest.c:	/* A loop over all completion vectors of current port,
drivers/net/ethernet/mellanox/mlx4/en_selftest.c:	 * completions to that vector and performing a NOP command
drivers/net/ethernet/mellanox/mlx4/en_tx.c:	/* tx completion can avoid cache line miss for common cases */
drivers/net/ethernet/mellanox/mlx4/en_tx.c:	/* tx completion can avoid cache line miss for common cases */
drivers/net/ethernet/mellanox/mlx4/eq.c:			mlx4_cq_completion(dev, cqn);
drivers/net/ethernet/mellanox/mlx4/eq.c:	/* Temporary use polling for command completions */
drivers/net/ethernet/mellanox/mlx4/main.c:		mlx4_err(dev, "Failed to initialize completion queue table, aborting\n");
drivers/net/ethernet/mellanox/mlx4/mlx4.h:	/* lock on completion tasklet list */
drivers/net/ethernet/mellanox/mlx4/mlx4.h:void mlx4_cq_completion(struct mlx4_dev *dev, u32 cqn);
drivers/net/ethernet/mellanox/mlx4/mlx4_en.h:	/* cache line used and dirtied in tx completion
drivers/net/ethernet/mellanox/mlx4/qp.c:	init_completion(&qp->free);
drivers/net/ethernet/mellanox/mlx4/qp.c:	wait_for_completion(&qp->free);
drivers/net/ethernet/mellanox/mlx4/srq.c:	init_completion(&srq->free);
drivers/net/ethernet/mellanox/mlx4/srq.c:	wait_for_completion(&srq->free);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	/* aborted due to PCI error or via reset flow mlx5_cmd_trigger_completions() */
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	cmd_ent_get(ent); /* for the _real_ FW event on completion */
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	if (wait_for_completion_timeout(&ent->done, timeout)) {
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	mlx5_core_warn(dev, "cmd[%d]: %s(0x%x) No done completion\n", ent->idx,
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	if (!wait_for_completion_timeout(&ent->handling, timeout) &&
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	wait_for_completion(&ent->slotted);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:		wait_for_completion(&ent->done);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	else if (!wait_for_completion_timeout(&ent->done, timeout))
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: *    2. page queue commands do not support asynchrous completion
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	init_completion(&ent->handling);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	init_completion(&ent->slotted);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:		init_completion(&ent->done);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:				/* only real completion can free the cmd slot */
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:					mlx5_core_err(dev, "Command completion arrived after timeout (entry idx = %d).\n",
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:			if (!forced || /* Real FW completion */
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:			     mlx5_cmd_is_down(dev) || /* No real FW completion is expected */
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:static void mlx5_cmd_trigger_completions(struct mlx5_core_dev *dev)
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	/* we must increment the allocated entries refcount before triggering the completions
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:			mlx5_cmd_trigger_completions(dev);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:		mlx5_cmd_trigger_completions(dev);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: *    2. Page queue commands do not support asynchrous completion
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: * mlx5_cmd_do - Executes a fw command, wait for completion.
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: * mlx5_cmd_exec - Executes a fw command, wait for completion
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: * mlx5_cmd_exec_polling - Executes a fw command, poll for completion
drivers/net/ethernet/mellanox/mlx5/core/cmd.c: *	Needed for driver force teardown, when command completion EQ
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:	init_completion(&ctx->inflight_done);
drivers/net/ethernet/mellanox/mlx5/core/cmd.c:		wait_for_completion(&ctx->inflight_done);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	 * while migrating a CQ, completions on the old EQs could
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	init_completion(&cq->free);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	wait_for_completion(&cq->free);
drivers/net/ethernet/mellanox/mlx5/core/en.h:	/* dirtied @completion */
drivers/net/ethernet/mellanox/mlx5/core/en.h:	/* dirtied @completion */
drivers/net/ethernet/mellanox/mlx5/core/en.h:	/* write@xmit, read@completion */
drivers/net/ethernet/mellanox/mlx5/core/en/mod_hdr.c:	struct completion res_ready;
drivers/net/ethernet/mellanox/mlx5/core/en/mod_hdr.c:		wait_for_completion(&mh->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/mod_hdr.c:	init_completion(&mh->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h:	struct completion init_done;
drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h:	struct completion del_hw_done;
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:		wait_for_completion(&flow->del_hw_done);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:	wait_for_completion(&flow->init_done);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:	wait_for_completion(&next->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:	/* continue searching if encap entry is not in valid state after completion */
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:	init_completion(&e->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:		wait_for_completion(&d->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c:	init_completion(&d->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h:void mlx5e_completion_event(struct mlx5_core_cq *mcq, struct mlx5_eqe *eqe);
drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c:		 * unmapped and returned via xdp_return_frame on completion.
drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h:/* XDP packets can be transmitted in different ways. On completion, we need to
drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h:	 * page. The UMEM Completion Ring producer pointer has to be increased.
drivers/net/ethernet/mellanox/mlx5/core/en/xsk/tx.c:/* When TX fails (because of the size of the packet), we need to get completions
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec.c:	init_completion(&ipsec->comp);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec.h:	struct completion comp;
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_fs.c:	reinit_completion(&master_priv->ipsec->comp);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_fs.c:	wait_for_completion(&priv->ipsec->comp);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:	struct completion add_ctx;
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:void mlx5e_ktls_handle_get_psv_completion(struct mlx5e_icosq_wqe_info *wi,
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:void mlx5e_ktls_handle_ctx_completion(struct mlx5e_icosq_wqe_info *wi)
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:	init_completion(&priv_rx->add_ctx);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:		/* completion is needed, as the priv_rx in the add flow
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:		wait_for_completion(&priv_rx->add_ctx);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_rx.c:		 * it will be triggered by the outstanding ICOSQ completions.
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_tx.c:		 * released only upon their completions (or in mlx5e_free_txqsq_descs,
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_txrx.h:void mlx5e_ktls_handle_ctx_completion(struct mlx5e_icosq_wqe_info *wi);
drivers/net/ethernet/mellanox/mlx5/core/en_accel/ktls_txrx.h:void mlx5e_ktls_handle_get_psv_completion(struct mlx5e_icosq_wqe_info *wi,
drivers/net/ethernet/mellanox/mlx5/core/en_main.c:	 * popped from the list after completion but were not freed
drivers/net/ethernet/mellanox/mlx5/core/en_main.c:	mcq->comp       = mlx5e_completion_event;
drivers/net/ethernet/mellanox/mlx5/core/en_rep.h:	struct completion res_ready;
drivers/net/ethernet/mellanox/mlx5/core/en_rep.h:	struct completion res_ready;
drivers/net/ethernet/mellanox/mlx5/core/en_rx.c:			mlx5e_ktls_handle_ctx_completion(wi);
drivers/net/ethernet/mellanox/mlx5/core/en_rx.c:			mlx5e_ktls_handle_get_psv_completion(wi, sq);
drivers/net/ethernet/mellanox/mlx5/core/en_rx.c:				mlx5e_ktls_handle_ctx_completion(wi);
drivers/net/ethernet/mellanox/mlx5/core/en_rx.c:				mlx5e_ktls_handle_get_psv_completion(wi, sq);
drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c:	struct completion comp;
drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c:	init_completion(&lbtp->comp);
drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c:	wait_for_completion_timeout(&lbtp->comp, MLX5E_LB_VERIFY_TIMEOUT);
drivers/net/ethernet/mellanox/mlx5/core/en_stats.h:	/* dirtied @completion */
drivers/net/ethernet/mellanox/mlx5/core/en_stats.h:	/* dirtied @completion */
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:#include <linux/completion.h>
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:	struct completion res_ready;
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:		wait_for_completion(&hpe->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:	init_completion(&hpe->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:	init_completion(&flow->init_done);
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:	init_completion(&flow->del_hw_done);
drivers/net/ethernet/mellanox/mlx5/core/en_tc.c:		wait_for_completion(&hpe->res_ready);
drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c:	/* If SQ is empty, there are no TX completions to trigger NAPI, so set
drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c:void mlx5e_completion_event(struct mlx5_core_cq *mcq, struct mlx5_eqe *eqe)
drivers/net/ethernet/mellanox/mlx5/core/eq.c:					    "Completion event for bogus CQ 0x%x\n", cqn);
drivers/net/ethernet/mellanox/mlx5/core/eq.c:	mlx5_core_dbg(dev, "allocated completion EQN %d\n", eq->core.eqn);
drivers/net/ethernet/mellanox/mlx5/core/eq.c:	/* If ethernet is disabled we use just a single completion vector to
drivers/net/ethernet/mellanox/mlx5/core/fpga/conn.c:		mlx5_fpga_warn(conn->fdev, "RQ buf %p on FPGA QP %u completion status %d\n",
drivers/net/ethernet/mellanox/mlx5/core/fpga/conn.c:		mlx5_fpga_dbg(conn->fdev, "RQ buf %p on FPGA QP %u completion status %d\n",
drivers/net/ethernet/mellanox/mlx5/core/fpga/conn.c:		mlx5_fpga_warn(conn->fdev, "SQ buf %p on FPGA QP %u completion status %d\n",
drivers/net/ethernet/mellanox/mlx5/core/fpga/conn.c:		mlx5_fpga_dbg(conn->fdev, "SQ buf %p on FPGA QP %u completion status %d\n",
drivers/net/ethernet/mellanox/mlx5/core/fpga/sdk.h:	 * @complete: Completion routine, for TX packets
drivers/net/ethernet/mellanox/mlx5/core/fpga/sdk.h: * The buffer should not be modified or freed until completion.
drivers/net/ethernet/mellanox/mlx5/core/fpga/sdk.h: * Upon completion, the buf's complete() callback is invoked, indicating the
drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c:	struct completion done;
drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c:	if (!wait_for_completion_timeout(&fw_reset->done, timeout)) {
drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c:	init_completion(&fw_reset->done);
drivers/net/ethernet/mellanox/mlx5/core/lag/mpesw.c:	init_completion(&work->comp);
drivers/net/ethernet/mellanox/mlx5/core/lag/mpesw.c:	wait_for_completion(&work->comp);
drivers/net/ethernet/mellanox/mlx5/core/lag/mpesw.h:	struct completion  comp;
drivers/net/ethernet/mellanox/mlx5/core/lib/eq.h:	spinlock_t            lock; /* lock completion tasklet list */
drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c: * @rmap: pointer to reverse map pointer for completion interrupts
drivers/net/ethernet/mellanox/mlx5/core/pci_irq.c: * @rmap: pointer to reverse map pointer for completion interrupts
drivers/net/ethernet/mellanox/mlx5/core/steering/dr_send.c:	pr_err("CQ completion CQ: #%u\n", mcq->cqn);
drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h:	/* How much wqes are waiting for completion */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws.h:	/* Start executing all pending queued rules wait till completion */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws.h: * mlx5hws_send_queue_poll - Poll queue for rule creation and deletions completions.
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws.h: * @res: Completion array.
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws.h: * Return: negative number on failure, the number of completions otherwise.
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws.h: *   - polls till completion is received
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_action.c:	/* Poll for completion */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	/* Check if there are any completions at all */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:						    "BWC poll error: polling queue %d returned completion with error\n",
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	struct mlx5hws_flow_op_result completion;
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:		ret = mlx5hws_send_queue_poll(ctx, rule_attr->queue_id, &completion, 1);
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	if (unlikely(completion.status != MLX5HWS_FLOW_OP_SUCCESS ||
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:		mlx5hws_err(ctx, "Failed destroying BWC rule: completion %d, rule status %d\n",
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:			    completion.status, bwc_rule->rule->status);
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	u32 expected_completions = 1;
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	ret = hws_bwc_queue_poll(ctx, rule_attr->queue_id, &expected_completions, true);
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	u32 expected_completions = 1;
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	ret = hws_bwc_queue_poll(ctx, rule_attr->queue_id, &expected_completions, true);
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_bwc.c:	 * the status of completion is RTE_FLOW_OP_ERROR.
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_pat_arg.c:	/* Poll for completion */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_rule.c:		 * Generate completion as if write succeeded, and we can
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_send.c:	/* Update rule status for the last completion */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_send.c:			/* Completion is provided on the last rule WQE */
drivers/net/ethernet/mellanox/mlx5/core/steering/hws/mlx5hws_send.c:	pr_err("CQ completion CQ: #%u\n", mcq->cqn);
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige.h:/* Rx Completion Queue Element definitions */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige.h:/* Tx Completion Count */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_main.c:	/* Ensure completion of "clean port" write before polling status */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_main.c:	/* Ensure completion of all initialization before enabling interrupts */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_rx.c:	/* Ensure completion of all writes before notifying HW of replenish */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c: * 2) Allocates TX completion counter using coherent DMA mapping
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c:	/* Allocate address for TX completion count */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c: * namely the TX WQE array and the TX completion counter
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c:	/* Transmit completion logic needs to loop until the completion
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c:	 * to 0 while TX completion index is still < 0xFFFF.
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c:		/* Ensure completion of updates across all cores */
drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_tx.c:		 * which processes TX completions, and will hopefully drain
drivers/net/ethernet/mellanox/mlxsw/cmd.h: * following an unsuccessful completion of the command. It is required
drivers/net/ethernet/mellanox/mlxsw/cmd.h: * CQE ver 1 or 2 is configured by Completion Queue Context field cqe_ver.
drivers/net/ethernet/mellanox/mlxsw/cmd.h: * Number of the CQ that this Descriptor Queue reports completions to.
drivers/net/ethernet/mellanox/mlxsw/cmd.h: * a completion with error (flushed) for all descriptors posted in the RDQ/SDQ.
drivers/net/ethernet/mellanox/mlxsw/cmd.h: * Event Queue this CQ reports completion events to.
drivers/net/ethernet/mellanox/mlxsw/core.c:#include <linux/completion.h>
drivers/net/ethernet/mellanox/mlxsw/core.c:	struct completion completion;
drivers/net/ethernet/mellanox/mlxsw/core.c:	complete(&trans->completion);
drivers/net/ethernet/mellanox/mlxsw/core.c:	init_completion(&trans->completion);
drivers/net/ethernet/mellanox/mlxsw/core.c:	wait_for_completion(&trans->completion);
drivers/net/ethernet/mellanox/mlxsw/i2c.c:	/* Validate transaction completion status. */
drivers/net/ethernet/mellanox/mlxsw/i2c.c:		dev_err(&client->dev, "Bad transaction completion status %x\n",
drivers/net/ethernet/mellanox/mlxsw/i2c.c:	/* Validate transaction completion status. */
drivers/net/ethernet/mellanox/mlxsw/i2c.c:		dev_err(&client->dev, "Bad transaction completion status %x\n",
drivers/net/ethernet/mellanox/mlxsw/i2c.c:	/* Validate transaction completion status. */
drivers/net/ethernet/mellanox/mlxsw/i2c.c:		dev_err(&client->dev, "Bad transaction completion status %x\n",
drivers/net/ethernet/mellanox/mlxsw/pci.c:	/* The driver processed all the completions and handled exactly
drivers/net/ethernet/mellanox/mlxsw/pci.c:	 * driver still has completions to handle.
drivers/net/ethernet/mellanox/mlxsw/pci.c:		dev_err(&pdev->dev, "Failed to initialize completion queues\n");
drivers/net/ethernet/mellanox/mlxsw/pci.c:	mlxsw_pci_wqe_c_set(wqe, 1); /* always report completion */
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * If set it indicates that a completion should be reported upon
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * Completion Queue that triggered this EQE.
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * Command completion event - token
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * Command completion event - status
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * Command completion event - output parameter - higher part
drivers/net/ethernet/mellanox/mlxsw/pci_hw.h: * Command completion event - output parameter - lower part
drivers/net/ethernet/mellanox/mlxsw/reg.h: * Indicates the successful completion of the instruction, or the reason it
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:#define FBNIC_TWD_FLAG_REQ_COMPLETION		DESC_BIT(37)
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* MSS and Completion Req */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Tx Completion Descriptor Format */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Rx Completion Queue Descriptors */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Address/Length Completion Descriptors */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Optional Metadata Completion Descriptors */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Metadata Completion Descriptors */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Tx Completion Queue Registers */
drivers/net/ethernet/meta/fbnic/fbnic_csr.h:/* Rx Completion Queue Registers */
drivers/net/ethernet/meta/fbnic/fbnic_fw.c: * response will need to be caught via a completion if this action is
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:	/* TBD: Request completion more often if xmit_more becomes large */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:		*meta |= cpu_to_le64(FBNIC_TWD_FLAG_REQ_COMPLETION);
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:	/* Walk the completion queue collecting the heads reported by NIC */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:	/* Walk the completion queue collecting the heads reported by NIC */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:		/* Configure Tx completion queue */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:		/* Configure Rx completion queue */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:			/* Reset completion queue descriptor ring */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:			/* Reset completion queue descriptor ring */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:	/* Store interrupt information for the completion queue */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:	/* Store interrupt information for the completion queue */
drivers/net/ethernet/meta/fbnic/fbnic_txrx.c:			 * and therefore generate a completion and an IRQ.
drivers/net/ethernet/micrel/ks8851_par.c: * @irq: IRQ on completion of the packet.
drivers/net/ethernet/micrel/ks8851_par.c: * needs, such as IRQ on completion. Send the header and the packet data to
drivers/net/ethernet/micrel/ks8851_par.c:		fid |= TXFR_TXIC;	/* irq on completion */
drivers/net/ethernet/micrel/ks8851_spi.c: * @irq: IRQ on completion of the packet.
drivers/net/ethernet/micrel/ks8851_spi.c: * needs, such as IRQ on completion. Send the header and the packet data to
drivers/net/ethernet/micrel/ks8851_spi.c:		fid |= TXFR_TXIC;	/* irq on completion */
drivers/net/ethernet/microchip/lan743x_ethtool.c:				   "Timeout on OTP_STATUS completion\n");
drivers/net/ethernet/microchip/lan743x_main.h:#define GPIO_TX_COMPLETION		(2)
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:static int lan966x_mac_wait_for_completion(struct lan966x *lan966x)
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:	return lan966x_mac_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:	return lan966x_mac_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:	lan966x_mac_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:	ret = lan966x_mac_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/lan966x/lan966x_mac.c:		lan966x_mac_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/lan966x/lan966x_vlan.c:static int lan966x_vlan_wait_for_completion(struct lan966x *lan966x)
drivers/net/ethernet/microchip/lan966x/lan966x_vlan.c:	if (lan966x_vlan_wait_for_completion(lan966x))
drivers/net/ethernet/microchip/lan966x/lan966x_vlan.c:	lan966x_vlan_wait_for_completion(lan966x);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:static int sparx5_mact_wait_for_completion(struct sparx5 *sparx5)
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:	ret = sparx5_mact_wait_for_completion(sparx5);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:	ret = sparx5_mact_wait_for_completion(sparx5);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:	ret = sparx5_mact_wait_for_completion(sparx5);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:	ret = sparx5_mact_wait_for_completion(sparx5);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:		ret = sparx5_mact_wait_for_completion(sparx5);
drivers/net/ethernet/microchip/sparx5/sparx5_mactable.c:	if (sparx5_mact_wait_for_completion(sparx5) != 0)
drivers/net/ethernet/microchip/sparx5/sparx5_psfp.c:static int sparx5_psfp_sgid_wait_for_completion(struct sparx5 *sparx5)
drivers/net/ethernet/microchip/sparx5/sparx5_psfp.c:	if (sparx5_psfp_sgid_wait_for_completion(sparx5) < 0)
drivers/net/ethernet/microchip/sparx5/sparx5_psfp.c:		pr_debug("%s:%d timed out waiting for sgid completion",
drivers/net/ethernet/microchip/sparx5/sparx5_vcap_impl.c:/* Await the super VCAP completion of the current operation */
drivers/net/ethernet/microchip/sparx5/sparx5_vcap_impl.c:/* Await the ES0 VCAP completion of the current operation */
drivers/net/ethernet/microchip/sparx5/sparx5_vcap_impl.c:/* Await the ES2 VCAP completion of the current operation */
drivers/net/ethernet/microsoft/mana/gdma_main.c:	case GDMA_EQE_COMPLETION:
drivers/net/ethernet/microsoft/mana/gdma_main.c:	init_completion(&gc->eq_test_event);
drivers/net/ethernet/microsoft/mana/gdma_main.c:	if (!wait_for_completion_timeout(&gc->eq_test_event, 30 * HZ)) {
drivers/net/ethernet/microsoft/mana/gdma_main.c:	 * reading completion info
drivers/net/ethernet/microsoft/mana/hw_channel.c:	struct gdma_comp *completions;
drivers/net/ethernet/microsoft/mana/hw_channel.c:	completions = hwc_cq->comp_buf;
drivers/net/ethernet/microsoft/mana/hw_channel.c:	comp_read = mana_gd_poll_cq(q_self, completions, hwc_cq->queue_depth);
drivers/net/ethernet/microsoft/mana/hw_channel.c:		comp_data = *(struct hwc_rx_oob *)completions[i].cqe_data;
drivers/net/ethernet/microsoft/mana/hw_channel.c:		if (completions[i].is_sq)
drivers/net/ethernet/microsoft/mana/hw_channel.c:						completions[i].wq_num,
drivers/net/ethernet/microsoft/mana/hw_channel.c:						completions[i].wq_num,
drivers/net/ethernet/microsoft/mana/hw_channel.c:		init_completion(&ctx[i].comp_event);
drivers/net/ethernet/microsoft/mana/hw_channel.c:	init_completion(&hwc->hwc_init_eqe_comp);
drivers/net/ethernet/microsoft/mana/hw_channel.c:	if (!wait_for_completion_timeout(&hwc->hwc_init_eqe_comp, 60 * HZ))
drivers/net/ethernet/microsoft/mana/hw_channel.c:	if (!wait_for_completion_timeout(&ctx->comp_event,
drivers/net/ethernet/microsoft/mana/mana_en.c:	init_completion(&rxq->fence_event);
drivers/net/ethernet/microsoft/mana/mana_en.c:	if (wait_for_completion_timeout(&rxq->fence_event, 10 * HZ) == 0) {
drivers/net/ethernet/microsoft/mana/mana_en.c:	struct gdma_comp *completions = cq->gdma_comp_buf;
drivers/net/ethernet/microsoft/mana/mana_en.c:	comp_read = mana_gd_poll_cq(cq->gdma_cq, completions,
drivers/net/ethernet/microsoft/mana/mana_en.c:		if (WARN_ON_ONCE(!completions[i].is_sq))
drivers/net/ethernet/microsoft/mana/mana_en.c:		cqe_oob = (struct mana_tx_comp_oob *)completions[i].cqe_data;
drivers/net/ethernet/microsoft/mana/mana_en.c:				 MANA_CQE_COMPLETION))
drivers/net/ethernet/microsoft/mana/mana_en.c:		if (WARN_ON_ONCE(txq->gdma_txq_id != completions[i].wq_num))
drivers/net/ethernet/mscc/ocelot.c:static inline int ocelot_mact_wait_for_completion(struct ocelot *ocelot)
drivers/net/ethernet/mscc/ocelot.c:	err = ocelot_mact_wait_for_completion(ocelot);
drivers/net/ethernet/mscc/ocelot.c:	err = ocelot_mact_wait_for_completion(ocelot);
drivers/net/ethernet/mscc/ocelot.c:	if (ocelot_mact_wait_for_completion(ocelot)) {
drivers/net/ethernet/mscc/ocelot.c:static inline int ocelot_vlant_wait_for_completion(struct ocelot *ocelot)
drivers/net/ethernet/mscc/ocelot.c:	return ocelot_vlant_wait_for_completion(ocelot);
drivers/net/ethernet/mscc/ocelot.c:	ocelot_vlant_wait_for_completion(ocelot);
drivers/net/ethernet/mscc/ocelot.c:	if (ocelot_mact_wait_for_completion(ocelot))
drivers/net/ethernet/mscc/ocelot.c:	err = ocelot_mact_wait_for_completion(ocelot);
drivers/net/ethernet/mscc/ocelot.c:	err = ocelot_mact_wait_for_completion(ocelot);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:		 "Force firmware to assume aligned completions");
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:		 * and try to get the completion quickly
drivers/net/ethernet/myricom/myri10ge/myri10ge.c: * Enable ECRC to align PCI-E Completion packets on an 8-byte boundary.
drivers/net/ethernet/myricom/myri10ge/myri10ge.c: * when the PCI-E Completion packets are aligned on an 8-byte
drivers/net/ethernet/myricom/myri10ge/myri10ge.c: * boundary.  Some PCI-E chip sets always align Completion packets; on
drivers/net/ethernet/myricom/myri10ge/myri10ge.c: * When PCI-E Completion packets are not aligned, it is actually more
drivers/net/ethernet/myricom/myri10ge/myri10ge.c: * around unaligned completion packets (myri10ge_rss_ethp_z8e.dat), and it
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:	 * completions) in order to see if it works on this host.
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:	 * Run a DMA test which watches for unaligned completions and
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:		 * completions */
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:				 "Assuming aligned completions (forced)\n");
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:				 "Assuming unaligned completions (forced)\n");
drivers/net/ethernet/natsemi/natsemi.c:	 * and Auto-Negotiation Completion are among the affected.
drivers/net/ethernet/netronome/nfp/ccm_mbox.c: * Completions and next-to-run are signaled via the control buffer
drivers/net/ethernet/netronome/nfp/nfd3/dp.c: * someone else may be cleaning the TX ring completions so we need to be
drivers/net/ethernet/netronome/nfp/nfd3/dp.c:	/* We can race with the TX completion out of NAPI so recheck */
drivers/net/ethernet/netronome/nfp/nfdk/dp.c:	/* We can race with the TX completion out of NAPI so recheck */
drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c:	 *      (usecs > 0 && time_since_first_completion >= usecs) ||
drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c:	 * condition time_since_first_completion >= usecs
drivers/net/ethernet/netronome/nfp/nfpcore/nfp_cppcore.c: * nfp_cpp_explicit_set_posted() - Set completion fields for explicit
drivers/net/ethernet/netronome/nfp/nfpcore/nfp_cppcore.c: * @posted:	True for signaled completion, false otherwise
drivers/net/ethernet/netronome/nfp/nfpcore/nfp_nsp.c: * @timeout_sec:Timeout value to wait for completion in seconds
drivers/net/ethernet/netronome/nfp/nfpcore/nfp_nsp.c: *	 positive value for NSP completion with a result code
drivers/net/ethernet/netronome/nfp/nfpcore/nfp_nsp.c: *	-EINTR if interrupted while waiting for completion
drivers/net/ethernet/ni/nixge.c:#define XAXIDMA_IRQ_IOC_MASK		0x00001000 /* Completion intr */
drivers/net/ethernet/nxp/lpc_eth.c:	/* Wait for completion */
drivers/net/ethernet/oa_tc6.c:	 * complete status. IRQ is also asserted on reset completion and it is
drivers/net/ethernet/oki-semi/pch_gbe/pch_gbe.h:#define PCH_GBE_INT_MIIM_CMPLT    0x00010000 /* MIIM I/F Read completion */
drivers/net/ethernet/pensando/ionic/ionic.h:	struct completion work;
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_admin_comp - General admin command completion format
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_nop_comp - NOP command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_dev_init_comp - Device init command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_dev_reset_comp - Reset command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_dev_identify_comp - Driver/device identify command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_lif_identify_comp - LIF identify command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @IONIC_QIDENT_F_CQ:      Queue has completion ring
drivers/net/ethernet/pensando/ionic/ionic_if.h: *	@rdma.cq_qtype:        RDMA Completion Qtype
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_lif_init_comp - LIF init command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_q_identify_comp - queue identify command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: *     @comp_sz:        Completion descriptor size
drivers/net/ethernet/pensando/ionic/ionic_if.h: *    IRQ:        Interrupt requested on completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @cq_ring_base: Completion queue ring base address
drivers/net/ethernet/pensando/ionic/ionic_if.h:#define IONIC_QINIT_F_IRQ	0x01	/* Request interrupt on completion */
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_q_init_comp - Queue init command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_txq_comp - Ethernet transmit queue completion descriptor
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: *                      are recorded in Rx completion descriptor.
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_rxq_comp - Ethernet receive queue completion descriptor
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index:   Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_port_identify_comp - Port identify command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_port_init_comp - Port initialization command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_port_reset_comp - Port reset command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_port_setattr_comp - Port set attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_port_getattr_comp - Port get attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_dev_setattr_comp - Device set attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_dev_getattr_comp - Device set attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_lif_setattr_comp - LIF set attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_lif_getattr_comp - LIF get attr command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_rx_filter_add_comp - Add LIF Rx filter command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_vf_ctrl_comp - VF_CTRL command completion.
drivers/net/ethernet/pensando/ionic/ionic_if.h: * struct ionic_qos_identify_comp - QoS identify command completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * @comp_index: Index in the descriptor ring for which this is the completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * There is no RDMA specific dev command completion struct.  Completion uses
drivers/net/ethernet/pensando/ionic/ionic_if.h: * The same command struct is used to create an RDMA event queue, completion
drivers/net/ethernet/pensando/ionic/ionic_if.h: * queue, an event queue id for a completion queue, or a completion queue id
drivers/net/ethernet/pensando/ionic/ionic_if.h: * There is no RDMA specific dev command completion struct.  Completion uses
drivers/net/ethernet/pensando/ionic/ionic_if.h: *                   poll done for completion.
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		netdev_err(lif->netdev, "Cannot initialize completion queue\n");
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:			.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_lif.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_main.c:	/* Have we run out of new completions to process? */
drivers/net/ethernet/pensando/ionic/ionic_main.c:		remaining = wait_for_completion_timeout(&ctx->work,
drivers/net/ethernet/pensando/ionic/ionic_phc.c:	ctx->work = COMPLETION_INITIALIZER_ONSTACK(ctx->work);
drivers/net/ethernet/pensando/ionic/ionic_rx_filter.c:			ctx.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work);
drivers/net/ethernet/pensando/ionic/ionic_rx_filter.c:			.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_rx_filter.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_rx_filter.c:		.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),
drivers/net/ethernet/pensando/ionic/ionic_txrx.c:	/* clean the related q entry, only one per qc completion */
drivers/net/ethernet/pensando/ionic/ionic_txrx.c:	 * several q entries completed for each cq completion
drivers/net/ethernet/qlogic/netxen/netxen_nic.h: *	47:40 - completion id
drivers/net/ethernet/qlogic/qed/qed.h:	dma_addr_t	completion_word_phys_addr;
drivers/net/ethernet/qlogic/qed/qed.h:	/* The memory location where the DMAE writes the completion
drivers/net/ethernet/qlogic/qed/qed.h:	u32		*p_completion_word;
drivers/net/ethernet/qlogic/qed/qed_debug.c:		SET_FIELD(dmae_params.flags, QED_DMAE_PARAMS_COMPLETION_DST, 1);
drivers/net/ethernet/qlogic/qed/qed_dev.c:	/* Poll until completion */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:#define QED_DMAE_PARAMS_COMPLETION_DST_MASK	0x1
drivers/net/ethernet/qlogic/qed/qed_hsi.h:#define QED_DMAE_PARAMS_COMPLETION_DST_SHIFT	3
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* Completion params for aggregated interrupt completion */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:	u8 completion_opcode;
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* TOE RX completion queue opcodes (opcode 0 is illegal) */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* TOE rx ooo completion data */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* TOE rx in order completion data */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* Union for TOE rx completion data */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* TOE rx completion element */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:	u8 completion_opcode;
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* TOE completion opcodes */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* Toe transmission completion element */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* Toe transmission completion element page pointer */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* iWARP completion queue types */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:struct iwarp_eqe_data_mpa_async_completion {
drivers/net/ethernet/qlogic/qed/qed_hsi.h:struct iwarp_eqe_data_tcp_async_completion {
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* iWARP completion queue types */
drivers/net/ethernet/qlogic/qed/qed_hsi.h:/* iWARP EQE completion status */
drivers/net/ethernet/qlogic/qed/qed_hw.c:	/* Whether to write a completion word to the completion destination:
drivers/net/ethernet/qlogic/qed/qed_hw.c:	 * 0-Do not write a completion word
drivers/net/ethernet/qlogic/qed/qed_hw.c:	 * 1-Write the completion word
drivers/net/ethernet/qlogic/qed/qed_hw.c:	if (QED_DMAE_FLAGS_IS_SET(p_params, COMPLETION_DST))
drivers/net/ethernet/qlogic/qed/qed_hw.c:	dma_addr_t *p_addr = &p_hwfn->dmae_info.completion_word_phys_addr;
drivers/net/ethernet/qlogic/qed/qed_hw.c:	u32 **p_comp = &p_hwfn->dmae_info.p_completion_word;
drivers/net/ethernet/qlogic/qed/qed_hw.c:	if (p_hwfn->dmae_info.p_completion_word) {
drivers/net/ethernet/qlogic/qed/qed_hw.c:		p_phys = p_hwfn->dmae_info.completion_word_phys_addr;
drivers/net/ethernet/qlogic/qed/qed_hw.c:				  p_hwfn->dmae_info.p_completion_word, p_phys);
drivers/net/ethernet/qlogic/qed/qed_hw.c:		p_hwfn->dmae_info.p_completion_word = NULL;
drivers/net/ethernet/qlogic/qed/qed_hw.c:	while (*p_hwfn->dmae_info.p_completion_word != DMAE_COMPLETION_VAL) {
drivers/net/ethernet/qlogic/qed/qed_hw.c:				  "Timed-out waiting for operation to complete. Completion word is 0x%08x expected 0x%08x.\n",
drivers/net/ethernet/qlogic/qed/qed_hw.c:				  *p_hwfn->dmae_info.p_completion_word,
drivers/net/ethernet/qlogic/qed/qed_hw.c:				 DMAE_COMPLETION_VAL);
drivers/net/ethernet/qlogic/qed/qed_hw.c:		/* to sync the completion_word since we are not
drivers/net/ethernet/qlogic/qed/qed_hw.c:		 * using the volatile keyword for p_completion_word
drivers/net/ethernet/qlogic/qed/qed_hw.c:		*p_hwfn->dmae_info.p_completion_word = 0;
drivers/net/ethernet/qlogic/qed/qed_hw.c:	dma_addr_t phys = p_hwfn->dmae_info.completion_word_phys_addr;
drivers/net/ethernet/qlogic/qed/qed_hw.c:	cmd->comp_val = cpu_to_le32(DMAE_COMPLETION_VAL);
drivers/net/ethernet/qlogic/qed/qed_hw.h:#define DMAE_COMPLETION_VAL     0xD1AE
drivers/net/ethernet/qlogic/qed/qed_init_fw_funcs.c:	SET_FIELD(params.flags, QED_DMAE_PARAMS_COMPLETION_DST, 1);
drivers/net/ethernet/qlogic/qed/qed_iscsi.c:		DP_NOTICE(p_hwfn, "iSCSI async completion is not set\n");
drivers/net/ethernet/qlogic/qed/qed_iwarp.c: * completion function and can then be reposted to rx chain when done. The flow
drivers/net/ethernet/qlogic/qed/qed_iwarp.c:/* The only slowpath for iwarp ll2 is unalign flush. When this completion
drivers/net/ethernet/qlogic/qed/qed_iwarp.c:		/* Async completion after TCP 3-way handshake */
drivers/net/ethernet/qlogic/qed/qed_iwarp.c:		/* Async completion for Close Connection ramrod */
drivers/net/ethernet/qlogic/qed/qed_iwarp.h:	struct iwarp_eqe_data_mpa_async_completion mpa_response;
drivers/net/ethernet/qlogic/qed/qed_iwarp.h:	struct iwarp_eqe_data_tcp_async_completion mpa_request;
drivers/net/ethernet/qlogic/qed/qed_l2.c:			 bool b_eq_completion_only, bool b_cqe_completion)
drivers/net/ethernet/qlogic/qed/qed_l2.c:	/* Cleaning the queue requires the completion to arrive there.
drivers/net/ethernet/qlogic/qed/qed_l2.c:				      !b_eq_completion_only) ||
drivers/net/ethernet/qlogic/qed/qed_l2.c:				     b_cqe_completion;
drivers/net/ethernet/qlogic/qed/qed_l2.c:				       b_eq_completion_only;
drivers/net/ethernet/qlogic/qed/qed_l2.c:			  bool eq_completion_only, bool cqe_completion)
drivers/net/ethernet/qlogic/qed/qed_l2.c:					      eq_completion_only,
drivers/net/ethernet/qlogic/qed/qed_l2.c:					      cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_l2.c:		rc = qed_vf_pf_rxq_stop(p_hwfn, p_cid, cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_l2.c:static int qed_fp_cqe_completion(struct qed_dev *dev,
drivers/net/ethernet/qlogic/qed/qed_l2.c:	return qed_eth_cqe_completion(&dev->hwfns[rss_id % dev->num_hwfns],
drivers/net/ethernet/qlogic/qed/qed_l2.c:	.eth_cqe_completion = &qed_fp_cqe_completion,
drivers/net/ethernet/qlogic/qed/qed_l2.h: * @eq_completion_only: If True completion will be on
drivers/net/ethernet/qlogic/qed/qed_l2.h: *                      EQe, if False completion will be
drivers/net/ethernet/qlogic/qed/qed_l2.h: * @cqe_completion: If True completion will be receive on CQe.
drivers/net/ethernet/qlogic/qed/qed_l2.h:		      bool eq_completion_only, bool cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_l2.h: * @complete_cqe_flg: Post completion to the CQE Ring if set.
drivers/net/ethernet/qlogic/qed/qed_l2.h: * @complete_event_flg: Post completion to the Event Ring if set.
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		   "Got an LL2 Rx completion: [Buffer at phys 0x%llx, offset 0x%02x] Length 0x%04x Parse_flags 0x%04x vlan 0x%04x Opaque data [0x%08x:0x%08x]\n",
drivers/net/ethernet/qlogic/qed/qed_ll2.c:static int qed_ll2_txq_completion(struct qed_hwfn *p_hwfn, void *p_cookie)
drivers/net/ethernet/qlogic/qed/qed_ll2.c:qed_ll2_rxq_handle_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_ll2.c:			  "[%d] LL2 Rx completion but active_descq is empty\n",
drivers/net/ethernet/qlogic/qed/qed_ll2.c:static int qed_ll2_rxq_completion(struct qed_hwfn *p_hwfn, void *cookie)
drivers/net/ethernet/qlogic/qed/qed_ll2.c:			rc = qed_ll2_rxq_handle_completion(p_hwfn, p_ll2_conn,
drivers/net/ethernet/qlogic/qed/qed_ll2.c:				  "Got a non-regular LB LL2 completion [type 0x%02x]\n",
drivers/net/ethernet/qlogic/qed/qed_ll2.c:				  "Unexpected event (%d) TX OOO completion\n",
drivers/net/ethernet/qlogic/qed/qed_ll2.c:static int qed_ll2_lb_rxq_completion(struct qed_hwfn *p_hwfn, void *p_cookie)
drivers/net/ethernet/qlogic/qed/qed_ll2.c:static int qed_ll2_lb_txq_completion(struct qed_hwfn *p_hwfn, void *p_cookie)
drivers/net/ethernet/qlogic/qed/qed_ll2.c:				  "Unexpectedly many BDs(%d) in TX OOO completion\n",
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		comp_rx_cb = qed_ll2_lb_rxq_completion;
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		comp_tx_cb = qed_ll2_lb_txq_completion;
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		comp_rx_cb = qed_ll2_rxq_completion;
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		comp_tx_cb = qed_ll2_txq_completion;
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		smp_wmb(); /* Make sure this is seen by ll2_lb_rxq_completion */
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		smp_wmb(); /* Make sure this is seen by ll2_lb_rxq_completion */
drivers/net/ethernet/qlogic/qed/qed_ll2.c:	 * the completion routine after calling qed_ll2_prepare_tx_packet()
drivers/net/ethernet/qlogic/qed/qed_ll2.c:	 * there are no fragments in the skb and subsequently the completion
drivers/net/ethernet/qlogic/qed/qed_ll2.c:		 * we can't free memory, will need to wait for completion
drivers/net/ethernet/qlogic/qed/qed_mcp.c:#define MFW_COMPLETION_MAX_ITER 5000
drivers/net/ethernet/qlogic/qed/qed_mcp.c:#define MFW_COMPLETION_INTERVAL_MS 1
drivers/net/ethernet/qlogic/qed/qed_mcp.c:	u32 cnt = MFW_COMPLETION_MAX_ITER;
drivers/net/ethernet/qlogic/qed/qed_mcp.c:		msleep(MFW_COMPLETION_INTERVAL_MS);
drivers/net/ethernet/qlogic/qed/qed_mcp.c:			  "Failed to wait MFW event completion after %d msec\n",
drivers/net/ethernet/qlogic/qed/qed_mcp.c:			  MFW_COMPLETION_MAX_ITER * MFW_COMPLETION_INTERVAL_MS);
drivers/net/ethernet/qlogic/qed/qed_mcp.h: * qed_mcp_drain(): drains the nig, allowing completion to pass in
drivers/net/ethernet/qlogic/qed/qed_nvmetcp.c:		DP_NOTICE(p_hwfn, "nvmetcp async completion is not set\n");
drivers/net/ethernet/qlogic/qed/qed_nvmetcp_fw_funcs.c:/* The following function initializes Local Completion Contexts: */
drivers/net/ethernet/qlogic/qed/qed_nvmetcp_fw_funcs.c:set_local_completion_context(struct e5_nvmetcp_task_context *context)
drivers/net/ethernet/qlogic/qed/qed_sp.h:	QED_SPQ_MODE_EBLOCK,    /* QED should block until completion */
drivers/net/ethernet/qlogic/qed/qed_sp.h: * qed_eth_cqe_completion(): handles the completion of a
drivers/net/ethernet/qlogic/qed/qed_sp.h:int qed_eth_cqe_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_sp.h:	struct list_head	completion_pending;
drivers/net/ethernet/qlogic/qed/qed_sp.h:	/* Bitmap for handling out-of-order completions */
drivers/net/ethernet/qlogic/qed/qed_sp.h: * qed_eq_completion(): Completes currently pending EQ elements.
drivers/net/ethernet/qlogic/qed/qed_sp.h:int qed_eq_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_sp.h: * qed_spq_completion(): Completes a single event.
drivers/net/ethernet/qlogic/qed/qed_sp.h: * @echo: echo value from cookie (used for determining completion).
drivers/net/ethernet/qlogic/qed/qed_sp.h:int qed_spq_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_sp.h:#define QED_SP_EQ_COMPLETION  0x01
drivers/net/ethernet/qlogic/qed/qed_sp.h:#define QED_SP_CQE_COMPLETION 0x02
drivers/net/ethernet/qlogic/qed/qed_sp.h:	/* Information regarding operation upon sending & completion */
drivers/net/ethernet/qlogic/qed/qed_sp.h: * configure the function related parameters and write its completion to the
drivers/net/ethernet/qlogic/qed/qed_sp_commands.c:		DP_NOTICE(p_hwfn, "Unknown SPQE completion mode %d\n",
drivers/net/ethernet/qlogic/qed/qed_spq.c:	/* Make sure completion done is visible on waiting thread */
drivers/net/ethernet/qlogic/qed/qed_spq.c:		/* Validate we receive completion update */
drivers/net/ethernet/qlogic/qed/qed_spq.c:		DP_NOTICE(p_hwfn, "Unknown SPQE completion mode %d\n",
drivers/net/ethernet/qlogic/qed/qed_spq.c:qed_async_event_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_spq.c:			  "Unknown Async completion for %s:%d\n",
drivers/net/ethernet/qlogic/qed/qed_spq.c:int qed_eq_completion(struct qed_hwfn *p_hwfn, void *cookie)
drivers/net/ethernet/qlogic/qed/qed_spq.c:			if (qed_async_event_completion(p_hwfn, p_eqe))
drivers/net/ethernet/qlogic/qed/qed_spq.c:		} else if (qed_spq_completion(p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_spq.c:	/* register EQ completion on the SP SB */
drivers/net/ethernet/qlogic/qed/qed_spq.c:	qed_int_register_cb(p_hwfn, qed_eq_completion,
drivers/net/ethernet/qlogic/qed/qed_spq.c:static int qed_cqe_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_spq.c:	return qed_spq_completion(p_hwfn, cqe->echo, 0, NULL);
drivers/net/ethernet/qlogic/qed/qed_spq.c:int qed_eth_cqe_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_spq.c:	rc = qed_cqe_completion(p_hwfn, cqe, PROTOCOLID_ETH);
drivers/net/ethernet/qlogic/qed/qed_spq.c:	INIT_LIST_HEAD(&p_spq->completion_pending);
drivers/net/ethernet/qlogic/qed/qed_spq.c:		list_move_tail(&p_ent->list, &p_spq->completion_pending);
drivers/net/ethernet/qlogic/qed/qed_spq.c:/* Avoid overriding of SPQ entries when getting out-of-order completions, by
drivers/net/ethernet/qlogic/qed/qed_spq.c: * marking the completions in a bitmap and increasing the chain consumer only
drivers/net/ethernet/qlogic/qed/qed_spq.c:		/* For entries in QED BLOCK mode, the completion code cannot
drivers/net/ethernet/qlogic/qed/qed_spq.c:int qed_spq_completion(struct qed_hwfn *p_hwfn,
drivers/net/ethernet/qlogic/qed/qed_spq.c:	list_for_each_entry_safe(p_ent, tmp, &p_spq->completion_pending, list) {
drivers/net/ethernet/qlogic/qed/qed_spq.c:			   "Got completion for echo %04x - doesn't match echo %04x in completion pending list\n",
drivers/net/ethernet/qlogic/qed/qed_spq.c:			   "Got a completion without a callback function\n");
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				u8 qid_usage_idx, bool cqe_completion)
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				   false, cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				  qid_usage_idx, req->cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	SET_FIELD(params.flags, QED_DMAE_PARAMS_COMPLETION_DST, 0x1);
drivers/net/ethernet/qlogic/qed/qed_vf.c:		       struct qed_queue_cid *p_cid, bool cqe_completion)
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->cqe_completion = cqe_completion;
drivers/net/ethernet/qlogic/qed/qed_vf.h:	u8 cqe_completion;
drivers/net/ethernet/qlogic/qed/qed_vf.h: * @cqe_completion: CQE Completion.
drivers/net/ethernet/qlogic/qed/qed_vf.h:		       struct qed_queue_cid *p_cid, bool cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_vf.h:				     bool cqe_completion)
drivers/net/ethernet/qlogic/qede/qede.h:	struct completion event_comp;
drivers/net/ethernet/qlogic/qede/qede_ethtool.c:		DP_NOTICE(edev, "Tx completion didn't happen\n");
drivers/net/ethernet/qlogic/qede/qede_ethtool.c:		/* Get the CQE from the completion ring */
drivers/net/ethernet/qlogic/qede/qede_fp.c:	/* Get the CQE from the completion ring */
drivers/net/ethernet/qlogic/qede/qede_fp.c:		edev->ops->eth_cqe_completion(edev->cdev, fp->id, sp_cqe);
drivers/net/ethernet/qlogic/qede/qede_main.c:	/* Allocate FW completion ring */
drivers/net/ethernet/qlogic/qede/qede_rdma.c:	init_completion(&edev->rdma_info.event_comp);
drivers/net/ethernet/qlogic/qede/qede_rdma.c:	wait_for_completion(&edev->rdma_info.event_comp);
drivers/net/ethernet/qlogic/qla3xxx.c: * The difference between 3022 and 3032 for inbound completions:
drivers/net/ethernet/qlogic/qla3xxx.c: * 3022 uses two buffers per completion.  The first buffer contains
drivers/net/ethernet/qlogic/qla3xxx.c:		 * is necessary for 3022 IP completions.
drivers/net/ethernet/qlogic/qla3xxx.c:	/* While there are entries in the completion queue. */
drivers/net/ethernet/qlogic/qla3xxx.c:		 * if the inbound completion is for a VLAN.
drivers/net/ethernet/qlogic/qla3xxx.c:	 * Network Completion Queue Producer Index Register
drivers/net/ethernet/qlogic/qla3xxx.h:	/* Network Completion Queue */
drivers/net/ethernet/qlogic/qlcnic/qlcnic.h: *	47:40 - completion id
drivers/net/ethernet/qlogic/qlcnic/qlcnic.h:	struct completion	completion;
drivers/net/ethernet/qlogic/qlcnic/qlcnic.h:	struct completion	completion;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	complete(&mbx->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:static void qlcnic_83xx_poll_for_mbx_completion(struct qlcnic_adapter *adapter,
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		if (!wait_for_completion_timeout(&cmd->completion, timeout)) {
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		qlcnic_83xx_poll_for_mbx_completion(adapter, cmd);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	dev_dbg(&adapter->pdev->dev, "Completion AEN:0x%x.\n",
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	/* Wait for Link and IDC Completion AEN */
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			netdev_err(netdev, "%s: Did not receive loopback IDC completion AEN\n",
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	/* Wait for Link and IDC Completion AEN */
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			netdev_err(netdev, "%s: Did not receive loopback IDC completion AEN\n",
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	reinit_completion(&mbx->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:qlcnic_83xx_notify_cmd_completion(struct qlcnic_adapter *adapter,
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	complete(&cmd->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		qlcnic_83xx_notify_cmd_completion(adapter, cmd);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	qlcnic_83xx_notify_cmd_completion(adapter, cmd);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	complete(&mbx->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		init_completion(&cmd->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		if (wait_for_completion_timeout(&mbx->completion,
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			mbx_ops->nofity_fw(adapter, QLC_83XX_MBX_COMPLETION);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	init_completion(&mbx->completion);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.h:#define QLC_83XX_MBX_COMPLETION		0x0
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_init.c:				 "%s: Wait for diag completion\n", __func__);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_init.c:			 "%s: Wait for diag completion\n", __func__);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov.h:	struct completion		resp_cmpl;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov.h:	struct completion		ch_free_cmpl;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:		init_completion(&vf->ch_free_cmpl);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	if (!wait_for_completion_timeout(&cmd.completion, timeout)) {
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	init_completion(&(*trans)->resp_cmpl);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	struct completion *cmpl = &trans->resp_cmpl;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	if (wait_for_completion_timeout(cmpl, QLC_MBOX_RESP_TIMEOUT))
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	struct completion *cmpl = &vf->ch_free_cmpl;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_sriov_common.c:	if (!wait_for_completion_timeout(cmpl, QLC_MBOX_CH_FREE_TIMEOUT)) {
drivers/net/ethernet/realtek/8139too.c:#include <linux/completion.h>
drivers/net/ethernet/renesas/rswitch.h:/* Completion flags */
drivers/net/ethernet/samsung/sxgbe/sxgbe_desc.c:/* Clear interrupt on tx frame completion. When this bit is
drivers/net/ethernet/samsung/sxgbe/sxgbe_desc.c:/* Set Interrupt on completion bit */
drivers/net/ethernet/samsung/sxgbe/sxgbe_desc.h:	/* Clear interrupt on tx frame completion. When this bit is
drivers/net/ethernet/samsung/sxgbe/sxgbe_desc.h:	/* Set Interrupt on completion bit */
drivers/net/ethernet/samsung/sxgbe/sxgbe_main.c: * interrupt on completion bit.
drivers/net/ethernet/sfc/ef10.c:		/* Check that RX completion merging is valid, i.e.
drivers/net/ethernet/sfc/ef10.c:		/* Merged completion for multiple non-scattered packets */
drivers/net/ethernet/sfc/ef10.c:		/* Transmit completion */
drivers/net/ethernet/sfc/ef10.c:	 *  - the normal completion event (may be omitted)
drivers/net/ethernet/sfc/ef10.c:	 * It's possible for multiple completion events to appear before the
drivers/net/ethernet/sfc/ef10.c:	 * In addition it's also possible for the adjacent completions to be
drivers/net/ethernet/sfc/ef10.c:	 * merged, so we may not see COMP N above. As such, the completion
drivers/net/ethernet/sfc/ef10.c:	case TX_TIMESTAMP_EVENT_TX_EV_COMPLETION:
drivers/net/ethernet/sfc/ef100_nic.c:	/* Allocate an extra descriptor for the QMDA status completion entry */
drivers/net/ethernet/sfc/ef100_nic.c:		case ESE_GZ_EF100_EV_TX_COMPLETION:
drivers/net/ethernet/sfc/ef100_regs.h:#define	ESF_GZ_D2C_COMPLETION_LBN 0
drivers/net/ethernet/sfc/ef100_regs.h:#define	ESF_GZ_D2C_COMPLETION_WIDTH 64
drivers/net/ethernet/sfc/ef100_regs.h:#define	ESE_GZ_EF100_EV_TX_COMPLETION 0x1
drivers/net/ethernet/sfc/ef100_tx.c:	/* Allocate an extra descriptor for the QMDA status completion entry */
drivers/net/ethernet/sfc/ef100_tx.c:	 * completion path, so ensure these operations are not
drivers/net/ethernet/sfc/ef100_tx.c:		 * the completion path. Otherwise there's a danger we'll never
drivers/net/ethernet/sfc/ef100_tx.c:		 * restart the queue if all completions have just happened.
drivers/net/ethernet/sfc/efx_channels.c:	 * plus some extra for link state events and MCDI completions.
drivers/net/ethernet/sfc/efx_common.c:	 * reset is scheduled. So switch back to poll'd MCDI completions.
drivers/net/ethernet/sfc/ethtool.c: * completion (or other event).  Unless the module parameter
drivers/net/ethernet/sfc/ethtool.c: * shared between RX and TX completions.  In this case, when RX IRQ
drivers/net/ethernet/sfc/ethtool.c: * The hardware does not support a limit on the number of completions
drivers/net/ethernet/sfc/falcon/efx.c:	 * plus some extra for link state events and MCDI completions. */
drivers/net/ethernet/sfc/falcon/ethtool.c: * completion (or other event).  Unless the module parameter
drivers/net/ethernet/sfc/falcon/ethtool.c: * shared between RX and TX completions.  In this case, when RX IRQ
drivers/net/ethernet/sfc/falcon/ethtool.c: * The hardware does not support a limit on the number of completions
drivers/net/ethernet/sfc/falcon/falcon.c:/* Wait for SPI command completion */
drivers/net/ethernet/sfc/falcon/falcon.c:/* Wait up to 10 ms for buffered write completion */
drivers/net/ethernet/sfc/falcon/falcon.c:	/* Wait up to 10 ms for completion, then reinitialise */
drivers/net/ethernet/sfc/falcon/farch.c:				 * receive a flush completion event
drivers/net/ethernet/sfc/falcon/farch.c: * completion events.  This means that efx->rxq_flush_outstanding remained at 4
drivers/net/ethernet/sfc/falcon/farch.c: * after the FLR; also, efx->active_queues was non-zero (as no flush completion
drivers/net/ethernet/sfc/falcon/farch.c:/* Handle a transmit completion event
drivers/net/ethernet/sfc/falcon/farch.c: * The NIC batches TX completion events; the message we receive is of
drivers/net/ethernet/sfc/falcon/farch.c:		/* Transmit completion */
drivers/net/ethernet/sfc/falcon/farch.c: * of all transmit completions.
drivers/net/ethernet/sfc/falcon/farch_regs.h:/* Sub-fields of an RX flush completion event */
drivers/net/ethernet/sfc/falcon/net_driver.h: * Since the TX completion path always executes on the same
drivers/net/ethernet/sfc/falcon/net_driver.h: * performance is increased by ensuring that the completion
drivers/net/ethernet/sfc/falcon/net_driver.h: * executing on one CPU which is different from the completion
drivers/net/ethernet/sfc/falcon/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/falcon/net_driver.h: * @merge_events: Number of TX merged completion events
drivers/net/ethernet/sfc/falcon/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/falcon/net_driver.h: * @empty_read_count: If the completion path has seen the queue as empty
drivers/net/ethernet/sfc/falcon/net_driver.h:	/* Members used mainly on the completion path */
drivers/net/ethernet/sfc/falcon/net_driver.h: * @n_rx_merge_events: Number of RX merged completion events
drivers/net/ethernet/sfc/falcon/net_driver.h: * @flush_wq: wait queue used by ef4_nic_flush_queues() to wait for flush completions.
drivers/net/ethernet/sfc/falcon/selftest.c:		 * transmit completion counting */
drivers/net/ethernet/sfc/falcon/selftest.c:	/* Count the number of tx completions, and decrement the refcnt. Any
drivers/net/ethernet/sfc/falcon/selftest.c:	/* Check TX completion and received packet counts */
drivers/net/ethernet/sfc/falcon/selftest.c:			  "TX completion events in %s loopback test\n",
drivers/net/ethernet/sfc/falcon/tx.c:	 * queue, it is possible for the completion path to race with
drivers/net/ethernet/sfc/falcon/tx.c:	 * after which there will be no more completions to wake it.
drivers/net/ethernet/sfc/falcon/tx.c:			 * the completion.
drivers/net/ethernet/sfc/falcon/tx.c:				  "TX queue %d spurious TX completion id %x\n",
drivers/net/ethernet/sfc/falcon/tx.c: * completion events will be directed back to the CPU that transmitted
drivers/net/ethernet/sfc/mcdi.c:	/* Poll for completion. Poll quickly (once a us) for the 1st jiffy,
drivers/net/ethernet/sfc/mcdi.c:static int efx_mcdi_await_completion(struct efx_nic *efx)
drivers/net/ethernet/sfc/mcdi.c:	/* Check if efx_mcdi_set_mode() switched us back to polled completions.
drivers/net/ethernet/sfc/mcdi.c:	 * In which case, poll for completions directly. If efx_mcdi_ev_cpl()
drivers/net/ethernet/sfc/mcdi.c: * asynchronous completion function, and release the interface.
drivers/net/ethernet/sfc/mcdi.c:		/* Ensure that if the completion event arrives later,
drivers/net/ethernet/sfc/mcdi.c:		 * completion after we've already transitioned back to
drivers/net/ethernet/sfc/mcdi.c:		rc = efx_mcdi_await_completion(efx);
drivers/net/ethernet/sfc/mcdi.c: * efx_mcdi_rpc - Issue an MCDI command and wait for completion
drivers/net/ethernet/sfc/mcdi.c: * @complete: Function to be called on completion or cancellation.
drivers/net/ethernet/sfc/mcdi.c: * event completions have been disabled due to an error.
drivers/net/ethernet/sfc/mcdi.c: * (a) the completion event is received (in NAPI context)
drivers/net/ethernet/sfc/mcdi.c:/* Switch to polled MCDI completions.  This can be called in various
drivers/net/ethernet/sfc/mcdi.c:	 * If in fail-fast state, don't switch to polled completion.
drivers/net/ethernet/sfc/mcdi.c:	/* We can switch from event completion to polled completion, because
drivers/net/ethernet/sfc/mcdi.c:	 * efx_mcdi_await_completion() will then call efx_mcdi_poll().
drivers/net/ethernet/sfc/mcdi.c:	 * We need an smp_wmb() to synchronise with efx_mcdi_await_completion(),
drivers/net/ethernet/sfc/mcdi.c:	/* If already in event completion mode, nothing to do.
drivers/net/ethernet/sfc/mcdi.c:	 * If in fail-fast state, don't switch to event completion.  FLR
drivers/net/ethernet/sfc/mcdi.c:	/* We can't switch from polled to event completion in the middle of a
drivers/net/ethernet/sfc/mcdi.c:	 * request, because the completion method is specified in the request.
drivers/net/ethernet/sfc/mcdi.c:		 * queue as completions, and one to event queue 0.
drivers/net/ethernet/sfc/mcdi.c:		 * because we want to wait for all completions.
drivers/net/ethernet/sfc/mcdi.c:		/* Re-enable polled MCDI completion */
drivers/net/ethernet/sfc/mcdi.h: * @MCDI_MODE_POLL: poll for MCDI completion, until timeout
drivers/net/ethernet/sfc/mcdi.h: * @mode: Poll for mcdi completion, or wait for an mcdi_event.
drivers/net/ethernet/sfc/mcdi.h: * @credits: Number of spurious MCDI completion events allowed before we
drivers/net/ethernet/sfc/mcdi_pcol.h: * All MCDI commands support completion by shared memory response. Each
drivers/net/ethernet/sfc/mcdi_pcol.h: * Some MCDI commands support completion by event, in which any associated
drivers/net/ethernet/sfc/mcdi_pcol.h: * OUT.GLOBAL_FLAGS is guaranteed to exist in the completion payload. The other
drivers/net/ethernet/sfc/mcdi_pcol.h: * sensor notifications and MCDI completions
drivers/net/ethernet/sfc/mcdi_pcol.h: * Poll for BIST completion. Returns a single status code, and optionally some
drivers/net/ethernet/sfc/mcdi_pcol.h:/* Result of nvram update completion processing. Result codes that indicate an
drivers/net/ethernet/sfc/mcdi_pcol.h:/* Type of TX event, ordinary TX completion, low or high part of TX timestamp
drivers/net/ethernet/sfc/mcdi_pcol.h:/* enum: This is a TX completion event, not a timestamp */
drivers/net/ethernet/sfc/mcdi_pcol.h:#define          TX_TIMESTAMP_EVENT_TX_EV_COMPLETION 0x0
drivers/net/ethernet/sfc/mcdi_pcol.h:/* enum: This is a TX completion event for a CTPIO transmit. The event format
drivers/net/ethernet/sfc/mcdi_pcol.h: * is the same as for TX_EV_COMPLETION.
drivers/net/ethernet/sfc/mcdi_pcol.h:#define          TX_TIMESTAMP_EVENT_TX_EV_CTPIO_COMPLETION 0x11
drivers/net/ethernet/sfc/mcdi_pcol.h: * memory and descriptor-to-completion mechanisms. Primary user is Virtio-blk
drivers/net/ethernet/sfc/net_driver.h: * Since the TX completion path always executes on the same
drivers/net/ethernet/sfc/net_driver.h: * performance is increased by ensuring that the completion
drivers/net/ethernet/sfc/net_driver.h: * executing on one CPU which is different from the completion
drivers/net/ethernet/sfc/net_driver.h: * @label: Label for TX completion events.
drivers/net/ethernet/sfc/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/net_driver.h: * @merge_events: Number of TX merged completion events
drivers/net/ethernet/sfc/net_driver.h: *	don't produce completion events, they won't update this.
drivers/net/ethernet/sfc/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/net_driver.h: * @empty_read_count: If the completion path has seen the queue as empty
drivers/net/ethernet/sfc/net_driver.h:	/* Members used mainly on the completion path */
drivers/net/ethernet/sfc/net_driver.h: * @n_rx_merge_events: Number of RX merged completion events
drivers/net/ethernet/sfc/net_driver.h: * @flush_wq: wait queue used by efx_nic_flush_queues() to wait for flush completions.
drivers/net/ethernet/sfc/selftest.c:		 * transmit completion counting */
drivers/net/ethernet/sfc/selftest.c:	/* Count the number of tx completions, and decrement the refcnt. Any
drivers/net/ethernet/sfc/selftest.c:	/* Check TX completion and received packet counts */
drivers/net/ethernet/sfc/selftest.c:			  "TX completion events in %s loopback test\n",
drivers/net/ethernet/sfc/siena/efx_channels.c:	 * plus some extra for link state events and MCDI completions.
drivers/net/ethernet/sfc/siena/efx_common.c:	 * reset is scheduled. So switch back to poll'd MCDI completions.
drivers/net/ethernet/sfc/siena/ethtool.c: * completion (or other event).  Unless the module parameter
drivers/net/ethernet/sfc/siena/ethtool.c: * shared between RX and TX completions.  In this case, when RX IRQ
drivers/net/ethernet/sfc/siena/ethtool.c: * The hardware does not support a limit on the number of completions
drivers/net/ethernet/sfc/siena/farch.c:				 * receive a flush completion event
drivers/net/ethernet/sfc/siena/farch.c:		 * completion). If that fails, fall back to the old scheme.
drivers/net/ethernet/sfc/siena/farch.c: * completion events.  This means that efx->rxq_flush_outstanding remained at 4
drivers/net/ethernet/sfc/siena/farch.c: * after the FLR; also, efx->active_queues was non-zero (as no flush completion
drivers/net/ethernet/sfc/siena/farch.c:/* Handle a transmit completion event
drivers/net/ethernet/sfc/siena/farch.c: * The NIC batches TX completion events; the message we receive is of
drivers/net/ethernet/sfc/siena/farch.c:		/* Transmit completion */
drivers/net/ethernet/sfc/siena/farch.c: * of all transmit completions.
drivers/net/ethernet/sfc/siena/farch_regs.h:/* Sub-fields of an RX flush completion event */
drivers/net/ethernet/sfc/siena/mcdi.c:	/* Poll for completion. Poll quickly (once a us) for the 1st jiffy,
drivers/net/ethernet/sfc/siena/mcdi.c:static int efx_mcdi_await_completion(struct efx_nic *efx)
drivers/net/ethernet/sfc/siena/mcdi.c:	/* Check if efx_mcdi_set_mode() switched us back to polled completions.
drivers/net/ethernet/sfc/siena/mcdi.c:	 * In which case, poll for completions directly. If efx_mcdi_ev_cpl()
drivers/net/ethernet/sfc/siena/mcdi.c: * asynchronous completion function, and release the interface.
drivers/net/ethernet/sfc/siena/mcdi.c:		/* Ensure that if the completion event arrives later,
drivers/net/ethernet/sfc/siena/mcdi.c:		 * completion after we've already transitioned back to
drivers/net/ethernet/sfc/siena/mcdi.c:		rc = efx_mcdi_await_completion(efx);
drivers/net/ethernet/sfc/siena/mcdi.c: * efx_siena_mcdi_rpc - Issue an MCDI command and wait for completion
drivers/net/ethernet/sfc/siena/mcdi.c: * @complete: Function to be called on completion or cancellation.
drivers/net/ethernet/sfc/siena/mcdi.c: * event completions have been disabled due to an error.
drivers/net/ethernet/sfc/siena/mcdi.c: * (a) the completion event is received (in NAPI context)
drivers/net/ethernet/sfc/siena/mcdi.c:/* Switch to polled MCDI completions.  This can be called in various
drivers/net/ethernet/sfc/siena/mcdi.c:	 * If in fail-fast state, don't switch to polled completion.
drivers/net/ethernet/sfc/siena/mcdi.c:	/* We can switch from event completion to polled completion, because
drivers/net/ethernet/sfc/siena/mcdi.c:	 * efx_mcdi_await_completion() will then call efx_mcdi_poll().
drivers/net/ethernet/sfc/siena/mcdi.c:	 * We need an smp_wmb() to synchronise with efx_mcdi_await_completion(),
drivers/net/ethernet/sfc/siena/mcdi.c:	/* If already in event completion mode, nothing to do.
drivers/net/ethernet/sfc/siena/mcdi.c:	 * If in fail-fast state, don't switch to event completion.  FLR
drivers/net/ethernet/sfc/siena/mcdi.c:	/* We can't switch from polled to event completion in the middle of a
drivers/net/ethernet/sfc/siena/mcdi.c:	 * request, because the completion method is specified in the request.
drivers/net/ethernet/sfc/siena/mcdi.c:		 * queue as completions, and one to event queue 0.
drivers/net/ethernet/sfc/siena/mcdi.c:		 * because we want to wait for all completions.
drivers/net/ethernet/sfc/siena/mcdi.c:		/* Re-enable polled MCDI completion */
drivers/net/ethernet/sfc/siena/mcdi.h: * @MCDI_MODE_POLL: poll for MCDI completion, until timeout
drivers/net/ethernet/sfc/siena/mcdi.h: * @mode: Poll for mcdi completion, or wait for an mcdi_event.
drivers/net/ethernet/sfc/siena/mcdi.h: * @credits: Number of spurious MCDI completion events allowed before we
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * All MCDI commands support completion by shared memory response. Each
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * Some MCDI commands support completion by event, in which any associated
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * OUT.GLOBAL_FLAGS is guaranteed to exist in the completion payload. The other
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * sensor notifications and MCDI completions
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * Poll for BIST completion. Returns a single status code, and optionally some
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:/* Result of nvram update completion processing. Result codes that indicate an
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:/* Type of TX event, ordinary TX completion, low or high part of TX timestamp
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:/* enum: This is a TX completion event, not a timestamp */
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:#define          TX_TIMESTAMP_EVENT_TX_EV_COMPLETION 0x0
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:/* enum: This is a TX completion event for a CTPIO transmit. The event format
drivers/net/ethernet/sfc/siena/mcdi_pcol.h: * is the same as for TX_EV_COMPLETION.
drivers/net/ethernet/sfc/siena/mcdi_pcol.h:#define          TX_TIMESTAMP_EVENT_TX_EV_CTPIO_COMPLETION 0x11
drivers/net/ethernet/sfc/siena/net_driver.h: * Since the TX completion path always executes on the same
drivers/net/ethernet/sfc/siena/net_driver.h: * performance is increased by ensuring that the completion
drivers/net/ethernet/sfc/siena/net_driver.h: * executing on one CPU which is different from the completion
drivers/net/ethernet/sfc/siena/net_driver.h: * @label: Label for TX completion events.
drivers/net/ethernet/sfc/siena/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/siena/net_driver.h: * @merge_events: Number of TX merged completion events
drivers/net/ethernet/sfc/siena/net_driver.h: *	don't produce completion events, they won't update this.
drivers/net/ethernet/sfc/siena/net_driver.h: *	completion path.
drivers/net/ethernet/sfc/siena/net_driver.h: * @empty_read_count: If the completion path has seen the queue as empty
drivers/net/ethernet/sfc/siena/net_driver.h:	/* Members used mainly on the completion path */
drivers/net/ethernet/sfc/siena/net_driver.h: * @n_rx_merge_events: Number of RX merged completion events
drivers/net/ethernet/sfc/siena/net_driver.h: * @flush_wq: wait queue used by efx_nic_flush_queues() to wait for flush completions.
drivers/net/ethernet/sfc/siena/selftest.c:		 * transmit completion counting */
drivers/net/ethernet/sfc/siena/selftest.c:	/* Count the number of tx completions, and decrement the refcnt. Any
drivers/net/ethernet/sfc/siena/selftest.c:	/* Check TX completion and received packet counts */
drivers/net/ethernet/sfc/siena/selftest.c:			  "TX completion events in %s loopback test\n",
drivers/net/ethernet/sfc/siena/siena_sriov.c: *	to wait for flush completions.
drivers/net/ethernet/sfc/siena/siena_sriov.c:	/* Ignore flush completions triggered by an FLR */
drivers/net/ethernet/sfc/siena/tx.c:	 * queue, it is possible for the completion path to race with
drivers/net/ethernet/sfc/siena/tx.c:	 * after which there will be no more completions to wake it.
drivers/net/ethernet/sfc/siena/tx_common.c:				  "TX queue %d spurious TX completion id %d\n",
drivers/net/ethernet/sfc/siena/tx_common.c:			 * the completion.
drivers/net/ethernet/sfc/siena/vfdi.h: * @u.init_txq.evq: Instance of event queue to target transmit completion
drivers/net/ethernet/sfc/siena/vfdi.h: * @u.init_txq.label: Label used in transmit completion events.
drivers/net/ethernet/sfc/tx.c:	 * queue, it is possible for the completion path to race with
drivers/net/ethernet/sfc/tx.c:	 * after which there will be no more completions to wake it.
drivers/net/ethernet/sfc/tx.c:				  "TX queue %d spurious single TX completion\n",
drivers/net/ethernet/sfc/tx_common.c:				  "TX queue %d spurious TX completion id %d\n",
drivers/net/ethernet/sfc/tx_common.c:			 * the completion.
drivers/net/ethernet/sgi/meth.h:   dma completion. */
drivers/net/ethernet/smsc/smsc9420.c:	/* to ensure PCI write completion, we must perform a PCI read */
drivers/net/ethernet/smsc/smsc9420.c:	/* to ensure PCI write completion, we must perform a PCI read */
drivers/net/ethernet/stmicro/stmmac/dwmac4_descs.c:		flags |= RDES3_INT_ON_COMPLETION_EN;
drivers/net/ethernet/stmicro/stmmac/dwmac4_descs.c:	p->des2 |= cpu_to_le32(TDES2_INTERRUPT_ON_COMPLETION);
drivers/net/ethernet/stmicro/stmmac/dwmac4_descs.h:#define TDES2_INTERRUPT_ON_COMPLETION	BIT(31)
drivers/net/ethernet/stmicro/stmmac/dwmac4_descs.h:#define RDES3_INT_ON_COMPLETION_EN	BIT(30)
drivers/net/ethernet/stmicro/stmmac/hwif.h:	/* Clear interrupt on tx frame completion. When this bit is
drivers/net/ethernet/stmicro/stmmac/stmmac_main.c: * stmmac_tx_clean - to manage the transmission completion
drivers/net/ethernet/stmicro/stmmac/stmmac_main.c: * interrupt on completion bit.
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:#include <linux/completion.h>
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	struct completion comp;
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	wait_for_completion_timeout(&tpriv->comp, attr->timeout);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	wait_for_completion_timeout(&tpriv->comp, STMMAC_LB_TIMEOUT);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:		wait_for_completion_timeout(&tpriv->comp, STMMAC_LB_TIMEOUT);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:		wait_for_completion_timeout(&tpriv->comp, STMMAC_LB_TIMEOUT);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	wait_for_completion_timeout(&tpriv->comp, STMMAC_LB_TIMEOUT);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	init_completion(&tpriv->comp);
drivers/net/ethernet/stmicro/stmmac/stmmac_selftests.c:	wait_for_completion_timeout(&tpriv->comp, STMMAC_LB_TIMEOUT);
drivers/net/ethernet/sun/cassini.c: *  page-based RX descriptor engine with separate completion rings
drivers/net/ethernet/sun/cassini.c: * RX DATA: the rx completion ring has all the info, but the rx desc
drivers/net/ethernet/sun/cassini.c:#define USE_TX_COMPWB      /* use completion writeback registers */
drivers/net/ethernet/sun/cassini.c:	/* disable completion interrupts and selectively mask */
drivers/net/ethernet/sun/cassini.c:	/* poll for completion */
drivers/net/ethernet/sun/cassini.c:	/* poll for completion */
drivers/net/ethernet/sun/cassini.c:	/* rx completion registers */
drivers/net/ethernet/sun/cassini.c:	 * free desc and completion entries. these are used to trigger
drivers/net/ethernet/sun/cassini.c:		/* use the completion writeback registers */
drivers/net/ethernet/sun/cassini.c:/* process a completion ring. packets are set up in three basic ways:
drivers/net/ethernet/sun/cassini.c: *       the capability of using multiple RX completion rings, it isn't
drivers/net/ethernet/sun/cassini.c:/* put completion entries back on the ring */
drivers/net/ethernet/sun/cassini.c:/* cassini can use all four PCI interrupts for the completion ring.
drivers/net/ethernet/sun/cassini.c:	/* final rx completion */
drivers/net/ethernet/sun/cassini.c:	/* set up tx completion writeback registers. must be 8-byte aligned */
drivers/net/ethernet/sun/cassini.c:	/* enable completion writebacks, enable paced mode,
drivers/net/ethernet/sun/cassini.c:	/* disable RX MAC and wait for completion */
drivers/net/ethernet/sun/cassini.c:	/* disable hash filter and wait for completion */
drivers/net/ethernet/sun/cassini.h: * the source. tx completion register 3 is replicated in [19 - 31]
drivers/net/ethernet/sun/cassini.h:						      RX completion reg updated.
drivers/net/ethernet/sun/cassini.h:#define    INTR_RX_COMP_FULL           0x00000080  /* no more room in completion
drivers/net/ethernet/sun/cassini.h:						      use in completion descr
drivers/net/ethernet/sun/cassini.h:#define    INTR_TX_COMP_3_MASK         0xFFF80000  /* mask for TX completion
drivers/net/ethernet/sun/cassini.h: * reset. poll until TX and RX read back as 0's for completion.
drivers/net/ethernet/sun/cassini.h:#define    TX_CFG_COMPWB_Q1            0x02000000  /* completion writeback happens at
drivers/net/ethernet/sun/cassini.h:#define    TX_CFG_COMPWB_Q2            0x04000000  /* completion writeback happens at
drivers/net/ethernet/sun/cassini.h:#define    TX_CFG_COMPWB_Q3            0x08000000  /* completion writeback happens at
drivers/net/ethernet/sun/cassini.h:#define    TX_CFG_COMPWB_Q4            0x10000000  /* completion writeback happens at
drivers/net/ethernet/sun/cassini.h:#define    TX_CFG_INTR_COMPWB_DIS      0x20000000  /* disable pre-interrupt completion
drivers/net/ethernet/sun/cassini.h:#define    TX_SM_2_COMP_WB_MASK        0x07    /* completion writeback sm */
drivers/net/ethernet/sun/cassini.h:#define  REG_TX_COMP0                  0x2048  /* TX completion reg #1 */
drivers/net/ethernet/sun/cassini.h:/* values of TX_COMPLETE_1-4 are written. each completion register
drivers/net/ethernet/sun/cassini.h: * NOTE: completion reg values are only written back prior to TX_INTME and
drivers/net/ethernet/sun/cassini.h: * offset from base addr      completion # byte
drivers/net/ethernet/sun/cassini.h:#define  REG_TX_COMPWB_DB_LOW       0x2058  /* TX completion write back
drivers/net/ethernet/sun/cassini.h:#define  REG_TX_COMPWB_DB_HI        0x205C  /* TX completion write back
drivers/net/ethernet/sun/cassini.h: * dynamically with new weights set upon completion of the current
drivers/net/ethernet/sun/cassini.h:						 clears on completion. */
drivers/net/ethernet/sun/cassini.h: * completion ring size = (1 << n)*128 -> [128 - 32k], n < 9
drivers/net/ethernet/sun/cassini.h:/* 8KB aligned 64-bit pointer to the base of the RX free/completion rings.
drivers/net/ethernet/sun/cassini.h:#define  REG_RX_CB_LOW                     0x4030  /* RX completion ring
drivers/net/ethernet/sun/cassini.h:#define  REG_RX_CB_HI                      0x4034  /* RX completion ring
drivers/net/ethernet/sun/cassini.h:#define  REG_RX_COMP                       0x4038  /* (ro) RX completion */
drivers/net/ethernet/sun/cassini.h: * completion tail register.
drivers/net/ethernet/sun/cassini.h:#define  REG_RX_COMP_HEAD                  0x403C  /* RX completion head */
drivers/net/ethernet/sun/cassini.h:#define  REG_RX_COMP_TAIL                  0x4040  /* RX completion tail */
drivers/net/ethernet/sun/cassini.h:							 this many sets of completion
drivers/net/ethernet/sun/cassini.h: * many free desc and completion entries are available for hw use.
drivers/net/ethernet/sun/cassini.h:							 completion entries
drivers/net/ethernet/sun/cassini.h:							 on completion. */
drivers/net/ethernet/sun/cassini.h:							 completion writebacks
drivers/net/ethernet/sun/cassini.h:							 completion wb. */
drivers/net/ethernet/sun/cassini.h:#define  REG_PLUS_RX_CB1_LOW            0x4208  /* RX completion ring
drivers/net/ethernet/sun/cassini.h:#define  REG_PLUS_RX_CB1_HI             0x420C  /* RX completion ring
drivers/net/ethernet/sun/cassini.h:#define  REG_PLUS_RX_COMP1             0x4224  /* (ro) RX completion 2
drivers/net/ethernet/sun/cassini.h:#define  REG_PLUS_RX_COMP1_HEAD        0x4228  /* (ro) RX completion 2
drivers/net/ethernet/sun/cassini.h:#define  REG_PLUS_RX_COMP1_TAIL        0x422C  /* RX completion 2
drivers/net/ethernet/sun/cassini.h: * to start BIST. controller clears _START on completion. _START can also
drivers/net/ethernet/sun/cassini.h:						      on completion of an
drivers/net/ethernet/sun/cassini.h: * execution completion. during a read operation, this register will also
drivers/net/ethernet/sun/cassini.h: * completion.
drivers/net/ethernet/sun/cassini.h:							 completion, 1 means
drivers/net/ethernet/sun/cassini.h:							 completion, field is
drivers/net/ethernet/sun/cassini.h: * the completion ring.
drivers/net/ethernet/sun/cassini.h:/* received packets are put on the completion ring. */
drivers/net/ethernet/sun/niu.c:	 * FFLP/TCAM, Full RCR (Receive Completion Ring) RBR (Receive
drivers/net/ethernet/sun/sungem.c:		 * on the buffer address.  We sync on the RX completion
drivers/net/ethernet/sun/sungem.c:		/* Run TX completion thread */
drivers/net/ethernet/sun/sungem.h:#define TXDMA_TXDONE	0x2100UL	/* TX Completion Register	*/
drivers/net/ethernet/sun/sungem.h:/* TX Completion Register.
drivers/net/ethernet/sun/sungem.h:#define RXDMA_DONE	0x4104UL	/* RX Completion Register	*/
drivers/net/ethernet/sun/sungem.h:/* RX Completion Register.
drivers/net/ethernet/sun/sungem.h: * the host must poll this register for completion.  Also, after
drivers/net/ethernet/sun/sungem.h: * completion this register holds the data returned by the transceiver
drivers/net/ethernet/ti/am65-cpsw-nuss.c:	reinit_completion(&common->tdown_complete);
drivers/net/ethernet/ti/am65-cpsw-nuss.c:	i = wait_for_completion_timeout(&common->tdown_complete,
drivers/net/ethernet/ti/am65-cpsw-nuss.c:	reinit_completion(&common->tdown_complete);
drivers/net/ethernet/ti/am65-cpsw-nuss.c:		i = wait_for_completion_timeout(&common->tdown_complete, msecs_to_jiffies(1000));
drivers/net/ethernet/ti/am65-cpsw-nuss.c:	init_completion(&common->tdown_complete);
drivers/net/ethernet/ti/am65-cpsw-nuss.h:	struct completion	tdown_complete;
drivers/net/ethernet/ti/am65-cpsw-qos.c:/* target new EST RAM buffer, actual toggle happens after cycle completion */
drivers/net/ethernet/ti/cpts.c:	reinit_completion(&cpts->ts_push_complete);
drivers/net/ethernet/ti/cpts.c:	    !wait_for_completion_timeout(&cpts->ts_push_complete, HZ))
drivers/net/ethernet/ti/cpts.c:	init_completion(&cpts->ts_push_complete);
drivers/net/ethernet/ti/cpts.h:	struct completion	ts_push_complete;
drivers/net/ethernet/ti/icssg/icssg_common.c:		/* teardown completion */
drivers/net/ethernet/ti/icssg/icssg_common.c:	init_completion(&emac->tdown_complete);
drivers/net/ethernet/ti/icssg/icssg_common.c: * Doesn't wait for completion we'll check for TX completion in
drivers/net/ethernet/ti/icssg/icssg_prueth.c:	init_completion(&emac->cmd_complete);
drivers/net/ethernet/ti/icssg/icssg_prueth.c:	 * any SKB for completion. So set false to free_skb
drivers/net/ethernet/ti/icssg/icssg_prueth.c:	reinit_completion(&emac->tdown_complete);
drivers/net/ethernet/ti/icssg/icssg_prueth.c:	ret = wait_for_completion_timeout(&emac->tdown_complete,
drivers/net/ethernet/ti/icssg/icssg_prueth.h:	struct completion tdown_complete;
drivers/net/ethernet/ti/icssg/icssg_prueth.h:	struct completion cmd_complete;
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	reinit_completion(&emac->cmd_complete);
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	ret = wait_for_completion_timeout(&emac->cmd_complete, msecs_to_jiffies(100));
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:		netdev_err(emac->ndev, "cmd %x: completion timeout\n", cmd);
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	init_completion(&emac->cmd_complete);
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	 * any SKB for completion. So set false to free_skb
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	reinit_completion(&emac->tdown_complete);
drivers/net/ethernet/ti/icssg/icssg_prueth_sr1.c:	ret = wait_for_completion_timeout(&emac->tdown_complete,
drivers/net/ethernet/ti/netcp_core.c:	/* open Tx completion queue */
drivers/net/ethernet/ti/netcp_core.c:	/* Set notification for Tx completion */
drivers/net/ethernet/ti/netcp_core.c:	/* open Rx completion queue */
drivers/net/ethernet/ti/netcp_core.c:	/* Set notification for Rx completion */
drivers/net/ethernet/ti/netcp_core.c:	/* Recycle Rx descriptors from completion queue */
drivers/net/ethernet/ti/netcp_core.c:	/* Recycle Tx descriptors from completion queue */
drivers/net/ethernet/ti/netcp_core.c:	ret = of_property_read_u32(node_interface, "tx-completion-queue",
drivers/net/ethernet/ti/netcp_core.c:		dev_warn(dev, "missing \"tx-completion-queue\" parameter\n");
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&wl->cmd_done_intr);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	wait_for_completion(&wl->cmd_done_intr);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&cmd->done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	/* wait for command completion */
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	wait_for_completion(&cmd->done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&wl->scan_done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&wl->assoc_done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	rc = wait_for_completion_timeout(&wl->assoc_done, HZ * 4);/*FIXME*/
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	 * Wait for bss scan completion
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	wait_for_completion(&wl->scan_done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&wl->cmd_done_intr);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	init_completion(&wl->scan_done);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:		wait_for_completion_timeout(&wl->scan_done, HZ);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.h:	struct completion scan_done;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.h:	struct completion cmd_done_intr;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.h:	struct completion assoc_done;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.h:	struct completion done;
drivers/net/ethernet/toshiba/spider_net.c:	 * interrupt, as we poll for the completion of the read operation
drivers/net/ethernet/toshiba/spider_net.c:		/* we don't use semaphores, as we poll for the completion
drivers/net/ethernet/toshiba/tc35815.c:#define Tx_EnComp	       0x00004000 /* 1:Enable Completion	     */
drivers/net/ethernet/toshiba/tc35815.c:#define Tx_Comp		       0x00004000 /* Completion			     */
drivers/net/ethernet/toshiba/tc35815.c:	/* When the TX completion hw interrupt arrives, this
drivers/net/ethernet/via/via-rhine.c:	 * seen the transmit request, especially as the transmit completion
drivers/net/ethernet/via/via-rhine.c:	/* Pity we can't rely on the nearby BQL completion implicit barrier. */
drivers/net/ethernet/wangxun/libwx/wx_hw.c: *  @timeout: time in ms to wait for command completion
drivers/net/ethernet/wangxun/libwx/wx_hw.c:	/* Check command completion */
drivers/net/ethernet/wangxun/libwx/wx_lib.c:		/* place incomplete frames back on ring for completion */
drivers/net/ethernet/wangxun/txgbe/txgbe_fdir.c:	/* write hashes and fdirctrl register, poll for completion */
drivers/net/ethernet/wangxun/txgbe/txgbe_fdir.c:	/* write hashes and fdirctrl register, poll for completion */
drivers/net/ethernet/xilinx/ll_temac.h: *	1    IrqOnEnd    generate an interrupt at completion of DMA  op
drivers/net/ethernet/xilinx/xilinx_axienet.h:#define XAXIDMA_IRQ_IOC_MASK		0x00001000 /* Completion intr */
drivers/net/ethernet/xilinx/xilinx_axienet_main.c: * This function is invoked from the NAPI processing to notify the completion
drivers/net/ethernet/xilinx/xilinx_axienet_main.c:		/* Re-enable TX completion interrupts. This should
drivers/net/ethernet/xilinx/xilinx_axienet_main.c:		/* Re-enable RX completion interrupts. This should
drivers/net/ethernet/xilinx/xilinx_axienet_main.c:		/* Disable further TX completion interrupts and schedule
drivers/net/ethernet/xilinx/xilinx_axienet_main.c:		 * NAPI to handle the completions.
drivers/net/ethernet/xilinx/xilinx_axienet_main.c:		/* Disable further RX completion interrupts and schedule
drivers/net/ethernet/xilinx/xilinx_emaclite.c: * updates the stats and frees the socket buffer. The Tx completion is signaled
drivers/net/fddi/defxx.c: *		architecture is a standard producer, consumer, completion model in
drivers/net/fddi/defxx.c: *   Adapter should be in DMA_UNAVAILABLE state upon completion of this
drivers/net/fddi/defxx.c: *   or updating completion indices.
drivers/net/fddi/defxx.c:	 * Transmit and receive producer and completion indices are updated on the
drivers/net/fddi/defxx.c:	/* Bump (and wrap) the completion index and write out to register */
drivers/net/fddi/defxx.c:	/* Bump (and wrap) the completion index and write out to register */
drivers/net/fddi/defxx.c: *   to various PDQ port registers, then polling for completion.
drivers/net/fddi/defxx.c:		 * Advance the producer (for recycling) and advance the completion
drivers/net/fddi/defxx.c:		 * completion index because they are both advanced at the same
drivers/net/fddi/defxx.c:	 *	 current xmt completion index when we complete this
drivers/net/fddi/defxx.c:	 *	 completion, except to indicate that the queue is empty.
drivers/net/fddi/defxx.c:	 * entire packet, we can simply bump the completion index by
drivers/net/fddi/defxx.c:	u8			comp;			/* local transmit completion index */
drivers/net/fddi/defxx.c:		 * Move to start of next packet by updating completion index
drivers/net/fddi/defxx.c:		 * simplify the completion code by incrementing the
drivers/net/fddi/defxx.c:		 * completion index by one.  This code will need to be
drivers/net/fddi/defxx.c:	u8			comp;			/* local transmit completion index */
drivers/net/fddi/defxx.c:		 * Move to start of next packet by updating completion index
drivers/net/fddi/defxx.c:		 * simplify the completion code by incrementing the
drivers/net/fddi/defxx.c:		 * completion index by one.  This code will need to be
drivers/net/fddi/defxx.h:	/* Store pointers to transmit buffers for transmit completion code */
drivers/net/fddi/defza.h:#define FZA_RING_TX_DCC_MASK	0x0f000000	/* DMA completion code */
drivers/net/fddi/defza.h:	int cmd_done_flag;		/* command completion trigger */
drivers/net/hamradio/6pack.c:	struct completion	dead;
drivers/net/hamradio/6pack.c:	init_completion(&sp->dead);
drivers/net/hamradio/6pack.c:		wait_for_completion(&sp->dead);
drivers/net/hamradio/6pack.c:	 * on the free buffers. The sp->dead completion is not sufficient
drivers/net/hamradio/mkiss.c:	struct completion	dead;
drivers/net/hamradio/mkiss.c:	init_completion(&ax->dead);
drivers/net/hamradio/mkiss.c:		wait_for_completion(&ax->dead);
drivers/net/hyperv/hyperv_net.h:	/* completion variable to confirm vf association */
drivers/net/hyperv/hyperv_net.h:	struct completion vf_add;
drivers/net/hyperv/hyperv_net.h:	u32 recv_completion_cnt;
drivers/net/hyperv/hyperv_net.h:	struct completion channel_init_wait;
drivers/net/hyperv/netvsc.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/netvsc.c:	wait_for_completion(&nv_dev->channel_init_wait);
drivers/net/hyperv/netvsc.c:	init_completion(&net_device->channel_init_wait);
drivers/net/hyperv/netvsc.c:	size = net_device->recv_completion_cnt * sizeof(struct recv_comp_data);
drivers/net/hyperv/netvsc.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/netvsc.c:	wait_for_completion(&net_device->channel_init_wait);
drivers/net/hyperv/netvsc.c:	/* Setup receive completion ring.
drivers/net/hyperv/netvsc.c:	net_device->recv_completion_cnt = net_device->recv_section_cnt + 1;
drivers/net/hyperv/netvsc.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/netvsc.c:	wait_for_completion(&net_device->channel_init_wait);
drivers/net/hyperv/netvsc.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/netvsc.c:	wait_for_completion(&net_device->channel_init_wait);
drivers/net/hyperv/netvsc.c:static void netvsc_send_completion(struct net_device *ndev,
drivers/net/hyperv/netvsc.c:	/* First check if this is a VMBUS completion without data payload */
drivers/net/hyperv/netvsc.c:			netdev_err(ndev, "Unexpected VMBUS completion!!\n");
drivers/net/hyperv/netvsc.c:		 * there's a problem. But process the completion anyway so the
drivers/net/hyperv/netvsc.c:			   "Unknown send completion type %d received!!\n",
drivers/net/hyperv/netvsc.c:				       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/netvsc.c:/* Send pending recv completions */
drivers/net/hyperv/netvsc.c:static int send_recv_completions(struct net_device *ndev,
drivers/net/hyperv/netvsc.c:		if (++mrc->first == nvdev->recv_completion_cnt)
drivers/net/hyperv/netvsc.c:	/* receive completion ring has been emptied */
drivers/net/hyperv/netvsc.c:/* Count how many receive completions are outstanding */
drivers/net/hyperv/netvsc.c:	u32 count = nvdev->recv_completion_cnt;
drivers/net/hyperv/netvsc.c:		send_recv_completions(ndev, nvdev, nvchan);
drivers/net/hyperv/netvsc.c:	if (++mrc->next == nvdev->recv_completion_cnt)
drivers/net/hyperv/netvsc.c:		netvsc_send_completion(ndev, net_device, channel, desc, budget);
drivers/net/hyperv/netvsc.c:	/* Send any pending receive completions */
drivers/net/hyperv/netvsc.c:	ret = send_recv_completions(ndev, net_device, nvchan);
drivers/net/hyperv/netvsc.c:	 *   or sending receive completion failed.
drivers/net/hyperv/netvsc_drv.c:		wait_for_completion(&net_device_ctx->vf_add);
drivers/net/hyperv/netvsc_drv.c:	reinit_completion(&net_device_ctx->vf_add);
drivers/net/hyperv/netvsc_drv.c:	init_completion(&net_device_ctx->vf_add);
drivers/net/hyperv/rndis_filter.c:	struct completion  wait_event;
drivers/net/hyperv/rndis_filter.c:	init_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:		/* completion msgs */
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:		wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&request->wait_event);
drivers/net/hyperv/rndis_filter.c:	/* Wait for all send completions */
drivers/net/hyperv/rndis_filter.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/net/hyperv/rndis_filter.c:	wait_for_completion(&nvdev->channel_init_wait);
drivers/net/ieee802154/adf7242.c:	struct completion tx_complete;
drivers/net/ieee802154/adf7242.c:	reinit_completion(&lp->tx_complete);
drivers/net/ieee802154/adf7242.c:	ret = wait_for_completion_interruptible_timeout(&lp->tx_complete,
drivers/net/ieee802154/adf7242.c:			/* save CSMA-CA completion status */
drivers/net/ieee802154/adf7242.c:	init_completion(&lp->tx_complete);
drivers/net/ieee802154/at86rf230.c:	struct completion state_complete;
drivers/net/ieee802154/at86rf230.c:	rc = wait_for_completion_timeout(&lp->state_complete,
drivers/net/ieee802154/at86rf230.c:	init_completion(&lp->state_complete);
drivers/net/ieee802154/ca8210.c: * @spi_transfer_complete:  completion object for a single spi_transfer
drivers/net/ieee802154/ca8210.c: * @sync_exchange_complete: completion object for a complete synchronous API
drivers/net/ieee802154/ca8210.c:	struct completion ca8210_is_awake;
drivers/net/ieee802154/ca8210.c:	struct completion spi_transfer_complete, sync_exchange_complete;
drivers/net/ieee802154/ca8210.c:	reinit_completion(&priv->ca8210_is_awake);
drivers/net/ieee802154/ca8210.c:	status = wait_for_completion_interruptible_timeout(
drivers/net/ieee802154/ca8210.c:	reinit_completion(&priv->spi_transfer_complete);
drivers/net/ieee802154/ca8210.c:		reinit_completion(&priv->sync_exchange_complete);
drivers/net/ieee802154/ca8210.c:		reinit_completion(&priv->spi_transfer_complete);
drivers/net/ieee802154/ca8210.c:		wait_remaining = wait_for_completion_interruptible_timeout(
drivers/net/ieee802154/ca8210.c:	wait_remaining = wait_for_completion_interruptible_timeout(
drivers/net/ieee802154/ca8210.c:	init_completion(&priv->ca8210_is_awake);
drivers/net/ieee802154/ca8210.c:	init_completion(&priv->spi_transfer_complete);
drivers/net/ieee802154/ca8210.c:	init_completion(&priv->sync_exchange_complete);
drivers/net/ieee802154/cc2520.c:	struct completion tx_complete;	/* Work completion for Tx */
drivers/net/ieee802154/cc2520.c:	rc = wait_for_completion_interruptible(&priv->tx_complete);
drivers/net/ieee802154/cc2520.c:	init_completion(&priv->tx_complete);
drivers/net/ipa/gsi.c:#include <linux/completion.h>
drivers/net/ipa/gsi.c: * to the channel TRE whose completion the event represents.
drivers/net/ipa/gsi.c: * the completion of the transfer operation generates an entry (and possibly
drivers/net/ipa/gsi.c: * to signal completion of channel transfers.
drivers/net/ipa/gsi.c: * in order.  Completion of one entry implies the completion of all preceding
drivers/net/ipa/gsi.c: * entries.  A single completion interrupt can therefore communicate the
drivers/net/ipa/gsi.c: * completion of many transfers.
drivers/net/ipa/gsi.c:/* Event ring commands are performed one at a time.  Their completion
drivers/net/ipa/gsi.c:/* Channel commands are performed one at a time.  Their completion is
drivers/net/ipa/gsi.c: * completion to be signaled.  Returns true if the command completes
drivers/net/ipa/gsi.c:	struct completion *completion = &gsi->completion;
drivers/net/ipa/gsi.c:	reinit_completion(completion);
drivers/net/ipa/gsi.c:	return !!wait_for_completion_timeout(completion, timeout);
drivers/net/ipa/gsi.c:	/* Enable the completion interrupt for the command */
drivers/net/ipa/gsi.c:	/* Enable the completion interrupt for the command */
drivers/net/ipa/gsi.c:/* Find the transaction whose completion indicates a channel is quiesced */
drivers/net/ipa/gsi.c:		wait_for_completion(&trans->completion);
drivers/net/ipa/gsi.c:	/* Enable NAPI and the completion interrupt */
drivers/net/ipa/gsi.c:	/* Disable the completion interrupt and NAPI if successful */
drivers/net/ipa/gsi.c:		complete(&gsi->completion);
drivers/net/ipa/gsi.c:		complete(&gsi->completion);
drivers/net/ipa/gsi.c:		complete(&gsi->completion);
drivers/net/ipa/gsi.c:		complete(&gsi->completion);
drivers/net/ipa/gsi.c:	/* This interrupt is used to handle completions of GENERIC GSI
drivers/net/ipa/gsi.c:	complete(&gsi->completion);
drivers/net/ipa/gsi.c:/* I/O completion interrupt event */
drivers/net/ipa/gsi.c:/* Return the transaction associated with a transfer completion event */
drivers/net/ipa/gsi.c:	 * the number of transfers and bytes this completion represents.
drivers/net/ipa/gsi.c:	 * the number of transactions and bytes this completion represents
drivers/net/ipa/gsi.c: * completion processing and retire/free the transaction.
drivers/net/ipa/gsi.c:	init_completion(&gsi->completion);
drivers/net/ipa/gsi.c: * slots for writing completion information.  So the hardware limit
drivers/net/ipa/gsi.h:#include <linux/completion.h>
drivers/net/ipa/gsi.h:	struct completion completion;	/* Signals GSI command completion */
drivers/net/ipa/gsi_reg.h: * @GSI_IEOB:			Transfer (TRE) completion
drivers/net/ipa/gsi_trans.c: * performed strictly in order, signaling the completion of just the last
drivers/net/ipa/gsi_trans.c:	/* The completion event will indicate the last TRE used */
drivers/net/ipa/gsi_trans.c:	init_completion(&trans->completion);
drivers/net/ipa/gsi_trans.c:		/* All transactions end in a transfer completion interrupt */
drivers/net/ipa/gsi_trans.c:	wait_for_completion(&trans->completion);
drivers/net/ipa/gsi_trans.c:/* Process the completion of a transaction; called while polling */
drivers/net/ipa/gsi_trans.c:	complete(&trans->completion);
drivers/net/ipa/gsi_trans.c:	/* A completion event contains a pointer to the TRE that caused
drivers/net/ipa/gsi_trans.h:#include <linux/completion.h>
drivers/net/ipa/gsi_trans.h: * @completion:	Completed when the transaction completes
drivers/net/ipa/gsi_trans.h:	struct completion completion;
drivers/net/ipa/ipa.h: * @completion:		Used to signal pipeline clear transfer complete
drivers/net/ipa/ipa.h:	struct completion completion;
drivers/net/ipa/ipa_cmd.c: * Commands do not require a transaction completion callback, and are
drivers/net/ipa/ipa_cmd.c:	reinit_completion(&ipa->completion);
drivers/net/ipa/ipa_cmd.c:	 * command requests that status be generated on completion of
drivers/net/ipa/ipa_cmd.c:	wait_for_completion(&ipa->completion);
drivers/net/ipa/ipa_endpoint.c:		complete(&ipa->completion);
drivers/net/ipa/ipa_gsi.h: * ipa_gsi_trans_complete() - GSI transaction completion callback
drivers/net/ipa/ipa_gsi.h: * ipa_gsi_channel_tx_completed() - GSI transaction completion callback
drivers/net/ipa/ipa_gsi.h: * has reported the completion of some number of transactions.
drivers/net/ipa/ipa_interrupt.c: * transfer completions), IPA interrupts are related to other events related
drivers/net/ipa/ipa_main.c:	init_completion(&ipa->completion);
drivers/net/ipa/ipa_qmi.c:	complete(&txn->completion);
drivers/net/mctp/mctp-i2c.c:	struct completion rx_done;
drivers/net/mctp/mctp-i2c.c:		reinit_completion(&midev->rx_done);
drivers/net/mctp/mctp-i2c.c:	init_completion(&midev->rx_done);
drivers/net/mctp/mctp-i2c.c:	wait_for_completion(&midev->rx_done);
drivers/net/netdevsim/bus.c:#include <linux/completion.h>
drivers/net/netdevsim/bus.c:static DECLARE_COMPLETION(nsim_bus_devs_released);
drivers/net/netdevsim/bus.c:	wait_for_completion(&nsim_bus_devs_released);
drivers/net/phy/micrel.c:static int ksz9x31_cable_test_wait_for_completion(struct phy_device *phydev)
drivers/net/phy/micrel.c:	ret = ksz9x31_cable_test_wait_for_completion(phydev);
drivers/net/phy/micrel.c:static int ksz886x_cable_test_wait_for_completion(struct phy_device *phydev)
drivers/net/phy/micrel.c:	ret = ksz886x_cable_test_wait_for_completion(phydev);
drivers/net/phy/micrel.c:	ret = ksz886x_cable_test_wait_for_completion(phydev);
drivers/net/phy/microchip_t1.c:	/* Wait for cable diag test completion */
drivers/net/phy/motorcomm.c: * If it is reset, it will wait for completion.
drivers/net/phy/qcom/at803x.c:	ret = at803x_cdt_wait_for_completion(phydev, AT803X_CDT_ENABLE_TEST);
drivers/net/phy/qcom/qcom-phy-lib.c:int at803x_cdt_wait_for_completion(struct phy_device *phydev,
drivers/net/phy/qcom/qcom-phy-lib.c:EXPORT_SYMBOL_GPL(at803x_cdt_wait_for_completion);
drivers/net/phy/qcom/qcom-phy-lib.c:	ret = at803x_cdt_wait_for_completion(phydev, QCA808X_CDT_ENABLE_TEST);
drivers/net/phy/qcom/qcom.h:/* Added for reference of existence but should be handled by wait_for_completion already */
drivers/net/phy/qcom/qcom.h:int at803x_cdt_wait_for_completion(struct phy_device *phydev,
drivers/net/plip/plip.c:#include <linux/completion.h>
drivers/net/plip/plip.c:	struct completion killed_timer_cmp;
drivers/net/plip/plip.c:		init_completion(&nl->killed_timer_cmp);
drivers/net/plip/plip.c:		wait_for_completion(&nl->killed_timer_cmp);
drivers/net/ppp/ppp_async.c:	struct completion dead;
drivers/net/ppp/ppp_async.c:	init_completion(&ap->dead);
drivers/net/ppp/ppp_async.c:		wait_for_completion(&ap->dead);
drivers/net/ppp/ppp_synctty.c:#include <linux/completion.h>
drivers/net/ppp/ppp_synctty.c:	struct completion dead_cmp;
drivers/net/ppp/ppp_synctty.c:	init_completion(&ap->dead_cmp);
drivers/net/ppp/ppp_synctty.c:		wait_for_completion(&ap->dead_cmp);
drivers/net/usb/lan78xx.c:					    "timeout on OTP_PWR_DN completion");
drivers/net/usb/lan78xx.c:					    "Timeout on OTP_STATUS completion");
drivers/net/usb/lan78xx.c:				    "timeout on completion of LiteReset");
drivers/net/usb/lan78xx.c:			  "waited for %d urb completions", temp);
drivers/net/usb/lan78xx.c:	 * temporary queue. Rx URB completions will continue to add
drivers/net/usb/rndis_host.c: * RNDIS notifications from device: command completion; "reverse"
drivers/net/usb/rndis_host.c:	rsp = le32_to_cpu(buf->msg_type) | RNDIS_MSG_COMPLETION;
drivers/net/usb/smsc75xx.c:		netdev_warn(dev->net, "timeout on completion of Lite Reset\n");
drivers/net/usb/smsc95xx.c:	/* Initiate async writes, as we can't wait for completion here */
drivers/net/usb/smsc95xx.c:		netdev_warn(dev->net, "timeout waiting for completion of Lite Reset\n");
drivers/net/usb/usbnet.c: * completion callbacks.  2.5 should have fixed those bugs...
drivers/net/usb/usbnet.c:// unlink pending rx/tx; completion handlers do all other cleanup
drivers/net/usb/usbnet.c:		  "waited for %d urb completions\n", temp);
drivers/net/usb/usbnet.c: * NOTE:  with 2.5 we could do more of this using completion callbacks,
drivers/net/usb/usbnet.c:// tasklet (work deferred from completions, in_irq) or timer
drivers/net/vmxnet3/vmxnet3_defs.h:	u32 cq:1;       /* completion request */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32 cq:1;       /* completion request */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32		type:7;       /* completion type */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32		type:7;       /* completion type */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32		type:7;       /* completion type */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32		type:7;       /* completion type */
drivers/net/vmxnet3/vmxnet3_defs.h:	u32		type:7;       /* completion type */
drivers/net/vmxnet3/vmxnet3_defs.h:/* a union for accessing all cmd/completion descriptors */
drivers/net/vmxnet3/vmxnet3_defs.h: VMXNET3_ERR_TXD_REUSE    = 0x80000001,  /* reuse TxDesc before tx completion */
drivers/net/vmxnet3/vmxnet3_defs.h:/* completion descriptor types */
drivers/net/vmxnet3/vmxnet3_defs.h:#define VMXNET3_CDTYPE_TXCOMP      0    /* Tx Completion Descriptor */
drivers/net/vmxnet3/vmxnet3_defs.h:#define VMXNET3_CDTYPE_RXCOMP      3    /* Rx Completion Descriptor */
drivers/net/vmxnet3/vmxnet3_defs.h:#define VMXNET3_CDTYPE_RXCOMP_LRO  4    /* Rx Completion Descriptor for LRO */
drivers/net/vmxnet3/vmxnet3_drv.c:	/* no out of order completion */
drivers/net/vmxnet3/vmxnet3_drv.c:				/* rx completion hasn't occurred */
drivers/net/vmxnet3/vmxnet3_drv.c:	 * tx completions in that queue as well
drivers/net/vmxnet3/vmxnet3_drv.c: * Handle completion interrupts on tx queues
drivers/net/vmxnet3/vmxnet3_drv.c: * Handle completion interrupts on rx queues. Returns whether or not the
drivers/net/vmxnet3/vmxnet3_drv.c:	 * completion.
drivers/net/vmxnet3/vmxnet3_drv.c:	 * completion.
drivers/net/vmxnet3/vmxnet3_drv.c:	 * completion.
drivers/net/vmxnet3/vmxnet3_ethtool.c:	 * completion.
drivers/net/wan/farsync.c:/* Since we need to set the high bit to enable the completion interrupt this
drivers/net/wan/farsync.c:	u16 txa_done;		/* Obsolete completion flags */
drivers/net/wan/farsync.c: *      error and not waiting for completion.
drivers/net/wan/farsync.c:	/* Check for rx completions on all ports on this card */
drivers/net/wireless/ath/ar5523/ar5523.c:#include <linux/completion.h>
drivers/net/wireless/ath/ar5523/ar5523.c:	if (!wait_for_completion_timeout(&cmd->done, 2 * HZ)) {
drivers/net/wireless/ath/ar5523/ar5523.c:	init_completion(&cmd->done);
drivers/net/wireless/ath/ar5523/ar5523.h:	struct completion	done;
drivers/net/wireless/ath/ar5523/ar5523_hw.h:#define	UATH_CFLAGS_RXMSG	0x02	/* chunk contains rx completion */
drivers/net/wireless/ath/ath10k/ce.c:		 * The SW completion index has caught up with the cached
drivers/net/wireless/ath/ath10k/ce.c:		 * version of the HW completion index.
drivers/net/wireless/ath/ath10k/ce.c:		 * Update the cached HW completion index to see whether
drivers/net/wireless/ath/ath10k/ce.c:		 * The SW completion index has caught up with the cached
drivers/net/wireless/ath/ath10k/ce.c:		 * version of the HW completion index.
drivers/net/wireless/ath/ath10k/ce.c:		 * Update the cached HW completion index to see whether
drivers/net/wireless/ath/ath10k/ce.h:	 * and completion processed by software.
drivers/net/wireless/ath/ath10k/ce.h:/* no interrupt on copy completion */
drivers/net/wireless/ath/ath10k/core.c:	reinit_completion(&ar->target_suspend);
drivers/net/wireless/ath/ath10k/core.c:	time_left = wait_for_completion_timeout(&ar->target_suspend, 1 * HZ);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->scan.started);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->target_suspend);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->driver_recovery);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->wow.wakeup_completed);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->thermal.wmi_sync);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->peer_stats_info_complete);
drivers/net/wireless/ath/ath10k/core.c:	init_completion(&ar->offchan_tx_completed);
drivers/net/wireless/ath/ath10k/core.h:#include <linux/completion.h>
drivers/net/wireless/ath/ath10k/core.h:	struct completion service_ready;
drivers/net/wireless/ath/ath10k/core.h:	struct completion unified_ready;
drivers/net/wireless/ath/ath10k/core.h:	struct completion barrier;
drivers/net/wireless/ath/ath10k/core.h:	struct completion radar_confirm;
drivers/net/wireless/ath/ath10k/core.h:	struct completion fw_stats_complete;
drivers/net/wireless/ath/ath10k/core.h:	struct completion tpc_complete;
drivers/net/wireless/ath/ath10k/core.h:	 * prevents completion timeouts and makes the driver more responsive to
drivers/net/wireless/ath/ath10k/core.h:	struct completion target_suspend;
drivers/net/wireless/ath/ath10k/core.h:	struct completion driver_recovery;
drivers/net/wireless/ath/ath10k/core.h:		struct completion started;
drivers/net/wireless/ath/ath10k/core.h:		struct completion completed;
drivers/net/wireless/ath/ath10k/core.h:		struct completion on_channel;
drivers/net/wireless/ath/ath10k/core.h:	struct completion install_key_done;
drivers/net/wireless/ath/ath10k/core.h:	struct completion vdev_setup_done;
drivers/net/wireless/ath/ath10k/core.h:	struct completion vdev_delete_done;
drivers/net/wireless/ath/ath10k/core.h:	struct completion peer_stats_info_complete;
drivers/net/wireless/ath/ath10k/core.h:	struct completion offchan_tx_completed;
drivers/net/wireless/ath/ath10k/core.h:	struct completion bss_survey_done;
drivers/net/wireless/ath/ath10k/core.h:	struct completion peer_delete_done;
drivers/net/wireless/ath/ath10k/debug.c:		reinit_completion(&ar->debug.fw_stats_complete);
drivers/net/wireless/ath/ath10k/debug.c:		wait_for_completion_timeout(&ar->debug.fw_stats_complete,
drivers/net/wireless/ath/ath10k/debug.c:	reinit_completion(&ar->debug.tpc_complete);
drivers/net/wireless/ath/ath10k/debug.c:	time_left = wait_for_completion_timeout(&ar->debug.tpc_complete,
drivers/net/wireless/ath/ath10k/debug.c:	reinit_completion(&ar->debug.tpc_complete);
drivers/net/wireless/ath/ath10k/debug.c:	time_left = wait_for_completion_timeout(&ar->debug.tpc_complete,
drivers/net/wireless/ath/ath10k/debug.c:	init_completion(&ar->debug.tpc_complete);
drivers/net/wireless/ath/ath10k/debug.c:	init_completion(&ar->debug.fw_stats_complete);
drivers/net/wireless/ath/ath10k/hif.h:	void *transfer_context; /* NULL = tx completion callback not called */
drivers/net/wireless/ath/ath10k/htc.c:void ath10k_htc_notify_tx_completion(struct ath10k_htc_ep *ep,
drivers/net/wireless/ath/ath10k/htc.c:	/* A corner case where the copy completion is reaching to host but still
drivers/net/wireless/ath/ath10k/htc.c:EXPORT_SYMBOL(ath10k_htc_notify_tx_completion);
drivers/net/wireless/ath/ath10k/htc.c:void ath10k_htc_tx_completion_handler(struct ath10k *ar, struct sk_buff *skb)
drivers/net/wireless/ath/ath10k/htc.c:	ath10k_htc_notify_tx_completion(ep, skb);
drivers/net/wireless/ath/ath10k/htc.c:	/* the skb now belongs to the completion handler */
drivers/net/wireless/ath/ath10k/htc.c:EXPORT_SYMBOL(ath10k_htc_tx_completion_handler);
drivers/net/wireless/ath/ath10k/htc.c:void ath10k_htc_rx_completion_handler(struct ath10k *ar, struct sk_buff *skb)
drivers/net/wireless/ath/ath10k/htc.c:	ath10k_dbg(ar, ATH10K_DBG_HTC, "htc rx completion ep %d skb %pK\n",
drivers/net/wireless/ath/ath10k/htc.c:	/* skb is now owned by the rx completion handler */
drivers/net/wireless/ath/ath10k/htc.c:EXPORT_SYMBOL(ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/htc.c:		if (completion_done(&htc->ctl_resp)) {
drivers/net/wireless/ath/ath10k/htc.c:				ath10k_htc_notify_tx_completion(ep, skb);
drivers/net/wireless/ath/ath10k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath10k/htc.c:		ath10k_warn(ar, "failed to receive control response completion, polling..\n");
drivers/net/wireless/ath/ath10k/htc.c:		wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath10k/htc.c:	reinit_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath10k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath10k/htc.c:	init_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath10k/htc.h:	struct completion ctl_resp;
drivers/net/wireless/ath/ath10k/htc.h:void ath10k_htc_tx_completion_handler(struct ath10k *ar, struct sk_buff *skb);
drivers/net/wireless/ath/ath10k/htc.h:void ath10k_htc_rx_completion_handler(struct ath10k *ar, struct sk_buff *skb);
drivers/net/wireless/ath/ath10k/htc.h:void ath10k_htc_notify_tx_completion(struct ath10k_htc_ep *ep,
drivers/net/wireless/ath/ath10k/htt.c:		HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION,
drivers/net/wireless/ath/ath10k/htt.c:		HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION,
drivers/net/wireless/ath/ath10k/htt.c:		HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION,
drivers/net/wireless/ath/ath10k/htt.c:				HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION,
drivers/net/wireless/ath/ath10k/htt.c:	init_completion(&htt->target_version_received);
drivers/net/wireless/ath/ath10k/htt.c:	status = wait_for_completion_timeout(&htt->target_version_received,
drivers/net/wireless/ath/ath10k/htt.h:	HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION,
drivers/net/wireless/ath/ath10k/htt.h:struct htt_mgmt_tx_completion {
drivers/net/wireless/ath/ath10k/htt.h:struct htt_data_tx_completion_ext {
drivers/net/wireless/ath/ath10k/htt.h: * @brief target -> host TX completion indication message definition
drivers/net/wireless/ath/ath10k/htt.h: * The following diagram shows the format of the TX completion indication sent
drivers/net/wireless/ath/ath10k/htt.h: *     Purpose: identifies this as HTT TX completion indication
drivers/net/wireless/ath/ath10k/htt.h: *     Purpose: the TX completion status of payload fragmentations descriptors
drivers/net/wireless/ath/ath10k/htt.h:struct htt_data_tx_completion {
drivers/net/wireless/ath/ath10k/htt.h:		struct htt_mgmt_tx_completion mgmt_tx_completion;
drivers/net/wireless/ath/ath10k/htt.h:		struct htt_data_tx_completion data_tx_completion;
drivers/net/wireless/ath/ath10k/htt.h:	struct completion target_version_received;
drivers/net/wireless/ath/ath10k/htt.h:	/* This is used to group tx/rx completions separately and process them
drivers/net/wireless/ath/ath10k/htt.h:void ath10k_htt_rx_pktlog_completion_handler(struct ath10k *ar,
drivers/net/wireless/ath/ath10k/htt_rx.c:	int status = MS(resp->data_tx_completion.flags, HTT_DATA_TX_STATUS);
drivers/net/wireless/ath/ath10k/htt_rx.c:		ath10k_warn(ar, "unhandled tx completion status %d\n", status);
drivers/net/wireless/ath/ath10k/htt_rx.c:	ath10k_dbg(ar, ATH10K_DBG_HTT, "htt tx completion num_msdus %d\n",
drivers/net/wireless/ath/ath10k/htt_rx.c:		   resp->data_tx_completion.num_msdus);
drivers/net/wireless/ath/ath10k/htt_rx.c:	msdu_count = resp->data_tx_completion.num_msdus;
drivers/net/wireless/ath/ath10k/htt_rx.c:	msdus = resp->data_tx_completion.msdus;
drivers/net/wireless/ath/ath10k/htt_rx.c:	if (!(resp->data_tx_completion.flags2 & HTT_TX_CMPL_FLAG_PPDU_DURATION_PRESENT))
drivers/net/wireless/ath/ath10k/htt_rx.c:	if (resp->data_tx_completion.flags2 &
drivers/net/wireless/ath/ath10k/htt_rx.c:	case HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION: {
drivers/net/wireless/ath/ath10k/htt_rx.c:		int status = __le32_to_cpu(resp->mgmt_tx_completion.status);
drivers/net/wireless/ath/ath10k/htt_rx.c:		int info = __le32_to_cpu(resp->mgmt_tx_completion.info);
drivers/net/wireless/ath/ath10k/htt_rx.c:		tx_done.msdu_id = __le32_to_cpu(resp->mgmt_tx_completion.desc_id);
drivers/net/wireless/ath/ath10k/htt_rx.c:			    (resp->mgmt_tx_completion.flags &
drivers/net/wireless/ath/ath10k/htt_rx.c:void ath10k_htt_rx_pktlog_completion_handler(struct ath10k *ar,
drivers/net/wireless/ath/ath10k/htt_rx.c:EXPORT_SYMBOL(ath10k_htt_rx_pktlog_completion_handler);
drivers/net/wireless/ath/ath10k/htt_rx.c:	 *  The napi poll() function may also process TX completions, in which
drivers/net/wireless/ath/ath10k/htt_tx.c:	 * received. That's why HTC tx completion handler itself is ignored by
drivers/net/wireless/ath/ath10k/htt_tx.c:	 * it to simply rely a regular tx completion with discard status.
drivers/net/wireless/ath/ath10k/htt_tx.c:	 * received. That's why HTC tx completion handler itself is ignored by
drivers/net/wireless/ath/ath10k/htt_tx.c:	 * it to simply rely a regular tx completion with discard status.
drivers/net/wireless/ath/ath10k/hw.c:	return (resp->data_tx_completion.flags2 & HTT_TX_CMPL_FLAG_DATA_RSSI);
drivers/net/wireless/ath/ath10k/hw.c:	return (resp->data_tx_completion.flags2 &
drivers/net/wireless/ath/ath10k/hw.c:	struct htt_data_tx_completion_ext extd;
drivers/net/wireless/ath/ath10k/hw.c:	if (resp->data_tx_completion.flags2 & HTT_TX_DATA_APPEND_RETRIES)
drivers/net/wireless/ath/ath10k/hw.c:	if (resp->data_tx_completion.flags2 & HTT_TX_DATA_APPEND_TIMESTAMP)
drivers/net/wireless/ath/ath10k/hw.h:struct htt_data_tx_completion_ext;
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath10k/mac.c:	time_left = wait_for_completion_timeout(&ar->install_key_done, 3 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:		time_left = wait_for_completion_timeout(&ar->peer_delete_done,
drivers/net/wireless/ath/ath10k/mac.c:		time_left = wait_for_completion_timeout
drivers/net/wireless/ath/ath10k/mac.c:	time_left = wait_for_completion_timeout(&ar->vdev_setup_done,
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath10k/mac.c:	 * never transmitted. We delete the peer upon tx completion.
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->offchan_tx_completed);
drivers/net/wireless/ath/ath10k/mac.c:		wait_for_completion_timeout(&ar->offchan_tx_completed, 3 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.completed, 3 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:		ath10k_warn(ar, "failed to receive scan abortion completion: timed out\n");
drivers/net/wireless/ath/ath10k/mac.c:	/* Scan state should be updated upon scan completion but in case
drivers/net/wireless/ath/ath10k/mac.c:	 * dropped the scan completion event delivery due to transport pipe
drivers/net/wireless/ath/ath10k/mac.c:		 * abortion while scan completion was being processed.
drivers/net/wireless/ath/ath10k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.started, 1 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:	/* Some firmware revisions don't wait for beacon tx completion before
drivers/net/wireless/ath/ath10k/mac.c:	 * Since there are no beacon tx completions (implicit nor explicit)
drivers/net/wireless/ath/ath10k/mac.c:		time_left = wait_for_completion_timeout(&ar->vdev_delete_done,
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath10k/mac.c:		reinit_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath10k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.on_channel, 3 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath10k/mac.c:	ret = wait_for_completion_timeout(&ar->bss_survey_done, 3 * HZ);
drivers/net/wireless/ath/ath10k/mac.c:	reinit_completion(&ar->peer_stats_info_complete);
drivers/net/wireless/ath/ath10k/mac.c:	time_left = wait_for_completion_timeout(&ar->peer_stats_info_complete, 3 * HZ);
drivers/net/wireless/ath/ath10k/pci.c:		/* no need to call tx completion for NULL pointers */
drivers/net/wireless/ath/ath10k/pci.c:		ath10k_htc_tx_completion_handler(ar, skb);
drivers/net/wireless/ath/ath10k/pci.c:	ath10k_pci_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/pci.c:	ath10k_pci_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/pci.c:				 ath10k_htt_rx_pktlog_completion_handler);
drivers/net/wireless/ath/ath10k/pci.c:		/* no need to call tx completion for NULL pointers */
drivers/net/wireless/ath/ath10k/pci.c:		 * Decide whether to actually poll for completions, or just
drivers/net/wireless/ath/ath10k/pci.c:		ath10k_htc_tx_completion_handler(ar, skb);
drivers/net/wireless/ath/ath10k/pci.c: * not yet processed are on a completion queue. They
drivers/net/wireless/ath/ath10k/pci.c: * are handled when the completion thread shuts down.
drivers/net/wireless/ath/ath10k/qmi.c:#include <linux/completion.h>
drivers/net/wireless/ath/ath10k/sdio.c:	/* Free all packets that was not passed on to the RX completion
drivers/net/wireless/ath/ath10k/sdio.c:		ath10k_htc_notify_tx_completion(ep, skb);
drivers/net/wireless/ath/ath10k/sdio.c:				      struct completion *comp,
drivers/net/wireless/ath/ath10k/sdio.c:	struct completion irqs_disabled_comp;
drivers/net/wireless/ath/ath10k/sdio.c:	init_completion(&irqs_disabled_comp);
drivers/net/wireless/ath/ath10k/sdio.c:	/* Wait for the completion of the IRQ disable request.
drivers/net/wireless/ath/ath10k/sdio.c:	ret = wait_for_completion_timeout(&irqs_disabled_comp,
drivers/net/wireless/ath/ath10k/sdio.c:			ath10k_htc_notify_tx_completion(ep, req->skb);
drivers/net/wireless/ath/ath10k/sdio.h:	 * If not, the eid is not applicable an the TX completion handler
drivers/net/wireless/ath/ath10k/sdio.h:	/* Completion that (if set) will be invoked for non HTC requests
drivers/net/wireless/ath/ath10k/sdio.h:	struct completion *comp;
drivers/net/wireless/ath/ath10k/snoc.c:	ath10k_snoc_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/snoc.c:	ath10k_snoc_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/snoc.c:	ath10k_snoc_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);
drivers/net/wireless/ath/ath10k/snoc.c:		ath10k_htc_tx_completion_handler(ar, skb);
drivers/net/wireless/ath/ath10k/snoc.c:		ath10k_htc_tx_completion_handler(ar, skb);
drivers/net/wireless/ath/ath10k/snoc.c:	reinit_completion(&ar->driver_recovery);
drivers/net/wireless/ath/ath10k/snoc.c:		wait_for_completion_timeout(&ar->driver_recovery, 3 * HZ);
drivers/net/wireless/ath/ath10k/thermal.c:	reinit_completion(&ar->thermal.wmi_sync);
drivers/net/wireless/ath/ath10k/thermal.c:	time_left = wait_for_completion_timeout(&ar->thermal.wmi_sync,
drivers/net/wireless/ath/ath10k/thermal.h:	struct completion wmi_sync;
drivers/net/wireless/ath/ath10k/txrx.c:	/* If the original wait_for_completion() timed out before
drivers/net/wireless/ath/ath10k/txrx.c:		   "htt tx completion msdu_id %u status %d\n",
drivers/net/wireless/ath/ath10k/txrx.c:		ath10k_warn(ar, "received tx completion for invalid msdu_id: %d\n",
drivers/net/wireless/ath/ath10k/usb.c:/* hif usb rx/tx completion functions */
drivers/net/wireless/ath/ath10k/usb.c:	ath10k_htc_notify_tx_completion(ep, skb);
drivers/net/wireless/ath/ath10k/wmi-tlv.c:	case WMI_TLV_MGMT_TX_COMPLETION_EVENTID:
drivers/net/wireless/ath/ath10k/wmi-tlv.c:	case WMI_TLV_MGMT_TX_BUNDLE_COMPLETION_EVENTID:
drivers/net/wireless/ath/ath10k/wmi-tlv.h:	WMI_TLV_MGMT_TX_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath10k/wmi-tlv.h:	WMI_TLV_MGMT_TX_BUNDLE_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath10k/wmi.c:	time_left = wait_for_completion_timeout(&ar->wmi.service_ready,
drivers/net/wireless/ath/ath10k/wmi.c:		ath10k_warn(ar, "failed to receive service ready completion, polling..\n");
drivers/net/wireless/ath/ath10k/wmi.c:		time_left = wait_for_completion_timeout(&ar->wmi.service_ready,
drivers/net/wireless/ath/ath10k/wmi.c:		ath10k_warn(ar, "service ready completion received, continuing normally\n");
drivers/net/wireless/ath/ath10k/wmi.c:	time_left = wait_for_completion_timeout(&ar->wmi.unified_ready,
drivers/net/wireless/ath/ath10k/wmi.c:			       enum wmi_scan_completion_reason reason)
drivers/net/wireless/ath/ath10k/wmi.c:	enum wmi_scan_completion_reason reason;
drivers/net/wireless/ath/ath10k/wmi.c:		ath10k_warn(ar, "received mgmt tx completion for invalid msdu_id: %d\n",
drivers/net/wireless/ath/ath10k/wmi.c:	ath10k_dbg(ar, ATH10K_DBG_WMI, "wmi tlv evnt mgmt tx completion\n");
drivers/net/wireless/ath/ath10k/wmi.c:	ath10k_dbg(ar, ATH10K_DBG_WMI, "wmi tlv event bundle mgmt tx completion\n");
drivers/net/wireless/ath/ath10k/wmi.c:		 * do the completion, so don't return here.
drivers/net/wireless/ath/ath10k/wmi.c:		/* There are no completions for beacons so wait for next SWBA
drivers/net/wireless/ath/ath10k/wmi.c:	reinit_completion(&ar->wmi.radar_confirm);
drivers/net/wireless/ath/ath10k/wmi.c:	time_left = wait_for_completion_timeout(&ar->wmi.radar_confirm,
drivers/net/wireless/ath/ath10k/wmi.c:	reinit_completion(&ar->wmi.barrier);
drivers/net/wireless/ath/ath10k/wmi.c:	time_left = wait_for_completion_timeout(&ar->wmi.barrier,
drivers/net/wireless/ath/ath10k/wmi.c:	init_completion(&ar->wmi.service_ready);
drivers/net/wireless/ath/ath10k/wmi.c:	init_completion(&ar->wmi.unified_ready);
drivers/net/wireless/ath/ath10k/wmi.c:	init_completion(&ar->wmi.barrier);
drivers/net/wireless/ath/ath10k/wmi.c:	init_completion(&ar->wmi.radar_confirm);
drivers/net/wireless/ath/ath10k/wmi.h: * completion with a timedout reason.
drivers/net/wireless/ath/ath10k/wmi.h:enum wmi_scan_completion_reason {
drivers/net/wireless/ath/ath10k/wow.c:	reinit_completion(&ar->target_suspend);
drivers/net/wireless/ath/ath10k/wow.c:	ret = wait_for_completion_timeout(&ar->target_suspend, 3 * HZ);
drivers/net/wireless/ath/ath10k/wow.c:		ath10k_warn(ar, "timed out while waiting for suspend completion\n");
drivers/net/wireless/ath/ath10k/wow.c:	reinit_completion(&ar->wow.wakeup_completed);
drivers/net/wireless/ath/ath10k/wow.c:	ret = wait_for_completion_timeout(&ar->wow.wakeup_completed, 3 * HZ);
drivers/net/wireless/ath/ath10k/wow.c:		ath10k_warn(ar, "timed out while waiting for wow wakeup completion\n");
drivers/net/wireless/ath/ath10k/wow.h:	struct completion wakeup_completed;
drivers/net/wireless/ath/ath11k/ahb.c:	"wbm2host-tx-completions-ring3",
drivers/net/wireless/ath/ath11k/ahb.c:	"wbm2host-tx-completions-ring2",
drivers/net/wireless/ath/ath11k/ahb.c:	"wbm2host-tx-completions-ring1",
drivers/net/wireless/ath/ath11k/ahb.c:	wbm2host_tx_completions_ring3,
drivers/net/wireless/ath/ath11k/ahb.c:	wbm2host_tx_completions_ring2,
drivers/net/wireless/ath/ath11k/ahb.c:	wbm2host_tx_completions_ring1,
drivers/net/wireless/ath/ath11k/ahb.c:					wbm2host_tx_completions_ring1 - j;
drivers/net/wireless/ath/ath11k/ahb.c:	reinit_completion(&ab->wow.wakeup_completed);
drivers/net/wireless/ath/ath11k/ahb.c:	ret = wait_for_completion_timeout(&ab->wow.wakeup_completed, 3 * HZ);
drivers/net/wireless/ath/ath11k/ahb.c:		ath11k_warn(ab, "timed out while waiting for wow wakeup completion\n");
drivers/net/wireless/ath/ath11k/ahb.c:		left = wait_for_completion_timeout(&ab->driver_recovery,
drivers/net/wireless/ath/ath11k/ahb.c:			ath11k_warn(ab, "failed to receive recovery response completion\n");
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.recv_cb = ath11k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:		.send_cb = ath11k_htc_tx_completion_handler,
drivers/net/wireless/ath/ath11k/ce.c:	/* Check if some entries could be regained by handling tx completion if
drivers/net/wireless/ath/ath11k/ce.h:/* no interrupt on copy completion */
drivers/net/wireless/ath/ath11k/ce.h:/* Threshold to poll for tx completion in case of Interrupt disabled CE's */
drivers/net/wireless/ath/ath11k/ce.h:	 * and completion processed by software.
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ar->fw_stats_complete);
drivers/net/wireless/ath/ath11k/core.c:	reinit_completion(&ab->driver_recovery);
drivers/net/wireless/ath/ath11k/core.c:		reinit_completion(&ab->reset_complete);
drivers/net/wireless/ath/ath11k/core.c:		time_left = wait_for_completion_timeout(&ab->reset_complete,
drivers/net/wireless/ath/ath11k/core.c:	reinit_completion(&ab->recovery_start);
drivers/net/wireless/ath/ath11k/core.c:	reinit_completion(&ab->reconfigure_complete);
drivers/net/wireless/ath/ath11k/core.c:	time_left = wait_for_completion_timeout(&ab->recovery_start,
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->driver_recovery);
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->reset_complete);
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->reconfigure_complete);
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->recovery_start);
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->htc_suspend);
drivers/net/wireless/ath/ath11k/core.c:	init_completion(&ab->wow.wakeup_completed);
drivers/net/wireless/ath/ath11k/core.h:		struct completion started;
drivers/net/wireless/ath/ath11k/core.h:		struct completion completed;
drivers/net/wireless/ath/ath11k/core.h:		struct completion on_channel;
drivers/net/wireless/ath/ath11k/core.h:	struct completion peer_assoc_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion peer_delete_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion install_key_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion vdev_setup_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion vdev_delete_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion bss_survey_done;
drivers/net/wireless/ath/ath11k/core.h:	struct completion target_suspend;
drivers/net/wireless/ath/ath11k/core.h:	struct completion fw_mode_reset;
drivers/net/wireless/ath/ath11k/core.h:	struct completion completed_11d_scan;
drivers/net/wireless/ath/ath11k/core.h:	struct completion fw_stats_complete;
drivers/net/wireless/ath/ath11k/core.h:	struct completion fw_ready;
drivers/net/wireless/ath/ath11k/core.h:		struct completion wakeup_completed;
drivers/net/wireless/ath/ath11k/core.h:	struct completion driver_recovery;
drivers/net/wireless/ath/ath11k/core.h:	struct completion reset_complete;
drivers/net/wireless/ath/ath11k/core.h:	struct completion reconfigure_complete;
drivers/net/wireless/ath/ath11k/core.h:	struct completion recovery_start;
drivers/net/wireless/ath/ath11k/core.h:	struct completion htc_suspend;
drivers/net/wireless/ath/ath11k/debugfs.c:	reinit_completion(&ar->fw_stats_complete);
drivers/net/wireless/ath/ath11k/debugfs.c:	time_left = wait_for_completion_timeout(&ar->fw_stats_complete, 1 * HZ);
drivers/net/wireless/ath/ath11k/debugfs.h:	struct completion cmpln;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	bool send_completion = false;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:		send_completion = true;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	if (send_completion)
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	init_completion(&stats_req->cmpln);
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	while (!wait_for_completion_timeout(&stats_req->cmpln, 3 * HZ)) {
drivers/net/wireless/ath/ath11k/dp.c:		/* Allocate the reo dst and tx completion rings from cacheable memory */
drivers/net/wireless/ath/ath11k/dp.c:			ath11k_dp_tx_completion_handler(ab, i);
drivers/net/wireless/ath/ath11k/dp.h:	struct completion htt_tgt_version_received;
drivers/net/wireless/ath/ath11k/dp.h:/* HTT tx completion is overlaid in wbm_release_ring */
drivers/net/wireless/ath/ath11k/dp.h:struct htt_tx_wbm_completion {
drivers/net/wireless/ath/ath11k/dp.h: *        Indicates the completion of the stats entry, this will be the last
drivers/net/wireless/ath/ath11k/dp_tx.c:		ath11k_warn(ab, "tx completion for unknown msdu_id %d\n",
drivers/net/wireless/ath/ath11k/dp_tx.c:		ath11k_warn(ab, "htt tx completion for unknown msdu_id %d\n",
drivers/net/wireless/ath/ath11k/dp_tx.c:	struct htt_tx_wbm_completion *status_desc;
drivers/net/wireless/ath/ath11k/dp_tx.c:void ath11k_dp_tx_completion_handler(struct ath11k_base *ab, int ring_id)
drivers/net/wireless/ath/ath11k/dp_tx.c:			ath11k_warn(ab, "tx completion for unknown msdu_id %d\n",
drivers/net/wireless/ath/ath11k/dp_tx.c:	init_completion(&dp->htt_tgt_version_received);
drivers/net/wireless/ath/ath11k/dp_tx.c:	ret = wait_for_completion_timeout(&dp->htt_tgt_version_received,
drivers/net/wireless/ath/ath11k/dp_tx.h:void ath11k_dp_tx_completion_handler(struct ath11k_base *ab, int ring_id);
drivers/net/wireless/ath/ath11k/hal.h: * @HAL_RX_BUF_RBM_SW0_BM: For Tx completion -- returned to host
drivers/net/wireless/ath/ath11k/hal.h: * @HAL_RX_BUF_RBM_SW1_BM: For Tx completion -- returned to host
drivers/net/wireless/ath/ath11k/hal.h: * @HAL_RX_BUF_RBM_SW2_BM: For Tx completion -- returned to host
drivers/net/wireless/ath/ath11k/hal.h: * @HAL_RX_BUF_RBM_SW4_BM: For Tx completion -- returned to host
drivers/net/wireless/ath/ath11k/hal_desc.h: * for software based completions.
drivers/net/wireless/ath/ath11k/htc.c:void ath11k_htc_tx_completion_handler(struct ath11k_base *ab,
drivers/net/wireless/ath/ath11k/htc.c:void ath11k_htc_rx_completion_handler(struct ath11k_base *ab,
drivers/net/wireless/ath/ath11k/htc.c:			if (completion_done(&htc->ctl_resp)) {
drivers/net/wireless/ath/ath11k/htc.c:	/* poll tx completion for interrupt disabled CE's */
drivers/net/wireless/ath/ath11k/htc.c:	/* skb is now owned by the rx completion handler */
drivers/net/wireless/ath/ath11k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath11k/htc.c:		ath11k_warn(ab, "failed to receive control response completion, polling..\n");
drivers/net/wireless/ath/ath11k/htc.c:			wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath11k/htc.c:	reinit_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath11k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath11k/htc.c:	init_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath11k/htc.h:	struct completion ctl_resp;
drivers/net/wireless/ath/ath11k/htc.h:void ath11k_htc_rx_completion_handler(struct ath11k_base *ar,
drivers/net/wireless/ath/ath11k/htc.h:void ath11k_htc_tx_completion_handler(struct ath11k_base *ab,
drivers/net/wireless/ath/ath11k/mac.c:	if (!wait_for_completion_timeout(&ar->vdev_setup_done,
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath11k/mac.c:	time_left = wait_for_completion_timeout(&ar->vdev_delete_done,
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->peer_assoc_done);
drivers/net/wireless/ath/ath11k/mac.c:	if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ)) {
drivers/net/wireless/ath/ath11k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.completed, 3 * HZ);
drivers/net/wireless/ath/ath11k/mac.c:	/* Scan state should be updated upon scan completion but in case
drivers/net/wireless/ath/ath11k/mac.c:	 * dropped the scan completion event delivery due to transport pipe
drivers/net/wireless/ath/ath11k/mac.c:		 * abortion while scan completion was being processed.
drivers/net/wireless/ath/ath11k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.started, timeout);
drivers/net/wireless/ath/ath11k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath11k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath11k/mac.c:	if (!wait_for_completion_timeout(&ar->install_key_done, 1 * HZ))
drivers/net/wireless/ath/ath11k/mac.c:	if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ)) {
drivers/net/wireless/ath/ath11k/mac.c:			if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ))
drivers/net/wireless/ath/ath11k/mac.c:	wait_for_completion_timeout(&ab->reconfigure_complete,
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath11k/mac.c:	time_left = wait_for_completion_timeout(&ar->vdev_delete_done,
drivers/net/wireless/ath/ath11k/mac.c:			reinit_completion(&ar->completed_11d_scan);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath11k/mac.c:	ret = wait_for_completion_timeout(&ar->bss_survey_done, 3 * HZ);
drivers/net/wireless/ath/ath11k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath11k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath11k/mac.c:		reinit_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath11k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.on_channel, 3 * HZ);
drivers/net/wireless/ath/ath11k/mac.c:	reinit_completion(&ar->fw_stats_complete);
drivers/net/wireless/ath/ath11k/mac.c:	time_left = wait_for_completion_timeout(&ar->fw_stats_complete,
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->peer_assoc_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->scan.started);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->thermal.wmi_sync);
drivers/net/wireless/ath/ath11k/mac.c:		init_completion(&ar->completed_11d_scan);
drivers/net/wireless/ath/ath11k/pcic.c:	"wbm2host-tx-completions-ring3",
drivers/net/wireless/ath/ath11k/pcic.c:	"wbm2host-tx-completions-ring2",
drivers/net/wireless/ath/ath11k/pcic.c:	"wbm2host-tx-completions-ring1",
drivers/net/wireless/ath/ath11k/peer.c:	time_left = wait_for_completion_timeout(&ar->peer_delete_done,
drivers/net/wireless/ath/ath11k/peer.c:	reinit_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath11k/qmi.c:			 * boot completion, there is no need to process
drivers/net/wireless/ath/ath11k/reg.c:		left = wait_for_completion_timeout(&ar->completed_11d_scan,
drivers/net/wireless/ath/ath11k/reg.c:		left = wait_for_completion_timeout(&ar->scan.completed,
drivers/net/wireless/ath/ath11k/thermal.c:	reinit_completion(&ar->thermal.wmi_sync);
drivers/net/wireless/ath/ath11k/thermal.c:	time_left = wait_for_completion_timeout(&ar->thermal.wmi_sync,
drivers/net/wireless/ath/ath11k/thermal.h:	struct completion wmi_sync;
drivers/net/wireless/ath/ath11k/wmi.c:#include <linux/completion.h>
drivers/net/wireless/ath/ath11k/wmi.c:	time_left = wait_for_completion_timeout(&ab->wmi_ab.service_ready,
drivers/net/wireless/ath/ath11k/wmi.c:	time_left = wait_for_completion_timeout(&ab->wmi_ab.unified_ready,
drivers/net/wireless/ath/ath11k/wmi.c:			       enum wmi_scan_completion_reason reason)
drivers/net/wireless/ath/ath11k/wmi.c:	case WMI_MGMT_TX_COMPLETION_EVENTID:
drivers/net/wireless/ath/ath11k/wmi.c:	init_completion(&ab->wmi_ab.service_ready);
drivers/net/wireless/ath/ath11k/wmi.c:	init_completion(&ab->wmi_ab.unified_ready);
drivers/net/wireless/ath/ath11k/wmi.h:	WMI_MGMT_TX_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath11k/wmi.h:	WMI_MGMT_TX_BUNDLE_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath11k/wmi.h:	WMI_OFFCHAN_DATA_TX_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath11k/wmi.h: * completion with a timedout reason.
drivers/net/wireless/ath/ath11k/wmi.h:enum wmi_scan_completion_reason {
drivers/net/wireless/ath/ath11k/wmi.h:	struct completion service_ready;
drivers/net/wireless/ath/ath11k/wmi.h:	struct completion unified_ready;
drivers/net/wireless/ath/ath11k/wow.c:		reinit_completion(&ab->htc_suspend);
drivers/net/wireless/ath/ath11k/wow.c:		ret = wait_for_completion_timeout(&ab->htc_suspend, 3 * HZ);
drivers/net/wireless/ath/ath11k/wow.c:				    "timed out while waiting for htc suspend completion\n");
drivers/net/wireless/ath/ath11k/wow.c:	reinit_completion(&ab->wow.wakeup_completed);
drivers/net/wireless/ath/ath11k/wow.c:	ret = wait_for_completion_timeout(&ab->wow.wakeup_completed, 3 * HZ);
drivers/net/wireless/ath/ath11k/wow.c:		ath11k_warn(ab, "timed out while waiting for wow wakeup completion\n");
drivers/net/wireless/ath/ath11k/wow.h:	struct completion wakeup_completed;
drivers/net/wireless/ath/ath12k/ce.c:		.recv_cb = ath12k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath12k/ce.c:		.recv_cb = ath12k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath12k/ce.c:		.recv_cb = ath12k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath12k/ce.c:		.recv_cb = ath12k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath12k/ce.c:		.recv_cb = ath12k_htc_rx_completion_handler,
drivers/net/wireless/ath/ath12k/ce.c:	/* Check if some entries could be regained by handling tx completion if
drivers/net/wireless/ath/ath12k/ce.h:/* no interrupt on copy completion */
drivers/net/wireless/ath/ath12k/ce.h:/* Threshold to poll for tx completion in case of Interrupt disabled CE's */
drivers/net/wireless/ath/ath12k/ce.h:	 * and completion processed by software.
drivers/net/wireless/ath/ath12k/core.c:	reinit_completion(&ab->restart_completed);
drivers/net/wireless/ath/ath12k/core.c:	time_left = wait_for_completion_timeout(&ab->restart_completed,
drivers/net/wireless/ath/ath12k/core.c:		reinit_completion(&ab->reset_complete);
drivers/net/wireless/ath/ath12k/core.c:		time_left = wait_for_completion_timeout(&ab->reset_complete,
drivers/net/wireless/ath/ath12k/core.c:	init_completion(&ab->driver_recovery);
drivers/net/wireless/ath/ath12k/core.c:	init_completion(&ab->reset_complete);
drivers/net/wireless/ath/ath12k/core.c:	init_completion(&ab->htc_suspend);
drivers/net/wireless/ath/ath12k/core.c:	init_completion(&ab->restart_completed);
drivers/net/wireless/ath/ath12k/core.c:	init_completion(&ab->wow.wakeup_completed);
drivers/net/wireless/ath/ath12k/core.h:		struct completion started;
drivers/net/wireless/ath/ath12k/core.h:		struct completion completed;
drivers/net/wireless/ath/ath12k/core.h:		struct completion on_channel;
drivers/net/wireless/ath/ath12k/core.h:	struct completion peer_assoc_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion peer_delete_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion install_key_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion vdev_setup_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion vdev_delete_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion bss_survey_done;
drivers/net/wireless/ath/ath12k/core.h:	struct completion target_suspend;
drivers/net/wireless/ath/ath12k/core.h:	struct completion fw_ready;
drivers/net/wireless/ath/ath12k/core.h:		struct completion wakeup_completed;
drivers/net/wireless/ath/ath12k/core.h:	struct completion driver_recovery;
drivers/net/wireless/ath/ath12k/core.h:	struct completion reset_complete;
drivers/net/wireless/ath/ath12k/core.h:	struct completion htc_suspend;
drivers/net/wireless/ath/ath12k/core.h:	struct completion restart_completed;
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c:	bool send_completion = false;
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c:		send_completion = true;
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c:	if (send_completion)
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c:	init_completion(&stats_req->htt_stats_rcvd);
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c:	if (!wait_for_completion_timeout(&stats_req->htt_stats_rcvd, 3 * HZ)) {
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.h: *        Indicates the completion of the stats entry, this will be the last
drivers/net/wireless/ath/ath12k/debugfs_htt_stats.h:	struct completion htt_stats_rcvd;
drivers/net/wireless/ath/ath12k/dp.c:		ath12k_dp_tx_completion_handler(ab, i);
drivers/net/wireless/ath/ath12k/dp.h:	struct hal_wbm_completion_ring_tx *tx_status;
drivers/net/wireless/ath/ath12k/dp.h:	struct completion htt_tgt_version_received;
drivers/net/wireless/ath/ath12k/dp.h:/* HTT tx completion is overlaid in wbm_release_ring */
drivers/net/wireless/ath/ath12k/dp.h:struct htt_tx_wbm_completion {
drivers/net/wireless/ath/ath12k/dp_tx.c:	struct htt_tx_wbm_completion *status_desc;
drivers/net/wireless/ath/ath12k/dp_tx.c:	/* NOTE: Tx rate status reporting. Tx completion status does not have
drivers/net/wireless/ath/ath12k/dp_tx.c:				      struct hal_wbm_completion_ring_tx *desc,
drivers/net/wireless/ath/ath12k/dp_tx.c:void ath12k_dp_tx_completion_handler(struct ath12k_base *ab, int ring_id)
drivers/net/wireless/ath/ath12k/dp_tx.c:		struct hal_wbm_completion_ring_tx *tx_status;
drivers/net/wireless/ath/ath12k/dp_tx.c:	init_completion(&dp->htt_tgt_version_received);
drivers/net/wireless/ath/ath12k/dp_tx.c:	ret = wait_for_completion_timeout(&dp->htt_tgt_version_received,
drivers/net/wireless/ath/ath12k/dp_tx.h:void ath12k_dp_tx_completion_handler(struct ath12k_base *ab, int ring_id);
drivers/net/wireless/ath/ath12k/hal_desc.h:struct hal_wbm_completion_ring_rx {
drivers/net/wireless/ath/ath12k/hal_desc.h:struct hal_wbm_completion_ring_tx {
drivers/net/wireless/ath/ath12k/hal_desc.h: * for software based completions.
drivers/net/wireless/ath/ath12k/htc.c:void ath12k_htc_rx_completion_handler(struct ath12k_base *ab,
drivers/net/wireless/ath/ath12k/htc.c:			if (completion_done(&htc->ctl_resp)) {
drivers/net/wireless/ath/ath12k/htc.c:	ath12k_dbg(ab, ATH12K_DBG_HTC, "htc rx completion ep %d skb %p\n",
drivers/net/wireless/ath/ath12k/htc.c:	/* poll tx completion for interrupt disabled CE's */
drivers/net/wireless/ath/ath12k/htc.c:	/* skb is now owned by the rx completion handler */
drivers/net/wireless/ath/ath12k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath12k/htc.c:		ath12k_warn(ab, "failed to receive control response completion, polling..\n");
drivers/net/wireless/ath/ath12k/htc.c:			wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath12k/htc.c:	reinit_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath12k/htc.c:	time_left = wait_for_completion_timeout(&htc->ctl_resp,
drivers/net/wireless/ath/ath12k/htc.c:	init_completion(&htc->ctl_resp);
drivers/net/wireless/ath/ath12k/htc.h:	struct completion ctl_resp;
drivers/net/wireless/ath/ath12k/htc.h:void ath12k_htc_rx_completion_handler(struct ath12k_base *ar,
drivers/net/wireless/ath/ath12k/mac.c:	if (!wait_for_completion_timeout(&ar->vdev_setup_done,
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	time_left = wait_for_completion_timeout(&ar->vdev_delete_done,
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->peer_assoc_done);
drivers/net/wireless/ath/ath12k/mac.c:	if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ)) {
drivers/net/wireless/ath/ath12k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.completed, 3 * HZ);
drivers/net/wireless/ath/ath12k/mac.c:	/* Scan state should be updated upon scan completion but in case
drivers/net/wireless/ath/ath12k/mac.c:	 * dropped the scan completion event delivery due to transport pipe
drivers/net/wireless/ath/ath12k/mac.c:		 * abortion while scan completion was being processed.
drivers/net/wireless/ath/ath12k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.started, 1 * HZ);
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath12k/mac.c:	if (!wait_for_completion_timeout(&ar->install_key_done, 1 * HZ))
drivers/net/wireless/ath/ath12k/mac.c:	if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ)) {
drivers/net/wireless/ath/ath12k/mac.c:			if (!wait_for_completion_timeout(&ar->peer_assoc_done, 1 * HZ))
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	time_left = wait_for_completion_timeout(&ar->vdev_delete_done,
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath12k/mac.c:	reinit_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath12k/mac.c:	ret = wait_for_completion_timeout(&ar->bss_survey_done, 3 * HZ);
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->scan.started);
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath12k/mac.c:		reinit_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath12k/mac.c:	ret = wait_for_completion_timeout(&ar->scan.on_channel, 3 * HZ);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->vdev_setup_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->vdev_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->peer_assoc_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->install_key_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->bss_survey_done);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->scan.started);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->scan.completed);
drivers/net/wireless/ath/ath12k/mac.c:	init_completion(&ar->scan.on_channel);
drivers/net/wireless/ath/ath12k/pci.c:	"wbm2host-tx-completions-ring4",
drivers/net/wireless/ath/ath12k/pci.c:	"wbm2host-tx-completions-ring3",
drivers/net/wireless/ath/ath12k/pci.c:	"wbm2host-tx-completions-ring2",
drivers/net/wireless/ath/ath12k/pci.c:	"wbm2host-tx-completions-ring1",
drivers/net/wireless/ath/ath12k/peer.c:	time_left = wait_for_completion_timeout(&ar->peer_delete_done,
drivers/net/wireless/ath/ath12k/peer.c:	reinit_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath12k/peer.c:		reinit_completion(&ar->peer_delete_done);
drivers/net/wireless/ath/ath12k/wmi.c:#include <linux/completion.h>
drivers/net/wireless/ath/ath12k/wmi.c:	time_left = wait_for_completion_timeout(&ab->wmi_ab.service_ready,
drivers/net/wireless/ath/ath12k/wmi.c:	time_left = wait_for_completion_timeout(&ab->wmi_ab.unified_ready,
drivers/net/wireless/ath/ath12k/wmi.c:			       enum wmi_scan_completion_reason reason)
drivers/net/wireless/ath/ath12k/wmi.c:	case WMI_MGMT_TX_COMPLETION_EVENTID:
drivers/net/wireless/ath/ath12k/wmi.c:	init_completion(&ab->wmi_ab.service_ready);
drivers/net/wireless/ath/ath12k/wmi.c:	init_completion(&ab->wmi_ab.unified_ready);
drivers/net/wireless/ath/ath12k/wmi.h:	WMI_MGMT_TX_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath12k/wmi.h:	WMI_MGMT_TX_BUNDLE_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath12k/wmi.h:	WMI_OFFCHAN_DATA_TX_COMPLETION_EVENTID,
drivers/net/wireless/ath/ath12k/wmi.h: * completion with a timedout reason.
drivers/net/wireless/ath/ath12k/wmi.h:enum wmi_scan_completion_reason {
drivers/net/wireless/ath/ath12k/wmi.h:	struct completion service_ready;
drivers/net/wireless/ath/ath12k/wmi.h:	struct completion unified_ready;
drivers/net/wireless/ath/ath12k/wow.c:		reinit_completion(&ab->htc_suspend);
drivers/net/wireless/ath/ath12k/wow.c:		ret = wait_for_completion_timeout(&ab->htc_suspend, 3 * HZ);
drivers/net/wireless/ath/ath12k/wow.c:				    "timed out while waiting for htc suspend completion\n");
drivers/net/wireless/ath/ath12k/wow.c:	reinit_completion(&ab->wow.wakeup_completed);
drivers/net/wireless/ath/ath12k/wow.c:	ret = wait_for_completion_timeout(&ab->wow.wakeup_completed, 3 * HZ);
drivers/net/wireless/ath/ath12k/wow.c:		ath12k_warn(ab, "timed out while waiting for wow wakeup completion\n");
drivers/net/wireless/ath/ath12k/wow.h:	struct completion wakeup_completed;
drivers/net/wireless/ath/ath5k/phy.c:	 * Enable calibration and wait until completion
drivers/net/wireless/ath/ath5k/phy.c:	 * Enable the PHY and wait until completion
drivers/net/wireless/ath/ath6kl/core.h:		struct completion fwlog_completion;
drivers/net/wireless/ath/ath6kl/debug.c:	complete(&ar->debug.fwlog_completion);
drivers/net/wireless/ath/ath6kl/debug.c:		init_completion(&ar->debug.fwlog_completion);
drivers/net/wireless/ath/ath6kl/debug.c:		ret = wait_for_completion_interruptible(
drivers/net/wireless/ath/ath6kl/debug.c:			&ar->debug.fwlog_completion);
drivers/net/wireless/ath/ath6kl/debug.c:	init_completion(&ar->debug.fwlog_completion);
drivers/net/wireless/ath/ath6kl/debug.c:	complete(&ar->debug.fwlog_completion);
drivers/net/wireless/ath/ath6kl/hif.c:	ath6kl_dbg(ATH6KL_DBG_HIF, "hif rw completion pkt 0x%p status %d\n",
drivers/net/wireless/ath/ath6kl/hif.c:	packet->completion(packet->context, packet);
drivers/net/wireless/ath/ath6kl/hif.c:		 * completion routine of the callers read request. This can
drivers/net/wireless/ath/ath6kl/hif.h: *             driver to indicate the completion of operation through the
drivers/net/wireless/ath/ath6kl/htc.h:/* extended setup completion message */
drivers/net/wireless/ath/ath6kl/htc.h:	/* completion status */
drivers/net/wireless/ath/ath6kl/htc.h:	void (*completion) (struct htc_target *, struct htc_packet *);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	packet->completion = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	/* do completion */
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	if (!packet->completion)
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		packet->completion = htc_tx_comp_handler;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:				packet->completion(packet->context, packet);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	send_pkt->completion = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:			packet->completion = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		/* cleanup any packets in sync completion queue */
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	packet->completion = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		tx_pkt->completion = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	/* Indicate to the target of the setup completion */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:static void do_send_completion(struct htc_endpoint *ep,
drivers/net/wireless/ath/ath6kl/htc_pipe.c:static void send_packet_completion(struct htc_target *target,
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	/* do completion */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	do_send_completion(ep, &container);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		/* store in look up queue to match completions */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:			send_packet_completion(target, packet);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		send_packet_completion(target, packet);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		send_packet_completion(target, packet);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	/* do completion on any packets that couldn't get in */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		do_send_completion(ep, pkt_queue);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:static void do_recv_completion(struct htc_endpoint *ep,
drivers/net/wireless/ath/ath6kl/htc_pipe.c:static void recv_packet_completion(struct htc_target *target,
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	/* do completion */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	do_recv_completion(ep, &container);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	recv_packet_completion(target, ep, packet);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		do_recv_completion(ep, &container);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		do_recv_completion(ep, pkt_queue);
drivers/net/wireless/ath/ath6kl/sdio.c:		 * FIXME: should we also call completion handler with
drivers/net/wireless/ath/ath6kl/txrx.c:	 * will happen in the TX completion callback.
drivers/net/wireless/ath/ath6kl/usb.c:	 * until all scheduled work runs to completion.
drivers/net/wireless/ath/ath6kl/usb.c:/* hif usb rx/tx completion functions */
drivers/net/wireless/ath/ath9k/ar9003_calib.c:		 * in the HW, poll for completion and then process
drivers/net/wireless/ath/ath9k/ath9k.h:#include <linux/completion.h>
drivers/net/wireless/ath/ath9k/ath9k.h:	struct completion paprd_complete;
drivers/net/wireless/ath/ath9k/ath9k.h:	struct completion go_beacon;
drivers/net/wireless/ath/ath9k/ath9k_pci_owl_loader.c:#include <linux/completion.h>
drivers/net/wireless/ath/ath9k/ath9k_pci_owl_loader.c:	struct completion eeprom_load;
drivers/net/wireless/ath/ath9k/ath9k_pci_owl_loader.c:	init_completion(&ctx->eeprom_load);
drivers/net/wireless/ath/ath9k/ath9k_pci_owl_loader.c:		wait_for_completion(&ctx->eeprom_load);
drivers/net/wireless/ath/ath9k/beacon.c:	/* EDMA devices check that in the tx completion function. */
drivers/net/wireless/ath/ath9k/channel.c:	init_completion(&sc->go_beacon);
drivers/net/wireless/ath/ath9k/hif_usb.c:		ath9k_htc_txcompletion_cb(cmd->hif_dev->htc_handle,
drivers/net/wireless/ath/ath9k/hif_usb.c:	ath9k_htc_txcompletion_cb(cmd->hif_dev->htc_handle,
drivers/net/wireless/ath/ath9k/hif_usb.c:		ath9k_htc_txcompletion_cb(hif_dev->htc_handle,
drivers/net/wireless/ath/ath9k/hif_usb.c:			ath9k_htc_txcompletion_cb(hif_dev->htc_handle,
drivers/net/wireless/ath/ath9k/hif_usb.c:	init_completion(&hif_dev->fw_done);
drivers/net/wireless/ath/ath9k/hif_usb.c:	wait_for_completion(&hif_dev->fw_done);
drivers/net/wireless/ath/ath9k/hif_usb.c:	wait_for_completion(&hif_dev->fw_done);
drivers/net/wireless/ath/ath9k/hif_usb.h:	struct completion fw_done;
drivers/net/wireless/ath/ath9k/htc_drv_init.c:	time_left = wait_for_completion_timeout(&priv->htc->target_wait, HZ);
drivers/net/wireless/ath/ath9k/htc_drv_txrx.c:	 * and that the TX completion/failed tasklets is killed.
drivers/net/wireless/ath/ath9k/htc_hst.c:	time_left = wait_for_completion_timeout(&target->cmd_wait, HZ);
drivers/net/wireless/ath/ath9k/htc_hst.c:	time_left = wait_for_completion_timeout(&target->cmd_wait, HZ);
drivers/net/wireless/ath/ath9k/htc_hst.c:	time_left = wait_for_completion_timeout(&target->cmd_wait, HZ);
drivers/net/wireless/ath/ath9k/htc_hst.c:void ath9k_htc_txcompletion_cb(struct htc_target *htc_handle,
drivers/net/wireless/ath/ath9k/htc_hst.c:	init_completion(&target->target_wait);
drivers/net/wireless/ath/ath9k/htc_hst.c:	init_completion(&target->cmd_wait);
drivers/net/wireless/ath/ath9k/htc_hst.h:	struct completion target_wait;
drivers/net/wireless/ath/ath9k/htc_hst.h:	struct completion cmd_wait;
drivers/net/wireless/ath/ath9k/htc_hst.h:void ath9k_htc_txcompletion_cb(struct htc_target *htc_handle,
drivers/net/wireless/ath/ath9k/init.c:	struct completion complete;
drivers/net/wireless/ath/ath9k/init.c:	init_completion(&ec.complete);
drivers/net/wireless/ath/ath9k/init.c:	wait_for_completion(&ec.complete);
drivers/net/wireless/ath/ath9k/link.c:	init_completion(&sc->paprd_complete);
drivers/net/wireless/ath/ath9k/link.c:	time_left = wait_for_completion_timeout(&sc->paprd_complete,
drivers/net/wireless/ath/ath9k/main.c:			 * For EDMA chips, TX completion is enabled for the
drivers/net/wireless/ath/ath9k/main.c:		init_completion(&sc->go_beacon);
drivers/net/wireless/ath/ath9k/main.c:		if (wait_for_completion_timeout(&sc->go_beacon,
drivers/net/wireless/ath/ath9k/wmi.c:	init_completion(&wmi->cmd_wait);
drivers/net/wireless/ath/ath9k/wmi.c:	time_left = wait_for_completion_timeout(&wmi->cmd_wait, timeout);
drivers/net/wireless/ath/ath9k/wmi.h:	struct completion cmd_wait;
drivers/net/wireless/ath/ath9k/xmit.c:			/* transmit completion, subframe is
drivers/net/wireless/ath/ath9k/xmit.c:			/* transmit completion */
drivers/net/wireless/ath/ath9k/xmit.c:/* TX Completion */
drivers/net/wireless/ath/ath9k/xmit.c:		/* Process beacon completions separately */
drivers/net/wireless/ath/carl9170/carl9170.h:#include <linux/completion.h>
drivers/net/wireless/ath/carl9170/carl9170.h:	struct completion fw_load_wait;
drivers/net/wireless/ath/carl9170/carl9170.h:	struct completion fw_boot_wait;
drivers/net/wireless/ath/carl9170/carl9170.h:	struct completion tx_flush;
drivers/net/wireless/ath/carl9170/carl9170.h:	struct completion cmd_wait;
drivers/net/wireless/ath/carl9170/main.c:		WARN_ON(wait_for_completion_timeout(&ar->tx_flush, HZ) == 0);
drivers/net/wireless/ath/carl9170/main.c:	init_completion(&ar->tx_flush);
drivers/net/wireless/ath/carl9170/tx.c:			 * race between the urb's completion routine:
drivers/net/wireless/ath/carl9170/usb.c:	 * completion (hardirq context).
drivers/net/wireless/ath/carl9170/usb.c:	reinit_completion(&ar->cmd_wait);
drivers/net/wireless/ath/carl9170/usb.c:		time_left = wait_for_completion_timeout(&ar->cmd_wait, HZ);
drivers/net/wireless/ath/carl9170/usb.c:	if (wait_for_completion_timeout(&ar->fw_boot_wait, HZ) == 0) {
drivers/net/wireless/ath/carl9170/usb.c:	init_completion(&ar->cmd_wait);
drivers/net/wireless/ath/carl9170/usb.c:	init_completion(&ar->fw_boot_wait);
drivers/net/wireless/ath/carl9170/usb.c:	init_completion(&ar->fw_load_wait);
drivers/net/wireless/ath/carl9170/usb.c:	wait_for_completion(&ar->fw_load_wait);
drivers/net/wireless/ath/wcn36xx/firmware.c:	DEFINE(ENHANCED_TXBD_COMPLETION),
drivers/net/wireless/ath/wcn36xx/firmware.h:	ENHANCED_TXBD_COMPLETION = 54,
drivers/net/wireless/ath/wcn36xx/smd.c:	init_completion(&wcn->hal_rsp_compl);
drivers/net/wireless/ath/wcn36xx/smd.c:	if (wait_for_completion_timeout(&wcn->hal_rsp_compl,
drivers/net/wireless/ath/wcn36xx/wcn36xx.h:#include <linux/completion.h>
drivers/net/wireless/ath/wcn36xx/wcn36xx.h:	struct completion	hal_rsp_compl;
drivers/net/wireless/ath/wil6210/main.c:	/* napi_synchronize waits for completion of the current NAPI but will
drivers/net/wireless/ath/wil6210/main.c:	init_completion(&wil->wmi_ready);
drivers/net/wireless/ath/wil6210/main.c:	init_completion(&wil->wmi_call);
drivers/net/wireless/ath/wil6210/main.c:	init_completion(&wil->halp.comp);
drivers/net/wireless/ath/wil6210/main.c:	ulong left = wait_for_completion_timeout(&wil->wmi_ready, to);
drivers/net/wireless/ath/wil6210/main.c:	reinit_completion(&wil->wmi_ready);
drivers/net/wireless/ath/wil6210/main.c:	reinit_completion(&wil->wmi_call);
drivers/net/wireless/ath/wil6210/main.c:	reinit_completion(&wil->halp.comp);
drivers/net/wireless/ath/wil6210/main.c:		reinit_completion(&wil->halp.comp);
drivers/net/wireless/ath/wil6210/main.c:		rc = wait_for_completion_timeout(&wil->halp.comp, to_jiffies);
drivers/net/wireless/ath/wil6210/pm.c:	/* Wait for completion of the pending RX packets */
drivers/net/wireless/ath/wil6210/pm.c:	data_comp_to = jiffies + msecs_to_jiffies(WIL_DATA_COMPLETION_TO_MS);
drivers/net/wireless/ath/wil6210/txrx.c:					WIL_DATA_COMPLETION_TO_MS);
drivers/net/wireless/ath/wil6210/txrx.c:	 * This will prevent a race condition where the completion thread
drivers/net/wireless/ath/wil6210/txrx.c:	 * This will prevent a race condition where the completion thread
drivers/net/wireless/ath/wil6210/txrx_edma.c:	/* Process completion messages while DR bit has the expected polarity */
drivers/net/wireless/ath/wil6210/txrx_edma.h: *		     only completion.
drivers/net/wireless/ath/wil6210/wil6210.h:#define WIL_DATA_COMPLETION_TO_MS 200
drivers/net/wireless/ath/wil6210/wil6210.h: * Status ring structure, used for enhanced DMA completions for RX and TX.
drivers/net/wireless/ath/wil6210/wil6210.h:	struct completion	comp;
drivers/net/wireless/ath/wil6210/wil6210.h: * During Rx completion processing, the driver extracts a buffer ID which
drivers/net/wireless/ath/wil6210/wil6210.h:	struct completion wmi_ready;
drivers/net/wireless/ath/wil6210/wil6210.h:	struct completion wmi_call;
drivers/net/wireless/ath/wil6210/wmi.c:	reinit_completion(&wil->wmi_call);
drivers/net/wireless/ath/wil6210/wmi.c:	remain = wait_for_completion_timeout(&wil->wmi_call,
drivers/net/wireless/ath/wil6210/wmi.h:/* Power Save command completion status codes */
drivers/net/wireless/ath/wil6210/wmi.h:/* completion status codes */
drivers/net/wireless/atmel/at76c50x-usb.c:#define DBG_WAIT_COMPLETE	0x00200000	/* command completion */
drivers/net/wireless/atmel/at76c50x-usb.c:static int at76_wait_completion(struct at76_priv *priv, int cmd)
drivers/net/wireless/atmel/at76c50x-usb.c:	unsigned long timeout = jiffies + CMD_COMPLETION_TIMEOUT;
drivers/net/wireless/atmel/at76c50x-usb.c:				  "completion timeout for command %d\n", cmd);
drivers/net/wireless/atmel/at76c50x-usb.c:	ret = at76_wait_completion(priv, CMD_SET_MIB);
drivers/net/wireless/atmel/at76c50x-usb.c:			   "set_mib: at76_wait_completion failed with %d\n",
drivers/net/wireless/atmel/at76c50x-usb.c:	at76_wait_completion(priv, CMD_STARTUP);
drivers/net/wireless/atmel/at76c50x-usb.c:		at76_wait_completion(priv, CMD_RADIO_ON);
drivers/net/wireless/atmel/at76c50x-usb.c:	ret = at76_wait_completion(priv, CMD_JOIN);
drivers/net/wireless/atmel/at76c50x-usb.c:		wiphy_err(priv->hw->wiphy, "at76_wait_completion failed: %d\n",
drivers/net/wireless/atmel/at76c50x-usb.h:#define CMD_COMPLETION_TIMEOUT	(5 * HZ)
drivers/net/wireless/broadcom/b43/b43.h:#include <linux/completion.h>
drivers/net/wireless/broadcom/b43/b43.h:	/* a completion event structure needed if this call is asynchronous */
drivers/net/wireless/broadcom/b43/b43.h:	struct completion fw_load_complete;
drivers/net/wireless/broadcom/b43/main.c:		init_completion(&ctx->dev->fw_load_complete);
drivers/net/wireless/broadcom/b43/main.c:		wait_for_completion(&ctx->dev->fw_load_complete);
drivers/net/wireless/broadcom/b43legacy/b43legacy.h:#include <linux/completion.h>
drivers/net/wireless/broadcom/b43legacy/b43legacy.h:	/* completion struct for firmware loading */
drivers/net/wireless/broadcom/b43legacy/b43legacy.h:	struct completion fw_load_complete;
drivers/net/wireless/broadcom/b43legacy/main.c:		init_completion(&dev->fw_load_complete);
drivers/net/wireless/broadcom/b43legacy/main.c:		wait_for_completion(&dev->fw_load_complete);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bcmsdh.c:#include <linux/completion.h>
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bcmsdh.c:	struct completion resumed;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bcmsdh.c:	init_completion(&sdiodev->freezer->resumed);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bcmsdh.c:	reinit_completion(&sdiodev->freezer->resumed);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bcmsdh.c:	wait_for_completion(&sdiodev->freezer->resumed);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bus.h: * @max_completionrings: maximum number of completion rings(d2h) supported.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/bus.h:	u16 max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	init_completion(&cfg->vif_disabled);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	/* Add 10 ms for IOVAR completion */
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.h: * @vif_complete: completion for net attach.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.h: * @nd_data_completed: completion for net detect data.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.h:	struct completion vif_disabled;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwil_types.h: * @status: indicates completion status of PNO scan.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:#include <linux/completion.h>
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:	struct completion reg_done;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:		.reg_done = COMPLETION_INITIALIZER(fwvid_list[BRCMF_FWVENDOR_ ## _vid].reg_done), \
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:		struct completion *reg_done = &fwvid_list[fwvid].reg_done;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:		ret = wait_for_completion_interruptible(reg_done);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/fwvid.c:	reinit_completion(&fwvid_list[fwvid].reg_done);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:struct msgbuf_completion_hdr {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	struct msgbuf_completion_hdr	compl_hdr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/msgbuf.c:	u16 max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	reinit_completion(&afx_hdl->act_frm_scan);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:		wait_for_completion_timeout(&afx_hdl->act_frm_scan,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:			wait_for_completion_timeout(&afx_hdl->act_frm_scan,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:		 * So abort scan for off channel completion.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c: * This function waits for a completion event before returning.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	reinit_completion(&p2p->send_af_done);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	brcmf_dbg(TRACE, "Waiting for %s tx completion event\n",
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	wait_for_completion_timeout(&p2p->send_af_done, P2P_AF_MAX_WAIT_TIME);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:				wait_for_completion_timeout(&p2p->wait_next_af,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	init_completion(&p2p->send_af_done);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	init_completion(&p2p->afx_hdl.act_frm_scan);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:	init_completion(&p2p->wait_next_af);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.c:		wait_for_completion_timeout(&cfg->vif_disabled,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.h:	struct completion act_frm_scan;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.h: * @wait_for_offchan_complete: wait for off-channel tx completion event.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.h:	struct completion send_af_done;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/p2p.h:	struct completion wait_next_af;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	u16 max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c: * @max_completionrings: maximum number of completion rings(d2h) supported.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	__le16			max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	u16 max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:		max_completionrings = le16_to_cpu(ringinfo.max_completionrings);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:		max_completionrings = BRCMF_NROF_D2H_COMMON_MSGRINGS;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:		bufsz = (max_submissionrings + max_completionrings) *
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:				max_completionrings * idx_offset;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:		address += max_completionrings * idx_offset;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	devinfo->shared.max_completionrings = max_completionrings;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	struct completion watchdog_wait;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:		wait = wait_for_completion_interruptible(&bus->watchdog_wait);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:			reinit_completion(&bus->watchdog_wait);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	init_completion(&bus->watchdog_wait);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.h: *   complete: callback function for command completion (async only)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.h: *   handle:   handle for completion callback (first arg in callback)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	struct completion dev_init_done;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	/* Init completion, to protect for disconnect while still loading.
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	init_completion(&devinfo->dev_init_done);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		wait_for_completion(&devinfo->dev_init_done);
drivers/net/wireless/broadcom/brcm80211/brcmsmac/dma.c:#define	D64_CTRL1_IOC		((u32)1 << 29)	/* interrupt on completion */
drivers/net/wireless/broadcom/brcm80211/brcmsmac/main.c:/* process tx completion events in BMAC
drivers/net/wireless/intel/ipw2x00/ipw2100.c:		IPW_DEBUG_INFO("Command completion failed out after %dms.\n",
drivers/net/wireless/intel/ipw2x00/ipw2100.c: *       cycle and have the completion event trigger the wakeup
drivers/net/wireless/intel/ipw2x00/ipw2100.c:		 * driver upon completion.  Once received, the driver can
drivers/net/wireless/intel/ipw2x00/ipw2100.c:	/* Only userspace-requested scan completion events go out immediately */
drivers/net/wireless/intel/ipw2x00/ipw2100.h:	 * check for completion) */
drivers/net/wireless/intel/ipw2x00/ipw2200.c:		IPW_DEBUG_SCAN("Scan completion watchdog resetting "
drivers/net/wireless/intel/ipw2x00/ipw2200.c:		IPW_DEBUG_SCAN("Scan completion watchdog aborting scan "
drivers/net/wireless/intel/ipw2x00/ipw2200.c:	/* Only userspace-requested scan completion events go out immediately */
drivers/net/wireless/intel/iwlegacy/4965-mac.c:	init_completion(&il->_4965.firmware_loading_complete);
drivers/net/wireless/intel/iwlegacy/4965-mac.c:	wait_for_completion(&il->_4965.firmware_loading_complete);
drivers/net/wireless/intel/iwlegacy/4965.c:	/* the chain noise calibration will enabled PM upon completion
drivers/net/wireless/intel/iwlegacy/common.h:			struct completion firmware_loading_complete;
drivers/net/wireless/intel/iwlegacy/prph.h: * 5)  Wait for load completion:
drivers/net/wireless/intel/iwlegacy/prph.h: *     Tx completion may end up being out-of-order).
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		 * completion. If calibration has already been run
drivers/net/wireless/intel/iwlwifi/fw/api/location.h: *				   earlier of: measurements completion / timeout
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @IWL_PRPH_SCRATCH_MTR_MODE: format used for completion - 0: for
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: *	completion descriptor, 1 for responses (legacy)
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @cr_head_idx_arr_base_addr: the completion ring head index array
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @cr_tail_idx_arr_base_addr: the completion ring tail index array
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @cr_idx_arr_size: number of entries in the completion ring index array
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @mcr_base_addr: the message completion ring start address
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @mcr_size: number of entries which the message completion ring can hold
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: *	completion ring
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: *	completing a completion descriptor in the message completion ring
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @mcr_opt_header_size: the size of the optional header in the completion
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: *	descriptor associated with the message completion ring in DWs
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: * @mcr_opt_footer_size: the size of the optional footer in the completion
drivers/net/wireless/intel/iwlwifi/iwl-context-info-gen3.h: *	descriptor associated with the message completion ring in DWs
drivers/net/wireless/intel/iwlwifi/iwl-drv.c:#include <linux/completion.h>
drivers/net/wireless/intel/iwlwifi/iwl-drv.c:	struct completion request_firmware_complete;
drivers/net/wireless/intel/iwlwifi/iwl-drv.c:	init_completion(&drv->request_firmware_complete);
drivers/net/wireless/intel/iwlwifi/iwl-drv.c:	wait_for_completion(&drv->request_firmware_complete);
drivers/net/wireless/intel/iwlwifi/iwl-prph.h: *     Tx completion may end up being out-of-order).
drivers/net/wireless/intel/iwlwifi/mvm/quota.c:	/* update all upon completion */
drivers/net/wireless/intel/iwlwifi/mvm/rs.c:		 * immediately upon association completion, before the phy
drivers/net/wireless/intel/iwlwifi/pcie/internal.h: * struct iwl_rx_completion_desc - completion descriptor
drivers/net/wireless/intel/iwlwifi/pcie/internal.h:struct iwl_rx_completion_desc {
drivers/net/wireless/intel/iwlwifi/pcie/internal.h: * struct iwl_rx_completion_desc_bz - Bz completion descriptor
drivers/net/wireless/intel/iwlwifi/pcie/internal.h:struct iwl_rx_completion_desc_bz {
drivers/net/wireless/intel/iwlwifi/pcie/internal.h: * @imr_waitq: imr wait queue for dma completion
drivers/net/wireless/intel/iwlwifi/pcie/internal.h: * @sx_complete: completion for Sx transitions
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:		return sizeof(struct iwl_rx_completion_desc_bz);
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:		return sizeof(struct iwl_rx_completion_desc);
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:		 Allocator has another 6 from pool for the request completion*/
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:	BUILD_BUG_ON(sizeof(struct iwl_rx_completion_desc) != 32);
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:	BUILD_BUG_ON(sizeof(struct iwl_rx_completion_desc_bz) != 4);
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:		struct iwl_rx_completion_desc_bz *cd = rxq->used_bd;
drivers/net/wireless/intel/iwlwifi/pcie/rx.c:		struct iwl_rx_completion_desc *cd = rxq->used_bd;
drivers/net/wireless/intersil/p54/fwio.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/net/wireless/intersil/p54/main.c:		wait_for_completion_interruptible_timeout(&priv->beacon_comp, HZ);
drivers/net/wireless/intersil/p54/main.c:	ret = wait_for_completion_interruptible_timeout(&priv->stat_comp, HZ);
drivers/net/wireless/intersil/p54/main.c:	init_completion(&priv->stat_comp);
drivers/net/wireless/intersil/p54/main.c:	init_completion(&priv->eeprom_comp);
drivers/net/wireless/intersil/p54/main.c:	init_completion(&priv->beacon_comp);
drivers/net/wireless/intersil/p54/p54.h:	struct completion stat_comp;
drivers/net/wireless/intersil/p54/p54.h:	struct completion beacon_comp;
drivers/net/wireless/intersil/p54/p54.h:	struct completion eeprom_comp;
drivers/net/wireless/intersil/p54/p54pci.c:#include <linux/completion.h>
drivers/net/wireless/intersil/p54/p54pci.c:	init_completion(&priv->boot_comp);
drivers/net/wireless/intersil/p54/p54pci.c:	time_left = wait_for_completion_interruptible_timeout(
drivers/net/wireless/intersil/p54/p54pci.c:	init_completion(&priv->fw_loaded);
drivers/net/wireless/intersil/p54/p54pci.c:	wait_for_completion(&priv->fw_loaded);
drivers/net/wireless/intersil/p54/p54pci.h:	struct completion boot_comp;
drivers/net/wireless/intersil/p54/p54pci.h:	struct completion fw_loaded;
drivers/net/wireless/intersil/p54/p54spi.c:	time_left = wait_for_completion_interruptible_timeout(&priv->fw_comp,
drivers/net/wireless/intersil/p54/p54spi.c:	init_completion(&priv->fw_comp);
drivers/net/wireless/intersil/p54/p54spi.h:	struct completion fw_comp;
drivers/net/wireless/intersil/p54/p54usb.c:	init_completion(&priv->fw_wait_load);
drivers/net/wireless/intersil/p54/p54usb.c:	wait_for_completion(&priv->fw_wait_load);
drivers/net/wireless/intersil/p54/p54usb.h:	struct completion fw_wait_load;
drivers/net/wireless/marvell/libertas/README:    will be displayed upon completion by use of the getscantable ioctl.
drivers/net/wireless/marvell/libertas/cfg.c:	/* Wake up anything waiting on scan completion */
drivers/net/wireless/marvell/libertas/dev.h:	/* Queue of things waiting for scan completion */
drivers/net/wireless/marvell/libertas/if_spi.c:	 * If auto-interrupts are on, the completion of certain transactions
drivers/net/wireless/marvell/mwifiex/11h.c:		    "indicating channel switch completion to kernel\n");
drivers/net/wireless/marvell/mwifiex/cfg80211.c: * the IBSS if it does not exist. On successful completion in either case,
drivers/net/wireless/marvell/mwifiex/cfg80211.c: * the user specified scan configuration. On successful completion,
drivers/net/wireless/marvell/mwifiex/cfg80211.c: * the user specified sched_scan configuration. On successful completion,
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * This function will however call the receive completion callback
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * The function also calls the completion callback if required, before
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * The function calls the completion callback for all the command
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * After processing, the function calls the completion callback
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * commands in scan pending queue are cancelled. All the completion callbacks
drivers/net/wireless/marvell/mwifiex/cmdevt.c: * searched for matching IOCTL request. The completion callback of
drivers/net/wireless/marvell/mwifiex/init.c: *      - Notify completion
drivers/net/wireless/marvell/mwifiex/main.c:	struct completion *fw_done = adapter->fw_done;
drivers/net/wireless/marvell/mwifiex/main.c:	wait_for_completion(adapter->fw_done);
drivers/net/wireless/marvell/mwifiex/main.c:	reinit_completion(adapter->fw_done);
drivers/net/wireless/marvell/mwifiex/main.c:mwifiex_add_card(void *card, struct completion *fw_done,
drivers/net/wireless/marvell/mwifiex/main.h:#include <linux/completion.h>
drivers/net/wireless/marvell/mwifiex/main.h:	struct completion *fw_done;
drivers/net/wireless/marvell/mwifiex/main.h:int mwifiex_add_card(void *card, struct completion *fw_done,
drivers/net/wireless/marvell/mwifiex/pcie.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/pcie.c:	init_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/pcie.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/pcie.c:		 * send dnld-rdy intr again, wait for completion.
drivers/net/wireless/marvell/mwifiex/pcie.h:#include    <linux/completion.h>
drivers/net/wireless/marvell/mwifiex/pcie.h:	struct completion fw_done;
drivers/net/wireless/marvell/mwifiex/sdio.c:	init_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/sdio.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/sdio.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/sdio.h:#include <linux/completion.h>
drivers/net/wireless/marvell/mwifiex/sdio.h:	struct completion fw_done;
drivers/net/wireless/marvell/mwifiex/sta_cmdresp.c: * of the scan completion.
drivers/net/wireless/marvell/mwifiex/sta_ioctl.c: * Wait queue completion handler.
drivers/net/wireless/marvell/mwifiex/sta_ioctl.c:	/* Wait for completion */
drivers/net/wireless/marvell/mwifiex/sta_rx.c: * The completion callback is called after processing in complete.
drivers/net/wireless/marvell/mwifiex/sta_rx.c: * The completion callback is called after processing in complete.
drivers/net/wireless/marvell/mwifiex/txrx.c: * On successful completion, the function calls the completion callback
drivers/net/wireless/marvell/mwifiex/txrx.c: * Packet send completion callback handler.
drivers/net/wireless/marvell/mwifiex/txrx.c: * completion callback which checks conditions, updates statistics,
drivers/net/wireless/marvell/mwifiex/uap_txrx.c: * The completion callback is called after processing is complete.
drivers/net/wireless/marvell/mwifiex/usb.c:	init_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/usb.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/usb.c:	wait_for_completion(&card->fw_done);
drivers/net/wireless/marvell/mwifiex/usb.h:#include <linux/completion.h>
drivers/net/wireless/marvell/mwifiex/usb.h:	struct completion fw_done;
drivers/net/wireless/marvell/mwifiex/util.c: * IOCTL completion callback handler.
drivers/net/wireless/marvell/mwifiex/wmm.c: * The packet sent completion callback handler are called with
drivers/net/wireless/marvell/mwifiex/wmm.c: * packet send completion callback is called with status failure.
drivers/net/wireless/marvell/mwl8k.c:#include <linux/completion.h>
drivers/net/wireless/marvell/mwl8k.c:	struct completion *hostcmd_wait;
drivers/net/wireless/marvell/mwl8k.c:	/* TX quiesce completion, protected by fw_mutex and tx_lock */
drivers/net/wireless/marvell/mwl8k.c:	struct completion *tx_wait;
drivers/net/wireless/marvell/mwl8k.c:	struct completion firmware_loading_complete;
drivers/net/wireless/marvell/mwl8k.c:	DECLARE_COMPLETION_ONSTACK(tx_wait);
drivers/net/wireless/marvell/mwl8k.c:		timeout = wait_for_completion_timeout(&tx_wait,
drivers/net/wireless/marvell/mwl8k.c:	DECLARE_COMPLETION_ONSTACK(cmd_wait);
drivers/net/wireless/marvell/mwl8k.c:	 * Enable these stopped BSSes after completion of the commands
drivers/net/wireless/marvell/mwl8k.c:	time_left = wait_for_completion_timeout(&cmd_wait,
drivers/net/wireless/marvell/mwl8k.c:	init_completion(&priv->firmware_loading_complete);
drivers/net/wireless/marvell/mwl8k.c:	wait_for_completion(&priv->firmware_loading_complete);
drivers/net/wireless/mediatek/mt76/dma.c:	init_completion(&dev->mmio.wed_reset);
drivers/net/wireless/mediatek/mt76/dma.c:	init_completion(&dev->mmio.wed_reset_complete);
drivers/net/wireless/mediatek/mt76/mt76.h:	struct completion wed_reset;
drivers/net/wireless/mediatek/mt76/mt76.h:	struct completion wed_reset_complete;
drivers/net/wireless/mediatek/mt76/mt7615/mt7615.h:#include <linux/completion.h>
drivers/net/wireless/mediatek/mt76/mt76x0/mt76x0.h:#include <linux/completion.h>
drivers/net/wireless/mediatek/mt76/mt76x0/phy.c:	/* vcocal_en: initiate VCO calibration (reset after completion)) */
drivers/net/wireless/mediatek/mt76/mt7915/mmio.c:	if (!wait_for_completion_timeout(&mdev->mmio.wed_reset, 20 * HZ)) {
drivers/net/wireless/mediatek/mt76/mt7996/mmio.c:	if (!wait_for_completion_timeout(&mdev->mmio.wed_reset, 20 * HZ)) {
drivers/net/wireless/mediatek/mt76/wed.c:	if (!wait_for_completion_timeout(&mmio->wed_reset_complete, 3 * HZ))
drivers/net/wireless/mediatek/mt7601u/mcu.c:		if (!wait_for_completion_timeout(&dev->mcu.resp_cmpl,
drivers/net/wireless/mediatek/mt7601u/mcu.c:	DECLARE_COMPLETION_ONSTACK(cmpl);
drivers/net/wireless/mediatek/mt7601u/mcu.c:	if (!wait_for_completion_timeout(&cmpl, msecs_to_jiffies(1000))) {
drivers/net/wireless/mediatek/mt7601u/mcu.c:	init_completion(&dev->mcu.resp_cmpl);
drivers/net/wireless/mediatek/mt7601u/mt7601u.h:#include <linux/completion.h>
drivers/net/wireless/mediatek/mt7601u/mt7601u.h:	struct completion resp_cmpl;
drivers/net/wireless/mediatek/mt7601u/usb.c:	struct completion *cmpl = urb->context;
drivers/net/wireless/microchip/wilc1000/cfg80211.c:	init_completion(&wl->txq_event);
drivers/net/wireless/microchip/wilc1000/cfg80211.c:	init_completion(&wl->cfg_event);
drivers/net/wireless/microchip/wilc1000/cfg80211.c:	init_completion(&wl->sync_event);
drivers/net/wireless/microchip/wilc1000/cfg80211.c:	init_completion(&wl->txq_thread_started);
drivers/net/wireless/microchip/wilc1000/hif.c:	struct completion work_comp;
drivers/net/wireless/microchip/wilc1000/hif.c:		init_completion(&msg->work_comp);
drivers/net/wireless/microchip/wilc1000/netdev.c:		if (wait_for_completion_interruptible(&wl->txq_event))
drivers/net/wireless/microchip/wilc1000/netdev.c:	if (!wait_for_completion_timeout(&wilc->sync_event,
drivers/net/wireless/microchip/wilc1000/netdev.c:	wait_for_completion(&wilc->txq_thread_started);
drivers/net/wireless/microchip/wilc1000/netdev.h:	struct completion cfg_event;
drivers/net/wireless/microchip/wilc1000/netdev.h:	struct completion sync_event;
drivers/net/wireless/microchip/wilc1000/netdev.h:	struct completion txq_event;
drivers/net/wireless/microchip/wilc1000/netdev.h:	struct completion txq_thread_started;
drivers/net/wireless/microchip/wilc1000/wlan.c:		wait_for_completion_timeout(&wilc->txq_event,
drivers/net/wireless/microchip/wilc1000/wlan.c:	if (!wait_for_completion_timeout(&wilc->cfg_event,
drivers/net/wireless/microchip/wilc1000/wlan.c:	if (!wait_for_completion_timeout(&wilc->cfg_event,
drivers/net/wireless/microchip/wilc1000/wlan.h:/* time for expiring the completion of cfg packets */
drivers/net/wireless/purelifi/plfxlc/usb.h:#include <linux/completion.h>
drivers/net/wireless/quantenna/qtnfmac/pcie/pcie.c:#include <linux/completion.h>
drivers/net/wireless/quantenna/qtnfmac/pcie/pearl_pcie.c:#include <linux/completion.h>
drivers/net/wireless/quantenna/qtnfmac/pcie/topaz_pcie.c:#include <linux/completion.h>
drivers/net/wireless/quantenna/qtnfmac/pcie/topaz_pcie.c:	/* upload completion mark: zero-sized block */
drivers/net/wireless/quantenna/qtnfmac/pcie/topaz_pcie.c:		pr_err("confirmation for FW upload completion timed out\n");
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.c:		complete(&ipc->tx_completion);
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.c:	init_completion(&ipc->tx_completion);
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.c:	complete_all(&ipc->tx_completion);
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.c:	if (!wait_for_completion_timeout(&ipc->tx_completion,
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.h:#include <linux/completion.h>
drivers/net/wireless/quantenna/qtnfmac/shm_ipc.h:	struct completion tx_completion;
drivers/net/wireless/quantenna/qtnfmac/trans.c:	status = wait_for_completion_interruptible_timeout(
drivers/net/wireless/quantenna/qtnfmac/trans.c:						&ctl_node->cmd_resp_completion,
drivers/net/wireless/quantenna/qtnfmac/trans.c:	complete(&ctl_node->cmd_resp_completion);
drivers/net/wireless/quantenna/qtnfmac/trans.c:	init_completion(&trans->curr_cmd.cmd_resp_completion);
drivers/net/wireless/quantenna/qtnfmac/trans.h:	struct completion cmd_resp_completion;
drivers/net/wireless/ralink/rt2x00/rt2800mmio.c:		 * For TX queues schedule completion tasklet to catch
drivers/net/wireless/ralink/rt2x00/rt2x00.h:	 * other work structures and wait for their completion in order
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:	struct work_struct *completion;
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:	 * Obtain the queue completion handler
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:		completion = &queue->rt2x00dev->txdone_work;
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:		completion = &queue->rt2x00dev->rxdone_work;
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:		 * Schedule the completion handler manually, when this
drivers/net/wireless/ralink/rt2x00/rt2x00usb.c:		queue_work(queue->rt2x00dev->workqueue, completion);
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:		reinit_completion(&btcoexist->bt_mp_comp);
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:	if (wait_for_completion_timeout(&btcoexist->bt_mp_comp,
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:	/* need wait completion to return correct value */
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:	/* need wait completion to return correct value */
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:	/* need wait completion to return correct value */
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.c:	init_completion(&btcoexist->bt_mp_comp);
drivers/net/wireless/realtek/rtlwifi/btcoexist/halbtcoutsrc.h:	struct completion bt_mp_comp;
drivers/net/wireless/realtek/rtlwifi/pci.c:	init_completion(&rtlpriv->firmware_loading_complete);
drivers/net/wireless/realtek/rtlwifi/pci.c:	wait_for_completion(&rtlpriv->firmware_loading_complete);
drivers/net/wireless/realtek/rtlwifi/usb.c:	init_completion(&rtlpriv->firmware_loading_complete);
drivers/net/wireless/realtek/rtlwifi/usb.c:	wait_for_completion(&rtlpriv->firmware_loading_complete);
drivers/net/wireless/realtek/rtlwifi/wifi.h:#include <linux/completion.h>
drivers/net/wireless/realtek/rtlwifi/wifi.h:	struct completion firmware_loading_complete;
drivers/net/wireless/realtek/rtw88/main.c:static int rtw_wait_firmware_completion(struct rtw_dev *rtwdev)
drivers/net/wireless/realtek/rtw88/main.c:	wait_for_completion(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:		wait_for_completion(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:	ret = rtw_wait_firmware_completion(rtwdev);
drivers/net/wireless/realtek/rtw88/main.c:		rtw_err(rtwdev, "failed to wait firmware completion\n");
drivers/net/wireless/realtek/rtw88/main.c:		reinit_completion(&rtwdev->fw_scan_density);
drivers/net/wireless/realtek/rtw88/main.c:		if (!wait_for_completion_timeout(&rtwdev->fw_scan_density,
drivers/net/wireless/realtek/rtw88/main.c:		complete_all(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:	complete_all(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:	init_completion(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:	wait_for_completion(&fw->completion);
drivers/net/wireless/realtek/rtw88/main.c:	init_completion(&rtwdev->lps_leave_check);
drivers/net/wireless/realtek/rtw88/main.c:	init_completion(&rtwdev->fw_scan_density);
drivers/net/wireless/realtek/rtw88/main.c:			wait_for_completion(&rtwdev->fw.completion);
drivers/net/wireless/realtek/rtw88/main.c:	rtw_wait_firmware_completion(rtwdev);
drivers/net/wireless/realtek/rtw88/main.h:	struct completion completion;
drivers/net/wireless/realtek/rtw88/main.h:	struct completion lps_leave_check;
drivers/net/wireless/realtek/rtw88/main.h:	struct completion fw_scan_density;
drivers/net/wireless/realtek/rtw88/pci.c:	/* Disable 8821ce completion timeout by default */
drivers/net/wireless/realtek/rtw88/ps.c:	if (wait_for_completion_timeout(&rtwdev->lps_leave_check,
drivers/net/wireless/realtek/rtw88/ps.c:		reinit_completion(&rtwdev->lps_leave_check);
drivers/net/wireless/realtek/rtw89/core.c:	init_completion(&wait->completion);
drivers/net/wireless/realtek/rtw89/core.c:	time_left = wait_for_completion_timeout(&wait->completion,
drivers/net/wireless/realtek/rtw89/core.c:	struct completion *cmpl = &wait->completion;
drivers/net/wireless/realtek/rtw89/core.c:	time_left = wait_for_completion_timeout(cmpl, RTW89_WAIT_FOR_COND_TIMEOUT);
drivers/net/wireless/realtek/rtw89/core.c:			 const struct rtw89_completion_data *data)
drivers/net/wireless/realtek/rtw89/core.c:	complete(&wait->completion);
drivers/net/wireless/realtek/rtw89/core.c:	init_completion(&rtwdev->fw.req.completion);
drivers/net/wireless/realtek/rtw89/core.c:	init_completion(&rtwdev->rfk_wait.completion);
drivers/net/wireless/realtek/rtw89/core.c:	ret = rtw89_wait_firmware_completion(rtwdev);
drivers/net/wireless/realtek/rtw89/core.c:		rtw89_err(rtwdev, "failed to wait firmware completion\n");
drivers/net/wireless/realtek/rtw89/core.h:	struct completion completion;
drivers/net/wireless/realtek/rtw89/core.h:#define RTW89_COMPLETION_BUF_SIZE 40
drivers/net/wireless/realtek/rtw89/core.h:struct rtw89_completion_data {
drivers/net/wireless/realtek/rtw89/core.h:	u8 buf[RTW89_COMPLETION_BUF_SIZE];
drivers/net/wireless/realtek/rtw89/core.h:	struct completion completion;
drivers/net/wireless/realtek/rtw89/core.h:	struct rtw89_completion_data data;
drivers/net/wireless/realtek/rtw89/core.h:	init_completion(&wait->completion);
drivers/net/wireless/realtek/rtw89/core.h:	struct completion completion;
drivers/net/wireless/realtek/rtw89/core.h:	struct completion completion;
drivers/net/wireless/realtek/rtw89/core.h:	complete(&wait->completion);
drivers/net/wireless/realtek/rtw89/core.h:			 const struct rtw89_completion_data *data);
drivers/net/wireless/realtek/rtw89/fw.c:int rtw89_wait_firmware_completion(struct rtw89_dev *rtwdev)
drivers/net/wireless/realtek/rtw89/fw.c:	wait_for_completion(&fw->req.completion);
drivers/net/wireless/realtek/rtw89/fw.c:		complete_all(&req->completion);
drivers/net/wireless/realtek/rtw89/fw.c:	complete_all(&req->completion);
drivers/net/wireless/realtek/rtw89/fw.c:	 * because scan abort command always waits for completion of
drivers/net/wireless/realtek/rtw89/fw.h:static_assert(sizeof(struct rtw89_mac_mcc_tsf_rpt) <= RTW89_COMPLETION_BUF_SIZE);
drivers/net/wireless/realtek/rtw89/fw.h:static_assert(sizeof(struct rtw89_mac_mrc_tsf_rpt) <= RTW89_COMPLETION_BUF_SIZE);
drivers/net/wireless/realtek/rtw89/fw.h:int rtw89_wait_firmware_completion(struct rtw89_dev *rtwdev);
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/mac.c:	struct rtw89_completion_data data = {};
drivers/net/wireless/realtek/rtw89/phy.c:	reinit_completion(&wait->completion);
drivers/net/wireless/realtek/rtw89/phy.c:	time_left = wait_for_completion_timeout(&wait->completion,
drivers/net/wireless/realtek/rtw89/phy.c:	complete(&wait->completion);
drivers/net/wireless/rsi/rsi_91x_coex.c:	kthread_complete_and_exit(&coex_cb->coex_tx_thread.completion, 0);
drivers/net/wireless/rsi/rsi_91x_mac80211.c:		wait_for_completion(&adapter->priv->wlan_init_completion);
drivers/net/wireless/rsi/rsi_91x_main.c:	kthread_complete_and_exit(&common->tx_thread.completion, 0);
drivers/net/wireless/rsi/rsi_91x_main.c:	init_completion(&common->wlan_init_completion);
drivers/net/wireless/rsi/rsi_91x_mgmt.c:					complete(&common->wlan_init_completion);
drivers/net/wireless/rsi/rsi_91x_sdio_ops.c:	kthread_complete_and_exit(&sdev->rx_thread.completion, 0);
drivers/net/wireless/rsi/rsi_91x_usb_ops.c:	kthread_complete_and_exit(&dev->rx_thread.completion, 0);
drivers/net/wireless/rsi/rsi_common.h:	init_completion(&thread->completion);
drivers/net/wireless/rsi/rsi_main.h:	struct completion completion;
drivers/net/wireless/rsi/rsi_main.h:	struct completion wlan_init_completion;
drivers/net/wireless/silabs/wfx/bh.c:		if (!completion_done(&wdev->hif.ctrl_ready))
drivers/net/wireless/silabs/wfx/bh.c:		/* completion.h does not provide any function to wait completion without consume it
drivers/net/wireless/silabs/wfx/bh.c:		 * (a kind of wait_for_completion_done_timeout()). So we have to emulate it.
drivers/net/wireless/silabs/wfx/bh.c:		if (wait_for_completion_timeout(&wdev->hif.ctrl_ready, msecs_to_jiffies(2))) {
drivers/net/wireless/silabs/wfx/bh.c:		else if (try_wait_for_completion(&wdev->hif.ctrl_ready))
drivers/net/wireless/silabs/wfx/bh.c:			if (try_wait_for_completion(&wdev->hif_cmd.ready)) {
drivers/net/wireless/silabs/wfx/bh.c:	init_completion(&wdev->hif.ctrl_ready);
drivers/net/wireless/silabs/wfx/bh.h:#include <linux/completion.h>
drivers/net/wireless/silabs/wfx/bh.h:	struct completion ctrl_ready;
drivers/net/wireless/silabs/wfx/debug.c:	struct completion complete;
drivers/net/wireless/silabs/wfx/debug.c:	if (completion_done(&context->complete)) {
drivers/net/wireless/silabs/wfx/debug.c:	ret = wait_for_completion_interruptible(&context->complete);
drivers/net/wireless/silabs/wfx/debug.c:	init_completion(&context->complete);
drivers/net/wireless/silabs/wfx/hif_tx.c:	init_completion(&hif_cmd->ready);
drivers/net/wireless/silabs/wfx/hif_tx.c:	init_completion(&hif_cmd->done);
drivers/net/wireless/silabs/wfx/hif_tx.c:	ret = wait_for_completion_timeout(&wdev->hif_cmd.done, 1 * HZ);
drivers/net/wireless/silabs/wfx/hif_tx.c:		reinit_completion(&wdev->hif_cmd.ready);
drivers/net/wireless/silabs/wfx/hif_tx.c:		ret = wait_for_completion_timeout(&wdev->hif_cmd.done, 3 * HZ);
drivers/net/wireless/silabs/wfx/hif_tx.c:		reinit_completion(&wdev->hif_cmd.done);
drivers/net/wireless/silabs/wfx/hif_tx.h:#include <linux/completion.h>
drivers/net/wireless/silabs/wfx/hif_tx.h:	struct completion  ready;
drivers/net/wireless/silabs/wfx/hif_tx.h:	struct completion  done;
drivers/net/wireless/silabs/wfx/main.c:	init_completion(&wdev->firmware_ready);
drivers/net/wireless/silabs/wfx/main.c:	err = wait_for_completion_timeout(&wdev->firmware_ready, 1 * HZ);
drivers/net/wireless/silabs/wfx/scan.c:	reinit_completion(&wvif->scan_complete);
drivers/net/wireless/silabs/wfx/scan.c:	ret = wait_for_completion_timeout(&wvif->scan_complete, 1 * HZ);
drivers/net/wireless/silabs/wfx/scan.c:		ret = wait_for_completion_timeout(&wvif->scan_complete, 1 * HZ);
drivers/net/wireless/silabs/wfx/scan.c:	reinit_completion(&wvif->scan_complete);
drivers/net/wireless/silabs/wfx/scan.c:	ret = wait_for_completion_timeout(&wvif->scan_complete,
drivers/net/wireless/silabs/wfx/scan.c:		ret = wait_for_completion_timeout(&wvif->scan_complete, 1 * HZ);
drivers/net/wireless/silabs/wfx/sta.c:	if (!wait_for_completion_timeout(&wvif->set_pm_mode_complete, TU_TO_JIFFIES(512)))
drivers/net/wireless/silabs/wfx/sta.c:	init_completion(&wvif->set_pm_mode_complete);
drivers/net/wireless/silabs/wfx/sta.c:	init_completion(&wvif->scan_complete);
drivers/net/wireless/silabs/wfx/sta.c:	wait_for_completion_timeout(&wvif->set_pm_mode_complete, msecs_to_jiffies(300));
drivers/net/wireless/silabs/wfx/wfx.h:#include <linux/completion.h>
drivers/net/wireless/silabs/wfx/wfx.h:	struct completion          firmware_ready;
drivers/net/wireless/silabs/wfx/wfx.h:	struct completion          set_pm_mode_complete;
drivers/net/wireless/silabs/wfx/wfx.h:	struct completion          scan_complete;
drivers/net/wireless/st/cw1200/fwio.c:	/* Wait for the download completion */
drivers/net/wireless/st/cw1200/fwio.c:		pr_err("Wait for download completion failed: 0x%.8X\n", val32);
drivers/net/wireless/st/cw1200/wsm.c:	/* Wait for command completion */
drivers/net/wireless/st/cw1200/wsm.h: * join complete to notify about completion
drivers/net/wireless/st/cw1200/wsm.h:	/* Packet identifier that meant to be used in completion. */
drivers/net/wireless/ti/wl1251/acx.h:/* Command processing completion */
drivers/net/wireless/ti/wl1251/tx.h:	 * upon frame sending completion.
drivers/net/wireless/ti/wl18xx/main.c:static void wl18xx_tx_immediate_completion(struct wl1271 *wl)
drivers/net/wireless/ti/wl18xx/main.c:	.tx_immediate_compl = wl18xx_tx_immediate_completion,
drivers/net/wireless/ti/wl18xx/tx.c:		wl1271_warning("illegal id in tx completion: %d", id);
drivers/net/wireless/ti/wlcore/acx.h:/* Command processing completion*/
drivers/net/wireless/ti/wlcore/cmd.c:			     timeout ? "completion " : "");
drivers/net/wireless/ti/wlcore/main.c:	/* complete the ELP completion */
drivers/net/wireless/ti/wlcore/main.c:	init_completion(&wl->nvs_loading_complete);
drivers/net/wireless/ti/wlcore/main.c:	DECLARE_COMPLETION_ONSTACK(compl);
drivers/net/wireless/ti/wlcore/main.c:		ret = wait_for_completion_timeout(&compl,
drivers/net/wireless/ti/wlcore/main.c:		wait_for_completion(&wl->nvs_loading_complete);
drivers/net/wireless/ti/wlcore/tx.c:	 * only it uses Tx-completion.
drivers/net/wireless/ti/wlcore/tx.c:	 * only it uses Tx-completion.
drivers/net/wireless/ti/wlcore/wlcore.h:	struct completion *elp_compl;
drivers/net/wireless/ti/wlcore/wlcore.h:	struct completion nvs_loading_complete;
drivers/net/wireless/ti/wlcore/wlcore_i.h:#include <linux/completion.h>
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		complete(&intr->read_regs.completion);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		complete(&intr->read_regs.completion);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c: * completion. The frame must contain the control set and have all the
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	init_completion(&intr->read_regs.completion);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	reinit_completion(&intr->read_regs.completion);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	time_left = wait_for_completion_timeout(&usb->intr.read_regs.completion,
drivers/net/wireless/zydas/zd1211rw/zd_usb.h:#include <linux/completion.h>
drivers/net/wireless/zydas/zd1211rw/zd_usb.h:	struct completion completion;
drivers/net/wwan/iosm/iosm_ipc_devlink.c:	init_completion(&ipc_devlink->devlink_sio.read_sem);
drivers/net/wwan/iosm/iosm_ipc_devlink.h:	struct completion read_sem;
drivers/net/wwan/iosm/iosm_ipc_imem.c:	init_completion(&channel->ul_sem);
drivers/net/wwan/iosm/iosm_ipc_imem.c:	init_completion(&ipc_imem->ul_pend_sem);
drivers/net/wwan/iosm/iosm_ipc_imem.c:	init_completion(&ipc_imem->dl_pend_sem);
drivers/net/wwan/iosm/iosm_ipc_imem.h:	struct completion ul_sem;
drivers/net/wwan/iosm/iosm_ipc_imem.h:	struct completion ul_pend_sem;
drivers/net/wwan/iosm/iosm_ipc_imem.h:	struct completion dl_pend_sem;
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	/* If there are any pending TDs then wait for Timeout/Completion before
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		status = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	/* If there are any pending TDs then wait for Timeout/Completion before
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		status = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	/* Due to wait for completion in messages, there is a small window
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	/* If there are any pending TDs then wait for Timeout/Completion before
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		status = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		status = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	/* Due to wait for completion in messages, there is a small window
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	ret = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:	ret = wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		ret = wait_for_completion_interruptible(&channel->ul_sem);
drivers/net/wwan/iosm/iosm_ipc_imem_ops.c:		if (!wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_mux_codec.c:	struct completion *completion = &ipc_mux->channel->ul_sem;
drivers/net/wwan/iosm/iosm_ipc_mux_codec.c:		reinit_completion(completion);
drivers/net/wwan/iosm/iosm_ipc_mux_codec.c:		if (wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_mux_codec.c:		   (completion, msecs_to_jiffies(wait_time_milliseconds)) ==
drivers/net/wwan/iosm/iosm_ipc_pm.c:		if (!wait_for_completion_interruptible_timeout
drivers/net/wwan/iosm/iosm_ipc_pm.c:	/* Create generic wait-for-completion handler for Host Sleep
drivers/net/wwan/iosm/iosm_ipc_pm.c:	init_completion(&ipc_pm->host_sleep_complete);
drivers/net/wwan/iosm/iosm_ipc_pm.h: * @host_sleep_complete:	Generic wait-for-completion used in
drivers/net/wwan/iosm/iosm_ipc_pm.h:	struct completion host_sleep_complete;
drivers/net/wwan/iosm/iosm_ipc_protocol.c:	init_completion(&response.completion);
drivers/net/wwan/iosm/iosm_ipc_protocol.c:	switch (wait_for_completion_timeout(&response.completion,
drivers/net/wwan/iosm/iosm_ipc_protocol.c:		 * Remove the reference to the local response completion
drivers/net/wwan/iosm/iosm_ipc_protocol.c:		/* We got a response in time; check completion status: */
drivers/net/wwan/iosm/iosm_ipc_protocol.c:				"msg completion status error %d",
drivers/net/wwan/iosm/iosm_ipc_protocol.h: *				completion for Messages.
drivers/net/wwan/iosm/iosm_ipc_protocol.h: * @rsp_ring:		Array of OS completion objects to be triggered once CP
drivers/net/wwan/iosm/iosm_ipc_protocol.h: *			completion object and return code.
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.c:			msg->common.completion_status);
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.c:				le32_to_cpu(msg->common.completion_status);
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.c:			complete(&rsp_ring[i]->completion);
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.c:	} else if (le32_to_cpu(p_td->scs) >> COMPLETION_STATUS ==
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:#define COMPLETION_STATUS 24
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * enum ipc_mem_td_cs - Completion status of a TD
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * enum ipc_mem_msg_cs - Completion status of IPC Message
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @IPC_MEM_MSG_CS_SUCCESS:	IPC Message completion success.
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion:	For waking up requestor
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @status:	Completion status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	struct completion completion;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @IPC_MEM_MSG_ABORT_PIPE:	AP ->CP: wait for completion of the
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:		Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:		Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:		Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:	Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:		Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * struct ipc_mem_msg_common - Message structure for completion status update.
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @completion_status:		Message Completion Status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	__le32 completion_status;
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h: * @common:		Used to access msg_type and to set the completion status
drivers/net/wwan/iosm/iosm_ipc_protocol_ops.h:	 *	3rd byte - This field provides the completion status
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:		/* Signal completion for synchronous calls */
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:		if (args->completion)
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:			complete(args->completion);
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:		args->completion = NULL;
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:/* Free memory alloc and trigger completions left in the queue during dealloc */
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:		if (args->completion)
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:			complete(args->completion);
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:	struct completion completion;
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:	init_completion(&completion);
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:		ipc_task->args[pos].completion = wait ? &completion : NULL;
drivers/net/wwan/iosm/iosm_ipc_task_queue.c:			wait_for_completion(&completion);
drivers/net/wwan/iosm/iosm_ipc_task_queue.h: * @completion: OS object used to wait for the tasklet function to finish for
drivers/net/wwan/iosm/iosm_ipc_task_queue.h:	struct completion *completion;
drivers/net/wwan/mhi_wwan_ctrl.c:	/* Protect against concurrent TX and TX-completion (bh) */
drivers/net/wwan/qcom_bam_dmux.c:#include <linux/completion.h>
drivers/net/wwan/qcom_bam_dmux.c:	struct completion pc_ack_completion;
drivers/net/wwan/qcom_bam_dmux.c:	reinit_completion(&dmux->pc_ack_completion);
drivers/net/wwan/qcom_bam_dmux.c:	complete_all(&dmux->pc_ack_completion);
drivers/net/wwan/qcom_bam_dmux.c:	if (!wait_for_completion_timeout(&dmux->pc_ack_completion,
drivers/net/wwan/qcom_bam_dmux.c:	if (!wait_for_completion_timeout(&dmux->pc_ack_completion,
drivers/net/wwan/qcom_bam_dmux.c:	init_completion(&dmux->pc_ack_completion);
drivers/net/wwan/qcom_bam_dmux.c:	complete_all(&dmux->pc_ack_completion);
drivers/net/wwan/t7xx/t7xx_hif_dpmaif_rx.c:	ret = try_wait_for_completion(&t7xx_dev->sleep_lock_acquire);
drivers/net/wwan/t7xx/t7xx_mhccif.c:#include <linux/completion.h>
drivers/net/wwan/t7xx/t7xx_modem_ops.c:		t7xx_fsm_append_cmd(md->fsm_ctl, FSM_CMD_PRE_STOP, FSM_CMD_FLAG_WAIT_FOR_COMPLETION);
drivers/net/wwan/t7xx/t7xx_pci.c:#include <linux/completion.h>
drivers/net/wwan/t7xx/t7xx_pci.c:	init_completion(&t7xx_dev->sleep_lock_acquire);
drivers/net/wwan/t7xx/t7xx_pci.c:	init_completion(&t7xx_dev->pm_sr_ack);
drivers/net/wwan/t7xx/t7xx_pci.c:	init_completion(&t7xx_dev->init_done);
drivers/net/wwan/t7xx/t7xx_pci.c:	ret = wait_for_completion_timeout(&t7xx_dev->sleep_lock_acquire,
drivers/net/wwan/t7xx/t7xx_pci.c:		reinit_completion(&t7xx_dev->sleep_lock_acquire);
drivers/net/wwan/t7xx/t7xx_pci.c:	reinit_completion(&t7xx_dev->pm_sr_ack);
drivers/net/wwan/t7xx/t7xx_pci.c:	wait_ret = wait_for_completion_timeout(&t7xx_dev->pm_sr_ack,
drivers/net/wwan/t7xx/t7xx_pci.c:		ret = t7xx_fsm_append_cmd(fsm_ctl, FSM_CMD_STOP, FSM_CMD_FLAG_WAIT_FOR_COMPLETION);
drivers/net/wwan/t7xx/t7xx_pci.c:	if (!wait_for_completion_timeout(&t7xx_dev->init_done, T7XX_INIT_TIMEOUT * HZ)) {
drivers/net/wwan/t7xx/t7xx_pci.h:#include <linux/completion.h>
drivers/net/wwan/t7xx/t7xx_pci.h:	struct completion	init_done;
drivers/net/wwan/t7xx/t7xx_pci.h:	struct completion	pm_sr_ack;
drivers/net/wwan/t7xx/t7xx_pci.h:	struct completion	sleep_lock_acquire;
drivers/net/wwan/t7xx/t7xx_state_monitor.c:#include <linux/completion.h>
drivers/net/wwan/t7xx/t7xx_state_monitor.c:	if (cmd->flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {
drivers/net/wwan/t7xx/t7xx_state_monitor.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/net/wwan/t7xx/t7xx_state_monitor.c:	if (flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {
drivers/net/wwan/t7xx/t7xx_state_monitor.c:	if (flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {
drivers/net/wwan/t7xx/t7xx_state_monitor.c:		wait_ret = wait_for_completion_timeout(&done,
drivers/net/wwan/t7xx/t7xx_state_monitor.h:#define FSM_CMD_FLAG_WAIT_FOR_COMPLETION	BIT(0)
drivers/net/wwan/t7xx/t7xx_state_monitor.h:	struct completion	*done;
drivers/net/wwan/wwan_hwsim.c:	flush_workqueue(wwan_wq);	/* Wait deletion works completion */
drivers/net/wwan/wwan_hwsim.c:	flush_workqueue(wwan_wq);	/* Wait deletion works completion */
drivers/nfc/mei_phy.h: * @send_wq: send completion wait queue
drivers/nfc/nfcmrvl/spi.c:	struct completion handshake_completion;
drivers/nfc/nfcmrvl/spi.c:		complete(&drv_data->handshake_completion);
drivers/nfc/nfcmrvl/spi.c:	/* Reinit completion for slave handshake */
drivers/nfc/nfcmrvl/spi.c:	reinit_completion(&drv_data->handshake_completion);
drivers/nfc/nfcmrvl/spi.c:	err = nci_spi_send(drv_data->nci_spi, &drv_data->handshake_completion,
drivers/nfc/nfcmrvl/spi.c:	/* Init completion for slave handshake */
drivers/nfc/nfcmrvl/spi.c:	init_completion(&drv_data->handshake_completion);
drivers/nfc/nxp-nci/core.c:	init_completion(&info->fw_info.cmd_completion);
drivers/nfc/nxp-nci/firmware.c:#include <linux/completion.h>
drivers/nfc/nxp-nci/firmware.c:	long completion_rc;
drivers/nfc/nxp-nci/firmware.c:	reinit_completion(&fw_info->cmd_completion);
drivers/nfc/nxp-nci/firmware.c:		completion_rc = wait_for_completion_interruptible_timeout(
drivers/nfc/nxp-nci/firmware.c:			&fw_info->cmd_completion, NXP_NCI_FW_ANSWER_TIMEOUT);
drivers/nfc/nxp-nci/firmware.c:		if (completion_rc == 0)
drivers/nfc/nxp-nci/firmware.c:	complete(&fw_info->cmd_completion);
drivers/nfc/nxp-nci/nxp-nci.h:#include <linux/completion.h>
drivers/nfc/nxp-nci/nxp-nci.h:	struct completion cmd_completion;
drivers/nfc/pn533/pn533.c:	struct completion done;
drivers/nfc/pn533/pn533.c:	init_completion(&arg.done);
drivers/nfc/pn533/pn533.c:	wait_for_completion(&arg.done);
drivers/nfc/pn533/usb.c:	struct completion done;
drivers/nfc/pn533/usb.c:	init_completion(&arg.done);
drivers/nfc/pn533/usb.c:	wait_for_completion(&arg.done);
drivers/nfc/pn533/usb.c:	struct completion done;
drivers/nfc/pn533/usb.c:	init_completion(&arg.done);
drivers/nfc/pn533/usb.c:	wait_for_completion(&arg.done);
drivers/nfc/port100.c:	struct completion cmd_cancel_done;
drivers/nfc/port100.c:		reinit_completion(&dev->cmd_cancel_done);
drivers/nfc/port100.c:		 * URB completion callback port100_send_complete().
drivers/nfc/port100.c:		wait_for_completion(&dev->cmd_cancel_done);
drivers/nfc/port100.c:	struct completion done;
drivers/nfc/port100.c:	init_completion(&arg.done);
drivers/nfc/port100.c:	wait_for_completion(&arg.done);
drivers/nfc/port100.c:	init_completion(&dev->cmd_cancel_done);
drivers/nfc/s3fwrn5/firmware.c:#include <linux/completion.h>
drivers/nfc/s3fwrn5/firmware.c:	reinit_completion(&fw_info->completion);
drivers/nfc/s3fwrn5/firmware.c:	ret = wait_for_completion_interruptible_timeout(
drivers/nfc/s3fwrn5/firmware.c:		&fw_info->completion, msecs_to_jiffies(1000));
drivers/nfc/s3fwrn5/firmware.c:	init_completion(&fw_info->completion);
drivers/nfc/s3fwrn5/firmware.c:	complete(&fw_info->completion);
drivers/nfc/s3fwrn5/firmware.h:	struct completion completion;
drivers/nfc/s3fwrn5/nci.c:#include <linux/completion.h>
drivers/nfc/st-nci/se.c:				complete(&info->se_info.req_completion);
drivers/nfc/st-nci/se.c:			complete(&info->se_info.req_completion);
drivers/nfc/st-nci/se.c:	reinit_completion(&info->se_info.req_completion);
drivers/nfc/st-nci/se.c:	wait_for_completion_interruptible(&info->se_info.req_completion);
drivers/nfc/st-nci/se.c:	complete(&info->se_info.req_completion);
drivers/nfc/st-nci/se.c:	init_completion(&info->se_info.req_completion);
drivers/nfc/st-nci/st-nci.h:	struct completion req_completion;
drivers/nfc/st21nfca/core.c:			complete(&info->se_info.req_completion);
drivers/nfc/st21nfca/core.c:				complete(&info->se_info.req_completion);
drivers/nfc/st21nfca/se.c:	reinit_completion(&info->se_info.req_completion);
drivers/nfc/st21nfca/se.c:	wait_for_completion_interruptible(&info->se_info.req_completion);
drivers/nfc/st21nfca/se.c:	complete(&info->se_info.req_completion);
drivers/nfc/st21nfca/se.c:	init_completion(&info->se_info.req_completion);
drivers/nfc/st21nfca/st21nfca.h:	struct completion req_completion;
drivers/nfc/st21nfca/st21nfca.h:	struct completion req_completion;
drivers/nfc/st21nfca/vendor_cmds.c:	complete(&info->vendor_info.req_completion);
drivers/nfc/st21nfca/vendor_cmds.c:	reinit_completion(&info->vendor_info.req_completion);
drivers/nfc/st21nfca/vendor_cmds.c:	wait_for_completion_interruptible(&info->vendor_info.req_completion);
drivers/nfc/st21nfca/vendor_cmds.c:	init_completion(&info->vendor_info.req_completion);
drivers/nfc/st95hf/core.c:	init_completion(&spicontext->done);
drivers/nfc/st95hf/spi.c:		reinit_completion(&spicontext->done);
drivers/nfc/st95hf/spi.c:	result = wait_for_completion_timeout(&spicontext->done,
drivers/nfc/st95hf/spi.h: * @done: completion structure to wait for st95hf response
drivers/nfc/st95hf/spi.h:	struct completion done;
drivers/ntb/core.c:	init_completion(&ntb->released);
drivers/ntb/core.c:	wait_for_completion(&ntb->released);
drivers/ntb/hw/idt/ntb_hw_idt.c: * - enable Completion TLPs translation
drivers/ntb/hw/idt/ntb_hw_idt.c:	/* Enable the ID protection and Completion TLPs translation */
drivers/ntb/hw/idt/ntb_hw_idt.c: * - disable Completion TLPs translation
drivers/ntb/hw/idt/ntb_hw_idt.c:	/* Disable Completion TLPs translation */
drivers/ntb/hw/idt/ntb_hw_idt.c: * - NTCTL has Completion TLPs translation enabled
drivers/ntb/hw/idt/ntb_hw_idt.c:	/* Read the local Completion TLPs translation enable status */
drivers/ntb/hw/idt/ntb_hw_idt.c: * - NTCTL has Completion TLPs translation enabled
drivers/ntb/hw/idt/ntb_hw_idt.c:	/* Check if Completion TLPs translation is enabled on the peer port */
drivers/ntb/hw/idt/ntb_hw_idt.h: * @IDT_NTCTL_CPEN:		Completion enable
drivers/ntb/hw/idt/ntb_hw_idt.h: *				Completion TLPs
drivers/ntb/ntb_transport.c:	 * cases, there is nothing to add to the completion queue.
drivers/ntb/test/ntb_msi_test.c:		struct completion init_comp;
drivers/ntb/test/ntb_msi_test.c:	*ready = try_wait_for_completion(&peer->init_comp);
drivers/ntb/test/ntb_msi_test.c:	return wait_for_completion_interruptible(&peer->init_comp);
drivers/ntb/test/ntb_msi_test.c:		init_completion(&nm->peers[i].init_comp);
drivers/ntb/test/ntb_perf.c:	struct completion init_comp;
drivers/ntb/test/ntb_perf.c:		init_completion(&peer->init_comp);
drivers/ntb/test/ntb_perf.c:	 * We call it anyway just to be sure of the transfers completion.
drivers/ntb/test/ntb_perf.c:	ret = wait_for_completion_interruptible(&peer->init_comp);
drivers/ntb/test/ntb_perf.c:		init_completion(&peer->init_comp);
drivers/nvme/host/apple.c: * The completion queue works as usual. The submission "queue" instead is
drivers/nvme/host/apple.c:	struct nvme_completion *cqes;
drivers/nvme/host/apple.c:	struct nvme_completion *hcqe = &q->cqes[q->cq_head];
drivers/nvme/host/apple.c:	struct nvme_completion *cqe = &q->cqes[idx];
drivers/nvme/host/apple.c:	 * must flush all entered requests to their failed completion to avoid
drivers/nvme/host/apple.c:				 "I/O %d(aq:%d) timeout: completion polled\n",
drivers/nvme/host/apple.c:	memset(q->cqes, 0, depth * sizeof(struct nvme_completion));
drivers/nvme/host/apple.c:				      depth * sizeof(struct nvme_completion),
drivers/nvme/host/constants.c:	[NVME_SC_CQ_INVALID] = "Completion Queue Invalid",
drivers/nvme/host/core.c:	 * Completions of long-running commands should not be able to
drivers/nvme/host/core.c:	 * command completion can postpone sending a keep alive command
drivers/nvme/host/fc.c:	struct completion	ls_done;
drivers/nvme/host/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/host/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/host/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/host/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/host/fc.c:	init_completion(&lsop->ls_done);
drivers/nvme/host/fc.c:		wait_for_completion(&lsop->ls_done);
drivers/nvme/host/fc.c:	/* don't wait for completion */
drivers/nvme/host/fc.c:	/* process connect LS completion */
drivers/nvme/host/fc.c:	/* process connect LS completion */
drivers/nvme/host/fc.c: * processing.  As such, upon completion of the routine, the LLDD may
drivers/nvme/host/fc.c:	struct nvme_completion *cqe = &op->rsp_iu.cqe;
drivers/nvme/host/fc.c:	 *    completions.
drivers/nvme/host/fc.c:	 *    ERSP completions are to go back to the nvme layer in order
drivers/nvme/host/fc.c:	 * detected fashion unrelated to the nvme completion status,
drivers/nvme/host/fc.c:		 * The ERSP IU contains a full completion with CQE.
drivers/nvme/host/fc.c:	 * io requests back to the block layer as part of normal completions
drivers/nvme/host/fc.c:	 * Attempt to abort the offending command. Command completion
drivers/nvme/host/fc.c:	 * restarted and the abort completion will complete the io
drivers/nvme/host/fc.c: * steps to complete the io. Upon completion, the transport done routine
drivers/nvme/host/ioctl.c:	 * safe to use the polled completion helper.
drivers/nvme/host/ioctl.c:	 * Otherwise, move the completion to task work.
drivers/nvme/host/ioctl.c:	/* to free bio on completion, as req->bio will be null at that time */
drivers/nvme/host/pci.c:#define CQ_SIZE(q)	((q)->q_depth * sizeof(struct nvme_completion))
drivers/nvme/host/pci.c:	struct nvme_completion *cqes;
drivers/nvme/host/pci.c:	struct completion delete_done;
drivers/nvme/host/pci.c:	struct nvme_completion *hcqe = &nvmeq->cqes[nvmeq->cq_head];
drivers/nvme/host/pci.c:	struct nvme_completion *cqe = &nvmeq->cqes[idx];
drivers/nvme/host/pci.c: * Poll for completions for any interrupt driven queue
drivers/nvme/host/pci.c:			 "I/O tag %d (%04x) QID %d timeout, completion polled\n",
drivers/nvme/host/pci.c: * that can check this device's completion queues have synced, except
drivers/nvme/host/pci.c: * completion before nvme_cancel_request() terminates all incomplete requests.
drivers/nvme/host/pci.c:		 * queue to flush these to completion.
drivers/nvme/host/pci.c:	init_completion(&nvmeq->delete_done);
drivers/nvme/host/pci.c:		timeout = wait_for_completion_io_timeout(&nvmeq->delete_done,
drivers/nvme/host/pci.c:	 * must flush all entered requests to their failed completion to avoid
drivers/nvme/host/rdma.c:	struct completion	cm_done;
drivers/nvme/host/rdma.c:	ret = wait_for_completion_interruptible(&queue->cm_done);
drivers/nvme/host/rdma.c:			sizeof(struct nvme_completion), DMA_FROM_DEVICE);
drivers/nvme/host/rdma.c:	 * Spread I/O queues completion vectors according their queue index.
drivers/nvme/host/rdma.c:	 * Admin queues can always go on completion vector 0.
drivers/nvme/host/rdma.c:			sizeof(struct nvme_completion), DMA_FROM_DEVICE);
drivers/nvme/host/rdma.c:			    sizeof(struct nvme_completion), DMA_FROM_DEVICE);
drivers/nvme/host/rdma.c:	init_completion(&queue->cm_done);
drivers/nvme/host/rdma.c:	refcount_set(&req->ref, 2); /* send and recv completions */
drivers/nvme/host/rdma.c:	list.length = sizeof(struct nvme_completion);
drivers/nvme/host/rdma.c:		struct nvme_completion *cqe, struct ib_wc *wc)
drivers/nvme/host/rdma.c:		/* the local invalidation completion will end the request */
drivers/nvme/host/rdma.c:	struct nvme_completion *cqe = qe->data;
drivers/nvme/host/rdma.c:	const size_t len = sizeof(struct nvme_completion);
drivers/nvme/host/rdma.c:			"Unexpected nvme completion length(%d)\n", wc->byte_len);
drivers/nvme/host/tcp.c:	struct completion       tls_complete;
drivers/nvme/host/tcp.c:		struct nvme_completion *cqe)
drivers/nvme/host/tcp.c:	struct nvme_completion *cqe = &pdu->cqe;
drivers/nvme/host/tcp.c:	init_completion(&queue->tls_complete);
drivers/nvme/host/tcp.c:	ret = wait_for_completion_interruptible_timeout(&queue->tls_complete, tmo);
drivers/nvme/target/admin-cmd.c:	id->iorcsz = cpu_to_le32(sizeof(struct nvme_completion) / 16);
drivers/nvme/target/core.c:	wait_for_completion(&ns->disable_done);
drivers/nvme/target/core.c:	init_completion(&ns->disable_done);
drivers/nvme/target/core.c:	wait_for_completion(&sq->confirm_done);
drivers/nvme/target/core.c:	wait_for_completion(&sq->free_done);
drivers/nvme/target/core.c:	init_completion(&sq->free_done);
drivers/nvme/target/core.c:	init_completion(&sq->confirm_done);
drivers/nvme/target/fc.c:	/* don't wait for completion */
drivers/nvme/target/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/target/fc.c: * a completion status. Must be 0 upon success; a negative errno
drivers/nvme/target/fc.c: * processing.  As such, upon completion of the routine, the LLDD may
drivers/nvme/target/fc.c:	struct nvme_completion *cqe = &ersp->cqe;
drivers/nvme/target/fc.c: * actual completion handler after execution by the nvmet layer
drivers/nvme/target/fc.c:	struct nvme_completion *cqe = &fod->rspiubuf.cqe;
drivers/nvme/target/fc.c:	 * can invoke the nvmet_layer now. If read data, cmd completion will
drivers/nvme/target/fc.c: * completion (returns 0), the LLDD may immediately free/reuse
drivers/nvme/target/fc.c: * response, but the LLDD may not get the hw completion for that command
drivers/nvme/target/fc.c: * The LLDD, when receiving an -EOVERFLOW completion status, is to treat
drivers/nvme/target/fc.c: * the completion as successful but must not reuse the CMD IU buffer
drivers/nvme/target/fc.c: * completion from the nvmet layer of the nvme command), then will
drivers/nvme/target/fc.c:		 * mark as abort. The abort handler, invoked upon completion
drivers/nvme/target/fcloop.c:	struct completion unreg_done;
drivers/nvme/target/fcloop.c: * FCP IO operation done by target completion.
drivers/nvme/target/fcloop.c:	init_completion(&lport->unreg_done);
drivers/nvme/target/fcloop.c:		wait_for_completion(&lport->unreg_done);
drivers/nvme/target/loop.c:	struct nvme_completion	cqe;
drivers/nvme/target/loop.c:	struct nvme_completion *cqe = req->cqe;
drivers/nvme/target/nvmet.h:	struct completion	disable_done;
drivers/nvme/target/nvmet.h:	struct completion	free_done;
drivers/nvme/target/nvmet.h:	struct completion	confirm_done;
drivers/nvme/target/nvmet.h:	struct nvme_completion	*cqe;
drivers/nvme/target/passthru.c:	id->iorcsz = cpu_to_le32(sizeof(struct nvme_completion) / 16);
drivers/nvme/target/rdma.c:	 * Upon RDMA completion check the signature status
drivers/nvme/target/rdma.c:	 * Spread the io queues across completion vectors,
drivers/parisc/lba_pci.c:** guarantee non-postable completion semantics - not avoid X4107.
drivers/parport/parport_ip32.c:#include <linux/completion.h>
drivers/parport/parport_ip32.c:	struct completion		irq_complete;
drivers/parport/parport_ip32.c:		reinit_completion(&priv->irq_complete);
drivers/parport/parport_ip32.c:			wait_for_completion_interruptible_timeout(
drivers/parport/parport_ip32.c:	reinit_completion(&priv->irq_complete);
drivers/parport/parport_ip32.c:		wait_for_completion_interruptible_timeout(&priv->irq_complete,
drivers/parport/parport_ip32.c:	init_completion(&priv->irq_complete);
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_SHIFT		7
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_MASK		GENMASK(9, 7)
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_OK		0
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_UR		1
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_RRS		2
drivers/pci/controller/pci-aardvark.c:#define   PIO_COMPLETION_STATUS_CA		4
drivers/pci/controller/pci-aardvark.c:	status = (reg & PIO_COMPLETION_STATUS_MASK) >>
drivers/pci/controller/pci-aardvark.c:		PIO_COMPLETION_STATUS_SHIFT;
drivers/pci/controller/pci-aardvark.c:	 * 1) even if COMPLETION_STATUS(bit9:7) indicates successful,
drivers/pci/controller/pci-aardvark.c:	 * 2) value Unsupported Request(1) of COMPLETION_STATUS(bit9:7) only
drivers/pci/controller/pci-aardvark.c:	 * 3) value Config Request Retry Status(RRS) of COMPLETION_STATUS(bit9:7)
drivers/pci/controller/pci-aardvark.c:	 * 4) value Completer Abort (CA) of COMPLETION_STATUS(bit9:7) means
drivers/pci/controller/pci-aardvark.c:	case PIO_COMPLETION_STATUS_OK:
drivers/pci/controller/pci-aardvark.c:	case PIO_COMPLETION_STATUS_UR:
drivers/pci/controller/pci-aardvark.c:	case PIO_COMPLETION_STATUS_RRS:
drivers/pci/controller/pci-aardvark.c:		 * of Configuration Request/RRS Completion Status loops before
drivers/pci/controller/pci-aardvark.c:	case PIO_COMPLETION_STATUS_CA:
drivers/pci/controller/pci-aardvark.c:	/* Indicates supports for Completion Retry Status */
drivers/pci/controller/pci-aardvark.c:	 * advk_pcie_wait_pio() does not always have to wait for completion.
drivers/pci/controller/pci-hyperv.c:	void (*completion_func)(void *context, struct pci_response *resp,
drivers/pci/controller/pci-hyperv.c:	struct completion *survey_event;
drivers/pci/controller/pci-hyperv.c:	struct completion host_event;
drivers/pci/controller/pci-hyperv.c:	s32 completion_status;
drivers/pci/controller/pci-hyperv.c: * hv_pci_generic_compl() - Invoked for a completion packet
drivers/pci/controller/pci-hyperv.c: * for any message for which the completion packet contains a
drivers/pci/controller/pci-hyperv.c:	comp_pkt->completion_status = resp->status;
drivers/pci/controller/pci-hyperv.c:			     struct completion *comp)
drivers/pci/controller/pci-hyperv.c:		if (wait_for_completion_timeout(comp, HZ / 10))
drivers/pci/controller/pci-hyperv.c:		comp->comp_pkt.completion_status = -1;
drivers/pci/controller/pci-hyperv.c:	comp->comp_pkt.completion_status = read_resp->status;
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt.pkt.completion_func = hv_pci_read_config_compl;
drivers/pci/controller/pci-hyperv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:	if (comp_pkt.comp_pkt.completion_status != 0 ||
drivers/pci/controller/pci-hyperv.c:			comp_pkt.comp_pkt.completion_status,
drivers/pci/controller/pci-hyperv.c:	comp_pkt->completion_status = resp->status;
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt.pkt.completion_func = hv_pci_write_config_compl;
drivers/pci/controller/pci-hyperv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:	if (comp_pkt.completion_status != 0) {
drivers/pci/controller/pci-hyperv.c:			comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:		comp_pkt->comp_pkt.completion_status = -1;
drivers/pci/controller/pci-hyperv.c:	comp_pkt->comp_pkt.completion_status = resp->status;
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp.comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	ctxt.pci_pkt.completion_func = hv_pci_compose_compl;
drivers/pci/controller/pci-hyperv.c:				     VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:			comp.comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:	 * do normal wait for completion; instead poll.
drivers/pci/controller/pci-hyperv.c:	while (!try_wait_for_completion(&comp.comp_pkt.host_event)) {
drivers/pci/controller/pci-hyperv.c:	if (comp.comp_pkt.completion_status < 0) {
drivers/pci/controller/pci-hyperv.c:			comp.comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:	 * The completion packet on the stack becomes invalid after 'return';
drivers/pci/controller/pci-hyperv.c:	struct completion *event;
drivers/pci/controller/pci-hyperv.c:	struct completion host_event;
drivers/pci/controller/pci-hyperv.c: * @context:		The completion context.
drivers/pci/controller/pci-hyperv.c: * This function is invoked on completion of a Query Resource
drivers/pci/controller/pci-hyperv.c:	struct q_res_req_compl *completion = context;
drivers/pci/controller/pci-hyperv.c:		dev_err(&completion->hpdev->hbus->hdev->device,
drivers/pci/controller/pci-hyperv.c:			completion->hpdev->probed_bar[i] =
drivers/pci/controller/pci-hyperv.c:	complete(&completion->host_event);
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt.init_packet.completion_func = q_resource_requirements;
drivers/pci/controller/pci-hyperv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:			 * Call ->completion_func() within the critical section to make
drivers/pci/controller/pci-hyperv.c:			 * completion, and that the packet data is still on the waiting
drivers/pci/controller/pci-hyperv.c:			comp_packet->completion_func(comp_packet->compl_ctxt,
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt->completion_func = hv_pci_generic_compl;
drivers/pci/controller/pci-hyperv.c:				VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:		if (comp_pkt.completion_status >= 0) {
drivers/pci/controller/pci-hyperv.c:		if (comp_pkt.completion_status != STATUS_REVISION_MISMATCH) {
drivers/pci/controller/pci-hyperv.c:				comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:		reinit_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt->completion_func = hv_pci_generic_compl;
drivers/pci/controller/pci-hyperv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:	if (comp_pkt.completion_status < 0 && retry) {
drivers/pci/controller/pci-hyperv.c:	if (comp_pkt.completion_status < 0) {
drivers/pci/controller/pci-hyperv.c:			comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:	struct completion comp;
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp);
drivers/pci/controller/pci-hyperv.c:		init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:		pkt->completion_func = hv_pci_generic_compl;
drivers/pci/controller/pci-hyperv.c:				VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:		if (comp_pkt.completion_status < 0) {
drivers/pci/controller/pci-hyperv.c:				comp_pkt.completion_status);
drivers/pci/controller/pci-hyperv.c:	init_completion(&comp_pkt.host_event);
drivers/pci/controller/pci-hyperv.c:	pkt.teardown_packet.completion_func = hv_pci_generic_compl;
drivers/pci/controller/pci-hyperv.c:				     VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/pci/controller/pci-hyperv.c:	if (wait_for_completion_timeout(&comp_pkt.host_event, 10 * HZ) == 0) {
drivers/pci/controller/pci-hyperv.c:		 * The completion packet on the stack becomes invalid after
drivers/pci/controller/pcie-apple.c:	struct completion	event;
drivers/pci/controller/pcie-apple.c:	/* Read back to ensure completion of the write */
drivers/pci/controller/pcie-apple.c:	init_completion(&pcie->event);
drivers/pci/controller/pcie-apple.c:	if (!wait_for_completion_timeout(&pcie->event, HZ / 10))
drivers/pci/controller/pcie-iproc.c:	 * when it receives a RRS completion, regardless of the address of
drivers/pci/controller/pcie-iproc.c:	 * a RRS completion, so we will incorrectly retry the read and
drivers/pci/controller/pcie-mediatek.c:	/* Check completion status */
drivers/pci/controller/pcie-mediatek.c:	/* Check completion status */
drivers/pci/controller/pcie-rcar-ep.c:	/* Set the completion timer timeout to the maximum 50ms. */
drivers/pci/controller/pcie-rcar-host.c:	/* Set the completion timer timeout to the maximum 50ms. */
drivers/pci/controller/pcie-rockchip-host.c:			dev_dbg(dev, "parity error detected while reading from the Completion Receive FIFO RAM\n");
drivers/pci/controller/pcie-rockchip-host.c:			dev_dbg(dev, "overflow occurred in the completion receive FIFO\n");
drivers/pci/controller/pcie-rockchip-host.c:			dev_dbg(dev, "a request timed out waiting for completion\n");
drivers/pci/controller/pcie-xilinx-cpm.c:	_IC(SLV_UNEXP,		"Slave unexpected completion"),
drivers/pci/controller/pcie-xilinx-cpm.c:	_IC(SLV_COMPL,		"Slave completion timeout"),
drivers/pci/controller/pcie-xilinx-cpm.c:	_IC(CFG_ERR_POISON,	"ECAM poisoned completion received"),
drivers/pci/controller/pcie-xilinx-cpm.c:	_IC(SLV_PCIE_TIMEOUT,	"PCIe completion timeout received"),
drivers/pci/controller/pcie-xilinx-dma-pl.c:	_IC(SLV_UNEXP,		"Slave unexpected completion"),
drivers/pci/controller/pcie-xilinx-dma-pl.c:	_IC(SLV_COMPL,		"Slave completion timeout"),
drivers/pci/controller/pcie-xilinx.c:		dev_warn(dev, "Slave unexpected completion\n");
drivers/pci/controller/pcie-xilinx.c:		dev_warn(dev, "Slave completion timeout\n");
drivers/pci/controller/vmd.c: * read-back in this function forces the completion so it returns only after
drivers/pci/doe.c:	DECLARE_COMPLETION_ONSTACK(c);
drivers/pci/doe.c:	wait_for_completion(&c);
drivers/pci/endpoint/functions/pci-epf-mhi.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/pci/endpoint/functions/pci-epf-mhi.c:	ret = wait_for_completion_timeout(&complete, msecs_to_jiffies(1000));
drivers/pci/endpoint/functions/pci-epf-mhi.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/pci/endpoint/functions/pci-epf-mhi.c:	ret = wait_for_completion_timeout(&complete, msecs_to_jiffies(1000));
drivers/pci/endpoint/functions/pci-epf-mhi.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/pci/endpoint/functions/pci-epf-mhi.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/pci/endpoint/functions/pci-epf-test.c:	struct completion	transfer_complete;
drivers/pci/endpoint/functions/pci-epf-test.c:	reinit_completion(&epf_test->transfer_complete);
drivers/pci/endpoint/functions/pci-epf-test.c:	ret = wait_for_completion_interruptible(&epf_test->transfer_complete);
drivers/pci/endpoint/functions/pci-epf-test.c:		dev_err(dev, "DMA wait_for_completion interrupted\n");
drivers/pci/endpoint/functions/pci-epf-test.c:	init_completion(&epf_test->transfer_complete);
drivers/pci/endpoint/functions/pci-epf-test.c:	init_completion(&epf_test->transfer_complete);
drivers/pci/hotplug/ibmphp_hpc.c:#include <linux/completion.h>
drivers/pci/hotplug/ibmphp_hpc.c:static DECLARE_COMPLETION(exit_complete); // make sure polling thread goes away
drivers/pci/hotplug/ibmphp_hpc.c:	wait_for_completion(&exit_complete);
drivers/pci/hotplug/ibmphp_hpc.c:	debug("after exit_completion down\n");
drivers/pci/hotplug/pciehp.h: * @requester: wait queue to wake up on completion of user request,
drivers/pci/hotplug/pciehp_hpc.c:	 * completions, we never need to wait between writes.
drivers/pci/hotplug/pciehp_hpc.c:	 * indicating completion of the above issued command.
drivers/pci/hotplug/shpchp_hpc.c:	 * Wait for command completion.
drivers/pci/hotplug/shpchp_hpc.c:		 * RO only - clear by writing 1 to the Command Completion
drivers/pci/npem.c:	 * in a command completion indication in the NPEM Status Register.
drivers/pci/pci-acpi.c:		 * If the Root Port supports Read Completion Boundary of
drivers/pci/pci.c: * completions (PCIe r6.0 sec 2.3.1).  The spec does not provide an upper
drivers/pci/pci.c:	/* P2P Completion Redirect */
drivers/pci/pci.c:	 * Successful Completion, hardware generally synthesizes ~0
drivers/pci/pci.c: * the requested completion capabilities (32-bit, 64-bit and/or 128-bit
drivers/pci/pci.c: * AtomicOp completion), or negative otherwise.
drivers/pci/pci.c: * Retrain completion status is retrieved from the Link Status Register
drivers/pci/pci.c:	 * Retry Status completions.
drivers/pci/pci.h: * request (device able to respond with a "Request Retry Status" completion),
drivers/pci/pcie/dpc.c:	"Configuration Request received UR Completion",	 /* Bit Position 0  */
drivers/pci/pcie/dpc.c:	"Configuration Request received CA Completion",	 /* Bit Position 1  */
drivers/pci/pcie/dpc.c:	"Configuration Request Completion Timeout",	 /* Bit Position 2  */
drivers/pci/pcie/dpc.c:	"I/O Request received UR Completion",		 /* Bit Position 8  */
drivers/pci/pcie/dpc.c:	"I/O Request received CA Completion",		 /* Bit Position 9  */
drivers/pci/pcie/dpc.c:	"I/O Request Completion Timeout",		 /* Bit Position 10 */
drivers/pci/pcie/dpc.c:	"Memory Request received UR Completion",	 /* Bit Position 16 */
drivers/pci/pcie/dpc.c:	"Memory Request received CA Completion",	 /* Bit Position 17 */
drivers/pci/pcie/dpc.c:	"Memory Request Completion Timeout",		 /* Bit Position 18 */
drivers/pci/probe.c:		return true;	/* not a Configuration RRS completion */
drivers/pci/probe.c:	 * We got the reserved Vendor ID that indicates a completion with
drivers/pci/probe.c:	 * ACS Source Validation errors on completions for config reads.
drivers/pci/quirks.c: * Intel 5000 and 5100 Memory controllers have an erratum with read completion
drivers/pci/quirks.c: * until all of the devices are discovered and buses walked, read completion
drivers/pci/quirks.c:		pci_err(dev, "Error attempting to read the read completion coalescing register\n");
drivers/pci/quirks.c:		pci_err(dev, "Error attempting to write the read completion coalescing register\n");
drivers/pci/quirks.c:	pr_info_once("Read completion coalescing disabled due to hardware erratum relating to 256B MPS\n");
drivers/pci/quirks.c:	 * in order generate Completions.  Issue a config write to let the
drivers/pci/quirks.c:	pci_info(dev, "Disable Relaxed Ordering Attributes to avoid PCIe Completion erratum\n");
drivers/pci/quirks.c: * Per PCIe r3.0, sec 2.2.9, "Completion headers must supply the same
drivers/pci/quirks.c: * If a non-compliant device generates a completion with a different
drivers/pci/quirks.c: * Malformed TLP or an Unexpected Completion, which will probably lead to a
drivers/pci/quirks.c: * If the non-compliant device generates completions with zero attributes
drivers/pci/quirks.c:		pci_warn(pdev, "PCIe Completion erratum may cause device errors\n");
drivers/pci/quirks.c:	pci_info(root_port, "Disabling No Snoop/Relaxed Ordering Attributes to avoid PCIe Completion erratum in %s\n",
drivers/pci/quirks.c: * Completion it generates.
drivers/pci/quirks.c: * Such devices effectively enable request redirect (RR) and completion
drivers/pci/quirks.c:	 * Source Validation, Request Redirection, Completion Redirection,
drivers/pci/quirks.c: * completions for config read requests even though PCIe r4.0, sec
drivers/pci/quirks.c: * 6.12.1.1, says that completions are never affected by ACS Source
drivers/pci/quirks.c: *   Item #36 - Downstream port applies ACS Source Validation to Completions
drivers/pci/quirks.c: *   completions are never affected by ACS Source Validation.  However,
drivers/pci/quirks.c: *   completions received by a downstream port of the PCIe switch from a
drivers/pci/quirks.c: * sec 2.2.9), thus avoiding the ACS error on the completion.
drivers/pci/switch/switchtec.c:	/* Mark the hardware as unavailable and complete all completions */
drivers/pcmcia/cs.c:	init_completion(&socket->socket_released);
drivers/pcmcia/cs.c:	init_completion(&socket->thread_done);
drivers/pcmcia/cs.c:	wait_for_completion(&socket->thread_done);
drivers/pcmcia/cs.c:	wait_for_completion(&socket->socket_released);
drivers/pcmcia/cs.c:static struct completion pcmcia_unload;
drivers/pcmcia/cs.c:	init_completion(&pcmcia_unload);
drivers/pcmcia/cs.c:	wait_for_completion(&pcmcia_unload);
drivers/peci/controller/peci-aspeed.c:	spinlock_t lock; /* to sync completion status handling */
drivers/peci/controller/peci-aspeed.c:	struct completion xfer_complete;
drivers/peci/controller/peci-aspeed.c:	reinit_completion(&priv->xfer_complete);
drivers/peci/controller/peci-aspeed.c:	ret = wait_for_completion_interruptible_timeout(&priv->xfer_complete, timeout);
drivers/peci/controller/peci-aspeed.c:	init_completion(&priv->xfer_complete);
drivers/peci/controller/peci-npcm.c:	struct completion	xfer_complete;
drivers/peci/controller/peci-npcm.c:	spinlock_t		lock; /* to sync completion status handling */
drivers/peci/controller/peci-npcm.c:	reinit_completion(&priv->xfer_complete);
drivers/peci/controller/peci-npcm.c:	ret = wait_for_completion_interruptible_timeout(&priv->xfer_complete, timeout);
drivers/peci/controller/peci-npcm.c:	init_completion(&priv->xfer_complete);
drivers/peci/request.c:/* Device Specific Completion Code (CC) Definition */
drivers/peci/request.c: * peci_request_status() - return -errno based on PECI completion code
drivers/peci/request.c: * @req: the PECI request that contains response data with completion code
drivers/peci/request.c: * don't expect completion code in the response.
drivers/peci/request.c:	WARN_ONCE(1, "Unknown PECI completion code: %#02x\n", cc);
drivers/perf/dwc_pcie_pmu.c:	DWC_PCIE_PMU_LANE_EVENT_ATTR(tx_completion_without_data, 0x706),
drivers/perf/dwc_pcie_pmu.c:	DWC_PCIE_PMU_LANE_EVENT_ATTR(tx_completion_with_data, 0x707),
drivers/perf/dwc_pcie_pmu.c:	DWC_PCIE_PMU_LANE_EVENT_ATTR(rx_completion_without_data, 0x711),
drivers/perf/dwc_pcie_pmu.c:	DWC_PCIE_PMU_LANE_EVENT_ATTR(rx_completion_with_data, 0x712),
drivers/phy/cadence/phy-cadence-torrent.c:	/* Wait, until PHY acknowledges power state completion. */
drivers/phy/motorola/phy-mapphone-mdm6600.c:	struct completion ack;
drivers/phy/motorola/phy-mapphone-mdm6600.c:	if (wait_for_completion_timeout(&ddata->ack,
drivers/phy/motorola/phy-mapphone-mdm6600.c:	if (wait_for_completion_timeout(&ddata->ack,
drivers/phy/motorola/phy-mapphone-mdm6600.c:	init_completion(&ddata->ack);
drivers/phy/motorola/phy-mapphone-mdm6600.c:		wait_for_completion_timeout(&ddata->ack,
drivers/phy/phy-xgene.c:	/* Poll the PLL calibration completion status for at least 1 ms */
drivers/phy/st/phy-spear1340-miphy.c:	/* Wait for SATA reset de-assert completion */
drivers/phy/st/phy-spear1340-miphy.c:	/* Wait for SATA reset assert completion */
drivers/platform/chrome/cros_ec_rpmsg.c:#include <linux/completion.h>
drivers/platform/chrome/cros_ec_rpmsg.c: * @xfer_ack:	completion for host command transfer.
drivers/platform/chrome/cros_ec_rpmsg.c:	struct completion xfer_ack;
drivers/platform/chrome/cros_ec_rpmsg.c:	reinit_completion(&ec_rpmsg->xfer_ack);
drivers/platform/chrome/cros_ec_rpmsg.c:	ret = wait_for_completion_timeout(&ec_rpmsg->xfer_ack, timeout);
drivers/platform/chrome/cros_ec_rpmsg.c:	init_completion(&ec_rpmsg->xfer_ack);
drivers/platform/cznic/turris-omnia-mcu-gpio.c:	 * completion of the OMNIA_CMD_GET_STATUS_WORD command, resulting in
drivers/platform/cznic/turris-omnia-mcu-trng.c:#include <linux/completion.h>
drivers/platform/cznic/turris-omnia-mcu-trng.c:	if (!wait && !completion_done(&mcu->trng_entropy_ready))
drivers/platform/cznic/turris-omnia-mcu-trng.c:		if (wait_for_completion_interruptible(&mcu->trng_entropy_ready))
drivers/platform/cznic/turris-omnia-mcu-trng.c:	init_completion(&mcu->trng_entropy_ready);
drivers/platform/cznic/turris-omnia-mcu.h:#include <linux/completion.h>
drivers/platform/cznic/turris-omnia-mcu.h:	struct completion trng_entropy_ready;
drivers/platform/mellanox/mlxreg-hotplug.c: * @after_probe: flag indication probing completion;
drivers/platform/mellanox/mlxreg-lc.c:static int mlxreg_lc_completion_notify(void *handle, struct i2c_adapter *parent,
drivers/platform/mellanox/mlxreg-lc.c:	mlxreg_lc->mux_data->completion_notify = mlxreg_lc_completion_notify;
drivers/platform/mellanox/nvsw-sn2201.c: * Completion notify callback is used to make this flow synchronized.
drivers/platform/mellanox/nvsw-sn2201.c:static int nvsw_sn2201_i2c_completion_notify(void *handle, int id)
drivers/platform/mellanox/nvsw-sn2201.c:	nvsw_sn2201->i2c_data->completion_notify = nvsw_sn2201_i2c_completion_notify;
drivers/platform/olpc/olpc-ec.c:#include <linux/completion.h>
drivers/platform/olpc/olpc-ec.c:	struct completion finished;
drivers/platform/olpc/olpc-ec.c:	init_completion(&desc.finished);
drivers/platform/olpc/olpc-ec.c:	wait_for_completion(&desc.finished);
drivers/platform/olpc/olpc-xo175-ec.c:#include <linux/completion.h>
drivers/platform/olpc/olpc-xo175-ec.c:	struct completion cmd_done;
drivers/platform/olpc/olpc-xo175-ec.c:	init_completion(&priv->cmd_done);
drivers/platform/olpc/olpc-xo175-ec.c:	if (!wait_for_completion_timeout(&priv->cmd_done,
drivers/platform/olpc/olpc-xo175-ec.c:	init_completion(&priv->cmd_done);
drivers/platform/surface/aggregator/controller.c:#include <linux/completion.h>
drivers/platform/surface/aggregator/controller.c:/* -- Event/async request completion system. -------------------------------- */
drivers/platform/surface/aggregator/controller.c: * SSAM_CPLT_WQ_BATCH - Maximum number of event item completions executed per
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system on which to look for the queue.
drivers/platform/surface/aggregator/controller.c: * ssam_cplt_submit() - Submit a work item to the completion system workqueue.
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system.
drivers/platform/surface/aggregator/controller.c: * ssam_cplt_submit_event() - Submit an event to the completion system.
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system.
drivers/platform/surface/aggregator/controller.c: * Submits the event to the completion system by queuing it on the event item
drivers/platform/surface/aggregator/controller.c: * queue and queuing the respective event queue work item on the completion
drivers/platform/surface/aggregator/controller.c: * ssam_cplt_flush() - Flush the completion system.
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system.
drivers/platform/surface/aggregator/controller.c: * Flush the completion system by waiting until all currently submitted work
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system on which the queue resides.
drivers/platform/surface/aggregator/controller.c: * ssam_cplt_init() - Initialize completion system.
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system to initialize.
drivers/platform/surface/aggregator/controller.c: * ssam_cplt_destroy() - Deinitialize the completion system.
drivers/platform/surface/aggregator/controller.c: * @cplt: The completion system to deinitialize.
drivers/platform/surface/aggregator/controller.c: * Deinitialize the given completion system and ensure that all pending, i.e.
drivers/platform/surface/aggregator/controller.c:	/* Initialize event/request completion system. */
drivers/platform/surface/aggregator/controller.c:	init_completion(&rqst->comp);
drivers/platform/surface/aggregator/controller.c: * request specification, submits it, and finally waits for its completion
drivers/platform/surface/aggregator/controller.c: * waits for its completion before returning its status. The
drivers/platform/surface/aggregator/controller.h:/* -- Event/async request completion system. -------------------------------- */
drivers/platform/surface/aggregator/controller.h: * struct ssam_event_item - Struct for event queuing and completion.
drivers/platform/surface/aggregator/controller.h: * @cplt: Reference to the completion system on which this queue is active.
drivers/platform/surface/aggregator/controller.h: * @work: The &struct work_struct performing completion work for this queue.
drivers/platform/surface/aggregator/controller.h: * struct ssam_cplt - SSAM event/async request completion system.
drivers/platform/surface/aggregator/controller.h: * @wq:           The &struct workqueue_struct on which all completion work
drivers/platform/surface/aggregator/controller.h: * @event:        Event completion management.
drivers/platform/surface/aggregator/controller.h: * @cplt:  Completion system for SSH/SSAM events and asynchronous requests.
drivers/platform/surface/aggregator/core.c:#include <linux/completion.h>
drivers/platform/surface/aggregator/ssh_packet_layer.c: * On transmission failure (such as repeated packet timeouts), the completion
drivers/platform/surface/aggregator/ssh_packet_layer.c: * Note that the packet completion callback is, in case of success and for a
drivers/platform/surface/aggregator/ssh_packet_layer.c: * a way to reliably identify responses to the packet. The packet completion
drivers/platform/surface/aggregator/ssh_packet_layer.c: * the packet is being re-transmitted while the completion callback runs.
drivers/platform/surface/aggregator/ssh_packet_layer.c: * Completion will occur both on success and internal error, as well as when
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   Indicates if the packet completion callback has been executed or is about
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   to be executed. This flag is used to ensure that the packet completion
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   re-transmissions, it is only safe to wait on the "transmitted" completion
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   after this flag has been set. The completion will be set both in success
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   and/or the completion may be triggered an error even though this bit is
drivers/platform/surface/aggregator/ssh_packet_layer.c: *   set. Rely on the status provided to the completion callback instead.
drivers/platform/surface/aggregator/ssh_packet_layer.c:	status = wait_for_completion_interruptible(&ptl->tx.thread_cplt_pkt);
drivers/platform/surface/aggregator/ssh_packet_layer.c:	reinit_completion(&ptl->tx.thread_cplt_pkt);
drivers/platform/surface/aggregator/ssh_packet_layer.c:	 * Ensure completion is cleared before continuing to avoid lost update
drivers/platform/surface/aggregator/ssh_packet_layer.c:	status = wait_for_completion_interruptible_timeout(&ptl->tx.thread_cplt_tx,
drivers/platform/surface/aggregator/ssh_packet_layer.c:	reinit_completion(&ptl->tx.thread_cplt_tx);
drivers/platform/surface/aggregator/ssh_packet_layer.c:	 * Ensure completion is cleared before continuing to avoid lost update
drivers/platform/surface/aggregator/ssh_packet_layer.c:		 * error completion. The packet will be removed shortly.
drivers/platform/surface/aggregator/ssh_packet_layer.c: * Cancels a packet. There are no guarantees on when completion and release
drivers/platform/surface/aggregator/ssh_packet_layer.c:	init_completion(&ptl->tx.thread_cplt_pkt);
drivers/platform/surface/aggregator/ssh_packet_layer.c:	init_completion(&ptl->tx.thread_cplt_tx);
drivers/platform/surface/aggregator/ssh_packet_layer.h: * @tx.thread_cplt_tx:  Completion for transmitter thread waiting on transfer.
drivers/platform/surface/aggregator/ssh_packet_layer.h: * @tx.thread_cplt_pkt: Completion for transmitter thread waiting on packets.
drivers/platform/surface/aggregator/ssh_packet_layer.h: * @tx.packet_wq:  Waitqueue-head for packet transmit completion.
drivers/platform/surface/aggregator/ssh_packet_layer.h:		struct completion thread_cplt_tx;
drivers/platform/surface/aggregator/ssh_packet_layer.h:		struct completion thread_cplt_pkt;
drivers/platform/surface/aggregator/ssh_request_layer.c:#include <linux/completion.h>
drivers/platform/surface/aggregator/ssh_request_layer.c:	 * request, we are guaranteed that the completion callback will run on
drivers/platform/surface/aggregator/ssh_request_layer.c:	 * this will subsequently (and synchronously) call the completion
drivers/platform/surface/aggregator/ssh_request_layer.c: * If the request has been canceled by calling this function, both completion
drivers/platform/surface/aggregator/ssh_request_layer.c:	struct completion completion;
drivers/platform/surface/aggregator/ssh_request_layer.c:	complete_all(&rqst->completion);
drivers/platform/surface/aggregator/ssh_request_layer.c: * Queue a special flush request and wait for its completion. This request
drivers/platform/surface/aggregator/ssh_request_layer.c: * a special flush packet, meaning that upon completion, also the underlying
drivers/platform/surface/aggregator/ssh_request_layer.c:	init_completion(&rqst.completion);
drivers/platform/surface/aggregator/ssh_request_layer.c:	if (!wait_for_completion_timeout(&rqst.completion, timeout)) {
drivers/platform/surface/aggregator/ssh_request_layer.c:		wait_for_completion(&rqst.completion);
drivers/platform/surface/surface_acpi_notify.c:	 * all delayed works they may have spawned are run to completion.
drivers/platform/x86/apple-gmux.c:	struct completion powerchange_done;
drivers/platform/x86/apple-gmux.c:	reinit_completion(&gmux_data->powerchange_done);
drivers/platform/x86/apple-gmux.c:	    !wait_for_completion_interruptible_timeout(&gmux_data->powerchange_done,
drivers/platform/x86/apple-gmux.c:	init_completion(&gmux_data->powerchange_done);
drivers/platform/x86/intel/ifs/ifs.h: * | 0xFE | Partial completion |
drivers/platform/x86/intel/ifs/ifs.h: * rest of the system during execution. Upon completion, the core
drivers/platform/x86/intel/ifs/ifs.h:#define IFS_SW_PARTIAL_COMPLETION		0xFE
drivers/platform/x86/intel/ifs/load.c:static DECLARE_COMPLETION(ifs_done);
drivers/platform/x86/intel/ifs/load.c:		reinit_completion(&ifs_done);
drivers/platform/x86/intel/ifs/load.c:		wait_for_completion(&ifs_done);
drivers/platform/x86/intel/ifs/runtest.c:	} else if (status.error_code == IFS_SW_PARTIAL_COMPLETION) {
drivers/platform/x86/intel/ifs/runtest.c:					status.error_code = IFS_SW_PARTIAL_COMPLETION;
drivers/platform/x86/intel/ifs/runtest.c:	} else if (status.error_code == IFS_SW_PARTIAL_COMPLETION) {
drivers/platform/x86/intel/ifs/runtest.c:					status.error_code = IFS_SW_PARTIAL_COMPLETION;
drivers/platform/x86/intel/punit_ipc.c:	struct completion cmd_complete;
drivers/platform/x86/intel/punit_ipc.c:		if (!wait_for_completion_timeout(&ipcdev->cmd_complete,
drivers/platform/x86/intel/punit_ipc.c:	reinit_completion(&ipcdev->cmd_complete);
drivers/platform/x86/intel/punit_ipc.c:	reinit_completion(&ipcdev->cmd_complete);
drivers/platform/x86/intel/punit_ipc.c:	init_completion(&punit_ipcdev->cmd_complete);
drivers/platform/x86/intel/speed_select_if/isst_if_mbox_msr.c:	 * and also with wait flag, wait for completion.
drivers/platform/x86/intel/tpmi.c:	/* Set CPL "completion" bit */
drivers/platform/x86/intel_scu_ipc.c:	struct completion cmd_complete;
drivers/platform/x86/intel_scu_ipc.c:	reinit_completion(&scu->cmd_complete);
drivers/platform/x86/intel_scu_ipc.c:	wait_for_completion_timeout(&scu->cmd_complete, IPC_TIMEOUT);
drivers/platform/x86/intel_scu_ipc.c:	init_completion(&scu->cmd_complete);
drivers/platform/x86/mlx-platform.c:static int mlxplat_i2c_main_completion_notify(void *handle, int id);
drivers/platform/x86/mlx-platform.c:	.completion_notify = mlxplat_i2c_main_completion_notify,
drivers/platform/x86/mlx-platform.c:	.completion_notify = mlxplat_i2c_main_completion_notify,
drivers/platform/x86/mlx-platform.c:static int mlxplat_i2c_main_completion_notify(void *handle, int id)
drivers/platform/x86/samsung-laptop.c:			" completion flag 0x%02x and interface data 0x%02x",
drivers/platform/x86/winmate-fm07-keys.c:	/* Send request and wait for write completion */
drivers/pmdomain/core.c: * genpd_finish_suspend - Completion of suspend or hibernation of device in an
drivers/pmdomain/core.c: * genpd_suspend_noirq - Completion of suspend of device in an I/O PM domain.
drivers/pmdomain/core.c: * genpd_finish_resume - Completion of resume of device in an I/O PM domain.
drivers/pmdomain/core.c: * genpd_freeze_noirq - Completion of freezing a device in an I/O PM domain.
drivers/pmdomain/core.c: * genpd_poweroff_noirq - Completion of hibernation of device in an
drivers/pmdomain/sunxi/sun20i-ppu.c:	/* Clear the completion flag. */
drivers/pnp/pnpbios/bioscalls.c:#include <linux/completion.h>
drivers/pnp/pnpbios/core.c:#include <linux/completion.h>
drivers/pnp/pnpbios/core.c:static struct completion unload_sem;
drivers/pnp/pnpbios/core.c:	init_completion(&unload_sem);
drivers/power/reset/atc260x-poweroff.c:	/* Wait for trigger completion */
drivers/power/reset/atc260x-poweroff.c:	/* Wait for trigger completion */
drivers/power/supply/ab8500_btemp.c:#include <linux/completion.h>
drivers/power/supply/ab8500_chargalg.c:#include <linux/completion.h>
drivers/power/supply/ab8500_charger.c:#include <linux/completion.h>
drivers/power/supply/ab8500_fg.c:#include <linux/completion.h>
drivers/power/supply/ab8500_fg.c: * @ab8500_fg_started	Completion struct used for the instant current start
drivers/power/supply/ab8500_fg.c: * @ab8500_fg_complete	Completion struct used for the instant current reading
drivers/power/supply/ab8500_fg.c:	struct completion ab8500_fg_started;
drivers/power/supply/ab8500_fg.c:	struct completion ab8500_fg_complete;
drivers/power/supply/ab8500_fg.c:	reinit_completion(&di->ab8500_fg_started);
drivers/power/supply/ab8500_fg.c:	reinit_completion(&di->ab8500_fg_complete);
drivers/power/supply/ab8500_fg.c:	return completion_done(&di->ab8500_fg_started);
drivers/power/supply/ab8500_fg.c:	return completion_done(&di->ab8500_fg_complete);
drivers/power/supply/ab8500_fg.c:	if (!completion_done(&di->ab8500_fg_complete)) {
drivers/power/supply/ab8500_fg.c:		timeout = wait_for_completion_timeout(
drivers/power/supply/ab8500_fg.c:			dev_err(di->dev, "completion timed out [%d]\n",
drivers/power/supply/ab8500_fg.c:	if (!completion_done(&di->ab8500_fg_started)) {
drivers/power/supply/ab8500_fg.c:		timeout = wait_for_completion_timeout(
drivers/power/supply/ab8500_fg.c:			dev_err(di->dev, "completion timed out [%d]\n",
drivers/power/supply/ab8500_fg.c:	 * Initialize completion used to notify completion and start
drivers/power/supply/ab8500_fg.c:	init_completion(&di->ab8500_fg_started);
drivers/power/supply/ab8500_fg.c:	init_completion(&di->ab8500_fg_complete);
drivers/power/supply/qcom_battmgr.c:	struct completion ack;
drivers/power/supply/qcom_battmgr.c:	reinit_completion(&battmgr->ack);
drivers/power/supply/qcom_battmgr.c:	left = wait_for_completion_timeout(&battmgr->ack, HZ);
drivers/power/supply/qcom_battmgr.c:	init_completion(&battmgr->ack);
drivers/power/supply/rt9467-charger.c:#include <linux/completion.h>
drivers/power/supply/rt9467-charger.c:	struct completion aicl_done;
drivers/power/supply/rt9467-charger.c:	reinit_completion(&data->aicl_done);
drivers/power/supply/rt9467-charger.c:	ret = wait_for_completion_timeout(&data->aicl_done, msecs_to_jiffies(3500));
drivers/power/supply/rt9467-charger.c:	struct completion *aicl_done = data;
drivers/power/supply/rt9467-charger.c:	init_completion(&data->aicl_done);
drivers/power/supply/rt9467-charger.c:		return dev_err_probe(dev, ret, "Failed to init AICL done completion\n");
drivers/powercap/idle_inject.c: * kthread activity after its completion is guaranteed.
drivers/ps3/ps3av.c:	struct completion done;
drivers/ps3/ps3av.c:	wait_for_completion(&ps3av->done);
drivers/ps3/ps3av.c:	init_completion(&ps3av->done);
drivers/ps3/ps3stor_lib.c:	init_completion(&dev->done);
drivers/ps3/ps3stor_lib.c:	wait_for_completion(&dev->done);
drivers/ps3/ps3stor_lib.c:	init_completion(&dev->done);
drivers/ps3/ps3stor_lib.c:	wait_for_completion(&dev->done);
drivers/rapidio/devices/rio_mport_cdev.c:	struct completion comp;
drivers/rapidio/devices/rio_mport_cdev.c:	struct completion	comp;
drivers/rapidio/devices/rio_mport_cdev.c:	struct completion req_comp;
drivers/rapidio/devices/rio_mport_cdev.c:		init_completion(&priv->comp);
drivers/rapidio/devices/rio_mport_cdev.c:	wret = wait_for_completion_interruptible_timeout(&req->req_comp, tmo);
drivers/rapidio/devices/rio_mport_cdev.c:		/* Wait_for_completion was interrupted by a signal but DMA may
drivers/rapidio/devices/rio_mport_cdev.c:		/* DMA transaction completion was signaled with error */
drivers/rapidio/devices/rio_mport_cdev.c:	init_completion(&req->req_comp);
drivers/rapidio/devices/rio_mport_cdev.c:	wret = wait_for_completion_interruptible_timeout(&req->req_comp, tmo);
drivers/rapidio/devices/rio_mport_cdev.c:		/* Wait_for_completion was interrupted by a signal but DMA may
drivers/rapidio/devices/rio_mport_cdev.c:		/* DMA transaction completion signaled with transfer error */
drivers/rapidio/devices/rio_mport_cdev.c:		rmcd_error("%s(%d) ASYNC DMA_%s completion with status %d",
drivers/rapidio/devices/rio_mport_cdev.c:				   completion_done(&req->req_comp)?"yes":"no");
drivers/rapidio/devices/rio_mport_cdev.c:	wret = wait_for_completion_interruptible_timeout(&priv->comp, tmo);
drivers/rapidio/devices/tsi721.c:		/* Inform upper layer about transfer completion */
drivers/rapidio/devices/tsi721.c:	/* Set PCIe completion timeout to 1-10ms */
drivers/rapidio/rio-scan.c: * When enumeration completion is signaled, start recursive
drivers/rapidio/rio_cm.c:	struct completion	comp;
drivers/rapidio/rio_cm.c:	struct completion	comp_close;
drivers/rapidio/rio_cm.c: * rio_txcq_handler - TX completion handler
drivers/rapidio/rio_cm.c: * TX completion handler also ensures that pending request packets are placed
drivers/rapidio/rio_cm.c:	/* ATTN: Add TX completion notification if/when direct buffer
drivers/rapidio/rio_cm.c:	wret = wait_for_completion_interruptible_timeout(&ch->comp, timeout);
drivers/rapidio/rio_cm.c:	wret = wait_for_completion_interruptible_timeout(&ch->comp,
drivers/rapidio/rio_cm.c:		if (!try_wait_for_completion(&ch->comp)) {
drivers/rapidio/rio_cm.c:		wret = wait_for_completion_interruptible_timeout(&ch->comp,
drivers/rapidio/rio_cm.c:		riocm_debug(WAIT, "on %d accept_queue is empty on completion",
drivers/rapidio/rio_cm.c:	init_completion(&ch->comp);
drivers/rapidio/rio_cm.c:	init_completion(&ch->comp_close);
drivers/rapidio/rio_cm.c:	wret = wait_for_completion_interruptible_timeout(&ch->comp_close, tmo);
drivers/rapidio/rio_cm.c:		/* Wait_for_completion was interrupted by a signal */
drivers/regulator/core.c:	 * We punt completion for an arbitrary amount of time since
drivers/remoteproc/imx_dsp_rproc.c: * @pm_comp: completion primitive to sync for suspend response
drivers/remoteproc/imx_dsp_rproc.c:	struct completion			pm_comp;
drivers/remoteproc/imx_dsp_rproc.c:	init_completion(&priv->pm_comp);
drivers/remoteproc/imx_dsp_rproc.c:	reinit_completion(&priv->pm_comp);
drivers/remoteproc/imx_dsp_rproc.c:	if (!wait_for_completion_timeout(&priv->pm_comp, msecs_to_jiffies(100)))
drivers/remoteproc/omap_remoteproc.c: * @pm_comp: completion primitive to sync for suspend response
drivers/remoteproc/omap_remoteproc.c:	struct completion pm_comp;
drivers/remoteproc/omap_remoteproc.c:	reinit_completion(&oproc->pm_comp);
drivers/remoteproc/omap_remoteproc.c:	ret = wait_for_completion_timeout(&oproc->pm_comp, to);
drivers/remoteproc/omap_remoteproc.c:	 * register set, sending this ACK or signalling the completion of the
drivers/remoteproc/omap_remoteproc.c:	init_completion(&oproc->pm_comp);
drivers/remoteproc/qcom_q6v5.c:	reinit_completion(&q6v5->start_done);
drivers/remoteproc/qcom_q6v5.c:	reinit_completion(&q6v5->stop_done);
drivers/remoteproc/qcom_q6v5.c:	ret = wait_for_completion_timeout(&q6v5->start_done, timeout);
drivers/remoteproc/qcom_q6v5.c:	ret = wait_for_completion_timeout(&q6v5->stop_done, 5 * HZ);
drivers/remoteproc/qcom_q6v5.c:	init_completion(&q6v5->start_done);
drivers/remoteproc/qcom_q6v5.c:	init_completion(&q6v5->stop_done);
drivers/remoteproc/qcom_q6v5.h:#include <linux/completion.h>
drivers/remoteproc/qcom_q6v5.h:	struct completion start_done;
drivers/remoteproc/qcom_q6v5.h:	struct completion stop_done;
drivers/remoteproc/qcom_q6v5_adsp.c:	struct completion start_done;
drivers/remoteproc/qcom_q6v5_adsp.c:	struct completion stop_done;
drivers/remoteproc/qcom_q6v5_mss.c:		/* Poll the MSS_STATUS for FSM completion */
drivers/remoteproc/qcom_q6v5_pas.c:	struct completion start_done;
drivers/remoteproc/qcom_q6v5_pas.c:	struct completion stop_done;
drivers/remoteproc/qcom_sysmon.c:	struct completion comp;
drivers/remoteproc/qcom_sysmon.c:	struct completion ind_comp;
drivers/remoteproc/qcom_sysmon.c:	struct completion shutdown_comp;
drivers/remoteproc/qcom_sysmon.c:	struct completion ssctl_comp;
drivers/remoteproc/qcom_sysmon.c:	reinit_completion(&sysmon->comp);
drivers/remoteproc/qcom_sysmon.c:	ret = wait_for_completion_timeout(&sysmon->comp,
drivers/remoteproc/qcom_sysmon.c:	reinit_completion(&sysmon->comp);
drivers/remoteproc/qcom_sysmon.c:	ret = wait_for_completion_timeout(&sysmon->comp,
drivers/remoteproc/qcom_sysmon.c:	ret = wait_for_completion_timeout(&sysmon->shutdown_comp, 10 * HZ);
drivers/remoteproc/qcom_sysmon.c:	ret = try_wait_for_completion(&sysmon->ind_comp);
drivers/remoteproc/qcom_sysmon.c:	reinit_completion(&sysmon->ind_comp);
drivers/remoteproc/qcom_sysmon.c:	reinit_completion(&sysmon->shutdown_comp);
drivers/remoteproc/qcom_sysmon.c:	reinit_completion(&sysmon->ssctl_comp);
drivers/remoteproc/qcom_sysmon.c:		if (!wait_for_completion_timeout(&sysmon->ssctl_comp, HZ / 2))
drivers/remoteproc/qcom_sysmon.c:	init_completion(&sysmon->comp);
drivers/remoteproc/qcom_sysmon.c:	init_completion(&sysmon->ind_comp);
drivers/remoteproc/qcom_sysmon.c:	init_completion(&sysmon->shutdown_comp);
drivers/remoteproc/qcom_sysmon.c:	init_completion(&sysmon->ssctl_comp);
drivers/remoteproc/qcom_wcnss.c:	struct completion start_done;
drivers/remoteproc/qcom_wcnss.c:	struct completion stop_done;
drivers/remoteproc/qcom_wcnss.c:	ret = wait_for_completion_timeout(&wcnss->start_done,
drivers/remoteproc/qcom_wcnss.c:		ret = wait_for_completion_timeout(&wcnss->stop_done,
drivers/remoteproc/qcom_wcnss.c:	init_completion(&wcnss->start_done);
drivers/remoteproc/qcom_wcnss.c:	init_completion(&wcnss->stop_done);
drivers/remoteproc/remoteproc_coredump.c:#include <linux/completion.h>
drivers/remoteproc/remoteproc_coredump.c:	struct completion dump_done;
drivers/remoteproc/remoteproc_coredump.c:	init_completion(&dump_state.dump_done);
drivers/remoteproc/remoteproc_coredump.c:	wait_for_completion(&dump_state.dump_done);
drivers/remoteproc/remoteproc_coredump.c:	init_completion(&dump_state.dump_done);
drivers/remoteproc/remoteproc_coredump.c:	wait_for_completion(&dump_state.dump_done);
drivers/rpmsg/qcom_glink_native.c:	struct completion open_ack;
drivers/rpmsg/qcom_glink_native.c:	struct completion open_req;
drivers/rpmsg/qcom_glink_native.c:	init_completion(&channel->open_req);
drivers/rpmsg/qcom_glink_native.c:	init_completion(&channel->open_ack);
drivers/rpmsg/qcom_glink_native.c:	ret = wait_for_completion_timeout(&channel->open_ack, 5 * HZ);
drivers/rpmsg/qcom_glink_native.c:	ret = wait_for_completion_timeout(&channel->open_req, 5 * HZ);
drivers/rpmsg/qcom_glink_native.c:	ret = wait_for_completion_timeout(&channel->open_ack, 5 * HZ);
drivers/rpmsg/qcom_glink_native.c:	if (glink->intentless || !completion_done(&channel->open_ack))
drivers/rpmsg/qcom_glink_ssr.c:#include <linux/completion.h>
drivers/rpmsg/qcom_glink_ssr.c:	struct completion completion;
drivers/rpmsg/qcom_glink_ssr.c:	complete(&ssr->completion);
drivers/rpmsg/qcom_glink_ssr.c:	reinit_completion(&ssr->completion);
drivers/rpmsg/qcom_glink_ssr.c:	ret = wait_for_completion_timeout(&ssr->completion, HZ);
drivers/rpmsg/qcom_glink_ssr.c:	init_completion(&ssr->completion);
drivers/rtc/rtc-as3722.c:#include <linux/completion.h>
drivers/rtc/rtc-at91rm9200.c:#include <linux/completion.h>
drivers/rtc/rtc-at91rm9200.c:static DECLARE_COMPLETION(at91_rtc_updated);
drivers/rtc/rtc-at91rm9200.c:static DECLARE_COMPLETION(at91_rtc_upd_rdy);
drivers/rtc/rtc-at91rm9200.c:	wait_for_completion(&at91_rtc_upd_rdy);
drivers/rtc/rtc-at91rm9200.c:	wait_for_completion(&at91_rtc_updated);	/* wait for ACKUPD interrupt */
drivers/rtc/rtc-at91rm9200.c:	 * completion.
drivers/rtc/rtc-hid-sensor-time.c:	struct completion comp_last_time;
drivers/rtc/rtc-hid-sensor-time.c:	reinit_completion(&time_state->comp_last_time);
drivers/rtc/rtc-hid-sensor-time.c:	ret = wait_for_completion_killable_timeout(
drivers/rtc/rtc-hid-sensor-time.c:	init_completion(&time_state->comp_last_time);
drivers/rtc/rtc-imxdi.c: * LP (Low Power) domain and set the WCF upon completion. Writes to the
drivers/rtc/rtc-imxdi.c: * on the write completion.
drivers/rtc/rtc-mc146818-lib.c:		 * for completion.
drivers/rtc/rtc-opal.c:	if (rc != OPAL_ASYNC_COMPLETION) {
drivers/rtc/rtc-opal.c:	if (rc != OPAL_ASYNC_COMPLETION) {
drivers/rtc/rtc-wm831x.c:#include <linux/completion.h>
drivers/rtc/rtc-wm8350.c:#include <linux/completion.h>
drivers/s390/block/dasd.c: * uses this to start a ccw that detects the format. The completion
drivers/s390/block/dasd.c: * it's completion.
drivers/s390/block/dasd.c: * Start requests from a ccw_queue and wait for their completion.
drivers/s390/block/dasd.c: * Start requests from a ccw_queue and wait interruptible for their completion.
drivers/s390/block/dasd.c: * interruptible for it's completion.
drivers/s390/block/dasd_alias.c:	init_completion(&lcu->lcu_setup);
drivers/s390/block/dasd_eckd.h:	struct completion lcu_setup;
drivers/s390/block/dasd_int.h:	unsigned int proc_bytes;	/* bytes for partial completion */
drivers/s390/block/dcssblk.c:#include <linux/completion.h>
drivers/s390/char/con3270.c: * Write request completion callback.
drivers/s390/char/con3270.c: * Read request completion callback.
drivers/s390/char/diag_ftp.c:static DECLARE_COMPLETION(diag_ftp_rx_complete);
drivers/s390/char/diag_ftp.c: *    for completion (asynchronous execution).
drivers/s390/char/diag_ftp.c:	init_completion(&diag_ftp_rx_complete);
drivers/s390/char/diag_ftp.c:	wait_for_completion(&diag_ftp_rx_complete);
drivers/s390/char/fs3270.c:			/* Started successfully. Now wait for completion. */
drivers/s390/char/sclp.c:			/* UNEX: Unexpected SCCB completion (a=sccb address) */
drivers/s390/char/sclp_cmd.c:#include <linux/completion.h>
drivers/s390/char/sclp_cmd.c:	struct completion *completion = data;
drivers/s390/char/sclp_cmd.c:	complete(completion);
drivers/s390/char/sclp_cmd.c:	struct completion completion;
drivers/s390/char/sclp_cmd.c:	request->callback_data = &completion;
drivers/s390/char/sclp_cmd.c:	init_completion(&completion);
drivers/s390/char/sclp_cmd.c:	wait_for_completion(&completion);
drivers/s390/char/sclp_cmd.c: * and wait for completion. On success return 0. Return non-zero otherwise.
drivers/s390/char/sclp_cmd.c: * Perform read channel-path information sclp command and wait for completion.
drivers/s390/char/sclp_cpi_sys.c:#include <linux/completion.h>
drivers/s390/char/sclp_cpi_sys.c:	struct completion *completion = data;
drivers/s390/char/sclp_cpi_sys.c:	complete(completion);
drivers/s390/char/sclp_cpi_sys.c:	struct completion completion;
drivers/s390/char/sclp_cpi_sys.c:	init_completion(&completion);
drivers/s390/char/sclp_cpi_sys.c:	req->callback_data = &completion;
drivers/s390/char/sclp_cpi_sys.c:	wait_for_completion(&completion);
drivers/s390/char/sclp_early_core.c: * back into the buffer sclp_info_sccb upon successful completion.
drivers/s390/char/sclp_ftp.c:static DECLARE_COMPLETION(sclp_ftp_rx_complete);
drivers/s390/char/sclp_ftp.c: * @data: pointer to struct completion
drivers/s390/char/sclp_ftp.c:	struct completion *completion = data;
drivers/s390/char/sclp_ftp.c:	complete(completion);
drivers/s390/char/sclp_ftp.c:	struct completion completion;
drivers/s390/char/sclp_ftp.c:	req->callback_data = &completion;
drivers/s390/char/sclp_ftp.c:	init_completion(&completion);
drivers/s390/char/sclp_ftp.c:	wait_for_completion(&completion);
drivers/s390/char/sclp_ftp.c:	 * asynchronously and the completion is indicated with an
drivers/s390/char/sclp_ftp.c:	init_completion(&sclp_ftp_rx_complete);
drivers/s390/char/sclp_ftp.c:	wait_for_completion(&sclp_ftp_rx_complete);
drivers/s390/char/sclp_pci.c:#include <linux/completion.h>
drivers/s390/char/sclp_pci.c:	struct completion *completion = data;
drivers/s390/char/sclp_pci.c:	complete(completion);
drivers/s390/char/sclp_pci.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/char/sclp_pci.c:	req.callback_data = &completion;
drivers/s390/char/sclp_pci.c:	wait_for_completion(&completion);
drivers/s390/char/sclp_quiesce.c:/* Shutdown handler. Signal completion of shutdown by loading special PSW. */
drivers/s390/char/sclp_rw.c: * interruption indicating completion of Service Call.
drivers/s390/char/sclp_rw.c:		/* Normal completion, buffer processed, message(s) sent */
drivers/s390/char/sclp_sd.c:#include <linux/completion.h>
drivers/s390/char/sclp_sd.c: * @completion: Can be used to wait for response
drivers/s390/char/sclp_sd.c: * @evbuf: Contains the resulting Store Data response after completion
drivers/s390/char/sclp_sd.c:	struct completion completion;
drivers/s390/char/sclp_sd.c:	init_completion(&listener->completion);
drivers/s390/char/sclp_sd.c:		complete(&listener->completion);
drivers/s390/char/sclp_sd.c: * Perform Store Data request with specified parameters and wait for completion.
drivers/s390/char/sclp_sd.c:		rc = wait_for_completion_interruptible_timeout(&listener.completion, SD_TIMEOUT);
drivers/s390/char/sclp_sdias.c:#include <linux/completion.h>
drivers/s390/char/sclp_sdias.c:static DECLARE_COMPLETION(evbuf_accepted);
drivers/s390/char/sclp_sdias.c:static DECLARE_COMPLETION(evbuf_done);
drivers/s390/char/sclp_sdias.c:		/* initiated, wait for completion of service call */
drivers/s390/char/sclp_sdias.c:		wait_for_completion(&evbuf_accepted);
drivers/s390/char/sclp_sdias.c:		/* otherwise we wait for completion */
drivers/s390/char/sclp_sdias.c:		wait_for_completion(&evbuf_done);
drivers/s390/char/sclp_vt220.c: * buffer should be converted to 0x0a 0x0d. After completion, return the number
drivers/s390/char/tape_core.c: * tape is idle and wait uninterruptible for its completion.
drivers/s390/char/tape_core.c:	/* Request added to the queue. Wait for its completion. */
drivers/s390/char/tape_core.c: * tape is idle and wait uninterruptible for its completion.
drivers/s390/char/tape_core.c:	/* Request added to the queue. Wait for its completion. */
drivers/s390/char/tape_core.c:		/* Upon normal completion the device _is_ online */
drivers/s390/char/tape_core.c:			/* Upon normal completion the device _is_ online */
drivers/s390/char/vmur.c: * on a completion event it publishes at urd->io_done. The function
drivers/s390/char/vmur.c:	DECLARE_COMPLETION_ONSTACK(event);
drivers/s390/char/vmur.c:	wait_for_completion(&event);
drivers/s390/char/vmur.c: * cc=0  normal completion, we have a real device
drivers/s390/char/vmur.c: * cc=0  normal completion
drivers/s390/char/vmur.c: * cc=0  normal completion
drivers/s390/char/vmur.c: * cc=0  normal completion
drivers/s390/char/vmur.h:	struct completion *io_done;	/* do_ur_io waits; irq completes */
drivers/s390/cio/chp.c:/* Wait queue for configure completion events. */
drivers/s390/cio/chsc_sch.c:	complete(&request->completion);
drivers/s390/cio/chsc_sch.c:		complete(&private->request->completion);
drivers/s390/cio/chsc_sch.c:	init_completion(&request->completion);
drivers/s390/cio/chsc_sch.c:		wait_for_completion(&request->completion);
drivers/s390/cio/chsc_sch.c:	init_completion(&on_close_request->completion);
drivers/s390/cio/chsc_sch.c:		wait_for_completion(&on_close_request->completion);
drivers/s390/cio/chsc_sch.h:	struct completion completion;
drivers/s390/cio/cio.c:		 * useless to wait for request completion
drivers/s390/cio/device.h:	/* states to wait for i/o completion before doing something */
drivers/s390/cio/device_fsm.c:	/* states to wait for i/o completion before doing something */
drivers/s390/cio/device_ops.c:#include <linux/completion.h>
drivers/s390/cio/device_pgid.c:	struct completion done;
drivers/s390/cio/device_pgid.c:	init_completion(&data.done);
drivers/s390/cio/device_pgid.c:	if (wait_for_completion_interruptible(&data.done)) {
drivers/s390/cio/device_pgid.c:		wait_for_completion(&data.done);
drivers/s390/cio/eadm_sch.c:#include <linux/completion.h>
drivers/s390/cio/eadm_sch.c:	if (private->completion)
drivers/s390/cio/eadm_sch.c:		complete(private->completion);
drivers/s390/cio/eadm_sch.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/cio/eadm_sch.c:	private->completion = &completion;
drivers/s390/cio/eadm_sch.c:	wait_for_completion_io(&completion);
drivers/s390/cio/eadm_sch.c:	private->completion = NULL;
drivers/s390/cio/eadm_sch.h:#include <linux/completion.h>
drivers/s390/cio/eadm_sch.h:	struct completion *completion;
drivers/s390/cio/vfio_ccw_drv.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/cio/vfio_ccw_drv.c:		 * cancel/halt/clear completion.
drivers/s390/cio/vfio_ccw_drv.c:		private->completion = &completion;
drivers/s390/cio/vfio_ccw_drv.c:			wait_for_completion_timeout(&completion, 3*HZ);
drivers/s390/cio/vfio_ccw_drv.c:		private->completion = NULL;
drivers/s390/cio/vfio_ccw_fsm.c:	if (private->completion)
drivers/s390/cio/vfio_ccw_fsm.c:		complete(private->completion);
drivers/s390/cio/vfio_ccw_private.h:#include <linux/completion.h>
drivers/s390/cio/vfio_ccw_private.h: * @completion: synchronization helper of the I/O completion
drivers/s390/cio/vfio_ccw_private.h:	struct completion	*completion;
drivers/s390/crypto/ap_bus.c:/* completion for APQN bindings complete */
drivers/s390/crypto/ap_bus.c:static DECLARE_COMPLETION(ap_apqn_bindings_complete);
drivers/s390/crypto/ap_bus.c:			if (!completion_done(&ap_apqn_bindings_complete)) {
drivers/s390/crypto/ap_bus.c: * on a condition with wait_for_completion_interruptible_timeout().
drivers/s390/crypto/ap_bus.c:	if (completion_done(&ap_apqn_bindings_complete))
drivers/s390/crypto/ap_bus.c:		l = wait_for_completion_interruptible_timeout(
drivers/s390/crypto/ap_bus.c:		l = wait_for_completion_interruptible(
drivers/s390/crypto/ap_bus.c:	 * Rearm the bindings complete completion to trigger
drivers/s390/crypto/ap_bus.c:	reinit_completion(&ap_apqn_bindings_complete);
drivers/s390/crypto/ap_bus.c:			 * completion.
drivers/s390/crypto/ap_bus.c:			reinit_completion(&ap_apqn_bindings_complete);
drivers/s390/crypto/ap_bus.h: * bitmap - Pointer to a bitmap. Upon successful completion of this function,
drivers/s390/crypto/ap_bus.h: * on a condition with wait_for_completion_killable_timeout().
drivers/s390/crypto/ap_queue.c: * ap_sm_reset_wait(): Test queue for completion of the reset operation
drivers/s390/crypto/ap_queue.c: * ap_sm_setirq_wait(): Test queue for completion of the irq enablement
drivers/s390/crypto/ap_queue.c: * ap_sm_assoc_wait(): Test queue for completion of a pending
drivers/s390/crypto/zcrypt_msgtype50.c:	complete((struct completion *)msg->private);
drivers/s390/crypto/zcrypt_msgtype50.c:	struct completion work;
drivers/s390/crypto/zcrypt_msgtype50.c:	init_completion(&work);
drivers/s390/crypto/zcrypt_msgtype50.c:	rc = wait_for_completion_interruptible(&work);
drivers/s390/crypto/zcrypt_msgtype50.c:	struct completion work;
drivers/s390/crypto/zcrypt_msgtype50.c:	init_completion(&work);
drivers/s390/crypto/zcrypt_msgtype50.c:	rc = wait_for_completion_interruptible(&work);
drivers/s390/crypto/zcrypt_msgtype6.c:	struct completion work;
drivers/s390/crypto/zcrypt_msgtype6.c:	init_completion(&resp_type.work);
drivers/s390/crypto/zcrypt_msgtype6.c:	rc = wait_for_completion_interruptible(&resp_type.work);
drivers/s390/crypto/zcrypt_msgtype6.c:	init_completion(&resp_type.work);
drivers/s390/crypto/zcrypt_msgtype6.c:	rc = wait_for_completion_interruptible(&resp_type.work);
drivers/s390/crypto/zcrypt_msgtype6.c:	init_completion(&rtype->work);
drivers/s390/crypto/zcrypt_msgtype6.c:	rc = wait_for_completion_interruptible(&rtype->work);
drivers/s390/crypto/zcrypt_msgtype6.c:	init_completion(&rtype->work);
drivers/s390/crypto/zcrypt_msgtype6.c:	rc = wait_for_completion_interruptible(&rtype->work);
drivers/s390/crypto/zcrypt_msgtype6.c:	init_completion(&rtype->work);
drivers/s390/crypto/zcrypt_msgtype6.c:	rc = wait_for_completion_interruptible(&rtype->work);
drivers/s390/net/lcs.c:	/* Asynchronous halt initialted. Wait for its completion. */
drivers/s390/net/lcs.h:	/* Callback for completion notification. */
drivers/s390/net/lcs.h:	/* Callback for completion notification. */
drivers/s390/net/qeth_core.h:#include <linux/completion.h>
drivers/s390/net/qeth_core.h:	u64 completion_irq;
drivers/s390/net/qeth_core.h:	u64 completion_yield;
drivers/s390/net/qeth_core.h:	u64 completion_timer;
drivers/s390/net/qeth_core.h:	struct completion done;
drivers/s390/net/qeth_core_main.c:					"Failed to create completion queue\n");
drivers/s390/net/qeth_core_main.c:	/* keep the cmd alive after completion: */
drivers/s390/net/qeth_core_main.c:	init_completion(&iob->done);
drivers/s390/net/qeth_core_main.c:		QETH_TXQ_STAT_INC(queue, completion_irq);
drivers/s390/net/qeth_core_main.c:	timeout = wait_for_completion_interruptible_timeout(&iob->done,
drivers/s390/net/qeth_core_main.c:static void qeth_tx_completion_timer(struct timer_list *timer)
drivers/s390/net/qeth_core_main.c:	QETH_TXQ_STAT_INC(queue, completion_timer);
drivers/s390/net/qeth_core_main.c:	/* completion */
drivers/s390/net/qeth_core_main.c:		timer_setup(&queue->timer, qeth_tx_completion_timer, 0);
drivers/s390/net/qeth_core_main.c:	/* completion */
drivers/s390/net/qeth_core_main.c:		/* Fake the TX completion interrupt: */
drivers/s390/net/qeth_core_main.c:		/* If a TX completion happens right _here_ and misses to wake
drivers/s390/net/qeth_core_main.c:		/* If a TX completion happens right _here_ and misses to wake
drivers/s390/net/qeth_core_main.c:		/* TODO: drop skb_orphan() once TX completion is fast enough */
drivers/s390/net/qeth_core_main.c:			"Completion Queueing supported\n");
drivers/s390/net/qeth_core_main.c:		dev_info(&card->gdev->dev, "Completion Queue support enabled");
drivers/s390/net/qeth_core_main.c:		dev_info(&card->gdev->dev, "Completion Queue support disabled");
drivers/s390/net/qeth_core_main.c:			QETH_TXQ_STAT_INC(queue, completion_yield);
drivers/s390/net/qeth_core_main.c:			/* Ensure we see TX completion for pending work: */
drivers/s390/net/qeth_ethtool.c:	QETH_TXQ_STAT("Completion IRQ", completion_irq),
drivers/s390/net/qeth_ethtool.c:	QETH_TXQ_STAT("Completion yield", completion_yield),
drivers/s390/net/qeth_ethtool.c:	QETH_TXQ_STAT("Completion timer", completion_timer),
drivers/s390/scsi/zfcp_dbf.h: * zfcp_dbf_hba_fsf_response - trace event for request completion
drivers/s390/scsi/zfcp_dbf.h: * zfcp_dbf_scsi_result - trace event for SCSI command completion
drivers/s390/scsi/zfcp_def.h:						      completion races */
drivers/s390/scsi/zfcp_def.h: * @completion: used to signal the completion of the request
drivers/s390/scsi/zfcp_def.h:	struct completion	completion;
drivers/s390/scsi/zfcp_erp.c: * zfcp_erp_lun_shutdown_wait - Shutdown LUN and wait for erp completion
drivers/s390/scsi/zfcp_erp.c: * zfcp_erp_wait - wait for completion of error recovery on an adapter
drivers/s390/scsi/zfcp_erp.c: * @adapter: adapter for which to wait for completion of its error recovery
drivers/s390/scsi/zfcp_fc.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.handler_data = &completion;
drivers/s390/scsi/zfcp_fc.c:		wait_for_completion(&completion);
drivers/s390/scsi/zfcp_fc.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/scsi/zfcp_fc.c:	ct_els->handler_data = &completion;
drivers/s390/scsi/zfcp_fc.c:		wait_for_completion(&completion);
drivers/s390/scsi/zfcp_fc.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/scsi/zfcp_fc.c:	ct_els->handler_data = &completion;
drivers/s390/scsi/zfcp_fc.c:	wait_for_completion(&completion);
drivers/s390/scsi/zfcp_fc.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/s390/scsi/zfcp_fc.c:	ct_els->handler_data = &completion;
drivers/s390/scsi/zfcp_fc.c:		wait_for_completion(&completion);
drivers/s390/scsi/zfcp_fc.h: * @opened: Wait for completion of open command
drivers/s390/scsi/zfcp_fc.h: * @closed: Wait for completion of close command
drivers/s390/scsi/zfcp_fsf.c: * zfcp_fsf_req_complete - process completion of a FSF request
drivers/s390/scsi/zfcp_fsf.c: * is called to process the completion status and trigger further
drivers/s390/scsi/zfcp_fsf.c:		complete(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:	init_completion(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:	 *	 ONLY TOUCH SYNC req AGAIN ON req->completion.
drivers/s390/scsi/zfcp_fsf.c:	 * when it is completed via req->completion, is it safe to use req
drivers/s390/scsi/zfcp_fsf.c:		/* NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */
drivers/s390/scsi/zfcp_fsf.c:		wait_for_completion(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:		/* NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */
drivers/s390/scsi/zfcp_fsf.c:		wait_for_completion(&req->completion);
drivers/s390/scsi/zfcp_qdio.c:	 * Request Queue completion processing in tasklet context.
drivers/s390/scsi/zfcp_qdio.c:	/* Enable processing for Request Queue completions: */
drivers/s390/scsi/zfcp_qdio.h: * @request_tasklet: used for Request Queue completion processing
drivers/s390/scsi/zfcp_qdio.h: * @request_timer: used to trigger the Request Queue completion processing
drivers/s390/scsi/zfcp_scsi.c:	/* avoid race condition between late normal completion and abort */
drivers/s390/scsi/zfcp_scsi.c:		return FAILED; /* completion could be in progress */
drivers/s390/scsi/zfcp_scsi.c:	wait_for_completion(&abrt_req->completion);
drivers/s390/scsi/zfcp_scsi.c:	wait_for_completion(&fsf_req->completion);
drivers/sbus/char/oradax.c:/* completion status */
drivers/sbus/char/oradax.c:/* completion err */
drivers/sbus/char/oradax.c:	u32 cca_addr_type:2;	/* 1:0 Completion Address Type */
drivers/sbus/char/oradax.c:	void *ca;		/* Completion Address */
drivers/sbus/char/oradax.c:/* map completion area */
drivers/sbus/char/oradax.c:	/* completion area is mapped read-only for user */
drivers/sbus/char/oradax.c:	dax_dbg("mmapped completion area at uva 0x%lx", vma->vm_start);
drivers/sbus/char/oradax.c:	/* allocate CCB completion area buffer */
drivers/sbus/char/oradax.c: * Validates user CCB content.  Also sets completion address and address types
drivers/sbus/char/oradax.c:		/* set completion (real) address and address type */
drivers/sbus/char/oradax.c:		 * to wait for completion of the submitted CCBs since
drivers/scsi/3w-9xxx.c:	/* First check for internal completion of set param for time sync */
drivers/scsi/3w-9xxx.c:		/* Now poll for completion */
drivers/scsi/3w-9xxx.c:	/* Poll for completion */
drivers/scsi/3w-9xxx.c:	/* Poll for completion */
drivers/scsi/3w-9xxx.c:			/* Check for internal command completion */
drivers/scsi/3w-sas.c:	/* First check for internal completion of set param for time sync */
drivers/scsi/3w-sas.c:		/* Now poll for completion */
drivers/scsi/3w-sas.c:	/* Poll for completion */
drivers/scsi/3w-sas.c:	/* Poll for completion */
drivers/scsi/3w-sas.c:		/* Check for internal command completion */
drivers/scsi/3w-xxxx.c:		/* Now poll for completion */
drivers/scsi/3w-xxxx.c:	/* Poll for completion */
drivers/scsi/3w-xxxx.c:	/* Poll for completion */
drivers/scsi/3w-xxxx.c:	/* Get the host lock for io completions */
drivers/scsi/3w-xxxx.c:			/* Check for internal command completion */
drivers/scsi/3w-xxxx.c:				/* Check for chrdev ioctl completion */
drivers/scsi/53c700.c:#include <linux/completion.h>
drivers/scsi/53c700.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/scsi/53c700.c:	wait_for_completion(&complete);
drivers/scsi/53c700.h:	/* Completion for waited for ops, like reset, abort or
drivers/scsi/53c700.h:	struct completion *eh_complete;
drivers/scsi/BusLogic.c:	   Select an appropriate timeout value for awaiting command completion.
drivers/scsi/BusLogic.c:	   Wait 100 microseconds to allow completion of any initial diagnostic
drivers/scsi/BusLogic.c:	   queued for completion processing.
drivers/scsi/BusLogic.c:  blogic_qcompleted_ccb queues CCB for completion processing.
drivers/scsi/BusLogic.c:  Incoming Mailbox entries for completion processing.
drivers/scsi/BusLogic.c:	   completion processing is performed exactly once.  Therefore,
drivers/scsi/BusLogic.c:	   only Incoming Mailboxes with completion code Command Completed
drivers/scsi/BusLogic.c:	   At Host Request are saved for completion processing. When an
drivers/scsi/BusLogic.c:	   Incoming Mailbox has a completion code of Aborted Command Not
drivers/scsi/BusLogic.c:	   current Abort request was processed, and so completion processing
drivers/scsi/BusLogic.c:				   Save the Completion Code for this CCB and
drivers/scsi/BusLogic.c:				   queue the CCB for completion processing.
drivers/scsi/BusLogic.c:  calling the SCSI Subsystem Completion Routines.  The Host Adapter's Lock
drivers/scsi/BusLogic.c:			   Completion Routine called otherwise.
drivers/scsi/BusLogic.c:			   performing completion processing for any CCBs
drivers/scsi/BusLogic.c:			   Translate the Completion Code, Host Adapter Status,
drivers/scsi/BusLogic.c:			   Call the SCSI Command Completion Routine.
drivers/scsi/BusLogic.h:  Define the Incoming Mailbox Completion Codes.  The MultiMaster Firmware
drivers/scsi/BusLogic.h:  completion codes are stored in the CCB; it only uses codes 1, 2, 4, and 5.
drivers/scsi/FlashPoint.c:#define  CC    0x25		/*Command Completion failure */
drivers/scsi/a100u2w.c:	   a completion ? */
drivers/scsi/a100u2w.c: *	Perform completion processing on a control block. Do the conversions
drivers/scsi/aacraid/aachba.c:#include <linux/completion.h>
drivers/scsi/aacraid/aachba.c: * Handles the completion of a scsi command to a non dasd device
drivers/scsi/aacraid/aachba.c: * Handles the completion of a native HBA scsi command
drivers/scsi/aacraid/aacraid.h:#include <linux/completion.h>
drivers/scsi/aacraid/aacraid.h:	struct completion	completion;	// this is used to wait for the next fib to arrive.
drivers/scsi/aacraid/aacraid.h:	struct completion	event_wait;
drivers/scsi/aacraid/commctrl.c:#include <linux/completion.h>
drivers/scsi/aacraid/commctrl.c:		init_completion(&fibctx->completion);
drivers/scsi/aacraid/commctrl.c:			if (wait_for_completion_interruptible(&fibctx->completion) < 0) {
drivers/scsi/aacraid/comminit.c:#include <linux/completion.h>
drivers/scsi/aacraid/comminit.c:static void aac_wait_for_io_completion(struct aac_dev *aac)
drivers/scsi/aacraid/comminit.c:	aac_wait_for_io_completion(dev);
drivers/scsi/aacraid/commsup.c:#include <linux/completion.h>
drivers/scsi/aacraid/commsup.c:		init_completion(&fibptr->event_wait);
drivers/scsi/aacraid/commsup.c:			if (wait_for_completion_interruptible(&fibptr->event_wait)) {
drivers/scsi/aacraid/commsup.c:			while (!try_wait_for_completion(&fibptr->event_wait)) {
drivers/scsi/aacraid/commsup.c:		} else if (wait_for_completion_interruptible(&fibptr->event_wait)) {
drivers/scsi/aacraid/commsup.c:			 * wait_for_completion_interruptible must_check */
drivers/scsi/aacraid/commsup.c:		if (wait_for_completion_interruptible(&fibptr->event_wait))
drivers/scsi/aacraid/commsup.c: *	aac_fib_complete	-	fib completion handler
drivers/scsi/aacraid/commsup.c:			complete(&fibctx->completion);
drivers/scsi/aacraid/commsup.c:		complete(&fibctx->completion);
drivers/scsi/aacraid/dpcsup.c:#include <linux/completion.h>
drivers/scsi/aacraid/dpcsup.c: *	@index: completion reference
drivers/scsi/aacraid/linit.c:#include <linux/completion.h>
drivers/scsi/aacraid/linit.c:		/* Wait up to 15 secs for completion */
drivers/scsi/aacraid/linit.c:	/* Wait up to 15 seconds for completion */
drivers/scsi/aacraid/linit.c:	/* Wait up to 15 seconds for completion */
drivers/scsi/aacraid/rx.c:#include <linux/completion.h>
drivers/scsi/aacraid/rx.c: *	for its	completion.
drivers/scsi/aacraid/rx.c:	 *	Force the completion of the mask register write before issuing
drivers/scsi/aacraid/sa.c:#include <linux/completion.h>
drivers/scsi/aacraid/sa.c: *	for its	completion.
drivers/scsi/aacraid/src.c:#include <linux/completion.h>
drivers/scsi/aacraid/src.c: *	for its	completion.
drivers/scsi/aacraid/src.c:	 *	Force the completion of the mask register write before issuing
drivers/scsi/advansys.c:	uchar done_status;	/* Completion status. */
drivers/scsi/advansys.c: * Send an idle command to the chip and wait for completion.
drivers/scsi/advansys.c: * Command completion is polled for once per microsecond.
drivers/scsi/advansys.c:		/* Poll once each microsecond for command completion. */
drivers/scsi/advansys.c:	 * command completions.
drivers/scsi/aha152x.c:#include <linux/completion.h>
drivers/scsi/aha152x.c:	struct completion *done;/* semaphore to block on */
drivers/scsi/aha152x.c:				  struct completion *complete, int phase)
drivers/scsi/aha152x.c:		printk(KERN_ERR "aha152x: reset_done w/o completion\n");
drivers/scsi/aha152x.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/scsi/aha152x.c:	timeleft = wait_for_completion_timeout(&done, 100*HZ);
drivers/scsi/aha152x.c: * Run service completions on the card with interrupts enabled.
drivers/scsi/aha1740.h:	void (*done) (struct scsi_cmnd *);	/* Completion Function */
drivers/scsi/aic7xxx/aic79xx.h:struct ahd_completion
drivers/scsi/aic7xxx/aic79xx.h:	struct ahd_completion	  *qoutfifo;
drivers/scsi/aic7xxx/aic79xx.reg:						 * command completion method
drivers/scsi/aic7xxx/aic79xx.seq:	cmp	QFREEZE_COUNT, A jne check_frozen_completions;
drivers/scsi/aic7xxx/aic79xx.seq:	cmp	QFREEZE_COUNT[1], A jne check_frozen_completions;
drivers/scsi/aic7xxx/aic79xx.seq:check_frozen_completions:
drivers/scsi/aic7xxx/aic79xx.seq:	 * If we have completions stalled waiting for the qfreeze
drivers/scsi/aic7xxx/aic79xx.seq:	 * queue the SCB for normal completion.  Otherwise, we
drivers/scsi/aic7xxx/aic79xx.seq:	 * then queue the completion.
drivers/scsi/aic7xxx/aic79xx.seq:	test	SCB_SCSI_STATUS, 0xff jz scbdma_queue_completion;
drivers/scsi/aic7xxx/aic79xx.seq:scbdma_queue_completion:
drivers/scsi/aic7xxx/aic79xx.seq:	 * completion entries.  In PCI mode, at least in 32/33
drivers/scsi/aic7xxx/aic79xx.seq:	 * completions to continue the data transfer.
drivers/scsi/aic7xxx/aic79xx.seq: * is responsible for polling for transfer completion.
drivers/scsi/aic7xxx/aic79xx.seq: * queue and trigger a completion interrupt via the idle loop.  Before doing
drivers/scsi/aic7xxx/aic79xx.seq:	 * the completion.
drivers/scsi/aic7xxx/aic79xx.seq:	call	queue_scb_completion;
drivers/scsi/aic7xxx/aic79xx.seq:queue_scb_completion:
drivers/scsi/aic7xxx/aic79xx.seq:	 * change, and/or the completion of the last segment.
drivers/scsi/aic7xxx/aic79xx.seq:	 * SCB completion.
drivers/scsi/aic7xxx/aic79xx.seq:	 * count since the status received flag, and thus completion
drivers/scsi/aic7xxx/aic79xx_core.c:			/*len*/AHD_SCB_MAX * sizeof(struct ahd_completion), op);
drivers/scsi/aic7xxx/aic79xx_core.c:	 * completion queues.  This avoids a costly PCI bus read in
drivers/scsi/aic7xxx/aic79xx_core.c:	 * attempt to handle the DMA completion.
drivers/scsi/aic7xxx/aic79xx_core.c: * Run a data fifo to completion for a transaction we know
drivers/scsi/aic7xxx/aic79xx_core.c: * The valid_tag completion field indicates the validity
drivers/scsi/aic7xxx/aic79xx_core.c: * the queue. We use the sg_status field in the completion
drivers/scsi/aic7xxx/aic79xx_core.c: * entry to avoid referencing the hscb if the completion
drivers/scsi/aic7xxx/aic79xx_core.c:	struct ahd_completion *completion;
drivers/scsi/aic7xxx/aic79xx_core.c:		completion = &ahd->qoutfifo[ahd->qoutfifonext];
drivers/scsi/aic7xxx/aic79xx_core.c:		if (completion->valid_tag != ahd->qoutfifonext_valid_tag)
drivers/scsi/aic7xxx/aic79xx_core.c:		scb_index = ahd_le16toh(completion->tag);
drivers/scsi/aic7xxx/aic79xx_core.c:		} else if ((completion->sg_status & SG_STATUS_VALID) != 0) {
drivers/scsi/aic7xxx/aic79xx_core.c:		 * that requires host assistance for completion.
drivers/scsi/aic7xxx/aic79xx_core.c:			 * sequencer interrupt for its completion.
drivers/scsi/aic7xxx/aic79xx_core.c:				 * for the command run to completion case.
drivers/scsi/aic7xxx/aic79xx_core.c:	ahd->qoutfifo = (struct ahd_completion *)ahd->shared_data_map.vaddr;
drivers/scsi/aic7xxx/aic79xx_core.c:		   + AHD_QOUT_SIZE*sizeof(struct ahd_completion);
drivers/scsi/aic7xxx/aic79xx_core.c:		 * Do not issue a target abort when a split completion
drivers/scsi/aic7xxx/aic79xx_core.c:	 * sequencer has already marked for completion.
drivers/scsi/aic7xxx/aic79xx_core.c:	 * completion processing on any commands that 'completed'
drivers/scsi/aic7xxx/aic79xx_core.c:		 * a normal command completion.
drivers/scsi/aic7xxx/aic79xx_core.c:		printk("Completions are pending\n");
drivers/scsi/aic7xxx/aic79xx_osm.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/scsi/aic7xxx/aic79xx_osm.c:	if (!wait_for_completion_timeout(&done, 5 * HZ)) {
drivers/scsi/aic7xxx/aic79xx_osm.c:		DECLARE_COMPLETION_ONSTACK(done);
drivers/scsi/aic7xxx/aic79xx_osm.c:		if (!wait_for_completion_timeout(&done, 5 * HZ)) {
drivers/scsi/aic7xxx/aic79xx_osm.h:	struct completion	*eh_done;
drivers/scsi/aic7xxx/aic79xx_osm.h:#define PCIXM_STATUS_SCDISC	0x0004	/* Split Completion Discarded */
drivers/scsi/aic7xxx/aic79xx_osm.h:#define PCIXM_STATUS_UNEXPSC	0x0008	/* Unexpected Split Completion */
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Received split completion error message in %s\n",
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Split completion data bucket in %s\n",
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Split completion address error in %s\n",
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Split completion byte count error in %s\n",
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Split completion read data parity error in %s\n",
drivers/scsi/aic7xxx/aic79xx_pci.c:	"%s: Split completion address attribute parity error in %s\n",
drivers/scsi/aic7xxx/aic7xxx.seq:		 * change, and/or the completion of the last segment.
drivers/scsi/aic7xxx/aic7xxx.seq: * and trigger a completion interrupt.  Before doing so, check to see if there
drivers/scsi/aic7xxx/aic7xxx.seq:	 * the completion.
drivers/scsi/aic7xxx/aic7xxx_core.c: * Block our completion routine from starting the next untagged
drivers/scsi/aic7xxx/aic7xxx_core.c:	 * completion queues.  This avoids a costly PCI bus read in
drivers/scsi/aic7xxx/aic7xxx_core.c:		 * that requires host assistance for completion.
drivers/scsi/aic7xxx/aic7xxx_core.c:				 * for the command run to completion case.
drivers/scsi/aic7xxx/aic7xxx_core.c:		 * have queued for completion, 0'ing their control byte too.
drivers/scsi/aic7xxx/aic7xxx_core.c:	 * completion processing on any commands that 'completed'
drivers/scsi/aic7xxx/aic7xxx_osm.c:		DECLARE_COMPLETION_ONSTACK(done);
drivers/scsi/aic7xxx/aic7xxx_osm.c:		if (!wait_for_completion_timeout(&done, 5 * HZ)) {
drivers/scsi/aic7xxx/aic7xxx_osm.h:	struct completion	*eh_done;
drivers/scsi/aic94xx/aic94xx_hwi.c:		asd_printk("couldn't disable split completion timer of %s\n",
drivers/scsi/aic94xx/aic94xx_hwi.c:		asd_printk("received split completion error for %s\n",
drivers/scsi/aic94xx/aic94xx_hwi.c:		asd_printk("unexpected split completion for %s\n",
drivers/scsi/aic94xx/aic94xx_hwi.c:		asd_printk("split completion discarded for %s\n",
drivers/scsi/aic94xx/aic94xx_hwi.h:	struct completion *completion;
drivers/scsi/aic94xx/aic94xx_sas.h: * _RESP - The completion includes an empty buffer containing status.
drivers/scsi/aic94xx/aic94xx_task.c:		struct completion *completion = ascb->completion;
drivers/scsi/aic94xx/aic94xx_task.c:		if (completion)
drivers/scsi/aic94xx/aic94xx_task.c:			complete(completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:struct tasklet_completion_status {
drivers/scsi/aic94xx/aic94xx_tmf.c:	struct tasklet_completion_status tcs = { \
drivers/scsi/aic94xx/aic94xx_tmf.c:	struct tasklet_completion_status *tcs = ascb->uldd_task;
drivers/scsi/aic94xx/aic94xx_tmf.c:	complete(ascb->completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	struct tasklet_completion_status *tcs = ascb->uldd_task;
drivers/scsi/aic94xx/aic94xx_tmf.c:	complete(ascb->completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	DECLARE_COMPLETION_ONSTACK(completion); \
drivers/scsi/aic94xx/aic94xx_tmf.c:	ascb->completion = &completion; \
drivers/scsi/aic94xx/aic94xx_tmf.c:	wait_for_completion(&completion); \
drivers/scsi/aic94xx/aic94xx_tmf.c:	struct tasklet_completion_status *tcs = ascb->uldd_task;
drivers/scsi/aic94xx/aic94xx_tmf.c:	complete(ascb->completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	struct tasklet_completion_status *tcs;
drivers/scsi/aic94xx/aic94xx_tmf.c:	complete(ascb->completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	tascb->completion = &completion;
drivers/scsi/aic94xx/aic94xx_tmf.c:	leftover = wait_for_completion_timeout(&completion,
drivers/scsi/aic94xx/aic94xx_tmf.c:	tascb->completion = NULL;
drivers/scsi/aic94xx/aic94xx_tmf.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	DECLARE_COMPLETION_ONSTACK(tascb_completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	tascb->completion = &tascb_completion;
drivers/scsi/aic94xx/aic94xx_tmf.c:	ascb->completion = &completion;
drivers/scsi/aic94xx/aic94xx_tmf.c:	wait_for_completion(&completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:				wait_for_completion_timeout(&tascb_completion,
drivers/scsi/aic94xx/aic94xx_tmf.c:	tascb->completion = NULL;
drivers/scsi/aic94xx/aic94xx_tmf.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/aic94xx/aic94xx_tmf.c:	ascb->completion = &completion;
drivers/scsi/aic94xx/aic94xx_tmf.c:	wait_for_completion(&completion);
drivers/scsi/am53c974.c:	 * spurious DMA completion interrupts when using
drivers/scsi/arcmsr/arcmsr.h:} DeliverQ, CompletionQ, *pDeliver_Q, *pCompletion_Q;
drivers/scsi/arcmsr/arcmsr.h:	uint32_t		completionQ_entry;
drivers/scsi/arcmsr/arcmsr.h:	pCompletion_Q		pCompletionQ;
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->pCompletionQ = dma_coherent;
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->completionQ_entry = acb->ioqueue_size / sizeof(struct deliver_completeQ);
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->pCompletionQ = dma_coherent;
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->completionQ_entry = acb->completeQ_size / sizeof(struct deliver_completeQ);
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->pCompletionQ = acb->dma_coherent2;
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->completionQ_entry = acb->ioqueue_size / sizeof(struct deliver_completeQ);
drivers/scsi/arcmsr/arcmsr_hba.c:		cmdSMID = acb->pCompletionQ[doneq_index].cmdSMID;
drivers/scsi/arcmsr/arcmsr_hba.c:		error = (acb->pCompletionQ[doneq_index].cmdFlag
drivers/scsi/arcmsr/arcmsr_hba.c:		if (doneq_index >= acb->completionQ_entry)
drivers/scsi/arcmsr/arcmsr_hba.c:		cmdSMID = acb->pCompletionQ[doneq_index].cmdSMID;
drivers/scsi/arcmsr/arcmsr_hba.c:		error = (acb->pCompletionQ[doneq_index].cmdFlag &
drivers/scsi/arcmsr/arcmsr_hba.c:		acb->pCompletionQ[doneq_index].cmdSMID = 0xffff;
drivers/scsi/arcmsr/arcmsr_hba.c:		if (doneq_index >= acb->completionQ_entry)
drivers/scsi/arcmsr/arcmsr_hba.c:		cmdSMID = acb->pCompletionQ[doneq_index].cmdSMID;
drivers/scsi/arcmsr/arcmsr_hba.c:		if (doneq_index >= acb->completionQ_entry)
drivers/scsi/arcmsr/arcmsr_hba.c:		error = (acb->pCompletionQ[doneq_index].cmdFlag &
drivers/scsi/arm/fas216.c:	 * Sanity check the completion - if we have zero bytes left
drivers/scsi/arm/fas216.h: * Purpose : queue a command for adapter to process, and process it to completion.
drivers/scsi/be2iscsi/be_cmds.c: * beiscsi_mcc_compl_status - Return the status of MCC completion
drivers/scsi/be2iscsi/be_cmds.c: * beiscsi_mccq_compl_wait()- Process completion in MCC CQ
drivers/scsi/be2iscsi/be_cmds.c: * Waits for MBX completion with the passed TAG.
drivers/scsi/be2iscsi/be_cmds.c:	/* wait for the mccq completion */
drivers/scsi/be2iscsi/be_cmds.c:	 * for cmd is not freed until FW returns completion.
drivers/scsi/be2iscsi/be_cmds.c:			    "BC_%d : MBX Cmd Completion timed out\n");
drivers/scsi/be2iscsi/be_cmds.c: * beiscsi_process_mbox_compl()- Check the MBX completion status
drivers/scsi/be2iscsi/be_cmds.c: * @compl: Completion status of MBX Command
drivers/scsi/be2iscsi/be_cmds.c: * Check for the MBX completion status when BMBX method used
drivers/scsi/be2iscsi/be_cmds.c:				"BC_%d : BMBX busy, no completion\n");
drivers/scsi/be2iscsi/be_cmds.c:		    "BC_%d : error in cmd completion: Subsystem : %d Opcode : %d status(compl/extd)=%d/%d\n",
drivers/scsi/be2iscsi/be_cmds.c:			    "BC_%d : MBX Completion for timeout Command from FW\n");
drivers/scsi/be2iscsi/be_cmds.c:		/* just check completion status and free wrb */
drivers/scsi/be2iscsi/be_cmds.c: * @cq: Completion Queue
drivers/scsi/be2iscsi/be_cmds.c:	 * SLI COMMON_FUNCTION_RESET completion is indicated by BMBX RDY bit.
drivers/scsi/be2iscsi/be_cmds.h:/* Completion Status */
drivers/scsi/be2iscsi/be_cmds.h: * complete. Upon completion, the MAILBOX will contain a valid completion
drivers/scsi/be2iscsi/be_cmds.h:/*** iSCSI ack/driver message completions ***/
drivers/scsi/be2iscsi/be_cmds.h: * Different types of iSCSI completions to host driver for both initiator
drivers/scsi/be2iscsi/be_cmds.h:						 * completion notify.
drivers/scsi/be2iscsi/be_cmds.h:						 * completion
drivers/scsi/be2iscsi/be_cmds.h:						 * completionnotifify.
drivers/scsi/be2iscsi/be_iscsi.c:	 * Break ep->conn link here so that completions after
drivers/scsi/be2iscsi/be_iscsi.c:	/* wait for all completions to arrive, then process them */
drivers/scsi/be2iscsi/be_main.c:completion_check:
drivers/scsi/be2iscsi/be_main.c:		goto completion_check;
drivers/scsi/be2iscsi/be_main.c: * beiscsi_process_cq()- Process the Completion Queue
drivers/scsi/be2iscsi/be_main.c: * @pbe_eq: Event Q on which the Completion has come
drivers/scsi/be2iscsi/be_main.c: *     Number of Completion Entries processed.
drivers/scsi/be2iscsi/be_main.c:	 * There is no completion for CONTEXT_UPDATE. The completion of next
drivers/scsi/be2iscsi/be_main.c:		/* completion of this is ignored */
drivers/scsi/be2iscsi/be_main.c:			    "BM_%d : EEH Reset Completion Failure\n");
drivers/scsi/be2iscsi/be_mgmt.c: * @cbfn: callback func on MCC completion
drivers/scsi/be2iscsi/be_mgmt.c: * beiscsi_if_set_vlan()- Issue and wait for CMD completion
drivers/scsi/be2iscsi/be_mgmt.c: * Issue the MBX Cmd and wait for the completion of the
drivers/scsi/be2iscsi/be_mgmt.c:	/* clear the tag so no other completion matches this tag */
drivers/scsi/bfa/bfa_core.c:	 * acknowledge RME completions and update CI
drivers/scsi/bfa/bfa_core.c:	 * RME completion queue interrupt
drivers/scsi/bfa/bfa_core.c:	 * CPE completion queue interrupt
drivers/scsi/bfa/bfa_core.c:	 * Unconditional RME completion queue interrupt
drivers/scsi/bfa/bfa_core.c:	 * CPE completion queue interrupt
drivers/scsi/bfa/bfa_core.c: * Actions on chip-reset completion.
drivers/scsi/bfa/bfa_defs_fcs.h:	u8 conf_comp;      /*  confirmed completion supp  */
drivers/scsi/bfa/bfa_defs_svc.h:	bfa_boolean_t	delay_comp;	/* delay completion of failed
drivers/scsi/bfa/bfa_defs_svc.h:	u32	io_comps;		/*  Total IO Completions	*/
drivers/scsi/bfa/bfa_defs_svc.h:	u32	iocomp_ok;		/*  Slowpath IO completions	*/
drivers/scsi/bfa/bfa_defs_svc.h:	u32	iocom_hostabrts;	/*  Host IO abort completions	*/
drivers/scsi/bfa/bfa_defs_svc.h:	u32	iocomp_aborted;		/*  IO abort completions	*/
drivers/scsi/bfa/bfa_defs_svc.h:	u32	tm_io_comps;		/* Abort completion due to TM command */
drivers/scsi/bfa/bfa_defs_svc.h:	u32	create_comps;		/*  IT Nexus FW create completions */
drivers/scsi/bfa/bfa_defs_svc.h:	u32	delete_comps;		/*  IT Nexus FW delete completions */
drivers/scsi/bfa/bfa_defs_svc.h:	u32	cleanup_comps;		/*  IT Nexus cleanup completions    */
drivers/scsi/bfa/bfa_defs_svc.h:	u32	tm_fw_rsps;		/*  TM Completions		*/
drivers/scsi/bfa/bfa_defs_svc.h:	u32	tm_cleanup_comps;	/*  TM cleanup completions	*/
drivers/scsi/bfa/bfa_fcpim.c: * task management completion handling
drivers/scsi/bfa/bfa_fcpim.c: * IO cleanup completion
drivers/scsi/bfa/bfa_fcpim.c: * IO is being aborted, waiting for completion from firmware.
drivers/scsi/bfa/bfa_fcpim.c: * IO is being cleaned up (implicit abort), waiting for completion from
drivers/scsi/bfa/bfa_fcpim.c:		 * setup residue value correctly for normal completions
drivers/scsi/bfa/bfa_fcpim.c: * TM command is active, awaiting completion from firmware to
drivers/scsi/bfa/bfa_fcpim.c: * completion event from firmware.
drivers/scsi/bfa/bfa_fcpim.c:		 * Ignore and wait for ABORT completion from firmware.
drivers/scsi/bfa/bfa_fcpim.c:		 * Notify TM conmpletion on IO cleanup completion.
drivers/scsi/bfa/bfa_fcpim.c: * IO cleanup completion
drivers/scsi/bfa/bfa_fcpim.c: * Notification on completions from related ioim.
drivers/scsi/bfa/bfa_fcpim.c:	 * requests. All other statuses are for normal completions.
drivers/scsi/bfa/bfa_fcpim.h:	BFA_IOIM_SM_ABORT_DONE	= 9,	/*  abort completion from f/w */
drivers/scsi/bfa/bfa_fcpim.h:	bfa_cb_cbfn_t		io_cbfn;	/*  IO completion handler */
drivers/scsi/bfa/bfa_fcpim.h:	BFA_TSKIM_SM_DONE	= 2,	/*  TM completion		*/
drivers/scsi/bfa/bfa_fcpim.h:	BFA_TSKIM_SM_HCB	= 6,	/*  BFA callback completion	*/
drivers/scsi/bfa/bfa_fcpim.h:	BFA_TSKIM_SM_IOS_DONE	= 7,	/*  IO and sub TM completions	*/
drivers/scsi/bfa/bfa_fcpim.h:	BFA_TSKIM_SM_CLEANUP_DONE = 9,	/*  TM abort completion	*/
drivers/scsi/bfa/bfa_fcpim.h:	BFA_TSKIM_SM_UTAG	= 10,	/*  TM completion unknown tag  */
drivers/scsi/bfa/bfa_fcpim.h:	BFA_ITNIM_SM_CLEANUP = 6,	/*  IO cleanup completion */
drivers/scsi/bfa/bfa_fcpim.h: * BFA completion callback for bfa_itnim_online().
drivers/scsi/bfa/bfa_fcpim.h: * BFA completion callback for bfa_itnim_offline().
drivers/scsi/bfa/bfa_fcpim.h: * I/O completion notification.
drivers/scsi/bfa/bfa_fcpim.h: * @param[in]		io_status		IO completion status
drivers/scsi/bfa/bfa_fcpim.h: * I/O good completion notification.
drivers/scsi/bfa/bfa_fcpim.h: * I/O abort completion notification
drivers/scsi/bfa/bfa_fcs.c: *   Fabric is being deleted, awaiting vport delete completions.
drivers/scsi/bfa/bfa_fcs.c: * Fabric is being stopped, awaiting vport stop completions.
drivers/scsi/bfa/bfa_fcs.c:		 * before the fabric completion callbk is done.
drivers/scsi/bfa/bfa_fcs.c: * bfa lps login completion callback
drivers/scsi/bfa/bfa_fcs.c: * Stop all vports and wait for vport stop completions.
drivers/scsi/bfa/bfa_fcs.c: * Delete all vports and wait for vport delete completions.
drivers/scsi/bfa/bfa_fcs.c: *   Flogi Acc completion callback.
drivers/scsi/bfa/bfa_fcs.c:	 * Initialize fabric delete completion handler. Fabric deletion is
drivers/scsi/bfa/bfa_fcs.h:	BFA_FCS_FABRIC_SM_STOPCOMP	= 18,	/*  Stop completion	*/
drivers/scsi/bfa/bfa_fcs.h:	BFA_FCS_FABRIC_SM_LOGOCOMP	= 19,	/*  FLOGO completion	*/
drivers/scsi/bfa/bfa_fcs.h:	BFA_FCS_VPORT_SM_DELCOMP = 11,	/*  lport delete completion */
drivers/scsi/bfa/bfa_fcs.h:	BFA_FCS_VPORT_SM_STOPCOMP = 14,	/* vport delete completion */
drivers/scsi/bfa/bfa_fcs_fcpim.c: * BFA completion callback for bfa_itnim_online().
drivers/scsi/bfa/bfa_fcs_fcpim.c: * BFA completion callback for bfa_itnim_offline().
drivers/scsi/bfa/bfa_fcs_fcpim.c: * Mark the beginning of PATH TOV handling. IO completion callbacks
drivers/scsi/bfa/bfa_fcs_lport.c:		/* If vport - send completion call back */
drivers/scsi/bfa/bfa_fcs_lport.c:			/* If vport - send completion call back */
drivers/scsi/bfa/bfa_fcs_lport.c:			/* If vport - send completion call back */
drivers/scsi/bfa/bfa_fcs_lport.c:			/* If vport - send completion call back */
drivers/scsi/bfa/bfa_fcs_lport.c: * bfa_fcs_vport_delete_comp() for vports on completion.
drivers/scsi/bfa/bfa_fcs_lport.c: * Vport is being stopped - awaiting lport stop completion to send
drivers/scsi/bfa/bfa_fcs_lport.c: * Vport is being deleted - awaiting lport delete completion to send
drivers/scsi/bfa/bfa_fcs_lport.c: * Stop completion callback from associated lport
drivers/scsi/bfa/bfa_fcs_lport.c: * Delete completion callback from associated lport
drivers/scsi/bfa/bfa_fcs_rport.c: * Rport has sent LOGO. Awaiting FC-4 offline completion callback.
drivers/scsi/bfa/bfa_fcs_rport.c: *		LOGO needs to be sent to rport. Awaiting FC-4 offline completion
drivers/scsi/bfa/bfa_fcs_rport.c: *	Rport is going offline. Awaiting FC-4 offline completion callback.
drivers/scsi/bfa/bfa_ioc.c: * IOC disable completion entry.
drivers/scsi/bfa/bfa_ioc.c: * Notify enable completion callback.
drivers/scsi/bfa/bfa_ioc.c: * IOC disable completion entry.
drivers/scsi/bfa/bfa_ioc.c:	 * just wait for an initialization completion interrupt.
drivers/scsi/bfa/bfa_ioc.c:	 * Provide enable completion callback.
drivers/scsi/bfa/bfa_ioc.c:		 * Queue completion callback.
drivers/scsi/bfa/bfa_modules.h:	struct list_head	comp_q;		/*  pending completions     */
drivers/scsi/bfa/bfa_svc.c:	/* discarded fcxp completion */
drivers/scsi/bfa/bfa_svc.c: * Indirect login completion handler for non-fcs
drivers/scsi/bfa/bfa_svc.c: * Login completion handler -- direct call for fcs, queue for others
drivers/scsi/bfa/bfa_svc.c: * Indirect logout completion handler for non-fcs
drivers/scsi/bfa/bfa_svc.c: * Logout completion handler -- direct call for fcs, queue for others
drivers/scsi/bfa/bfa_svc.c: * Clear virtual link completion handler for non-fcs
drivers/scsi/bfa/bfa_svc.c: * No need to wait for any pending login/logout completions.
drivers/scsi/bfa/bfa_svc.h:	bfa_cb_fcxp_send_t send_cbfn;   /*  send completion callback */
drivers/scsi/bfa/bfad.c:		init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:		/* Enable Interrupt and wait bfa_init completion */
drivers/scsi/bfa/bfad.c:		wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:				init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:				wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	struct completion fcomp;
drivers/scsi/bfa/bfad.c:	init_completion(vport->comp_del);
drivers/scsi/bfa/bfad.c:	wait_for_completion(vport->comp_del);
drivers/scsi/bfa/bfad.c:	init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:		init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:		wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	/* Enable Interrupt and wait bfa_init completion */
drivers/scsi/bfa/bfad.c:	init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	init_completion(&bfad->comp);
drivers/scsi/bfa/bfad.c:	wait_for_completion(&bfad->comp);
drivers/scsi/bfa/bfad_attr.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_attr.c:	struct completion fcomp;
drivers/scsi/bfa/bfad_attr.c:	init_completion(vport->comp_del);
drivers/scsi/bfa/bfad_attr.c:	wait_for_completion(vport->comp_del);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&bfad->enable_comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&bfad->enable_comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&bfad->disable_comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&bfad->disable_comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&cee_comp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&cee_comp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&cee_comp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&cee_comp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&fcomp.comp);
drivers/scsi/bfa/bfad_bsg.c:	init_completion(&drv_fcxp->comp);
drivers/scsi/bfa/bfad_bsg.c:		wait_for_completion(&drv_fcxp->comp);
drivers/scsi/bfa/bfad_drv.h:	struct completion *comp_del;
drivers/scsi/bfa/bfad_drv.h:	struct completion comp;
drivers/scsi/bfa/bfad_drv.h:	struct completion suspend;
drivers/scsi/bfa/bfad_drv.h:	struct completion enable_comp;
drivers/scsi/bfa/bfad_drv.h:	struct completion disable_comp;
drivers/scsi/bfa/bfad_drv.h:	struct completion comp;
drivers/scsi/bfa/bfad_drv.h:	struct completion comp;
drivers/scsi/bfa/bfad_im.c:			/* Queue depth adjustment for good status completion */
drivers/scsi/bfa/bfad_im.h: * @wq: Wait queue used to wait for completion of an operation.
drivers/scsi/bfa/bfi.h:	BFI_MC_IOIM_IOCOM	= 17,	/*  good IO completion		    */
drivers/scsi/bfa/bfi_ms.h: *	IO completions.
drivers/scsi/bfa/bfi_ms.h:	u8	io_status;	/*  IO completion status	 */
drivers/scsi/bnx2fc/57xx_hsi_bnx2fc.h: * Completion information $$KEEP_ENDIANNESS$$
drivers/scsi/bnx2fc/57xx_hsi_bnx2fc.h:	__le32 completion_status;
drivers/scsi/bnx2fc/57xx_hsi_bnx2fc.h:#define FCOE_KCQE_RAMROD_COMPLETION (0x1<<3)
drivers/scsi/bnx2fc/57xx_hsi_bnx2fc.h:#define FCOE_KCQE_RAMROD_COMPLETION_SHIFT 3
drivers/scsi/bnx2fc/bnx2fc.h:	struct completion stat_req_done;
drivers/scsi/bnx2fc/bnx2fc.h:	struct completion abts_done;
drivers/scsi/bnx2fc/bnx2fc.h:	struct completion cleanup_done;
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* KCQ (kernel completion queue) response op codes */
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* KCQ (kernel completion queue) completion status */
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_SUCCESS				(0x0)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_ERROR				(0x1)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_INVALID_OPCODE		(0x2)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE	(0x3)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_CTX_FREE_FAILURE	(0x4)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_NIC_ERROR			(0x5)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_WRONG_HSI_VERSION   (0x6)
drivers/scsi/bnx2fc/bnx2fc_constants.h:#define FCOE_KCQE_COMPLETION_STATUS_PARITY_ERROR	(0x81)
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* For completion the ABTS task. */
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* Obsolete: Intermediate completion (middle path with local completion) */
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* Special completion indication in case of task was aborted. */
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* FW only: Special completion indication in case of task was cleaned. */
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* Not in used: Special completion indication (in task requested the exchange
drivers/scsi/bnx2fc/bnx2fc_constants.h:/* Special completion indication (in task requested the sequence cleanup) in
drivers/scsi/bnx2fc/bnx2fc_els.c:		 * drop the completion. Remove from active_cmd_queue.
drivers/scsi/bnx2fc/bnx2fc_els.c:		 * drop the completion. libfc will handle the els timeout
drivers/scsi/bnx2fc/bnx2fc_els.c:		/* This IO doesn't receive cleanup completion */
drivers/scsi/bnx2fc/bnx2fc_fcoe.c:	init_completion(&hba->stat_req_done);
drivers/scsi/bnx2fc/bnx2fc_fcoe.c:	rc = wait_for_completion_timeout(&hba->stat_req_done, (2 * HZ));
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	BNX2FC_TGT_DBG(tgt, "Entered UNSOL COMPLETION wqe = 0x%x\n", wqe);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		 * completion with FW error.
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	/* Timestamp IO completion time */
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	/* Process other IO completion types */
drivers/scsi/bnx2fc/bnx2fc_hwi.c:/* Pending work request completion */
drivers/scsi/bnx2fc/bnx2fc_hwi.c: * bnx2fc_process_ofld_cmpl - process FCoE session offload completion
drivers/scsi/bnx2fc/bnx2fc_hwi.c: * handle session offload completion, enable the session if offload is
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	if (ofld_kcqe->completion_status) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		if (ofld_kcqe->completion_status ==
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				FCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c: * bnx2fc_process_enable_conn_cmpl - process FCoE session enable completion
drivers/scsi/bnx2fc/bnx2fc_hwi.c: * handle session enable completion, mark the rport as ready
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	if (!ofld_kcqe->completion_status)
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	if (disable_kcqe->completion_status) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			disable_kcqe->completion_status);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	if (destroy_kcqe->completion_status) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			destroy_kcqe->completion_status);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	case FCOE_KCQE_COMPLETION_STATUS_INVALID_OPCODE:
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	case FCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE:
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	case FCOE_KCQE_COMPLETION_STATUS_NIC_ERROR:
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	case FCOE_KCQE_COMPLETION_STATUS_ERROR:
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	case FCOE_KCQE_COMPLETION_STATUS_WRONG_HSI_VERSION:
drivers/scsi/bnx2fc/bnx2fc_hwi.c: * @num_cqe:	Number of completion queue elements
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			if (kcqe->completion_status !=
drivers/scsi/bnx2fc/bnx2fc_hwi.c:					FCOE_KCQE_COMPLETION_STATUS_SUCCESS) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:						kcqe->completion_status);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			if (kcqe->completion_status !=
drivers/scsi/bnx2fc/bnx2fc_hwi.c:					FCOE_KCQE_COMPLETION_STATUS_SUCCESS) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			if (kcqe->completion_status !=
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			    FCOE_KCQE_COMPLETION_STATUS_SUCCESS)
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	rc = wait_for_completion_timeout(&io_req->abts_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:		init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:		rc = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	time_left = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:	 * as part of task management completion and eh_abort
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:		wait_for_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	time_left = wait_for_completion_timeout(&io_req->abts_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:		 * between timeout and abts completion, and abts
drivers/scsi/bnx2fc/bnx2fc_io.c:		 * completion happens just in time.
drivers/scsi/bnx2fc/bnx2fc_io.c:	 * If we receive a cleanup completion for this request then the
drivers/scsi/bnx2fc/bnx2fc_io.c:	 * firmware will not give us an abort completion for this request
drivers/scsi/bnx2fc/bnx2fc_io.c:	 * If we receive an ABTS completion here then we will not receive
drivers/scsi/bnx2fc/bnx2fc_io.c:	 * a cleanup completion so clear any cleanup pending flags.
drivers/scsi/bnx2fc/bnx2fc_io.c:		 * of task management completion, or
drivers/scsi/bnx2fc/bnx2fc_io.c:		 * delayed completion. Ignore completion
drivers/scsi/bnx2fc/bnx2fc_io.c:				/* Good IO completion */
drivers/scsi/bnx2fc/bnx2fc_io.c:				      "Actual completion after cleanup request cleaning up\n");
drivers/scsi/bnx2fc/bnx2fc_io.c:	/* Cancel the timeout_work, as we received IO completion */
drivers/scsi/bnx2fc/bnx2fc_io.c:	/* Fetch fcp_rsp from task context and perform cmd completion */
drivers/scsi/bnx2fc/bnx2fc_io.c:		 * between command abort and (late) completion.
drivers/scsi/bnx2fc/bnx2fc_io.c:			/* Good IO completion */
drivers/scsi/bnx2fc/bnx2fc_tgt.c:	/* fake upload completion */
drivers/scsi/bnx2fc/bnx2fc_tgt.c:	 * Upon completion of offload process add
drivers/scsi/bnx2fc/bnx2fc_tgt.c: * This event_callback is called after successful completion of libfc
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			 * In offload/enable completion path, the
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_OPCODE_NOPOUT_LOCAL_COMPLETION    (0)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:/* KCQ (kernel completion queue) response op codes */
drivers/scsi/bnx2i/57xx_iscsi_constants.h:/* KCQ (kernel completion queue) completion status */
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_SUCCESS                            (0x0)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_INVALID_OPCODE                     (0x1)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE                  (0x2)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_CTX_FREE_FAILURE                   (0x3)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_NIC_ERROR                          (0x4)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_HDR_DIG_ERR                        (0x5)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_DATA_DIG_ERR                       (0x6)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_UNEXPECTED_OPCODE     (0xa)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_OPCODE                (0xb)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_AHS_LEN               (0xc)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_ITT                   (0xd)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_STATSN                (0xe)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_EXP_DATASN            (0xf)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T              (0x10)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATA_SEG_LEN_IS_ZERO  (0x2c)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATA_SEG_LEN_TOO_BIG  (0x2d)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_0                 (0x11)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_1                 (0x12)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_2                 (0x13)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_3                 (0x14)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_4                 (0x15)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_5                 (0x16)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_6                 (0x17)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REMAIN_RCV_LEN        (0x18)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_MAX_RCV_PDU_LEN       (0x19)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_F_BIT_ZERO            (0x1a)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_TTT_NOT_RSRV          (0x1b)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATASN                (0x1c)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REMAIN_BURST_LEN      (0x1d)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_BUFFER_OFF            (0x1f)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_LUN                   (0x20)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_R2TSN                 (0x21)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DESIRED_DATA_TRNS_LEN_0 (0x22)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DESIRED_DATA_TRNS_LEN_1 (0x23)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T_EXCEED       (0x24)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_TTT_IS_RSRV           (0x25)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_MAX_BURST_LEN         (0x26)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATA_SEG_LEN_NOT_ZERO (0x27)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REJECT_PDU_LEN        (0x28)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_ASYNC_PDU_LEN         (0x29)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_NOPIN_PDU_LEN         (0x2a)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T_IN_CLEANUP   (0x2b)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_IP_FRAGMENT               (0x40)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_IP_OPTIONS                (0x41)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_URGENT_FLAG               (0x42)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_MAX_RTRANS                (0x43)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_ISCSI_NOT_SUPPORTED                (0x50)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_LOM_ISCSI_NOT_ENABLED              (0x51)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_CID_BUSY				(0x80)
drivers/scsi/bnx2i/57xx_iscsi_constants.h:#define ISCSI_KCQE_COMPLETION_STATUS_PARITY_ERR                         (0x81)
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_FW_MP_REQUEST_LOCAL_COMPLETION (0x1<<1)
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_FW_MP_REQUEST_LOCAL_COMPLETION_SHIFT 1
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_FW_MP_REQUEST_LOCAL_COMPLETION (0x1<<1)
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_FW_MP_REQUEST_LOCAL_COMPLETION_SHIFT 1
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:	u32 completion_status;
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION (0x1<<1)
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION_SHIFT 1
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION (0x1<<1)
drivers/scsi/bnx2i/57xx_iscsi_hsi.h:#define ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION_SHIFT 1
drivers/scsi/bnx2i/bnx2i.h:#include <linux/completion.h>
drivers/scsi/bnx2i/bnx2i.h:	struct completion cmd_cleanup_cmpl;
drivers/scsi/bnx2i/bnx2i.h: * @ep_ofld_list:          connection list for pending offload completion
drivers/scsi/bnx2i/bnx2i.h: * @ep_destroy_list:       connection list for pending offload completion
drivers/scsi/bnx2i/bnx2i.h:	/* CQ pending completion counter */
drivers/scsi/bnx2i/bnx2i.h:	/* CQ pending completion ITT array */
drivers/scsi/bnx2i/bnx2i.h: * @cq_virt:            virtual address of completion queue (CQ) region
drivers/scsi/bnx2i/bnx2i.h: *	to send work requests (SQ), receive completion notifications (CQ)
drivers/scsi/bnx2i/bnx2i_hwi.c:	if (error_code == ISCSI_KCQE_COMPLETION_STATUS_ISCSI_NOT_SUPPORTED)
drivers/scsi/bnx2i/bnx2i_hwi.c:	if (error_code == ISCSI_KCQE_COMPLETION_STATUS_LOM_ISCSI_NOT_ENABLED)
drivers/scsi/bnx2i/bnx2i_hwi.c:	login_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:	tmfabort_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:	text_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:	scsi_cmd_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:		nopout_wqe->flags = ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION;
drivers/scsi/bnx2i/bnx2i_hwi.c:		nopout_wqe->flags = ISCSI_NOP_OUT_REQUEST_LOCAL_COMPLETION;
drivers/scsi/bnx2i/bnx2i_hwi.c:	nopout_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:	logout_wqe->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:	cmd_cleanup->cq_index = 0; /* CQ# used for completion, 5771x only */
drivers/scsi/bnx2i/bnx2i_hwi.c:		  ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_TTT_NOT_RSRV) |
drivers/scsi/bnx2i/bnx2i_hwi.c:		  ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_EXP_DATASN) |
drivers/scsi/bnx2i/bnx2i_hwi.c:		(1ULL << ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_LUN));
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_process_scsi_cmd_resp - this function handles scsi cmd completion.
drivers/scsi/bnx2i/bnx2i_hwi.c: * process iSCSI NOPIN local completion CQE, frees IIT and command structures
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_process_cmd_cleanup_resp - process scsi command clean-up completion
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_queue_scsi_cmd_resp - queue cmd completion to the percpu thread
drivers/scsi/bnx2i/bnx2i_hwi.c: * completion CQEs
drivers/scsi/bnx2i/bnx2i_hwi.c: * cpu_id gets recorded upon task_xmit.  No out-of-order completion!
drivers/scsi/bnx2i/bnx2i_hwi.c:		case ISCSI_OPCODE_NOPOUT_LOCAL_COMPLETION:
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_process_update_conn_cmpl - process iscsi conn update completion KCQE
drivers/scsi/bnx2i/bnx2i_hwi.c: * CONN_UPDATE completion handler, this completes iSCSI connection FFP migration
drivers/scsi/bnx2i/bnx2i_hwi.c:	if (update_kcqe->completion_status) {
drivers/scsi/bnx2i/bnx2i_hwi.c:			  iscsi_cid, tcp_err->completion_status);
drivers/scsi/bnx2i/bnx2i_hwi.c:	err_mask64 = (0x1ULL << iscsi_err->completion_status);
drivers/scsi/bnx2i/bnx2i_hwi.c:	switch (iscsi_err->completion_status) {
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_HDR_DIG_ERR:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_DATA_DIG_ERR:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_OPCODE:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_AHS_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_ITT:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_STATSN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_EXP_DATASN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_0:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_1:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_2:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_3:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_4:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_5:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_O_U_6:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REMAIN_RCV_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_MAX_RCV_PDU_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_F_BIT_ZERO:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_TTT_NOT_RSRV:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATASN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REMAIN_BURST_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_BUFFER_OFF:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_LUN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_R2TSN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DESIRED_DATA_TRNS_LEN_0
drivers/scsi/bnx2i/bnx2i_hwi.c:	ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DESIRED_DATA_TRNS_LEN_1
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T_EXCEED:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_TTT_IS_RSRV:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_MAX_BURST_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_DATA_SEG_LEN_NOT_ZERO
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_REJECT_PDU_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_ASYNC_PDU_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_NOPIN_PDU_LEN:
drivers/scsi/bnx2i/bnx2i_hwi.c:	ISCSI_KCQE_COMPLETION_STATUS_PROTOCOL_ERR_PEND_R2T_IN_CLEANUP
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_IP_FRAGMENT:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_IP_OPTIONS:
drivers/scsi/bnx2i/bnx2i_hwi.c:	case ISCI_KCQE_COMPLETION_STATUS_TCP_ERROR_URGENT_FLAG:
drivers/scsi/bnx2i/bnx2i_hwi.c:				  iscsi_err->completion_status);
drivers/scsi/bnx2i/bnx2i_hwi.c:		if (!test_and_set_bit(iscsi_err->completion_status,
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_process_conn_destroy_cmpl - process iscsi conn destroy completion
drivers/scsi/bnx2i/bnx2i_hwi.c: * handles connection destroy completion request.
drivers/scsi/bnx2i/bnx2i_hwi.c:				  "offload request, unexpected completion\n");
drivers/scsi/bnx2i/bnx2i_hwi.c:	if (conn_destroy->completion_status) {
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_process_ofld_cmpl - process initial iscsi conn offload completion
drivers/scsi/bnx2i/bnx2i_hwi.c: * handles initial connection offload completion, ep_connect() thread is
drivers/scsi/bnx2i/bnx2i_hwi.c:	if (ofld_kcqe->completion_status) {
drivers/scsi/bnx2i/bnx2i_hwi.c:		if (ofld_kcqe->completion_status ==
drivers/scsi/bnx2i/bnx2i_hwi.c:		    ISCSI_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE)
drivers/scsi/bnx2i/bnx2i_hwi.c:		else if (ofld_kcqe->completion_status ==
drivers/scsi/bnx2i/bnx2i_hwi.c:			 ISCSI_KCQE_COMPLETION_STATUS_INVALID_OPCODE)
drivers/scsi/bnx2i/bnx2i_hwi.c:		else if (ofld_kcqe->completion_status ==
drivers/scsi/bnx2i/bnx2i_hwi.c:			 ISCSI_KCQE_COMPLETION_STATUS_CID_BUSY)
drivers/scsi/bnx2i/bnx2i_hwi.c:				ofld_kcqe->completion_status);
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_indicate_kcqe - process iscsi conn update completion KCQE
drivers/scsi/bnx2i/bnx2i_hwi.c:			if (ikcqe->completion_status !=
drivers/scsi/bnx2i/bnx2i_hwi.c:			    ISCSI_KCQE_COMPLETION_STATUS_SUCCESS)
drivers/scsi/bnx2i/bnx2i_hwi.c:							  completion_status);
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_cm_connect_cmpl - process iscsi conn establishment completion
drivers/scsi/bnx2i/bnx2i_hwi.c: *	indicate completion of option-2 TCP connect request.
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_cm_close_cmpl - process tcp conn close completion
drivers/scsi/bnx2i/bnx2i_hwi.c: *	indicate completion of option-2 graceful TCP connect shutdown
drivers/scsi/bnx2i/bnx2i_hwi.c: * bnx2i_cm_abort_cmpl - process abortive tcp conn teardown completion
drivers/scsi/bnx2i/bnx2i_hwi.c: *	indicate completion of option-2 abortive TCP connect termination
drivers/scsi/bnx2i/bnx2i_init.c:	/* Create percpu kernel threads to handle iSCSI I/O completions */
drivers/scsi/bnx2i/bnx2i_iscsi.c: *	completion/interrupt thread using iscsi context ID
drivers/scsi/bnx2i/bnx2i_iscsi.c: * pending conn offload completion queue manager
drivers/scsi/bnx2i/bnx2i_iscsi.c: * pending conn offload completion queue manager
drivers/scsi/bnx2i/bnx2i_iscsi.c:		wait_for_completion_timeout(&bnx2i_conn->cmd_cleanup_cmpl,
drivers/scsi/bnx2i/bnx2i_iscsi.c:	init_completion(&bnx2i_conn->cmd_cleanup_cmpl);
drivers/scsi/ch.c:#include <linux/completion.h>
drivers/scsi/csiostor/csio_attr.c:		 * lock is held till completion of vnp mbox cmd.
drivers/scsi/csiostor/csio_hw.c: *	@reg: the register to check for completion
drivers/scsi/csiostor/csio_hw.c: *	@mask: a single-bit field within @reg that indicates completion
drivers/scsi/csiostor/csio_hw.c: *	@valp: where to store the value of the register at completion time
drivers/scsi/csiostor/csio_hw.c: *	at the time it indicated completion is stored there.  Returns 0 if the
drivers/scsi/csiostor/csio_hw.c: * FW_HELLO_CMD has to be polled for completion.
drivers/scsi/csiostor/csio_hw.c:	/* Post event to notify completion of configuration */
drivers/scsi/csiostor/csio_hw.c:	/* Set PCIe completion timeout to 4 seconds */
drivers/scsi/csiostor/csio_hw.c:			/* Post event to notify completion of configuration */
drivers/scsi/csiostor/csio_hw.c: * csio_mberr_worker - Worker thread (dpc) for mailbox/error completions
drivers/scsi/csiostor/csio_hw.c:	/* Now callback completions */
drivers/scsi/csiostor/csio_hw.c:	csio_mb_completions(hw, &cbfn_q);
drivers/scsi/csiostor/csio_hw.c: * into a local queue. Drops lock and calls the completions. Holds
drivers/scsi/csiostor/csio_hw.c:	csio_mb_completions(hw, &cbfn_q);
drivers/scsi/csiostor/csio_hw.c:				/* io_req will be freed by completion handler */
drivers/scsi/csiostor/csio_hw.c:			/* io_req will be freed by completion handler */
drivers/scsi/csiostor/csio_hw.c: * completion q. Allocate Egress and Ingress
drivers/scsi/csiostor/csio_hw.h:	struct list_head	cbfn_q;		/* Completion queue */
drivers/scsi/csiostor/csio_hw_t5.c:		{ PIOCPLGRPPERR_F, "PCI PIO completion Group FIFO parity error",
drivers/scsi/csiostor/csio_init.c:	/* Use FW IQ for MGMT req completion */
drivers/scsi/csiostor/csio_isr.c: * csio_process_scsi_cmpl - Process a SCSI WR completion.
drivers/scsi/csiostor/csio_isr.c: * Processes SCSI completions on the SCSI IQ indicated by scm->iq_idx
drivers/scsi/csiostor/csio_isr.c: * by calling csio_wr_process_iq_idx. If there are completions on the
drivers/scsi/csiostor/csio_isr.c: * Once done, add these completions onto the freelist.
drivers/scsi/csiostor/csio_isr.c:	int isr_completions = 0;
drivers/scsi/csiostor/csio_isr.c:	/* Call back the completion routines */
drivers/scsi/csiostor/csio_isr.c:		isr_completions++;
drivers/scsi/csiostor/csio_isr.c:	if (isr_completions) {
drivers/scsi/csiostor/csio_isr.c:					      isr_completions);
drivers/scsi/csiostor/csio_isr.c: * for handling SCSI completions.
drivers/scsi/csiostor/csio_isr.c: * for handling SCSI completions.
drivers/scsi/csiostor/csio_lnode.c: * csio_ln_fdmi_done - FDMI registeration completion
drivers/scsi/csiostor/csio_lnode.c: * csio_ln_fdmi_rhba_cbfn - RHBA completion
drivers/scsi/csiostor/csio_lnode.c: * csio_ln_fdmi_dprt_cbfn - DPRT completion
drivers/scsi/csiostor/csio_lnode.c: * csio_ln_fdmi_dhba_cbfn - DHBA completion
drivers/scsi/csiostor/csio_lnode.c: * csio_ln_vnp_read_cbfn - vnp read completion handler.
drivers/scsi/csiostor/csio_lnode.c: * @cbfn: Completion handler.
drivers/scsi/csiostor/csio_lnode.c: * @cbfn: Completion handler.
drivers/scsi/csiostor/csio_lnode.c: * @cbfn: Completion handler.
drivers/scsi/csiostor/csio_lnode.c:	/* io_req will be freed by completion handler */
drivers/scsi/csiostor/csio_lnode.c: * @io_cbfn - Completion handler.
drivers/scsi/csiostor/csio_mb.c:	/* Start completion timers in non-immediate modes and notify FW */
drivers/scsi/csiostor/csio_mb.c:	/* Poll for completion in immediate mode */
drivers/scsi/csiostor/csio_mb.c: * csio_mb_completions - Completion handler for Mailbox commands
drivers/scsi/csiostor/csio_mb.c: * @cbfn_q: Completion queue.
drivers/scsi/csiostor/csio_mb.c:csio_mb_completions(struct csio_hw *hw, struct list_head *cbfn_q)
drivers/scsi/csiostor/csio_mb.c:		/* Add completion to tail of cbfn queue */
drivers/scsi/csiostor/csio_mb.c:	 * Could be a race b/w the completion handler and the timer
drivers/scsi/csiostor/csio_mb.c:	 * and the completion handler won that race.
drivers/scsi/csiostor/csio_mb.c:		/* Stop mailbox completion timer */
drivers/scsi/csiostor/csio_mb.c:		/* Add completion to tail of cbfn queue */
drivers/scsi/csiostor/csio_mb.h:#include <linux/completion.h>
drivers/scsi/csiostor/csio_mb.h:	struct completion	cmplobj;		/* MB Completion
drivers/scsi/csiostor/csio_mb.h:	struct list_head	cbfn_q;			/* Mbox completion q */
drivers/scsi/csiostor/csio_mb.h:void csio_mb_completions(struct csio_hw *, struct list_head *);
drivers/scsi/csiostor/csio_rnode.c:		csio_dbg(hw, "Returning completion queue I/Os\n");
drivers/scsi/csiostor/csio_scsi.c:			 * but prior to LUN reset completion (in the event that
drivers/scsi/csiostor/csio_scsi.c:		 * loss itself. This forces us to serialize such completions
drivers/scsi/csiostor/csio_scsi.c:		 * internally queue up such up such completions in the rnode.
drivers/scsi/csiostor/csio_scsi.c:		 * FW (because the ABORT and completion of the I/O crossed each
drivers/scsi/csiostor/csio_scsi.c:		 * completion.
drivers/scsi/csiostor/csio_scsi.c:		 * 2. The completion of an I/O and the receipt of
drivers/scsi/csiostor/csio_scsi.c:		 * FW (because the CLOSE and completion of the I/O crossed each
drivers/scsi/csiostor/csio_scsi.c:		 * completion.
drivers/scsi/csiostor/csio_scsi.c: * csio_scsi_cmpl_handler - WR completion handler for SCSI.
drivers/scsi/csiostor/csio_scsi.c: * This is the WR completion handler called per completion from the
drivers/scsi/csiostor/csio_scsi.c:	/* Call back the completion routines of the active_q */
drivers/scsi/csiostor/csio_scsi.c:	 * need the abort/close completion to be received on the same queue
drivers/scsi/csiostor/csio_scsi.c:	reinit_completion(&ioreq->cmplobj);
drivers/scsi/csiostor/csio_scsi.c:	wait_for_completion_timeout(&ioreq->cmplobj, msecs_to_jiffies(tmo));
drivers/scsi/csiostor/csio_scsi.c:	 * FCP_RSP_LEN_VAL in flags shall be set for TM completions.
drivers/scsi/csiostor/csio_scsi.c:	 * completion. Any other rsp_code means TM operation failed.
drivers/scsi/csiostor/csio_scsi.c:	csio_dbg(hw, "Waiting max %d secs for LUN reset completion\n",
drivers/scsi/csiostor/csio_scsi.c:	/* Wait for completion */
drivers/scsi/csiostor/csio_scsi.c:		init_completion(&ioreq->cmplobj);
drivers/scsi/csiostor/csio_scsi.h:#include <linux/completion.h>
drivers/scsi/csiostor/csio_scsi.h:						   * with completions.
drivers/scsi/csiostor/csio_wr.c: * Handle FW_IQ_CMD mailbox completion. Save off the assigned IQ/FL ids.
drivers/scsi/csiostor/csio_wr.c: * @cbfn: Completion callback.
drivers/scsi/csiostor/csio_wr.c: * Handle FW_EQ_OFLD_CMD mailbox completion. Save off the assigned EQ ids.
drivers/scsi/csiostor/csio_wr.c: * @cbfn: Completion callback.
drivers/scsi/csiostor/csio_wr.c: * Handle FW_IQ_CMD (free) mailbox completion.
drivers/scsi/csiostor/csio_wr.c: * @cbfn: Completion callback.
drivers/scsi/csiostor/csio_wr.c: * Handle FW_OFLD_EQ_CMD (free) mailbox completion.
drivers/scsi/csiostor/csio_wr.c: * @cbfn: Completion callback.
drivers/scsi/csiostor/csio_wr.c: * csio_wr_process_fl - Process a freelist completion.
drivers/scsi/csiostor/csio_wr.c: * @wr: The freelist completion WR in the ingress queue.
drivers/scsi/csiostor/csio_wr.c: * @iq_handler: Caller's handler for this completion.
drivers/scsi/csiostor/csio_wr.h:	uint16_t		wr_status;	/* WR completion status */
drivers/scsi/csiostor/csio_wr.h:						/* completion callback */
drivers/scsi/csiostor/csio_wr.h:	struct completion	cmplobj;	/* ioreq completion object */
drivers/scsi/csiostor/csio_wr.h:	uint32_t	n_stray_comp;		/* Stray completion intr */
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:static int push_tx_frames(struct cxgbi_sock *csk, int req_completion);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:				   int len, int req_completion)
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:			(req_completion ? F_WR_COMPL : 0));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:static int push_tx_frames(struct cxgbi_sock *csk, int req_completion)
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:			if ((req_completion &&
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:				req_completion = 1;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:			make_tx_data_wr(csk, skb, len, req_completion);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c: * Process an acknowledgment of WR completion.  Advance snd_una and send the
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:static int push_tx_frames(struct cxgbi_sock *csk, int req_completion)
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		if (!req_completion &&
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			req_completion = 1;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:					       credits_needed, req_completion);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	reinit_completion(&csk->cmpl);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	wait_for_completion(&csk->cmpl);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	reinit_completion(&csk->cmpl);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	wait_for_completion(&csk->cmpl);
drivers/scsi/cxgbi/libcxgbi.c:	init_completion(&csk->cmpl);
drivers/scsi/cxgbi/libcxgbi.c:		/* If completion flag is set and data is directly
drivers/scsi/cxgbi/libcxgbi.c:		 * task->exp_datasn to the datasn in completion
drivers/scsi/cxgbi/libcxgbi.c:		 * iSCSI hdr as T6 adapter generates completion only
drivers/scsi/cxgbi/libcxgbi.h:	struct completion cmpl;
drivers/scsi/cxgbi/libcxgbi.h:	SKCBF_TX_FLAG_COMPL,    /* wr completion flag */
drivers/scsi/cxgbi/libcxgbi.h:	SKCBF_RX_ISCSI_COMPL,   /* received iscsi completion */
drivers/scsi/cxlflash/common.h:	struct completion cevent;
drivers/scsi/cxlflash/common.h:	struct list_head pending_cmds;	/* Commands pending completion */
drivers/scsi/cxlflash/main.c: * cmd_complete() - command completion handler
drivers/scsi/cxlflash/main.c:	timeout = wait_for_completion_timeout(&cmd->cevent, timeout);
drivers/scsi/cxlflash/main.c:	init_completion(&cmd->cevent);
drivers/scsi/cxlflash/sislite.h:#define SISL_MSI_RRQ_UPDATED       2	/* recommended for IO completion */
drivers/scsi/cxlflash/sislite.h:#define SISL_IOASC_GOOD_COMPLETION        0x00000000U
drivers/scsi/dc395x.c: * layer, invoke 'done' on completion
drivers/scsi/dc395x.c: * Signal completion to the generic SCSI driver  
drivers/scsi/elx/efct/efct_driver.c:	init_completion(&result.done);
drivers/scsi/elx/efct/efct_driver.c:		if (wait_for_completion_interruptible(&result.done) != 0) {
drivers/scsi/elx/efct/efct_driver.h:	struct completion done;
drivers/scsi/elx/efct/efct_hw.c:	 * the WQ to allow for 2 completions per IO. This allows us to
drivers/scsi/elx/efct/efct_hw.c:	 * a completion be received for one of these IOs
drivers/scsi/elx/efct/efct_hw.c:	 * Arming the EQ allows (e.g.) interrupts when CQ completions write EQ
drivers/scsi/elx/efct/efct_hw.c:	 * Arming the CQ allows (e.g.) MQ completions to write CQ entries
drivers/scsi/elx/efct/efct_hw.c:	 * a completion (EFCT_CMD_POLL) or get an optional asynchronous
drivers/scsi/elx/efct/efct_hw.c:	 * completion (EFCT_CMD_NOWAIT).
drivers/scsi/elx/efct/efct_hw.c:	 *   EFCT_HW_STATE_RESET_IN_PROGRESS - reset, we still want completions
drivers/scsi/elx/efct/efct_hw.c:	 *                                        completions.
drivers/scsi/elx/efct/efct_hw.c:	/* Every so often, set the wqec bit to generate comsummed completions */
drivers/scsi/elx/efct/efct_hw.c:	/* completion type */
drivers/scsi/elx/efct/efct_hw.c:			 * the MQ_ID from the completion entry.
drivers/scsi/elx/efct/efct_hw.c:	/* Process any remaining completions */
drivers/scsi/elx/efct/efct_hw.h: * WQE, causing a consummed/released completion to be posted.
drivers/scsi/elx/efct/efct_hw.h:	/* command executes synchronously and busy-waits for completion */
drivers/scsi/elx/efct/efct_hw.h: * @done		Function called on IO completion
drivers/scsi/elx/efct/efct_hw.h: * @abort_done		Function called on abort completion
drivers/scsi/elx/efct/efct_hw.h:/* RQ completion handlers for RQ pair mode */
drivers/scsi/elx/efct/efct_scsi.c:	/* Call target server completion */
drivers/scsi/elx/efct/efct_scsi.c:		 * NOP mailbox completion processing context
drivers/scsi/elx/efct/efct_scsi.c:		efc_log_debug(io->efct, "completion for non-busy io tag 0x%x\n",
drivers/scsi/elx/efct/efct_unsol.c:	/* Free WQ completion callback */
drivers/scsi/elx/efct/efct_xport.c:		/* Create a completion to synchronize the stat reset process */
drivers/scsi/elx/efct/efct_xport.c:		init_completion(&result->stats.done);
drivers/scsi/elx/efct/efct_xport.c:		/* Wait for completion to be signaled when the cmd completes */
drivers/scsi/elx/efct/efct_xport.c:		if (wait_for_completion_interruptible(&result->stats.done)) {
drivers/scsi/elx/efct/efct_xport.c:		/* Wait for completion to be signaled when the cmd completes */
drivers/scsi/elx/efct/efct_xport.c:		if (wait_for_completion_interruptible(&result->stats.done)) {
drivers/scsi/elx/efct/efct_xport.c:	struct completion *done = arg;
drivers/scsi/elx/efct/efct_xport.c:		struct completion done;
drivers/scsi/elx/efct/efct_xport.c:		init_completion(&done);
drivers/scsi/elx/efct/efct_xport.c:		if (!wait_for_completion_timeout(&done, timeout)) {
drivers/scsi/elx/efct/efct_xport.h:	struct completion		done;
drivers/scsi/elx/libefc/efc_device.c:	case EFC_EVT_SRRS_ELS_CMPL_OK:	/* PLOGI ACC completions */
drivers/scsi/elx/libefc/efc_device.c:		 *    (possible since completion comes in on another
drivers/scsi/elx/libefc/efc_device.c:		/* note: problem, we're now expecting an ELS REQ completion
drivers/scsi/elx/libefc/efc_device.c:		/* sent PLOGI and before completion was seen, received the
drivers/scsi/elx/libefc/efc_device.c:		/* Completion from PLOGI sent */
drivers/scsi/elx/libefc/efc_device.c:		/* Completion from PLOGI sent */
drivers/scsi/elx/libefc/efc_domain.c:		/* Request efc_hw_domain_free and wait for completion */
drivers/scsi/elx/libefc/efc_domain.c:	 * Wait for the domain alloc/attach completion
drivers/scsi/elx/libefc/efc_els.c:	/* increment ELS completion counter */
drivers/scsi/elx/libefc/efc_fabric.c:		/* sent PLOGI and before completion was seen, received the
drivers/scsi/elx/libefc/efc_fabric.c:		/* Completion from PLOGI sent */
drivers/scsi/elx/libefc/efc_node.c:	/* check to see if ELS requests, completions are quiesced */
drivers/scsi/elx/libefc/efc_node.c:	 * handle any ELS completions that
drivers/scsi/elx/libefc/efc_node.c:	 * handle any ELS request completions that
drivers/scsi/elx/libefc/efclib.h: * @send_plogi:		send PLOGI accept, upon completion of node attach
drivers/scsi/elx/libefc/efclib.h: * @els_cmpl_cnt:	number of outstanding ELS completions
drivers/scsi/elx/libefc_sli/sli4.c:	"Completion Queue",
drivers/scsi/elx/libefc_sli/sli4.c:	case SLI4_CQE_CODE_WORK_REQUEST_COMPLETION:
drivers/scsi/elx/libefc_sli/sli4.c:		efc_log_info(sli4, "CQE completion code %d not handled\n",
drivers/scsi/elx/libefc_sli/sli4.c:	/* Retrieve the RQ index from the completion */
drivers/scsi/elx/libefc_sli/sli4.c:	/* check completion queue entry status */
drivers/scsi/elx/libefc_sli/sli4.c:	 * Firmware can split mbx completions into two MCQEs: first with only
drivers/scsi/elx/libefc_sli/sli4.c:	if (le16_to_cpu(mcqe->completion_status)) {
drivers/scsi/elx/libefc_sli/sli4.c:			     le16_to_cpu(mcqe->completion_status),
drivers/scsi/elx/libefc_sli/sli4.c:	return le16_to_cpu(mcqe->completion_status);
drivers/scsi/elx/libefc_sli/sli4.h:	__le16		completion_status;
drivers/scsi/elx/libefc_sli/sli4.h:	SLI4_QUEUE_FLAG_MQ	= 1 << 0,	/* CQ has MQ/Async completion */
drivers/scsi/elx/libefc_sli/sli4.h:/* Generic Common Create EQ/CQ/MQ/WQ/RQ Queue completion */
drivers/scsi/elx/libefc_sli/sli4.h:/* Create a Completion Queue. */
drivers/scsi/elx/libefc_sli/sli4.h:	SLI4_CQE_CODE_WORK_REQUEST_COMPLETION = 0x01,
drivers/scsi/elx/libefc_sli/sli4.h:/* FC Completion Status Codes. */
drivers/scsi/elx/libefc_sli/sli4.h: * the payload in the completion.
drivers/scsi/esas2r/atvda.h:#define RS_SUCCESS          0x00        /*! successful completion            */
drivers/scsi/esas2r/esas2r.h: * or long completion times.
drivers/scsi/esas2r/esas2r_flash.c:/* Interrupt callback to process NVRAM completions. */
drivers/scsi/esas2r/esas2r_init.c:			/* override the completion function */
drivers/scsi/esas2r/esas2r_int.c:		/* Get the completion status */
drivers/scsi/esas2r/esas2r_int.c:			 * Copy the outbound completion struct for non-I/O
drivers/scsi/esas2r/esas2r_int.c:		/* Queue the request for completion. */
drivers/scsi/esas2r/esas2r_int.c:	 * callback called.  also set the dummy completion callback in case we
drivers/scsi/esas2r/esas2r_ioctl.c:	/* Now call the original completion callback. */
drivers/scsi/esas2r/esas2r_ioctl.c:	 * Always usurp the completion callback since the interrupt callback
drivers/scsi/esas2r/esas2r_ioctl.c:	/* Done, call the completion callback. */
drivers/scsi/esas2r/esas2r_ioctl.c:		 * always usurp the completion callback since the interrupt
drivers/scsi/esas2r/esas2r_ioctl.c:/* Callback for the completion of a VDA request. */
drivers/scsi/esas2r/esas2r_ioctl.c:		bool wait_for_completion;
drivers/scsi/esas2r/esas2r_ioctl.c:		wait_for_completion =
drivers/scsi/esas2r/esas2r_ioctl.c:		if (wait_for_completion) {
drivers/scsi/esas2r/esas2r_ioctl.c:/* Callback for the completion of an FS_API request.*/
drivers/scsi/esas2r/esas2r_main.c:		 * Wait for firmware to complete the request.  Completion
drivers/scsi/esas2r/esas2r_main.c:	 *       it will check the scsi_stat value in the completion anyway.
drivers/scsi/esp_scsi.c:#include <linux/completion.h>
drivers/scsi/esp_scsi.c:		     "Unexpected selection completion ireg[%x]\n", esp->ireg);
drivers/scsi/esp_scsi.c:	 * byte should be retrieved via PIO following completion
drivers/scsi/esp_scsi.c:	struct completion eh_done;
drivers/scsi/esp_scsi.c:	init_completion(&eh_done);
drivers/scsi/esp_scsi.c:	if (!wait_for_completion_timeout(&eh_done, 5 * HZ)) {
drivers/scsi/esp_scsi.c:	struct completion eh_reset;
drivers/scsi/esp_scsi.c:	init_completion(&eh_reset);
drivers/scsi/esp_scsi.c:	if (!wait_for_completion_timeout(&eh_reset, 5 * HZ)) {
drivers/scsi/esp_scsi.c:"	0x00000020	Log command completion\n"
drivers/scsi/esp_scsi.h:	struct completion	*eh_done;
drivers/scsi/esp_scsi.h:	struct completion	*eh_reset;
drivers/scsi/fcoe/fcoe.c: * Must be called with fcoe_create_mutex held to single-thread completion.
drivers/scsi/fnic/cq_desc.h: * Completion queue descriptor types
drivers/scsi/fnic/cq_desc.h:/* Completion queue descriptor: 16B
drivers/scsi/fnic/cq_desc.h: * All completion queues have this basic layout.  The
drivers/scsi/fnic/cq_desc.h: * type_specfic area is unique for each completion
drivers/scsi/fnic/cq_enet_desc.h:/* Ethernet completion queue descriptor: 16B */
drivers/scsi/fnic/cq_enet_desc.h:/* Completion queue descriptor: Ethernet receive queue, 16B */
drivers/scsi/fnic/cq_exch_desc.h:/* Exchange completion queue descriptor: 16B */
drivers/scsi/fnic/fnic.h:extern unsigned int io_completions;
drivers/scsi/fnic/fnic.h:#define FNIC_DFLT_IO_COMPLETIONS 256
drivers/scsi/fnic/fnic.h:	struct completion *remove_wait; /* device remove thread blocks */
drivers/scsi/fnic/fnic.h:	/* completion queue cache line section */
drivers/scsi/fnic/fnic_debugfs.c:		 * and IO Completions stats. Skip incrementing No IO Compls
drivers/scsi/fnic/fnic_io.h:	struct completion *abts_done; /* completion for abts */
drivers/scsi/fnic/fnic_io.h:	struct completion *dr_done; /* completion for device reset */
drivers/scsi/fnic/fnic_isr.c:		work_done += fnic_wq_copy_cmpl_handler(fnic, io_completions, FNIC_MQ_CQ_INDEX);
drivers/scsi/fnic/fnic_isr.c:	work_done += fnic_wq_copy_cmpl_handler(fnic, io_completions, FNIC_MQ_CQ_INDEX);
drivers/scsi/fnic/fnic_isr.c:	wq_copy_work_done = fnic_wq_copy_cmpl_handler(fnic, io_completions, i);
drivers/scsi/fnic/fnic_main.c:unsigned int io_completions = FNIC_DFLT_IO_COMPLETIONS;
drivers/scsi/fnic/fnic_main.c:module_param(io_completions, int, S_IRUGO|S_IWUSR);
drivers/scsi/fnic/fnic_main.c:MODULE_PARM_DESC(io_completions, "Max CQ entries to process at a time");
drivers/scsi/fnic/fnic_scsi.c: * Routine to handle fw reset completion
drivers/scsi/fnic/fnic_scsi.c:	atomic64_inc(&reset_stats->fw_reset_completions);
drivers/scsi/fnic/fnic_scsi.c:		/* Check status of reset completion */
drivers/scsi/fnic/fnic_scsi.c:			"Unexpected state while processing reset completion: %s\n",
drivers/scsi/fnic/fnic_scsi.c: * Routine to handle flogi register completion
drivers/scsi/fnic/fnic_scsi.c:	/* Update fnic state based on status of flogi reg completion */
drivers/scsi/fnic/fnic_scsi.c:		/* Check flogi registration completion status */
drivers/scsi/fnic/fnic_scsi.c:			      " processing flogi reg completion\n",
drivers/scsi/fnic/fnic_scsi.c: * Routine to handle icmnd completions
drivers/scsi/fnic/fnic_scsi.c:			"hdr status: %s icmnd completion on the wrong queue\n",
drivers/scsi/fnic/fnic_scsi.c:	 *  set completion of the IO. The abts path will clean it up
drivers/scsi/fnic/fnic_scsi.c:	/* Call SCSI completion function to complete the IO */
drivers/scsi/fnic/fnic_scsi.c:		atomic64_inc(&fnic_stats->io_stats.io_completions);
drivers/scsi/fnic/fnic_scsi.c: * Routine to handle itmf completions
drivers/scsi/fnic/fnic_scsi.c:			"hdr status: %s ITMF completion on the wrong queue\n",
drivers/scsi/fnic/fnic_scsi.c:		/* Abort and terminate completion of device reset req */
drivers/scsi/fnic/fnic_scsi.c:			"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s Abt/term completion received\n",
drivers/scsi/fnic/fnic_scsi.c:		/* Completion of abort cmd */
drivers/scsi/fnic/fnic_scsi.c:			/* This is a late completion. Ignore it */
drivers/scsi/fnic/fnic_scsi.c:		 * signal completion to it. IO will be cleaned in the thread
drivers/scsi/fnic/fnic_scsi.c:				atomic64_inc(&fnic_stats->io_stats.io_completions);
drivers/scsi/fnic/fnic_scsi.c:		/* Completion of device reset */
drivers/scsi/fnic/fnic_scsi.c:			/* Need to wait for terminate completion */
drivers/scsi/fnic/fnic_scsi.c:			"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s DR completion received\n",
drivers/scsi/fnic/fnic_scsi.c:			      "firmware completion type %d\n",
drivers/scsi/fnic/fnic_scsi.c:		 * without sending completions for outstanding ios.
drivers/scsi/fnic/fnic_scsi.c:		atomic64_inc(&fnic_stats->io_stats.io_completions);
drivers/scsi/fnic/fnic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/fnic/fnic_scsi.c:	 * happened, the completion wont actually complete the command
drivers/scsi/fnic/fnic_scsi.c:	 * the completion wont be done till mid-layer, since abort
drivers/scsi/fnic/fnic_scsi.c:	 * We queued an abort IO, wait for its completion.
drivers/scsi/fnic/fnic_scsi.c:	wait_for_completion_timeout(&tm_done,
drivers/scsi/fnic/fnic_scsi.c:	/* Call SCSI completion function to complete the IO */
drivers/scsi/fnic/fnic_scsi.c:		atomic64_inc(&fnic_stats->io_stats.io_completions);
drivers/scsi/fnic/fnic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/fnic/fnic_scsi.c:	wait_for_completion_timeout(&tm_done, msecs_to_jiffies
drivers/scsi/fnic/fnic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/fnic/fnic_scsi.c:	 * Wait on the local completion for LUN reset.  The io_req may be
drivers/scsi/fnic/fnic_scsi.c:	wait_for_completion_timeout(&tm_done,
drivers/scsi/fnic/fnic_scsi.c:				wait_for_completion_timeout(&tm_done,
drivers/scsi/fnic/fnic_scsi.c:				wait_for_completion_timeout(&tm_done,
drivers/scsi/fnic/fnic_scsi.c:		atomic64_inc(&reset_stats->fnic_reset_completions);
drivers/scsi/fnic/fnic_scsi.c:	DECLARE_COMPLETION_ONSTACK(remove_wait);
drivers/scsi/fnic/fnic_scsi.c:		/* fw reset is in progress, poll for its completion */
drivers/scsi/fnic/fnic_scsi.c:	wait_for_completion_timeout(&remove_wait,
drivers/scsi/fnic/fnic_scsi.c:		/* fw reset is in progress, poll for its completion */
drivers/scsi/fnic/fnic_stats.h:	atomic64_t io_completions;
drivers/scsi/fnic/fnic_stats.h:	atomic64_t fw_reset_completions;
drivers/scsi/fnic/fnic_stats.h:	atomic64_t fnic_reset_completions;
drivers/scsi/fnic/fnic_trace.c:		  "Number of IOs: %lld\nNumber of IO Completions: %lld\n"
drivers/scsi/fnic/fnic_trace.c:		  "\nIO completion times: \n"
drivers/scsi/fnic/fnic_trace.c:		  (u64)atomic64_read(&stats->io_stats.io_completions),
drivers/scsi/fnic/fnic_trace.c:		  "Number of FW Reset Completions: %lld\n"
drivers/scsi/fnic/fnic_trace.c:		  "Number of Fnic Reset Completions: %lld\n"
drivers/scsi/fnic/fnic_trace.c:		  (u64)atomic64_read(&stats->reset_stats.fw_reset_completions),
drivers/scsi/fnic/fnic_trace.c:			  &stats->reset_stats.fnic_reset_completions),
drivers/scsi/fnic/fnic_trace.c:		  "Number of no icmnd itmf Completions: %lld\n"
drivers/scsi/fnic/vnic_cq.h:/* Completion queue control */
drivers/scsi/fnic/vnic_devcmd.h:	u8  color;              /* 0 or 1 as with completion queues */
drivers/scsi/fnic/vnic_resource.h:	RES_TYPE_CQ,			/* Completion queues */
drivers/scsi/fnic/vnic_resource.h:	RES_TYPE_MQ_CQ,                 /* MQ Completion queues */
drivers/scsi/hisi_sas/hisi_sas.h:	struct completion *completion;
drivers/scsi/hisi_sas/hisi_sas.h:		.completion = &c, \
drivers/scsi/hisi_sas/hisi_sas.h:	DECLARE_COMPLETION_ONSTACK(c); \
drivers/scsi/hisi_sas/hisi_sas.h:	struct completion *reset_completion;
drivers/scsi/hisi_sas/hisi_sas.h:	struct completion *completion;
drivers/scsi/hisi_sas/hisi_sas_main.c:	/* make sure CQ entries being processed are processed to completion */
drivers/scsi/hisi_sas/hisi_sas_main.c:		 * before using task in IO completion
drivers/scsi/hisi_sas/hisi_sas_main.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/hisi_sas/hisi_sas_main.c:	phy->reset_completion = &completion;
drivers/scsi/hisi_sas/hisi_sas_main.c:	if (sts && !wait_for_completion_timeout(&completion,
drivers/scsi/hisi_sas/hisi_sas_main.c:	phy->reset_completion = NULL;
drivers/scsi/hisi_sas/hisi_sas_main.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/hisi_sas/hisi_sas_main.c:	phy->reset_completion = &completion;
drivers/scsi/hisi_sas/hisi_sas_main.c:	if (!wait_for_completion_timeout(&completion,
drivers/scsi/hisi_sas/hisi_sas_main.c:	phy->reset_completion = NULL;
drivers/scsi/hisi_sas/hisi_sas_main.c:			 * before using task in IO completion
drivers/scsi/hisi_sas/hisi_sas_main.c:			 * before using task in IO completion
drivers/scsi/hisi_sas/hisi_sas_main.c:	wait_for_completion(r.completion);
drivers/scsi/hisi_sas/hisi_sas_main.c:			 * before using task in IO completion
drivers/scsi/hisi_sas/hisi_sas_main.c:		/* Completion queue structure */
drivers/scsi/hisi_sas/hisi_sas_main.c:		/* Completion queue */
drivers/scsi/hisi_sas/hisi_sas_main.c:	complete(rst->completion);
drivers/scsi/hisi_sas/hisi_sas_v1_hw.c:/* Completion header */
drivers/scsi/hisi_sas/hisi_sas_v1_hw.c:		/* Completion queue */
drivers/scsi/hisi_sas/hisi_sas_v1_hw.c:	if (phy->reset_completion)
drivers/scsi/hisi_sas/hisi_sas_v1_hw.c:		complete(phy->reset_completion);
drivers/scsi/hisi_sas/hisi_sas_v1_hw.c:		/* The completion queue and queue slot index are not
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:/* Completion header */
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:	sas_dev->completion = &completion;
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		if (!wait_for_completion_timeout(sas_dev->completion,
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		/* Completion queue */
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:			dev_info(dev, "erroneous completion iptt=%d task=%pK dev id=%d CQ hdr: 0x%x 0x%x 0x%x 0x%x Error info: 0x%x 0x%x 0x%x 0x%x\n",
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:	if (phy->reset_completion)
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		complete(phy->reset_completion);
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		complete(sas_dev->completion);
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		/* Check for NCQ completion */
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:	if (phy->reset_completion)
drivers/scsi/hisi_sas/hisi_sas_v2_hw.c:		complete(phy->reset_completion);
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:/* Completion header */
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:		/* Completion queue */
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	sas_dev->completion = &completion;
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	if (!wait_for_completion_timeout(sas_dev->completion,
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	if (phy->reset_completion)
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:		complete(phy->reset_completion);
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:		complete(sas_dev->completion);
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	/* check for erroneous completion */
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:				dev_info(dev, "erroneous completion iptt=%d task=%pK dev id=%d addr=%016llx CQ hdr: 0x%x 0x%x 0x%x 0x%x Error info: 0x%x 0x%x 0x%x 0x%x\n",
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:			dev_err(dev, "erroneous completion disk err dev id=%d sas_addr=0x%llx CQ hdr: 0x%x 0x%x 0x%x 0x%x\n",
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	/* completion header size not fixed per HW version */
drivers/scsi/hisi_sas/hisi_sas_v3_hw.c:	/* completion header size not fixed per HW version */
drivers/scsi/hosts.c:#include <linux/completion.h>
drivers/scsi/hosts.c:	wait_for_completion(&shost->tagset_freed);
drivers/scsi/hosts.c:	init_completion(&shost->tagset_freed);
drivers/scsi/hosts.c: * completion is stopped when calling this function.
drivers/scsi/hosts.c: * If locking against concurrent command completions is required
drivers/scsi/hpsa.c:#include <linux/completion.h>
drivers/scsi/hpsa.c:static void process_ioaccel2_completion(struct ctlr_info *h,
drivers/scsi/hpsa.c:		return process_ioaccel2_completion(h, cp, cmd, dev);
drivers/scsi/hpsa.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/hpsa.c:		wait_for_completion_io(&wait);
drivers/scsi/hpsa.c:	if (!wait_for_completion_io_timeout(&wait,
drivers/scsi/hpsa.c:	 * Do the scan after a reset completion
drivers/scsi/hpsa.c:	/* Don't wait for completion, the reset won't complete.  Don't free
drivers/scsi/hpsa.c:static inline unsigned long get_next_completion(struct ctlr_info *h, u8 q)
drivers/scsi/hpsa.c:/* process completion of an indexed ("direct lookup") command */
drivers/scsi/hpsa.c: * Only need to check for this in the hpsa_xxx_discard_completions
drivers/scsi/hpsa.c:static irqreturn_t hpsa_intx_discard_completions(int irq, void *queue)
drivers/scsi/hpsa.c:		raw_tag = get_next_completion(h, q);
drivers/scsi/hpsa.c:static irqreturn_t hpsa_msix_discard_completions(int irq, void *queue)
drivers/scsi/hpsa.c:	raw_tag = get_next_completion(h, q);
drivers/scsi/hpsa.c:		raw_tag = get_next_completion(h, q);
drivers/scsi/hpsa.c:	raw_tag = get_next_completion(h, q);
drivers/scsi/hpsa.c:		/* This is kind of gross.  We may or may not get a completion
drivers/scsi/hpsa.c:		 * after the reset throwing away any completions we get during
drivers/scsi/hpsa.c:		 * fake ones to scoop up any residual completions.
drivers/scsi/hpsa.c:		rc = hpsa_request_irqs(h, hpsa_msix_discard_completions,
drivers/scsi/hpsa.c:					hpsa_intx_discard_completions);
drivers/scsi/hpsa.c:			"Waiting for stale completions to drain.\n");
drivers/scsi/hpsa.h:	 * Performant mode completion buffers
drivers/scsi/hpsa.h:/* Maximum time in seconds driver will wait for command completions
drivers/scsi/hpsa_cmd.h:	struct completion *waiting;
drivers/scsi/ibmvscsi/ibmvfc.c: * This function runs completions on commands to fail as a result of a
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_locked_done - Calls evt completion with host_lock held
drivers/scsi/ibmvscsi/ibmvfc.c: * All non-scsi command completion callbacks have the expectation that the
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_sync_completion - Signal that a synchronous command has completed
drivers/scsi/ibmvscsi/ibmvfc.c:static void ibmvfc_sync_completion(struct ibmvfc_event *evt)
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_bsg_timeout_done - Completion handler for cancelling BSG commands
drivers/scsi/ibmvscsi/ibmvfc.c:	ibmvfc_init_event(evt, ibmvfc_sync_completion, IBMVFC_MAD_FORMAT);
drivers/scsi/ibmvscsi/ibmvfc.c:	init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	ibmvfc_init_event(evt, ibmvfc_sync_completion, IBMVFC_MAD_FORMAT);
drivers/scsi/ibmvscsi/ibmvfc.c:	init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:		ibmvfc_init_event(evt, ibmvfc_sync_completion, IBMVFC_CMD_FORMAT);
drivers/scsi/ibmvscsi/ibmvfc.c:		init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/ibmvscsi/ibmvfc.c:			timeout = wait_for_completion_timeout(&comp, timeout);
drivers/scsi/ibmvscsi/ibmvfc.c:	ibmvfc_init_event(evt, ibmvfc_sync_completion, IBMVFC_MAD_FORMAT);
drivers/scsi/ibmvscsi/ibmvfc.c:	init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:		wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:		ibmvfc_init_event(evt, ibmvfc_sync_completion, IBMVFC_CMD_FORMAT);
drivers/scsi/ibmvscsi/ibmvfc.c:		init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvfc.c:	timeout = wait_for_completion_timeout(&evt->comp, timeout);
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_prli_done - Completion handler for Process Login
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_plogi_done - Completion handler for Port Login
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_implicit_logout_done - Completion handler for Implicit Logout MAD
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_implicit_logout_and_del_done - Completion handler for Implicit Logout MAD
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_move_login_done - Completion handler for Move Login
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_adisc_done - Completion handler for ADISC
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_adisc_cancel_done - Completion handler when cancelling an ADISC
drivers/scsi/ibmvscsi/ibmvfc.c: * the ADISC completion handler. If the ADISC never actually comes
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_tgt_query_target_done - Completion handler for Query Target MAD
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_discover_targets_done - Completion handler for discover targets MAD
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_npiv_login_done - Completion handler for NPIV Login
drivers/scsi/ibmvscsi/ibmvfc.c: * ibmvfc_npiv_logout_done - Completion handler for NPIV Logout
drivers/scsi/ibmvscsi/ibmvfc.h:	struct completion comp;
drivers/scsi/ibmvscsi/ibmvfc.h:	struct completion *eh_comp;
drivers/scsi/ibmvscsi/ibmvscsi.c: * sync_completion: Signal that a synchronous command has completed
drivers/scsi/ibmvscsi/ibmvscsi.c: * the caller waiting on this completion shouldn't touch the evt_struct
drivers/scsi/ibmvscsi/ibmvscsi.c:static void sync_completion(struct srp_event_struct *evt_struct)
drivers/scsi/ibmvscsi/ibmvscsi.c:				  sync_completion,
drivers/scsi/ibmvscsi/ibmvscsi.c:		init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvscsi.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvscsi.c:				  sync_completion,
drivers/scsi/ibmvscsi/ibmvscsi.c:		init_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvscsi.c:	wait_for_completion(&evt->comp);
drivers/scsi/ibmvscsi/ibmvscsi.h:#include <linux/completion.h>
drivers/scsi/ibmvscsi/ibmvscsi.h:	struct completion comp;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:			wait_for_completion(&vscsi->wait_idle);
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	init_completion(&vscsi->wait_idle);
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	init_completion(&vscsi->unconfig);
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	wait_for_completion(&vscsi->unconfig);
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h:	struct completion wait_idle;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.h:	struct completion unconfig;
drivers/scsi/imm.c:static int imm_completion(struct scsi_cmnd *const cmd)
drivers/scsi/imm.c:			retv = imm_completion(cmd);
drivers/scsi/initio.c: *	be managed by the controller and we will get a completion (or
drivers/scsi/initio.c: *	be managed by the controller and we will get a completion (or
drivers/scsi/ipr.c: * timeout given. The done function is invoked on command completion.
drivers/scsi/ipr.c:		complete(&ipr_cmd->completion);
drivers/scsi/ipr.c: * ipr_send_blocking_cmd - Send command and sleep on its completion.
drivers/scsi/ipr.c:	init_completion(&ipr_cmd->completion);
drivers/scsi/ipr.c:	wait_for_completion(&ipr_cmd->completion);
drivers/scsi/ipr.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/ipr.c:			timeout = wait_for_completion_timeout(&comp, timeout);
drivers/scsi/ipr.c:	if (ipr_cmd->completion.done || ioa_cfg->in_reset_reload) {
drivers/scsi/ipr.c: * __ipr_erp_done - Process completion of ERP for a device
drivers/scsi/ipr.c: * ipr_erp_done - Process completion of ERP for a device
drivers/scsi/ipr.c: * ipr_ioa_bringdown_done - IOA bring down completion.
drivers/scsi/ipr.c: * This function processes the completion of an adapter bring down.
drivers/scsi/ipr.c: * ipr_ioa_reset_done - IOA reset completion.
drivers/scsi/ipr.c: * This function processes the completion of an adapter reset.
drivers/scsi/ipr.c: * ipr_reset_ucode_download_done - Microcode download completion
drivers/scsi/ipr.c: * If the caller needs to wait on the completion of the reset,
drivers/scsi/ipr.c: * If the caller needs to wait on the completion of the reset,
drivers/scsi/ipr.c: * If the caller needs to wait on the completion of the reset,
drivers/scsi/ipr.c: * ipr_halt_done - Shutdown prepare completion
drivers/scsi/ipr.h:#include <linux/completion.h>
drivers/scsi/ipr.h:	struct completion completion;
drivers/scsi/ipr.h:	struct completion *eh_comp;
drivers/scsi/ips.c:		for (i = 0; i < 120; i++) {	/*    Wait Up to 2 Min. for Completion */
drivers/scsi/ips.c:				 * acknowledge completion of the command
drivers/scsi/isci/host.c:#include "scu_completion_codes.h"
drivers/scsi/isci/host.c: * This macro will normalize the completion queue put pointer so its value can
drivers/scsi/isci/host.c:	((x) & SMU_COMPLETION_QUEUE_PUT_POINTER_MASK)
drivers/scsi/isci/host.c: * This macro will normalize the completion queue event entry so its value can
drivers/scsi/isci/host.c:		((x) & SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_MASK) \
drivers/scsi/isci/host.c:		>> SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_SHIFT	\
drivers/scsi/isci/host.c: * This macro will normalize the completion queue get pointer so its value can
drivers/scsi/isci/host.c:	((x) & SMU_COMPLETION_QUEUE_GET_POINTER_MASK)
drivers/scsi/isci/host.c: * This macro will normalize the completion queue cycle pointer so it matches
drivers/scsi/isci/host.c: * the completion queue cycle bit
drivers/scsi/isci/host.c:	((SMU_CQGR_CYCLE_BIT & (x)) << (31 - SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_SHIFT))
drivers/scsi/isci/host.c: * COMPLETION_QUEUE_CYCLE_BIT() -
drivers/scsi/isci/host.c: * This macro will return the cycle bit of the completion queue entry
drivers/scsi/isci/host.c:#define COMPLETION_QUEUE_CYCLE_BIT(x) ((x) & 0x80000000)
drivers/scsi/isci/host.c:static bool sci_controller_completion_queue_has_entries(struct isci_host *ihost)
drivers/scsi/isci/host.c:	u32 get_value = ihost->completion_queue_get;
drivers/scsi/isci/host.c:	u32 get_index = get_value & SMU_COMPLETION_QUEUE_GET_POINTER_MASK;
drivers/scsi/isci/host.c:	    COMPLETION_QUEUE_CYCLE_BIT(ihost->completion_queue[get_index]))
drivers/scsi/isci/host.c:	if (sci_controller_completion_queue_has_entries(ihost))
drivers/scsi/isci/host.c:	 * emptied the completion queue from a previous interrupt
drivers/scsi/isci/host.c:	writel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);
drivers/scsi/isci/host.c:	 * notified of an interrupt completion if we do not take this
drivers/scsi/isci/host.c:		tasklet_schedule(&ihost->completion_tasklet);
drivers/scsi/isci/host.c:	 * of an interrupt completion if we do not take this step.  We will mask
drivers/scsi/isci/host.c:static void sci_controller_task_completion(struct isci_host *ihost, u32 ent)
drivers/scsi/isci/host.c:	u32 index = SCU_GET_COMPLETION_INDEX(ent);
drivers/scsi/isci/host.c:		sci_io_request_tc_completion(ireq, ent);
drivers/scsi/isci/host.c:static void sci_controller_sdma_completion(struct isci_host *ihost, u32 ent)
drivers/scsi/isci/host.c:	index = SCU_GET_COMPLETION_INDEX(ent);
drivers/scsi/isci/host.c:		dev_warn(&ihost->pdev->dev, "%s: unknown completion type %x\n",
drivers/scsi/isci/host.c:		index = SCU_GET_COMPLETION_INDEX(ent);
drivers/scsi/isci/host.c:static void sci_controller_event_completion(struct isci_host *ihost, u32 ent)
drivers/scsi/isci/host.c:	index = SCU_GET_COMPLETION_INDEX(ent);
drivers/scsi/isci/host.c:static void sci_controller_process_completions(struct isci_host *ihost)
drivers/scsi/isci/host.c:	u32 completion_count = 0;
drivers/scsi/isci/host.c:		"%s: completion queue beginning get:0x%08x\n",
drivers/scsi/isci/host.c:		ihost->completion_queue_get);
drivers/scsi/isci/host.c:	/* Get the component parts of the completion queue */
drivers/scsi/isci/host.c:	get_index = NORMALIZE_GET_POINTER(ihost->completion_queue_get);
drivers/scsi/isci/host.c:	get_cycle = SMU_CQGR_CYCLE_BIT & ihost->completion_queue_get;
drivers/scsi/isci/host.c:	event_get = NORMALIZE_EVENT_POINTER(ihost->completion_queue_get);
drivers/scsi/isci/host.c:	event_cycle = SMU_CQGR_EVENT_CYCLE_BIT & ihost->completion_queue_get;
drivers/scsi/isci/host.c:		== COMPLETION_QUEUE_CYCLE_BIT(ihost->completion_queue[get_index])
drivers/scsi/isci/host.c:		completion_count++;
drivers/scsi/isci/host.c:		ent = ihost->completion_queue[get_index];
drivers/scsi/isci/host.c:		get_cycle ^= ((get_index+1) & SCU_MAX_COMPLETION_QUEUE_ENTRIES) <<
drivers/scsi/isci/host.c:			     (SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_SHIFT - SCU_MAX_COMPLETION_QUEUE_SHIFT);
drivers/scsi/isci/host.c:		get_index = (get_index+1) & (SCU_MAX_COMPLETION_QUEUE_ENTRIES-1);
drivers/scsi/isci/host.c:			"%s: completion queue entry:0x%08x\n",
drivers/scsi/isci/host.c:		switch (SCU_GET_COMPLETION_TYPE(ent)) {
drivers/scsi/isci/host.c:		case SCU_COMPLETION_TYPE_TASK:
drivers/scsi/isci/host.c:			sci_controller_task_completion(ihost, ent);
drivers/scsi/isci/host.c:		case SCU_COMPLETION_TYPE_SDMA:
drivers/scsi/isci/host.c:			sci_controller_sdma_completion(ihost, ent);
drivers/scsi/isci/host.c:		case SCU_COMPLETION_TYPE_UFI:
drivers/scsi/isci/host.c:		case SCU_COMPLETION_TYPE_EVENT:
drivers/scsi/isci/host.c:			sci_controller_event_completion(ihost, ent);
drivers/scsi/isci/host.c:		case SCU_COMPLETION_TYPE_NOTIFY: {
drivers/scsi/isci/host.c:				       (SMU_COMPLETION_QUEUE_GET_EVENT_CYCLE_BIT_SHIFT - SCU_MAX_EVENTS_SHIFT);
drivers/scsi/isci/host.c:			sci_controller_event_completion(ihost, ent);
drivers/scsi/isci/host.c:				 "completion type %x\n",
drivers/scsi/isci/host.c:	if (completion_count > 0) {
drivers/scsi/isci/host.c:		ihost->completion_queue_get =
drivers/scsi/isci/host.c:		writel(ihost->completion_queue_get,
drivers/scsi/isci/host.c:		       &ihost->smu_registers->completion_queue_get);
drivers/scsi/isci/host.c:		"%s: completion queue ending get:0x%08x\n",
drivers/scsi/isci/host.c:		ihost->completion_queue_get);
drivers/scsi/isci/host.c:	    sci_controller_completion_queue_has_entries(ihost)) {
drivers/scsi/isci/host.c:		sci_controller_process_completions(ihost);
drivers/scsi/isci/host.c:	/* If we dont process any completions I am not sure that we want to do this.
drivers/scsi/isci/host.c:		writel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);
drivers/scsi/isci/host.c:		tasklet_schedule(&ihost->completion_tasklet);
drivers/scsi/isci/host.c: * @completion_status: This parameter specifies the completion status from the
drivers/scsi/isci/host.c:static void isci_host_start_complete(struct isci_host *ihost, enum sci_status completion_status)
drivers/scsi/isci/host.c:	if (completion_status != SCI_SUCCESS)
drivers/scsi/isci/host.c:static void sci_controller_initialize_completion_queue(struct isci_host *ihost)
drivers/scsi/isci/host.c:	u32 completion_queue_control_value;
drivers/scsi/isci/host.c:	u32 completion_queue_get_value;
drivers/scsi/isci/host.c:	u32 completion_queue_put_value;
drivers/scsi/isci/host.c:	ihost->completion_queue_get = 0;
drivers/scsi/isci/host.c:	completion_queue_control_value =
drivers/scsi/isci/host.c:		(SMU_CQC_QUEUE_LIMIT_SET(SCU_MAX_COMPLETION_QUEUE_ENTRIES - 1) |
drivers/scsi/isci/host.c:	writel(completion_queue_control_value,
drivers/scsi/isci/host.c:	       &ihost->smu_registers->completion_queue_control);
drivers/scsi/isci/host.c:	/* Set the completion queue get pointer and enable the queue */
drivers/scsi/isci/host.c:	completion_queue_get_value = (
drivers/scsi/isci/host.c:	writel(completion_queue_get_value,
drivers/scsi/isci/host.c:	       &ihost->smu_registers->completion_queue_get);
drivers/scsi/isci/host.c:	/* Set the completion queue put pointer */
drivers/scsi/isci/host.c:	completion_queue_put_value = (
drivers/scsi/isci/host.c:	writel(completion_queue_put_value,
drivers/scsi/isci/host.c:	       &ihost->smu_registers->completion_queue_put);
drivers/scsi/isci/host.c:	/* Initialize the cycle bit of the completion queue entries */
drivers/scsi/isci/host.c:	for (index = 0; index < SCU_MAX_COMPLETION_QUEUE_ENTRIES; index++) {
drivers/scsi/isci/host.c:		 * If get.cycle_bit != completion_queue.cycle_bit
drivers/scsi/isci/host.c:		 * its not a valid completion queue entry
drivers/scsi/isci/host.c:		ihost->completion_queue[index] = 0x80000000;
drivers/scsi/isci/host.c:	/* Now initialize the completion queue */
drivers/scsi/isci/host.c:	sci_controller_initialize_completion_queue(ihost);
drivers/scsi/isci/host.c:static void sci_controller_completion_handler(struct isci_host *ihost)
drivers/scsi/isci/host.c:	/* Empty out the completion queue */
drivers/scsi/isci/host.c:	if (sci_controller_completion_queue_has_entries(ihost))
drivers/scsi/isci/host.c:		sci_controller_process_completions(ihost);
drivers/scsi/isci/host.c:	writel(SMU_ISR_COMPLETION, &ihost->smu_registers->interrupt_status);
drivers/scsi/isci/host.c:	/* Could we write the value of SMU_ISR_COMPLETION? */
drivers/scsi/isci/host.c: * isci_host_completion_routine() - This function is the delayed service
drivers/scsi/isci/host.c: *    routine that calls the sci core library's completion handler. It's
drivers/scsi/isci/host.c:void isci_host_completion_routine(unsigned long data)
drivers/scsi/isci/host.c:	sci_controller_completion_handler(ihost);
drivers/scsi/isci/host.c: *    completion.  The completion callback is called when the following
drivers/scsi/isci/host.c: *    out.  No IO completions for outstanding devices occur.  Outstanding IO
drivers/scsi/isci/host.c: * @coalesce_number: Used to control the number of entries in the Completion
drivers/scsi/isci/host.c:	writel(0x00000000, &ihost->smu_registers->completion_queue_get);
drivers/scsi/isci/host.c:	if (ihost->completion_queue)
drivers/scsi/isci/host.c:	size = SCU_MAX_COMPLETION_QUEUE_ENTRIES * sizeof(u32);
drivers/scsi/isci/host.c:	ihost->completion_queue = dmam_alloc_coherent(dev, size, &ihost->cq_dma,
drivers/scsi/isci/host.c:	if (!ihost->completion_queue)
drivers/scsi/isci/host.c:	writel(lower_32_bits(ihost->cq_dma), &ihost->smu_registers->completion_queue_lower);
drivers/scsi/isci/host.c:	writel(upper_32_bits(ihost->cq_dma), &ihost->smu_registers->completion_queue_upper);
drivers/scsi/isci/host.c: *    completion operations for an IO request.  After this method is invoked,
drivers/scsi/isci/host.h: * @completion_queue: hw-producer driver-consumer communication ring
drivers/scsi/isci/host.h: * @completion_queue_get: tracks the driver 'head' of the ring to notify hw
drivers/scsi/isci/host.h:	u32 *completion_queue;
drivers/scsi/isci/host.h:	u32 completion_queue_get;
drivers/scsi/isci/host.h:	struct tasklet_struct completion_tasklet;
drivers/scsi/isci/host.h:void isci_host_completion_routine(unsigned long data);
drivers/scsi/isci/init.c:	tasklet_init(&ihost->completion_tasklet,
drivers/scsi/isci/init.c:		     isci_host_completion_routine, (unsigned long)ihost);
drivers/scsi/isci/isci.h:#define SCU_MAX_COMPLETION_QUEUE_SCRATCH  (128)
drivers/scsi/isci/isci.h:#define SCU_MAX_COMPLETION_QUEUE_ENTRIES  (SCU_MAX_CRITICAL_NOTIFICATIONS \
drivers/scsi/isci/isci.h:					   + SCU_MAX_COMPLETION_QUEUE_SCRATCH)
drivers/scsi/isci/isci.h:#define SCU_MAX_COMPLETION_QUEUE_SHIFT	  (ilog2(SCU_MAX_COMPLETION_QUEUE_ENTRIES))
drivers/scsi/isci/isci.h:	BUILD_BUG_ON_NOT_POWER_OF_2(SCU_MAX_COMPLETION_QUEUE_ENTRIES);
drivers/scsi/isci/isci.h:	 * This member indicates successful completion.
drivers/scsi/isci/isci.h:	 *  target device (mode pages, inquiry data, etc.). The completion routine
drivers/scsi/isci/isci.h:	 * of the controller is in a state that prevents successful completion.
drivers/scsi/isci/isci.h: *    completion status values.  Each value in this enumeration maps directly
drivers/scsi/isci/isci.h: *    completion status values.  Each value in this enumeration maps directly
drivers/scsi/isci/phy.c:		/* Change state to the final state this substate machine has run to completion */
drivers/scsi/isci/phy.c:		/* Change state to the final state this substate machine has run to completion */
drivers/scsi/isci/phy.c:	 * instead of a SATA PHY. This is done because the completion queue had a SAS
drivers/scsi/isci/phy.c:	 * instead of a SAS PHY.  This is done because the completion queue had a SATA
drivers/scsi/isci/phy.c: *    all protocols upon completion of link training.
drivers/scsi/isci/phy.c:			 * the completion queue while waiting for power
drivers/scsi/isci/phy.c:	/* State machine has run to completion so exit out and change
drivers/scsi/isci/port.c: * @completion_status: This parameter specifies the core status for the reset
drivers/scsi/isci/port.c:					  enum sci_status completion_status)
drivers/scsi/isci/port.c:		"%s: isci_port = %p, completion_status=%x\n",
drivers/scsi/isci/port.c:		     __func__, isci_port, completion_status);
drivers/scsi/isci/port.c:	isci_port->hard_reset_status = completion_status;
drivers/scsi/isci/port.c:	if (completion_status != SCI_SUCCESS) {
drivers/scsi/isci/port.c:			"%s: iport = %p; hard reset completion\n",
drivers/scsi/isci/registers.h:#define SMU_INTERRUPT_STATUS_COMPLETION_SHIFT       (31)
drivers/scsi/isci/registers.h:#define SMU_INTERRUPT_STATUS_COMPLETION_MASK        (0x80000000)
drivers/scsi/isci/registers.h:#define SMU_ISR_COMPLETION    SMU_ISR_GEN_BIT(COMPLETION)
drivers/scsi/isci/registers.h:#define SMU_INTERRUPT_MASK_COMPLETION_SHIFT         (31)
drivers/scsi/isci/registers.h:#define SMU_INTERRUPT_MASK_COMPLETION_MASK          (0x80000000)
drivers/scsi/isci/registers.h:#define SMU_IMR_COMPLETION    SMU_IMR_GEN_BIT(COMPLETION)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_POINTER_SHIFT          (0)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_POINTER_MASK           (0x00003FFF)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_CYCLE_BIT_SHIFT        (15)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_CYCLE_BIT_MASK         (0x00008000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_EVENT_POINTER_SHIFT    (16)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_EVENT_POINTER_MASK     (0x03FF0000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_EVENT_CYCLE_BIT_SHIFT  (26)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_EVENT_CYCLE_BIT_MASK   (0x04000000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_PUT_RESERVED_MASK          (0xF8004000)
drivers/scsi/isci/registers.h:	SCU_GEN_VALUE(SMU_COMPLETION_QUEUE_PUT_ ## name, value)
drivers/scsi/isci/registers.h:	SCU_GEN_BIT(SMU_COMPLETION_QUEUE_PUT_ ## name)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_POINTER_SHIFT          (0)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_POINTER_MASK           (0x00003FFF)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_SHIFT        (15)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_CYCLE_BIT_MASK         (0x00008000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_SHIFT    (16)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_POINTER_MASK     (0x03FF0000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_CYCLE_BIT_SHIFT  (26)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_CYCLE_BIT_MASK   (0x04000000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_ENABLE_SHIFT           (30)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_ENABLE_MASK            (0x40000000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_ENABLE_SHIFT     (31)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_EVENT_ENABLE_MASK      (0x80000000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_GET_RESERVED_MASK          (0x38004000)
drivers/scsi/isci/registers.h:	SCU_GEN_VALUE(SMU_COMPLETION_QUEUE_GET_ ## name, value)
drivers/scsi/isci/registers.h:	SCU_GEN_BIT(SMU_COMPLETION_QUEUE_GET_ ## name)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_CONTROL_QUEUE_LIMIT_SHIFT  (0)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_CONTROL_QUEUE_LIMIT_MASK   (0x00003FFF)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_CONTROL_EVENT_LIMIT_SHIFT  (16)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_CONTROL_EVENT_LIMIT_MASK   (0x03FF0000)
drivers/scsi/isci/registers.h:#define SMU_COMPLETION_QUEUE_CONTROL_RESERVED_MASK      (0xFC00C000)
drivers/scsi/isci/registers.h:	SCU_GEN_VALUE(SMU_COMPLETION_QUEUE_CONTROL_ ## name, value)
drivers/scsi/isci/registers.h:#define SMU_CONTROL_STATUS_COMPLETION_BYTE_SWAP_ENABLE_SHIFT    (1)
drivers/scsi/isci/registers.h:#define SMU_CONTROL_STATUS_COMPLETION_BYTE_SWAP_ENABLE_MASK     (0x00000002)
drivers/scsi/isci/registers.h:	u32 completion_queue_lower;
drivers/scsi/isci/registers.h:	u32 completion_queue_upper;
drivers/scsi/isci/registers.h:	u32 completion_queue_put;
drivers/scsi/isci/registers.h:	u32 completion_queue_get;
drivers/scsi/isci/registers.h:	u32 completion_queue_control;
drivers/scsi/isci/registers.h:struct scu_completion_ram {
drivers/scsi/isci/registers.h:	struct scu_completion_ram cram;
drivers/scsi/isci/remote_device.c:		 * Since the RNC is ready, it's alright to finish completion
drivers/scsi/isci/remote_device.c:	/* Terminate and wait for the completions. */
drivers/scsi/isci/remote_node_context.h: * a TC completion where the remote node will be suspended by the hardware.
drivers/scsi/isci/request.c:#include "scu_completion_codes.h"
drivers/scsi/isci/request.c:		      "isci: request completion from wrong state (%s)\n",
drivers/scsi/isci/request.c:			       u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EARLY_RESP): {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_CHECK_RESPONSE): {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RESP_LEN_ERR):
drivers/scsi/isci/request.c:		 * guaranteed to be received before this completion status is
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_PERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_NAK_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_DATA_LEN_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LL_ABORT_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_XR_WD_LEN):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_MAX_PLD_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_RESP):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_SDBFIS):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDB_ERR):
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:					   SCU_COMPLETION_TL_STATUS_SHIFT;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:					   SCU_COMPLETION_TL_STATUS_SHIFT;
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_LF_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_WRONG_DESTINATION):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_1):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_2):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_RESERVED_ABANDON_3):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_BAD_DESTINATION):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_ZONE_VIOLATION):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_STP_RESOURCES_BUSY):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_PROTOCOL_NOT_SUPPORTED):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_OPEN_REJECT_CONNECTION_RATE_NOT_SUPPORTED):
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:				   SCU_COMPLETION_TL_STATUS_SHIFT;
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_NAK_CMD_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_XR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_XR_IU_LEN_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SDMA_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_OFFSET_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_EXCESS_DATA):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_LL_RX_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_DATA):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_OPEN_FAIL):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_VIIT_ENTRY_NV):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_IIT_ENTRY_NV):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_RNCNV_OUTBOUND):
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:				   SCU_COMPLETION_TL_STATUS_SHIFT;
drivers/scsi/isci/request.c:	/* In all cases we will treat this as the completion of the IO req. */
drivers/scsi/isci/request.c:				u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
drivers/scsi/isci/request.c:	case (SCU_TASK_DONE_TASK_ABORT << SCU_COMPLETION_TL_STATUS_SHIFT):
drivers/scsi/isci/request.c:		 * TODO: Should there be a state change for this completion?
drivers/scsi/isci/request.c:						       u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_ACK_NAK_TO):
drivers/scsi/isci/request.c:			 "%s: TaskRequest:0x%p CompletionCode:%x - "
drivers/scsi/isci/request.c:			 completion_code);
drivers/scsi/isci/request.c:		 * All other completion status cause the IO to be complete.
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:				    u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		/* In the AWAIT RESPONSE state, any TC completion is
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_RESP_TO_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_UFI_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_FRM_TYPE_ERR):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_SMP_LL_RX_ERR):
drivers/scsi/isci/request.c:		 * the connection and set TC completion with one of
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be complete.  If a NAK
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:			   u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:					u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:stp_request_pio_await_h2d_completion_tc_event(struct isci_request *ireq,
drivers/scsi/isci/request.c:					      u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:			      u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		 * All other completion status cause the IO to be complete.
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:						       u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_UNEXP_FIS):
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_REG_ERR):
drivers/scsi/isci/request.c:		 * completion.
drivers/scsi/isci/request.c:			/* If we have an error completion status for the
drivers/scsi/isci/request.c:	/* TODO Check to see if any of these completion status need to
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be complete. */
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:static enum sci_status atapi_raw_completion(struct isci_request *ireq, u32 completion_code,
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case SCU_MAKE_COMPLETION_STATUS(SCU_TASK_DONE_GOOD):
drivers/scsi/isci/request.c:		/* All other completion status cause the IO to be complete.
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:static enum sci_status atapi_data_tc_completion_handler(struct isci_request *ireq,
drivers/scsi/isci/request.c:							u32 completion_code)
drivers/scsi/isci/request.c:	switch (SCU_GET_COMPLETION_TL_STATUS(completion_code)) {
drivers/scsi/isci/request.c:	case (SCU_TASK_DONE_GOOD << SCU_COMPLETION_TL_STATUS_SHIFT):
drivers/scsi/isci/request.c:	case (SCU_TASK_DONE_UNEXP_FIS << SCU_COMPLETION_TL_STATUS_SHIFT): {
drivers/scsi/isci/request.c:	case (SCU_TASK_DONE_EXCESS_DATA << SCU_COMPLETION_TL_STATUS_SHIFT):
drivers/scsi/isci/request.c:static int sci_request_smp_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:	switch (completion_status) {
drivers/scsi/isci/request.c:static int sci_request_smp_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:static int sci_request_ssp_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:	switch (completion_status) {
drivers/scsi/isci/request.c:static int sci_request_ssp_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:static int sci_request_stpsata_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:	switch (completion_status) {
drivers/scsi/isci/request.c:static int sci_request_stpsata_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:	unsigned int completion_status)
drivers/scsi/isci/request.c:	switch (completion_status) {
drivers/scsi/isci/request.c:static void sci_request_handle_suspending_completions(
drivers/scsi/isci/request.c:	u32 completion_code)
drivers/scsi/isci/request.c:		is_tx = sci_request_smp_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:			completion_code);
drivers/scsi/isci/request.c:		is_tx_rx = sci_request_smp_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:			completion_code);
drivers/scsi/isci/request.c:		is_tx = sci_request_ssp_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:			completion_code);
drivers/scsi/isci/request.c:		is_tx_rx = sci_request_ssp_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:			completion_code);
drivers/scsi/isci/request.c:		is_tx = sci_request_stpsata_completion_status_is_tx_suspend(
drivers/scsi/isci/request.c:			completion_code);
drivers/scsi/isci/request.c:			sci_request_stpsata_completion_status_is_tx_rx_suspend(
drivers/scsi/isci/request.c:				completion_code);
drivers/scsi/isci/request.c:sci_io_request_tc_completion(struct isci_request *ireq,
drivers/scsi/isci/request.c:			     u32 completion_code)
drivers/scsi/isci/request.c:	/* Decode those completions that signal upcoming suspension events. */
drivers/scsi/isci/request.c:	sci_request_handle_suspending_completions(
drivers/scsi/isci/request.c:		ireq, SCU_GET_COMPLETION_TL_STATUS(completion_code));
drivers/scsi/isci/request.c:		return request_started_state_tc_event(ireq, completion_code);
drivers/scsi/isci/request.c:						       completion_code);
drivers/scsi/isci/request.c:							   completion_code);
drivers/scsi/isci/request.c:		return smp_request_await_tc_event(ireq, completion_code);
drivers/scsi/isci/request.c:						       completion_code);
drivers/scsi/isci/request.c:							       completion_code);
drivers/scsi/isci/request.c:		return stp_request_pio_await_h2d_completion_tc_event(ireq,
drivers/scsi/isci/request.c:								     completion_code);
drivers/scsi/isci/request.c:		return pio_data_out_tx_done_tc_event(ireq, completion_code);
drivers/scsi/isci/request.c:						       completion_code);
drivers/scsi/isci/request.c:		return atapi_raw_completion(ireq, completion_code,
drivers/scsi/isci/request.c:		return atapi_raw_completion(ireq, completion_code,
drivers/scsi/isci/request.c:		return atapi_data_tc_completion_handler(ireq, completion_code);
drivers/scsi/isci/request.c:			 __func__, completion_code, req_state_name(state));
drivers/scsi/isci/request.c: *    completion for OPEN_REJECT conditions.
drivers/scsi/isci/request.c: *    controller-specific I/O completion error conditions.
drivers/scsi/isci/request.c:	 * Note that there are SCU completion codes being
drivers/scsi/isci/request.c:	 * a controller-specific completion code; these are left
drivers/scsi/isci/request.c:	/* Note that the only open reject completion codes seen here will be
drivers/scsi/isci/request.c:					     enum sci_io_status completion_status)
drivers/scsi/isci/request.c:		"task->data_dir = %d completion_status = 0x%x\n",
drivers/scsi/isci/request.c:		__func__, request, task, task->data_dir, completion_status);
drivers/scsi/isci/request.c:	switch (completion_status) {
drivers/scsi/isci/request.c:		if (completion_status == SCI_IO_SUCCESS_IO_DONE_EARLY) {
drivers/scsi/isci/request.c:		/* This is a special case, in that the I/O completion
drivers/scsi/isci/request.c:			"%s: invalid completion code: 0x%x - "
drivers/scsi/isci/request.c:			__func__, completion_status, request);
drivers/scsi/isci/request.c:static void sci_stp_request_started_non_data_await_h2d_completion_enter(struct sci_base_state_machine *sm)
drivers/scsi/isci/request.c:static void sci_stp_request_started_pio_await_h2d_completion_enter(struct sci_base_state_machine *sm)
drivers/scsi/isci/request.c:		.enter_state = sci_stp_request_started_non_data_await_h2d_completion_enter,
drivers/scsi/isci/request.c:		.enter_state = sci_stp_request_started_pio_await_h2d_completion_enter,
drivers/scsi/isci/request.c: * SCI_SUCCESS on successfull completion, or specific failure code.
drivers/scsi/isci/request.c: * SCI_SUCCESS on successfull completion, or specific failure code.
drivers/scsi/isci/request.c:	ireq->io_request_completion = NULL;
drivers/scsi/isci/request.h:	/* Note: "io_request_completion" is completed in two different ways
drivers/scsi/isci/request.h:	 * - regular requests are completed in the request completion callback
drivers/scsi/isci/request.h:	 * XXX kill io_request_completion
drivers/scsi/isci/request.h:	struct completion *io_request_completion;
drivers/scsi/isci/request.h:	 * non-NULL the saved frame must be released on IO request completion.
drivers/scsi/isci/request.h: * waiting for the TC completion notification for the H2D Register FIS
drivers/scsi/isci/request.h: * waiting for the TC completion notification for the H2D Register FIS
drivers/scsi/isci/request.h: * after receiving TC completion. While in this state IO request object is
drivers/scsi/isci/request.h: * task context completion after every frame submission, so in the
drivers/scsi/isci/request.h: * non-accelerated case we need to expect the completion for the "cdb" frame.
drivers/scsi/isci/request.h: * @SCI_REQ_TASK_WAIT_TC_COMP: The AWAIT_TC_COMPLETION sub-state indicates that
drivers/scsi/isci/request.h: * @SCI_REQ_SMP_WAIT_TC_COMP: The AWAIT_TC_COMPLETION sub-state indicates that
drivers/scsi/isci/request.h:sci_io_request_tc_completion(struct isci_request *ireq, u32 code);
drivers/scsi/isci/scu_completion_codes.h:#ifndef _SCU_COMPLETION_CODES_HEADER_
drivers/scsi/isci/scu_completion_codes.h:#define _SCU_COMPLETION_CODES_HEADER_
drivers/scsi/isci/scu_completion_codes.h: * This file contains the constants and macros for the SCU hardware completion
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_SHIFT      28
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_MASK       0x70000000
drivers/scsi/isci/scu_completion_codes.h: * SCU_COMPLETION_TYPE() -
drivers/scsi/isci/scu_completion_codes.h: * This macro constructs an SCU completion type
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE(type) \
drivers/scsi/isci/scu_completion_codes.h:	((u32)(type) << SCU_COMPLETION_TYPE_SHIFT)
drivers/scsi/isci/scu_completion_codes.h: * SCU_COMPLETION_TYPE() -
drivers/scsi/isci/scu_completion_codes.h: * These macros contain the SCU completion types SCU_COMPLETION_TYPE
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_TASK       SCU_COMPLETION_TYPE(0)
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_SDMA       SCU_COMPLETION_TYPE(1)
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_UFI        SCU_COMPLETION_TYPE(2)
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_EVENT      SCU_COMPLETION_TYPE(3)
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TYPE_NOTIFY     SCU_COMPLETION_TYPE(4)
drivers/scsi/isci/scu_completion_codes.h: * an SCU completion code.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_STATUS_MASK       0x0FFC0000
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TL_STATUS_MASK    0x0FC00000
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_TL_STATUS_SHIFT   22
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_SDMA_STATUS_MASK  0x003C0000
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_PEG_MASK          0x00010000
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_PORT_MASK         0x00007000
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_PE_MASK           SCU_COMPLETION_PORT_MASK
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_PE_SHIFT          12
drivers/scsi/isci/scu_completion_codes.h:#define SCU_COMPLETION_INDEX_MASK        0x00000FFF
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_TYPE() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the SCU completion type.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_TYPE(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_TYPE_MASK)
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_STATUS() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the SCU completion status.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_STATUS(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_STATUS_MASK)
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_TL_STATUS() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the transport layer completion status.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_TL_STATUS(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_TL_STATUS_MASK)
drivers/scsi/isci/scu_completion_codes.h: * SCU_MAKE_COMPLETION_STATUS() -
drivers/scsi/isci/scu_completion_codes.h: * This macro takes a completion code and performs the shift and mask
drivers/scsi/isci/scu_completion_codes.h: * operations to turn it into a completion code that can be compared to a
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_TL_STATUS.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_MAKE_COMPLETION_STATUS(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((u32)(completion_code) << SCU_COMPLETION_TL_STATUS_SHIFT)
drivers/scsi/isci/scu_completion_codes.h: * SCU_NORMALIZE_COMPLETION_STATUS() -
drivers/scsi/isci/scu_completion_codes.h: * This macro takes a SCU_GET_COMPLETION_TL_STATUS and normalizes it for a
drivers/scsi/isci/scu_completion_codes.h:#define SCU_NORMALIZE_COMPLETION_STATUS(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:		((completion_code) & SCU_COMPLETION_TL_STATUS_MASK) \
drivers/scsi/isci/scu_completion_codes.h:		>> SCU_COMPLETION_TL_STATUS_SHIFT \
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_SDMA_STATUS() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the SDMA completion status.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_SDMA_STATUS(completion_code)	\
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_SDMA_STATUS_MASK)
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_PEG() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the Protocol Engine Group from the completion code.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_PEG(completion_code)	\
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_PEG_MASK)
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_PORT() -
drivers/scsi/isci/scu_completion_codes.h: * This macro reuturns the logical port index from the completion code.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_PORT(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_PORT_MASK)
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the PE index from the completion code.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_PROTOCOL_ENGINE_INDEX(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	(((completion_code) & SCU_COMPLETION_PE_MASK) >> SCU_COMPLETION_PE_SHIFT)
drivers/scsi/isci/scu_completion_codes.h: * SCU_GET_COMPLETION_INDEX() -
drivers/scsi/isci/scu_completion_codes.h: * This macro returns the index of the completion which is either a TCi or an
drivers/scsi/isci/scu_completion_codes.h: * RNi depending on the completion type.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_COMPLETION_INDEX(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_COMPLETION_INDEX_MASK)
drivers/scsi/isci/scu_completion_codes.h: * completion.
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_FRAME_INDEX(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:		((completion_code) & SCU_UNSOLICITED_FRAME_MASK) \
drivers/scsi/isci/scu_completion_codes.h:#define SCU_GET_FRAME_ERROR(completion_code) \
drivers/scsi/isci/scu_completion_codes.h:	((completion_code) & SCU_UNSOLICITED_FRAME_ERROR_MASK)
drivers/scsi/isci/scu_completion_codes.h: * These constants represent normalized completion codes which must be shifted
drivers/scsi/isci/scu_completion_codes.h: * 18 bits to match it with the hardware completion code. In a 16-bit compiler,
drivers/scsi/isci/scu_completion_codes.h:#endif /* _SCU_COMPLETION_CODES_HEADER_ */
drivers/scsi/isci/task.c:#include <linux/completion.h>
drivers/scsi/isci/task.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/isci/task.c:	/* Assign the pointer to the TMF's completion kernel wait structure. */
drivers/scsi/isci/task.c:	tmf->complete = &completion;
drivers/scsi/isci/task.c:	timeleft = wait_for_completion_timeout(&completion,
drivers/scsi/isci/task.c:	DECLARE_COMPLETION_ONSTACK(aborted_io_completion);
drivers/scsi/isci/task.c:	 * after completion in the core.
drivers/scsi/isci/task.c: * @completion_status: This parameter specifies the completion status from the
drivers/scsi/isci/task.c:			   enum sci_task_status completion_status)
drivers/scsi/isci/task.c:	struct completion *tmf_complete = NULL;
drivers/scsi/isci/task.c:		__func__, ireq, completion_status);
drivers/scsi/isci/task.c:		tmf->status = completion_status;
drivers/scsi/isci/task.h:	struct completion *complete;
drivers/scsi/isci/task.h:	enum sci_task_status completion_status);
drivers/scsi/libfc/fc_disc.c: * @event: The discovery completion status
drivers/scsi/libfc/fc_exch.c: *	ULP completion.
drivers/scsi/libfc/fc_exch.c: *	RX-inferred completion.
drivers/scsi/libfc/fc_exch.c:	 * We must check for completion in case there are two threads
drivers/scsi/libfc/fc_fcp.c: * callers to call the completion function while the lock is held and
drivers/scsi/libfc/fc_fcp.c:	 * and completes the transfer, call the completion handler.
drivers/scsi/libfc/fc_fcp.c:	 * call I/O completion if we do not have a SCSI command.
drivers/scsi/libfc/fc_fcp.c:	 * decided to force completion.
drivers/scsi/libfc/fc_fcp.c: * Called to send an abort and then wait for abort completion
drivers/scsi/libfc/fc_fcp.c:	init_completion(&fsp->tm_done);
drivers/scsi/libfc/fc_fcp.c:	ticks_left = wait_for_completion_timeout(&fsp->tm_done,
drivers/scsi/libfc/fc_fcp.c:	init_completion(&fsp->tm_done);
drivers/scsi/libfc/fc_fcp.c:	 * wait for completion of reset
drivers/scsi/libfc/fc_fcp.c:	rc = wait_for_completion_timeout(&fsp->tm_done, FC_SCSI_TM_TOV);
drivers/scsi/libfc/fc_rport.c: * fc_rport_login_complete() - Handle parameters and completion of p-mp login.
drivers/scsi/libiscsi.c:			 * state is bad, allowing completion to happen
drivers/scsi/libiscsi.c:		 * for the completion path to finish freeing the cmd.
drivers/scsi/libiscsi.c:		 * Raced with completion. Blk layer has taken ownership
drivers/scsi/libiscsi.c:		 * Racing with the completion path right now, so give it more
drivers/scsi/libiscsi.c:		 * Instead, handle cmd, allow completion to happen and let
drivers/scsi/libiscsi.c:completion_check:
drivers/scsi/libiscsi.c:		goto completion_check;
drivers/scsi/libiscsi.c: * for the completion.
drivers/scsi/libiscsi_tcp.c:	 * lib iscsi will update this in the completion handling if there
drivers/scsi/libsas/sas_ata.c:static enum ata_completion_errors sas_to_ata_err(struct task_status_struct *ts)
drivers/scsi/libsas/sas_ata.c:	enum ata_completion_errors ac;
drivers/scsi/libsas/sas_ata.c:	struct completion *waiting;
drivers/scsi/libsas/sas_expander.c:		wait_for_completion(&task->slow_task->completion);
drivers/scsi/libsas/sas_init.c:	init_completion(&slow->completion);
drivers/scsi/libsas/sas_scsi_host.c:	 * any completions from the LLD.  Task is freed after this.
drivers/scsi/libsas/sas_scsi_host.c:	/* clean out any commands that won the completion vs eh race */
drivers/scsi/libsas/sas_scsi_host.c:	 * complete via the normal sas_task completion mechanism),
drivers/scsi/libsas/sas_scsi_host.c:	 * SAS_HA_FROZEN gives eh dominion over all sas_task completion.
drivers/scsi/libsas/sas_scsi_host.c:	complete(&task->slow_task->completion);
drivers/scsi/libsas/sas_scsi_host.c:		complete(&task->slow_task->completion);
drivers/scsi/libsas/sas_scsi_host.c:		wait_for_completion(&task->slow_task->completion);
drivers/scsi/libsas/sas_scsi_host.c:		wait_for_completion(&task->slow_task->completion);
drivers/scsi/lpfc/lpfc.h:	struct completion *fw_dump_cmpl; /* cmpl event tracker for fw_dump */
drivers/scsi/lpfc/lpfc.h:	unsigned long last_completion_time;
drivers/scsi/lpfc/lpfc_attr.c:	struct completion online_compl;
drivers/scsi/lpfc/lpfc_attr.c:	init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	wait_for_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	wait_for_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	struct completion online_compl;
drivers/scsi/lpfc/lpfc_attr.c:	init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	wait_for_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	struct completion online_compl;
drivers/scsi/lpfc/lpfc_attr.c:		init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:		wait_for_completion(phba->fw_dump_cmpl);
drivers/scsi/lpfc/lpfc_attr.c:		init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:		wait_for_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:	struct completion online_compl;
drivers/scsi/lpfc/lpfc_attr.c:	init_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c:		wait_for_completion(&online_compl);
drivers/scsi/lpfc/lpfc_attr.c: * lpfc_fcp_wait_abts_rsp: Modifies criteria for reporting completion of
drivers/scsi/lpfc/lpfc_attr.c:LPFC_ATTR_R(fcp_wait_abts_rsp, 0, 0, 1, "Wait for FCP ABTS completion");
drivers/scsi/lpfc/lpfc_attr.c: * lpfc_cq_poll_threshold: Set the threshold of CQE completions in a
drivers/scsi/lpfc/lpfc_attr.c: *   single handler call which should request a polled completion rather
drivers/scsi/lpfc/lpfc_attr.c:# lpfc_max_scsicmpl_time: Use scsi command completion time to control I/O queue
drivers/scsi/lpfc/lpfc_attr.c:# SCSI command completion time is not used for controlling I/O queue depth. When
drivers/scsi/lpfc/lpfc_attr.c:# to limit the I/O completion time to the parameter value.
drivers/scsi/lpfc/lpfc_attr.c:	"Use command completion time to control queue depth");
drivers/scsi/lpfc/lpfc_attr.c:LPFC_ATTR_RW(cr_count, 1, 1, 255, "A count of I/O completions after which an "
drivers/scsi/lpfc/lpfc_attr.c: * Driver always delay Nport discovery for subsequent FLOGI/FDISC completion
drivers/scsi/lpfc/lpfc_bsg.c: * lpfc_bsg_send_mgmt_cmd_cmp - lpfc_bsg_send_mgmt_cmd's completion handler
drivers/scsi/lpfc/lpfc_bsg.c: * This function is the completion handler for iocbs issued using
drivers/scsi/lpfc/lpfc_bsg.c: * sleeps for the iocb completion.
drivers/scsi/lpfc/lpfc_bsg.c: * lpfc_bsg_rport_els_cmp - lpfc_bsg_rport_els's completion handler
drivers/scsi/lpfc/lpfc_bsg.c: * This function is the completion handler for iocbs issued using
drivers/scsi/lpfc/lpfc_bsg.c: * sleeps for the iocb completion.
drivers/scsi/lpfc/lpfc_bsg.c: * lpfc_issue_ct_rsp_cmp - lpfc_issue_ct_rsp's completion handler
drivers/scsi/lpfc/lpfc_bsg.c: * This function is the completion handler for iocbs issued using
drivers/scsi/lpfc/lpfc_bsg.c: * sleeps for the iocb completion.
drivers/scsi/lpfc/lpfc_bsg.c: * lpfc_bsg_issue_mbox_cmpl - lpfc_bsg_issue_mbox mbox completion handler
drivers/scsi/lpfc/lpfc_bsg.c: * This is completion handler function for mailbox commands issued from
drivers/scsi/lpfc/lpfc_bsg.c: * This is routine handles BSG job for mailbox commands completions with
drivers/scsi/lpfc/lpfc_bsg.c: * This is completion handler function for mailbox read commands with multiple
drivers/scsi/lpfc/lpfc_bsg.c: * This is completion handler function for mailbox write commands with multiple
drivers/scsi/lpfc/lpfc_bsg.c: * let our completion handler finish the command.
drivers/scsi/lpfc/lpfc_bsg.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_bsg.c:	 * so the timeout is retried.  This avoids double completion issues
drivers/scsi/lpfc/lpfc_bsg.c:	 * command's completion handler executes.  Otherwise, prevent the
drivers/scsi/lpfc/lpfc_bsg.c:	 * command's completion handler from executing the job done callback
drivers/scsi/lpfc/lpfc_bsg.c:				list_move_tail(&check_iocb->list, &completions);
drivers/scsi/lpfc/lpfc_bsg.c:		if (list_empty(&completions))
drivers/scsi/lpfc/lpfc_bsg.c:		if (!list_empty(&completions)) {
drivers/scsi/lpfc/lpfc_bsg.c:			lpfc_sli_cancel_iocbs(phba, &completions,
drivers/scsi/lpfc/lpfc_ct.c: * lpfc_ct_unsol_cmpl : Completion callback function for unsol ct commands
drivers/scsi/lpfc/lpfc_ct.c:	/* Save for completion so we can release these resources */
drivers/scsi/lpfc/lpfc_ct.c: * @cmpl: completion routine to call when command completes
drivers/scsi/lpfc/lpfc_ct.c:	/* Save for completion so we can release these resources */
drivers/scsi/lpfc/lpfc_ct.c: * @cmpl: completion routine to call when command completes
drivers/scsi/lpfc/lpfc_ct.c: * lpfc_cmpl_ct_disc_fdmi - Handle a discovery FDMI completion
drivers/scsi/lpfc/lpfc_ct.c: * This function to handle the completion of a driver initiated FDMI
drivers/scsi/lpfc/lpfc_debugfs.h: * This function dumps all entries from a FCP or NVME completion queue
drivers/scsi/lpfc/lpfc_disc.h: * state changed to PRLI_ISSUE. When the PRLI completion occurs, the state is
drivers/scsi/lpfc/lpfc_disc.h: * changed to PRLI_COMPL. If the completion indicates a mapped
drivers/scsi/lpfc/lpfc_disc.h: * ADISC is initited for each one.  Completions / Events for each node are
drivers/scsi/lpfc/lpfc_disc.h: * Completions / Events for each node are funnelled thru the state machine.  As
drivers/scsi/lpfc/lpfc_disc.h: * handling. Upon completion, ALL nodes should be on either the mapped or
drivers/scsi/lpfc/lpfc_els.c: * This routine is called from FLOGI/FDISC completion handler functions.
drivers/scsi/lpfc/lpfc_els.c: * node nodename is changed in the completion service parameter else return
drivers/scsi/lpfc/lpfc_els.c: * NP_Port discovery after the FLOGI/FDISC completion if Clean address bit
drivers/scsi/lpfc/lpfc_els.c: * node nodename is changed in the completion service parameter.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_flogi_fabric - Completion function for flogi to a fabric port
drivers/scsi/lpfc/lpfc_els.c: * This routine is invoked by the lpfc_cmpl_els_flogi() completion callback
drivers/scsi/lpfc/lpfc_els.c: * function to handle the completion of a Fabric Login (FLOGI) into a fabric
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_flogi_nport - Completion function for flogi to an N_Port
drivers/scsi/lpfc/lpfc_els.c: * This routine is invoked by the lpfc_cmpl_els_flogi() completion callback
drivers/scsi/lpfc/lpfc_els.c: * function to handle the completion of a Fabric Login (FLOGI) into an N_Port
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_flogi - Completion callback function for flogi
drivers/scsi/lpfc/lpfc_els.c: * This routine is the top-level completion callback function for issuing
drivers/scsi/lpfc/lpfc_els.c: * specific topology completion conditions.
drivers/scsi/lpfc/lpfc_els.c:		 * already progressed, and this completion can be ignored.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_link_down - Completion callback function for ELS command
drivers/scsi/lpfc/lpfc_els.c: * to lpfc_cmpl_els_flogi() routine is put to the IOCB completion callback
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the FLOGI ELS command.
drivers/scsi/lpfc/lpfc_els.c:	/* Avoid race with FLOGI completion and hba_flags. */
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_rrq - Completion handled for els RRQs.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_plogi - Completion callback function for plogi
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for issuing the Port
drivers/scsi/lpfc/lpfc_els.c: * Login (PLOGI) command. For PLOGI completion, there must be an active
drivers/scsi/lpfc/lpfc_els.c: * (DSM) is set for this PLOGI completion. Finally, it checks whether
drivers/scsi/lpfc/lpfc_els.c: * of the IOCB for the completion callback function to the PLOGI ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_prli - Completion callback function for prli
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for a Process Login
drivers/scsi/lpfc/lpfc_els.c: * ndlp to mark the PRLI completion.
drivers/scsi/lpfc/lpfc_els.c: * is put to the IOCB completion callback func field before invoking the
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the PRLI ELS command.
drivers/scsi/lpfc/lpfc_els.c:		 * succeeded or failed because the ADISC completion
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_adisc - Completion callback function for adisc
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion function for issuing the Address Discover
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the ADISC ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_logo - Completion callback function for logo
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion function for issuing the ELS Logout (LOGO)
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the LOGO ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_cmd - Completion callback function for generic els command
drivers/scsi/lpfc/lpfc_els.c: * This routine is a generic completion callback function for ELS commands.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_disc_cmd - Completion callback function for Discovery ELS cmd
drivers/scsi/lpfc/lpfc_els.c: * This routine is a generic completion callback function for Discovery ELS cmd.
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the SCR ELS command.
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the RSCN ELS command.
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the FARPR ELS command.
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the RDF ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_edc - Completion callback function for EDC
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for issuing the Exchange
drivers/scsi/lpfc/lpfc_els.c:	 * the completion we settle on the higher frequency.
drivers/scsi/lpfc/lpfc_els.c: * IOCB completion callback function. If LPFC_DELAY_MEM_FREE flag is not
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_logo_acc - Completion callback function to logo acc response
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function to the Logout (LOGO)
drivers/scsi/lpfc/lpfc_els.c: * the completion of the LOGO process. If the node has transitioned to NPR,
drivers/scsi/lpfc/lpfc_els.c: * lpfc_mbx_cmpl_dflt_rpi - Completion callbk func for unreg dflt rpi mbox cmd
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for unregister default
drivers/scsi/lpfc/lpfc_els.c: * decrements the ndlp reference count held for this completion callback
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_rsp - Completion callback function for els response iocb cmd
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for ELS Response IOCB
drivers/scsi/lpfc/lpfc_els.c: * field of the IOCB for the completion callback function to issue the
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the corresponding
drivers/scsi/lpfc/lpfc_els.c: * context_un.mbox field of the IOCB for the completion callback function
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the reject response
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the ADISC Accept response
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the PRLI Accept response
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function.
drivers/scsi/lpfc/lpfc_els.c:	/* save address for completion */
drivers/scsi/lpfc/lpfc_els.c: *   1 - Sent the acc response and waited for name server completion
drivers/scsi/lpfc/lpfc_els.c: * lpfc_els_rsp_rls_acc - Completion callbk func for MBX_READ_LNK_STAT mbox cmd
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function for the MBX_READ_LNK_STAT
drivers/scsi/lpfc/lpfc_els.c: * collects the link statistics from the completion of the MBX_READ_LNK_STAT
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the RLS Accept Response
drivers/scsi/lpfc/lpfc_els.c:			/* Mbox completion will send ELS Response */
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the RTV Accept Response
drivers/scsi/lpfc/lpfc_els.c: * successful, the completion handler will clear the RRQ.
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the RPL Accept Response
drivers/scsi/lpfc/lpfc_els.c: * the IOCBs with a non-NULL completion callback function, the callback
drivers/scsi/lpfc/lpfc_els.c: * un.ulpWord[4] set to IOERR_SLI_ABORTED. For IOCBs with a NULL completion
drivers/scsi/lpfc/lpfc_els.c: * the ELS transmit completion queue to issue an abort IOCB to any transmit
drivers/scsi/lpfc/lpfc_els.c: * completion queue IOCB that is associated with the @vport and is not
drivers/scsi/lpfc/lpfc_els.c: * abort IOCB to any transmit completion queueed IOCB, it does not guarantee
drivers/scsi/lpfc/lpfc_els.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_els.c: * the IOCBs with the completion callback function associated, the callback
drivers/scsi/lpfc/lpfc_els.c: * un.ulpWord[4] set to IOERR_SLI_ABORTED. For IOCBs without the completion
drivers/scsi/lpfc/lpfc_els.c: * it walks the ELS transmit completion queue to issue an abort IOCB to any
drivers/scsi/lpfc/lpfc_els.c: * transmit completion queue IOCB that is not an IOCB from libdfc (i.e., the
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_reg_new_vport - Completion callback function to register new vport
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function to register new vport
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_fdisc - Completion function for fdisc iocb command
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function to a Fabric Discover
drivers/scsi/lpfc/lpfc_els.c: * single threaded, each FDISC completion callback function will reset
drivers/scsi/lpfc/lpfc_els.c: * assigned to the vport has been changed with the completion of the FDISC
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the FDISC ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_els_npiv_logo - Completion function with vport logo
drivers/scsi/lpfc/lpfc_els.c: * This routine is the completion callback function to the issuing of a LOGO
drivers/scsi/lpfc/lpfc_els.c: * reference count held on ndlp for this completion function, indicating that
drivers/scsi/lpfc/lpfc_els.c: * the IOCB for the completion callback function to the LOGO ELS command.
drivers/scsi/lpfc/lpfc_els.c: * lpfc_cmpl_fabric_iocb - Completion callback function for fabric iocb
drivers/scsi/lpfc/lpfc_els.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_els.c:		list_move_tail(&piocb->list, &completions);
drivers/scsi/lpfc/lpfc_els.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_els.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_els.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_els.c:			list_move_tail(&piocb->list, &completions);
drivers/scsi/lpfc/lpfc_els.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_els.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_els.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_els.c:	list_splice_init(&phba->fabric_iocb_list, &completions);
drivers/scsi/lpfc/lpfc_els.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_els.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_hbadisc.c:			complete((struct completion *)(evtp->evt_arg2));
drivers/scsi/lpfc/lpfc_hbadisc.c:			complete((struct completion *)(evtp->evt_arg2));
drivers/scsi/lpfc/lpfc_hbadisc.c:			complete((struct completion *)(evtp->evt_arg2));
drivers/scsi/lpfc/lpfc_hbadisc.c:			complete((struct completion *)(evtp->evt_arg2));
drivers/scsi/lpfc/lpfc_hbadisc.c:			complete((struct completion *)(evtp->evt_arg2));
drivers/scsi/lpfc/lpfc_hbadisc.c:	 * All Mailbox completions and LPFC_ELS_RING rcv ring IOCB events will
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c:	/* Mark successful completion of FCF table scan */
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_mbx_cmpl_read_fcf_rec - read fcf completion handler.
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_init_vfi_cmpl - Completion handler for init_vfi mbox command.
drivers/scsi/lpfc/lpfc_hbadisc.c: * This function handles completion of init vfi mailbox command.
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_init_vpi_cmpl - Completion handler for init_vpi mbox command.
drivers/scsi/lpfc/lpfc_hbadisc.c: * This function handles completion of init vpi mailbox command.
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is handed off to the SLI layer.
drivers/scsi/lpfc/lpfc_hbadisc.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_hbadisc.c:			lpfc_sli3_dequeue_nport_iocbs(phba, ndlp, &completions);
drivers/scsi/lpfc/lpfc_hbadisc.c:			lpfc_sli4_dequeue_nport_iocbs(phba, ndlp, &completions);
drivers/scsi/lpfc/lpfc_hbadisc.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_hbadisc.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_nlp_logo_unreg - Unreg mailbox completion handler before LOGO
drivers/scsi/lpfc/lpfc_hbadisc.c: * Sets the mailbox completion handler to be used for the
drivers/scsi/lpfc/lpfc_hbadisc.c:	/* Cleanup REG_LOGIN completions which are not yet processed */
drivers/scsi/lpfc/lpfc_hbadisc.c: *  Ignore completion for all IOCBs on tx and txcmpl queue for ELS
drivers/scsi/lpfc/lpfc_hbadisc.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_hbadisc.c:			list_move_tail(&iocb->list, &completions);
drivers/scsi/lpfc/lpfc_hbadisc.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_hbadisc.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_hbadisc.c:					 "completion error\n");
drivers/scsi/lpfc/lpfc_hbadisc.c: * command upon completion. It is setup in the LPFC_MBOXQ
drivers/scsi/lpfc/lpfc_hbadisc.c: * as the completion routine when the command is
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_unregister_vfi_cmpl - Completion handler for unreg vfi.
drivers/scsi/lpfc/lpfc_hbadisc.c: * lpfc_unregister_fcfi_cmpl - Completion handler for unreg fcfi.
drivers/scsi/lpfc/lpfc_hbadisc.c: * @ulp_status: IO completion status.
drivers/scsi/lpfc/lpfc_hw4.h:/* completion queue entry structure (common fields for all cqe types) */
drivers/scsi/lpfc/lpfc_hw4.h:/* Completion Queue Entry Status Codes */
drivers/scsi/lpfc/lpfc_hw4.h:/* Completion Queue Entry Codes */
drivers/scsi/lpfc/lpfc_hw4.h:/* completion queue entry for wqe completions */
drivers/scsi/lpfc/lpfc_hw4.h:/* completion queue entry for wqe release */
drivers/scsi/lpfc/lpfc_hw4.h:/* completion queue entry structure for rqe completion */
drivers/scsi/lpfc/lpfc_hw4.h:#define LPFC_QUEUE_TYPE_COMPLETION	0
drivers/scsi/lpfc/lpfc_hw4.h:/* Mailbox Completion Queue Error Messages */
drivers/scsi/lpfc/lpfc_hw4.h: * of a payload area of 256 bytes and a completion queue of length
drivers/scsi/lpfc/lpfc_init.c: * lpfc_config_async_cmpl - Completion handler for config async event mbox cmd
drivers/scsi/lpfc/lpfc_init.c: * This is the completion handler for driver's configuring asynchronous event
drivers/scsi/lpfc/lpfc_init.c: * lpfc_dump_wakeup_param_cmpl - dump memory mailbox command completion handler
drivers/scsi/lpfc/lpfc_init.c: * This is the completion handler for dump mailbox command for getting
drivers/scsi/lpfc/lpfc_init.c:	phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_init.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_init.c:			list_splice_init(&pring->txcmplq, &completions);
drivers/scsi/lpfc/lpfc_init.c:		/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_init.c:		lpfc_sli_cancel_iocbs(phba, &completions,
drivers/scsi/lpfc/lpfc_init.c:		list_splice_init(&pring->txcmplq, &completions);
drivers/scsi/lpfc/lpfc_init.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_init.c:	lpfc_sli_cancel_iocbs(phba, &completions,
drivers/scsi/lpfc/lpfc_init.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_init.c:		list_splice_init(&phba->elsbuf, &completions);
drivers/scsi/lpfc/lpfc_init.c:		while (!list_empty(&completions)) {
drivers/scsi/lpfc/lpfc_init.c:			list_remove_head(&completions, buf_ptr,
drivers/scsi/lpfc/lpfc_init.c:		if (time_after(phba->last_completion_time +
drivers/scsi/lpfc/lpfc_init.c:					 - phba->last_completion_time));
drivers/scsi/lpfc/lpfc_init.c:			} else if (time_before_eq(phba->last_completion_time,
drivers/scsi/lpfc/lpfc_init.c:					"2857 Last completion time not "
drivers/scsi/lpfc/lpfc_init.c:						 - phba->last_completion_time));
drivers/scsi/lpfc/lpfc_init.c: * @acqe_link: pointer to the async link completion queue entry.
drivers/scsi/lpfc/lpfc_init.c: * @acqe_link: pointer to the async link completion queue entry.
drivers/scsi/lpfc/lpfc_init.c: * @acqe_link: pointer to the async link completion queue entry.
drivers/scsi/lpfc/lpfc_init.c:	 * the READ_TOPOLOGY completion routine to continue without actually
drivers/scsi/lpfc/lpfc_init.c:	/* Initialize completion status */
drivers/scsi/lpfc/lpfc_init.c: * interval to the current point in time. It is called from IO completion
drivers/scsi/lpfc/lpfc_init.c: * @acqe_fc: pointer to the async fc completion queue entry.
drivers/scsi/lpfc/lpfc_init.c:		/* Initialize completion status */
drivers/scsi/lpfc/lpfc_init.c: * @acqe_sli: pointer to the async SLI completion queue entry.
drivers/scsi/lpfc/lpfc_init.c: * @acqe_fip: pointer to the async fcoe completion queue entry.
drivers/scsi/lpfc/lpfc_init.c: * @acqe_dcbx: pointer to the async dcbx completion queue entry.
drivers/scsi/lpfc/lpfc_init.c: * @acqe_grp5: pointer to the async grp5 completion queue entry.
drivers/scsi/lpfc/lpfc_init.c:		/* Free the completion event processed to the free pool */
drivers/scsi/lpfc/lpfc_init.c: * rediscovery pending completion event.
drivers/scsi/lpfc/lpfc_init.c:	/* Free the completion queue EQ event pool */
drivers/scsi/lpfc/lpfc_init.c:	 * Create Slow Path Completion Queues (CQs)
drivers/scsi/lpfc/lpfc_init.c: * lpfc_sli4_cq_event_pool_create - Create completion-queue event free pool
drivers/scsi/lpfc/lpfc_init.c: * This routine is invoked to allocate and set up a pool of completion queue
drivers/scsi/lpfc/lpfc_init.c: * events. The body of the completion queue event is a completion queue entry
drivers/scsi/lpfc/lpfc_init.c: * the following HBA completion queue events for the worker thread to process:
drivers/scsi/lpfc/lpfc_init.c: *   - Receive queue completion unsolicited events
drivers/scsi/lpfc/lpfc_init.c: * lpfc_sli4_cq_event_pool_destroy - Free completion-queue event free pool
drivers/scsi/lpfc/lpfc_init.c: * This routine is invoked to free the pool of completion queue events at
drivers/scsi/lpfc/lpfc_init.c: * cleanup routine to free all the outstanding completion-queue events
drivers/scsi/lpfc/lpfc_init.c: * __lpfc_sli4_cq_event_alloc - Allocate a completion-queue event from free pool
drivers/scsi/lpfc/lpfc_init.c: * completion-queue event from the free pool.
drivers/scsi/lpfc/lpfc_init.c: * Return: Pointer to the newly allocated completion-queue event if successful
drivers/scsi/lpfc/lpfc_init.c: * lpfc_sli4_cq_event_alloc - Allocate a completion-queue event from free pool
drivers/scsi/lpfc/lpfc_init.c: * completion-queue event from the free pool.
drivers/scsi/lpfc/lpfc_init.c: * Return: Pointer to the newly allocated completion-queue event if successful
drivers/scsi/lpfc/lpfc_init.c: * __lpfc_sli4_cq_event_release - Release a completion-queue event to free pool
drivers/scsi/lpfc/lpfc_init.c: * @cq_event: pointer to the completion queue event to be freed.
drivers/scsi/lpfc/lpfc_init.c: * completion-queue event back into the free pool.
drivers/scsi/lpfc/lpfc_init.c: * lpfc_sli4_cq_event_release - Release a completion-queue event to free pool
drivers/scsi/lpfc/lpfc_init.c: * @cq_event: pointer to the completion queue event to be freed.
drivers/scsi/lpfc/lpfc_init.c: * completion-queue event back into the free pool.
drivers/scsi/lpfc/lpfc_init.c: * This routine is to free all the pending completion-queue events to the
drivers/scsi/lpfc/lpfc_init.c: * This function is called in the SLI4 code path to wait for completion
drivers/scsi/lpfc/lpfc_init.c:		/* Wait for completion of device XRI exchange busy */
drivers/scsi/lpfc/lpfc_init.c: * for the completion.  The expectation is that this routine is called
drivers/scsi/lpfc/lpfc_mbox.c: * form of mailbox command to the HBA. The timely completion of the heart
drivers/scsi/lpfc/lpfc_mbox.c:	/* Save address for later completion and set the owner to host so that
drivers/scsi/lpfc/lpfc_mbox.c:	/* Mailbox command that have a completion handler must also have a
drivers/scsi/lpfc/lpfc_mbox.c:	/* Save the dma buffer for cleanup in the final completion. */
drivers/scsi/lpfc/lpfc_mbox.c:	/* save address for completion */
drivers/scsi/lpfc/lpfc_nportdisc.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_nportdisc.c:			/* The default completion handling for CONFIG_LINK
drivers/scsi/lpfc/lpfc_nportdisc.c: * lpfc_mbx_cmpl_resume_rpi - Resume RPI completion routine
drivers/scsi/lpfc/lpfc_nportdisc.c: * This routine is invoked to issue a completion to a rcv'ed
drivers/scsi/lpfc/lpfc_nportdisc.c: * state changed to PRLI_ISSUE. When the PRLI completion occurs, the state is
drivers/scsi/lpfc/lpfc_nportdisc.c: * changed to UNMAPPED_NODE. If the completion indicates a mapped
drivers/scsi/lpfc/lpfc_nportdisc.c: * ADISC is initited for each one.  Completions / Events for each node are
drivers/scsi/lpfc/lpfc_nportdisc.c: * Completions / Events for each node are funnelled thru the state machine.  As
drivers/scsi/lpfc/lpfc_nportdisc.c: * handling. Upon completion, ALL nodes should be on either the mapped or
drivers/scsi/lpfc/lpfc_nvme.c: * __lpfc_nvme_ls_req_cmp - Generic completion handler for a NVME
drivers/scsi/lpfc/lpfc_nvme.c: * This function is the generic completion handler for NVME LS requests.
drivers/scsi/lpfc/lpfc_nvme.c:	/* Save for completion so we can release these resources */
drivers/scsi/lpfc/lpfc_nvme.c: * @gen_req_cmp: Completion call-back
drivers/scsi/lpfc/lpfc_nvme.c:				 "release, skip completion\n");
drivers/scsi/lpfc/lpfc_nvme.c:					 "6081 NVME Completion Protocol Error: "
drivers/scsi/lpfc/lpfc_nvme.c:					 "6072 NVME Completion Error: xri %x "
drivers/scsi/lpfc/lpfc_nvme.c:	/* NVME targets need completion held off until the abort exchange
drivers/scsi/lpfc/lpfc_nvme.c:	/* Guard against IO completion being called at same time */
drivers/scsi/lpfc/lpfc_nvme.c:			   struct completion *lport_unreg_cmp)
drivers/scsi/lpfc/lpfc_nvme.c:		ret = wait_for_completion_timeout(lport_unreg_cmp, wait_tmo);
drivers/scsi/lpfc/lpfc_nvme.c:	DECLARE_COMPLETION_ONSTACK(lport_unreg_cmp);
drivers/scsi/lpfc/lpfc_nvme.c:	/* Wait for completion.  This either blocks
drivers/scsi/lpfc/lpfc_nvme.h:	struct completion *lport_unreg_cmp;
drivers/scsi/lpfc/lpfc_nvme.h:	struct completion rport_unreg_done;
drivers/scsi/lpfc/lpfc_nvme.h:	struct completion *tport_unreg_cmp;
drivers/scsi/lpfc/lpfc_nvmet.c: * __lpfc_nvme_xmt_ls_rsp_cmp - Generic completion handler for the
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_xmt_ls_rsp_cmp - Completion handler for LS Response
drivers/scsi/lpfc/lpfc_nvmet.c: * lock held. This function is the completion handler for NVME LS commands
drivers/scsi/lpfc/lpfc_nvmet.c: * generic completion handler to free resources.
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_xmt_fcp_op_cmp - Completion handler for FCP Response
drivers/scsi/lpfc/lpfc_nvmet.c: * lock held. This function is the completion handler for NVME FCP commands
drivers/scsi/lpfc/lpfc_nvmet.c: * @xmt_ls_rsp_cmp: completion routine to call upon RSP transmit done
drivers/scsi/lpfc/lpfc_nvmet.c:	 * As transport doesn't track completions of responses, if the rsp
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_ls_req_cmp - completion handler for a nvme ls request
drivers/scsi/lpfc/lpfc_nvmet.c: * This function is the completion handler for NVME LS requests.
drivers/scsi/lpfc/lpfc_nvmet.c: * generic completion handler to finish completion of the request.
drivers/scsi/lpfc/lpfc_nvmet.c:	 * of the IO completion. Thus a context that was allocated for MRQ A
drivers/scsi/lpfc/lpfc_nvmet.c:	DECLARE_COMPLETION_ONSTACK(tport_unreg_cmp);
drivers/scsi/lpfc/lpfc_nvmet.c:		if (!wait_for_completion_timeout(&tport_unreg_cmp,
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_sol_fcp_abort_cmp - Completion handler for ABTS
drivers/scsi/lpfc/lpfc_nvmet.c: * lock held. This function is the completion handler for NVME ABTS for FCP cmds
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_unsol_fcp_abort_cmp - Completion handler for ABTS
drivers/scsi/lpfc/lpfc_nvmet.c: * lock held. This function is the completion handler for NVME ABTS for FCP cmds
drivers/scsi/lpfc/lpfc_nvmet.c: * lpfc_nvmet_xmt_ls_abort_cmp - Completion handler for ABTS
drivers/scsi/lpfc/lpfc_nvmet.c: * lock held. This function is the completion handler for NVME ABTS for LS cmds
drivers/scsi/lpfc/lpfc_scsi.c:				 * for command completion wake up the thread.
drivers/scsi/lpfc/lpfc_scsi.c:					 * restore it on completion.
drivers/scsi/lpfc/lpfc_scsi.c:					 * restore it on completion.
drivers/scsi/lpfc/lpfc_scsi.c: * lpfc_update_cmf_cmpl - Adjust CMF counters for IO completion
drivers/scsi/lpfc/lpfc_scsi.c:				 "release, skip completion\n");
drivers/scsi/lpfc/lpfc_scsi.c:				 "9042 I/O completion: Not an active IO\n");
drivers/scsi/lpfc/lpfc_scsi.c:				 "9037 FCP Completion Error: xri %x "
drivers/scsi/lpfc/lpfc_scsi.c:	 * If there is an abort thread waiting for command completion
drivers/scsi/lpfc/lpfc_scsi.c: * lpfc_scsi_cmd_iocb_cmpl - Scsi cmnd IOCB completion routine
drivers/scsi/lpfc/lpfc_scsi.c:				 "2621 IO completion: Not an active IO\n");
drivers/scsi/lpfc/lpfc_scsi.c:	 * If there is an abort thread waiting for command completion
drivers/scsi/lpfc/lpfc_scsi.c: * lpfc_tskmgmt_def_cmpl - IOCB completion routine for task management command
drivers/scsi/lpfc/lpfc_scsi.c: * This routine is IOCB completion routine for device reset and target reset
drivers/scsi/lpfc/lpfc_scsi.c:	 * Store the midlayer's command structure for the completion phase
drivers/scsi/lpfc/lpfc_scsi.c:	/* Guard against IO completion being called at same time */
drivers/scsi/lpfc/lpfc_scsi.c:	 * see the completion before the eh fired. Just return SUCCESS.
drivers/scsi/lpfc/lpfc_scsi.c: * outstanding, then waits for their completions. The wait is
drivers/scsi/lpfc/lpfc_sli.c:/* There are only four IOCB completion types. */
drivers/scsi/lpfc/lpfc_sli.c:static bool lpfc_sli4_mbox_completions_pending(struct lpfc_hba *phba);
drivers/scsi/lpfc/lpfc_sli.c:static bool lpfc_sli4_process_missed_mbox_completions(struct lpfc_hba *phba);
drivers/scsi/lpfc/lpfc_sli.c:	/* Save off the mailbox pointer for completion */
drivers/scsi/lpfc/lpfc_sli.c:	/* Clear the mailbox pointer for completion */
drivers/scsi/lpfc/lpfc_sli.c: * @q: The Completion Queue to get the first valid CQE from
drivers/scsi/lpfc/lpfc_sli.c: * This routine will get the first valid Completion Queue Entry from @q, update
drivers/scsi/lpfc/lpfc_sli.c: * @q: The Completion Queue that the host has completed processing for.
drivers/scsi/lpfc/lpfc_sli.c:	bf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_COMPLETION);
drivers/scsi/lpfc/lpfc_sli.c: * @q: The Completion Queue that the host has completed processing for.
drivers/scsi/lpfc/lpfc_sli.c:			/* if we send the rrq then the completion handler
drivers/scsi/lpfc/lpfc_sli.c: * LPFC_SOL_IOCB     if it is a solicited iocb completion
drivers/scsi/lpfc/lpfc_sli.c: * completion, the firmware will indicate any BW restrictions the
drivers/scsi/lpfc/lpfc_sli.c:	/* Setup reqtag to match the wqe completion. */
drivers/scsi/lpfc/lpfc_sli.c: * a completion call back for this iocb else the function will free the
drivers/scsi/lpfc/lpfc_sli.c:	 * If there is no completion routine to call, we can release the
drivers/scsi/lpfc/lpfc_sli.c:	 * that have no rsp ring completion, cmd_cmpl MUST be NULL.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_wake_mbox_wait - lpfc_sli_issue_mbox_wait mbox completion handler
drivers/scsi/lpfc/lpfc_sli.c: * This is completion handler function for mailbox commands issued from
drivers/scsi/lpfc/lpfc_sli.c:	struct completion *pmbox_done;
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_def_mbox_cmpl - Default mailbox completion handler
drivers/scsi/lpfc/lpfc_sli.c: * This function is the default mailbox completion handler. It
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_unreg_rpi_cmpl_clr - mailbox completion handler
drivers/scsi/lpfc/lpfc_sli.c: * This function is the unreg rpi mailbox completion handler. It
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_handle_mb_event - Handle mailbox completions from firmware
drivers/scsi/lpfc/lpfc_sli.c: * service routine processes mailbox completion interrupt and adds completed
drivers/scsi/lpfc/lpfc_sli.c: * completion handler function of each mailbox.
drivers/scsi/lpfc/lpfc_sli.c:		 * It is a fatal error if unknown mbox command completion.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_process_sol_iocb - process solicited iocb completion
drivers/scsi/lpfc/lpfc_sli.c: * calls the completion handler for the command iocb. If there
drivers/scsi/lpfc/lpfc_sli.c: * is no completion handler, the function will free the resources
drivers/scsi/lpfc/lpfc_sli.c: * an already aborted command iocb, the status of the completion
drivers/scsi/lpfc/lpfc_sli.c:			 * Post all ELS completions to the worker thread.
drivers/scsi/lpfc/lpfc_sli.c:			 * All other are passed to the completion callback.
drivers/scsi/lpfc/lpfc_sli.c:			 * Ring <ringno> handler: unexpected completion IoTag
drivers/scsi/lpfc/lpfc_sli.c:					 "unexpected completion IoTag x%x "
drivers/scsi/lpfc/lpfc_sli.c: * LE bit set. The function will call the completion handler of the command iocb
drivers/scsi/lpfc/lpfc_sli.c: * if the response iocb indicates a completion for a command iocb or it is
drivers/scsi/lpfc/lpfc_sli.c: * an abort completion. The function will call lpfc_sli_process_unsol_iocb
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:						" completion\n",
drivers/scsi/lpfc/lpfc_sli.c: * completion of a command iocb. The function will call the
drivers/scsi/lpfc/lpfc_sli.c: * The function frees the resources or calls the completion handler if this
drivers/scsi/lpfc/lpfc_sli.c: * iocb is an abort completion. The function returns NULL when the response
drivers/scsi/lpfc/lpfc_sli.c:	 * associated with this iocb completion.
drivers/scsi/lpfc/lpfc_sli.c:	 * Fetch the iocb command type and call the correct completion
drivers/scsi/lpfc/lpfc_sli.c:			/* Call the specified completion routine */
drivers/scsi/lpfc/lpfc_sli.c:		 * Build a completion list and call the appropriate handler.
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:			       "completion.\n", __func__);
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(tx_completions);
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(txcmplq_completions);
drivers/scsi/lpfc/lpfc_sli.c:		list_splice_init(&pring->txq, &tx_completions);
drivers/scsi/lpfc/lpfc_sli.c:					 &txcmplq_completions);
drivers/scsi/lpfc/lpfc_sli.c:		list_splice_init(&pring->txq, &tx_completions);
drivers/scsi/lpfc/lpfc_sli.c:			list_splice_init(&pring->txcmplq, &txcmplq_completions);
drivers/scsi/lpfc/lpfc_sli.c:		/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_sli.c:		lpfc_sli_cancel_iocbs(phba, &txcmplq_completions,
drivers/scsi/lpfc/lpfc_sli.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_sli.c:	lpfc_sli_cancel_iocbs(phba, &tx_completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_sli.c:	/* There is no completion for a KILL_BOARD mbox cmd. Check for an error
drivers/scsi/lpfc/lpfc_sli.c: * The function does not guarantee completion of MBX_RESTART mailbox
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_arm_cqeq_intr - Arm sli-4 device completion and event queues
drivers/scsi/lpfc/lpfc_sli.c: * This routine is called to explicitly arm the SLI4 device's completion and
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_ras_mbox_cmpl: Completion handler for RAS MBX command
drivers/scsi/lpfc/lpfc_sli.c: * Completion handler for driver's RAS MBX command to the device.
drivers/scsi/lpfc/lpfc_sli.c:	phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_mbox_completions_pending - check to see if any mailbox completions
drivers/scsi/lpfc/lpfc_sli.c: * This function checks if any mailbox completions are present on the mailbox
drivers/scsi/lpfc/lpfc_sli.c: * completion queue.
drivers/scsi/lpfc/lpfc_sli.c:lpfc_sli4_mbox_completions_pending(struct lpfc_hba *phba)
drivers/scsi/lpfc/lpfc_sli.c:	bool pending_completions = false;
drivers/scsi/lpfc/lpfc_sli.c:	/* Check for completions on mailbox completion queue */
drivers/scsi/lpfc/lpfc_sli.c:			pending_completions = true;
drivers/scsi/lpfc/lpfc_sli.c:	return pending_completions;
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_process_missed_mbox_completions - process mbox completions
drivers/scsi/lpfc/lpfc_sli.c: * For sli4, it is possible to miss an interrupt. As such mbox completions
drivers/scsi/lpfc/lpfc_sli.c: * checks to see if mbox completions are on the mailbox completion queue
drivers/scsi/lpfc/lpfc_sli.c: * and will process all the completions associated with the eq for the
drivers/scsi/lpfc/lpfc_sli.c: * mailbox completion queue.
drivers/scsi/lpfc/lpfc_sli.c:lpfc_sli4_process_missed_mbox_completions(struct lpfc_hba *phba)
drivers/scsi/lpfc/lpfc_sli.c:	/* Check to see if a mbox completion is pending */
drivers/scsi/lpfc/lpfc_sli.c:	mbox_pending = lpfc_sli4_mbox_completions_pending(phba);
drivers/scsi/lpfc/lpfc_sli.c:	 * If a mbox completion is pending, process all the events on EQ
drivers/scsi/lpfc/lpfc_sli.c:	 * associated with the mbox completion queue (this could include
drivers/scsi/lpfc/lpfc_sli.c:	/* If the mailbox completed, process the completion */
drivers/scsi/lpfc/lpfc_sli.c:	lpfc_sli4_process_missed_mbox_completions(phba);
drivers/scsi/lpfc/lpfc_sli.c: * this function will wait in a polling loop for the completion of the
drivers/scsi/lpfc/lpfc_sli.c: * for the mailbox completion. The no_wait is supported only when HBA
drivers/scsi/lpfc/lpfc_sli.c: * The sli layer owns the mailbox object until the completion of mailbox
drivers/scsi/lpfc/lpfc_sli.c:		lpfc_sli4_process_missed_mbox_completions(phba);
drivers/scsi/lpfc/lpfc_sli.c: * This routine executes a synchronous completion operation on the
drivers/scsi/lpfc/lpfc_sli.c: * mailbox by polling for its completion.
drivers/scsi/lpfc/lpfc_sli.c:			 * completion, cmd_cmpl MUST be 0.
drivers/scsi/lpfc/lpfc_sli.c:		/* We will not likely get the completion for the caller
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_sli.c:	list_splice_init(&phba->sli.mboxq, &completions);
drivers/scsi/lpfc/lpfc_sli.c:		list_add_tail(&psli->mbox_active->list, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	list_splice_init(&phba->sli.mboxq_cmpl, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	while (!list_empty(&completions)) {
drivers/scsi/lpfc/lpfc_sli.c:		list_remove_head(&completions, pmb, LPFC_MBOXQ_t, list);
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_sli.c:				list_move_tail(&iocb->list, &completions);
drivers/scsi/lpfc/lpfc_sli.c:				list_move_tail(&iocb->list, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_sli.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_sli.c:			list_splice_init(&pring->txq, &completions);
drivers/scsi/lpfc/lpfc_sli.c:			list_splice_init(&pring->txq, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	/* Cancel all the IOCBs from the completions list */
drivers/scsi/lpfc/lpfc_sli.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_sli.c:	list_splice_init(&phba->elsbuf, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	while (!list_empty(&completions)) {
drivers/scsi/lpfc/lpfc_sli.c:		list_remove_head(&completions, buf_ptr,
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_abort_els_cmpl - Completion handler for the els abort iocbs
drivers/scsi/lpfc/lpfc_sli.c: * This function is the completion handler for the abort iocbs for
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_ignore_els_cmpl - Completion handler for aborted ELS command
drivers/scsi/lpfc/lpfc_sli.c: * lock held. This function is the completion handler for ELS commands
drivers/scsi/lpfc/lpfc_sli.c: * @cmpl: completion function.
drivers/scsi/lpfc/lpfc_sli.c:	 * before calling the completion handler
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_abort_fcp_cmpl - Completion handler function for aborted FCP IOCBs
drivers/scsi/lpfc/lpfc_sli.c:		/* Guard against IO completion being called at same time */
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli_wake_iocb_wait - lpfc_sli_issue_iocb_wait's completion handler
drivers/scsi/lpfc/lpfc_sli.c: * This function is the completion handler for iocbs issued using
drivers/scsi/lpfc/lpfc_sli.c: * sleeps for the iocb completion.
drivers/scsi/lpfc/lpfc_sli.c:		 * completion handler has been supplied, call it.  Otherwise,
drivers/scsi/lpfc/lpfc_sli.c: * needed, the caller is expected to provide a completion function
drivers/scsi/lpfc/lpfc_sli.c: * completion function set in the cmd_cmpl field and then return
drivers/scsi/lpfc/lpfc_sli.c: * The function waits for the iocb completion using an
drivers/scsi/lpfc/lpfc_sli.c: * This function will sleep while waiting for iocb completion.
drivers/scsi/lpfc/lpfc_sli.c: * This function assumes that the iocb completions occur while
drivers/scsi/lpfc/lpfc_sli.c: * the thread which process iocb completion for this ring.
drivers/scsi/lpfc/lpfc_sli.c: * issuing the iocb and the iocb completion handler sets this
drivers/scsi/lpfc/lpfc_sli.c: * by the completion handler when the command completes.
drivers/scsi/lpfc/lpfc_sli.c:			 * completion function and set local status
drivers/scsi/lpfc/lpfc_sli.c: * The function waits for the mailbox completion using an
drivers/scsi/lpfc/lpfc_sli.c: * This function will sleep while waiting for mailbox completion.
drivers/scsi/lpfc/lpfc_sli.c: * This function assumes that the mailbox completion occurs while
drivers/scsi/lpfc/lpfc_sli.c: * the worker thread which processes mailbox completion.
drivers/scsi/lpfc/lpfc_sli.c:	struct completion mbox_done;
drivers/scsi/lpfc/lpfc_sli.c:	init_completion(&mbox_done);
drivers/scsi/lpfc/lpfc_sli.c:		wait_for_completion_timeout(&mbox_done,
drivers/scsi/lpfc/lpfc_sli.c:				phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c: * @irspiocbq: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine handles an ELS work-queue completion event and construct
drivers/scsi/lpfc/lpfc_sli.c: * @mcqe: Pointer to mailbox completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a mailbox completion queue entry with asynchronous
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_sp_handle_mbox_event - Handle a mailbox completion event
drivers/scsi/lpfc/lpfc_sli.c: * @mcqe: Pointer to mailbox completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a mailbox completion queue entry with mailbox
drivers/scsi/lpfc/lpfc_sli.c: * completion event.
drivers/scsi/lpfc/lpfc_sli.c:	phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:	/* There is mailbox completion work to queue to the worker thread */
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_sp_handle_mcqe - Process a mailbox completion queue entry
drivers/scsi/lpfc/lpfc_sli.c: * @cqe: Pointer to mailbox completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a mailbox completion queue entry, it invokes the
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_sp_handle_els_wcqe - Handle els work-queue completion event
drivers/scsi/lpfc/lpfc_sli.c: * @wcqe: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine handles an ELS work-queue completion event.
drivers/scsi/lpfc/lpfc_sli.c: * @wcqe: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * @cq: Pointer to a WQ completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @wcqe: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_sp_handle_rcqe - Process a receive-queue completion queue entry
drivers/scsi/lpfc/lpfc_sli.c: * @rcqe: Pointer to receive-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a receive-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_sp_handle_cqe - Process a slow path completion queue entry
drivers/scsi/lpfc/lpfc_sli.c: * @cq: Pointer to the completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @cqe: Pointer to a completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a slow-path work-queue or receive queue completion queue
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c: * completion event on a completion queue, if not, an error shall be logged
drivers/scsi/lpfc/lpfc_sli.c: * and just return. Otherwise, it will get to the corresponding completion
drivers/scsi/lpfc/lpfc_sli.c: * queue and process all the entries on that completion queue, rearm the
drivers/scsi/lpfc/lpfc_sli.c: * completion queue, and then return.
drivers/scsi/lpfc/lpfc_sli.c: * This routine processes completion queue entries in a CQ. While a valid
drivers/scsi/lpfc/lpfc_sli.c:				"0369 No entry from completion queue "
drivers/scsi/lpfc/lpfc_sli.c:				"0370 Invalid completion queue type (%d)\n",
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_fp_handle_fcp_wcqe - Process fast-path work queue completion entry
drivers/scsi/lpfc/lpfc_sli.c: * @wcqe: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a fast-path work queue completion entry from fast-path
drivers/scsi/lpfc/lpfc_sli.c: * event queue for FCP command response completion.
drivers/scsi/lpfc/lpfc_sli.c: * @cq: Pointer to completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @wcqe: Pointer to work-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_nvmet_handle_rcqe - Process a receive-queue completion queue entry
drivers/scsi/lpfc/lpfc_sli.c: * @cq: Pointer to completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @rcqe: Pointer to receive-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a receive-queue completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_sli4_fp_handle_cqe - Process fast-path work queue completion entry
drivers/scsi/lpfc/lpfc_sli.c: * @cq: Pointer to the completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @cqe: Pointer to fast-path completion queue entry.
drivers/scsi/lpfc/lpfc_sli.c: * This routine process a fast-path work queue completion entry from fast-path
drivers/scsi/lpfc/lpfc_sli.c: * event queue for FCP command response completion.
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c:		phba->last_completion_time = jiffies;
drivers/scsi/lpfc/lpfc_sli.c: * completion event on a completion queue, if not, an error shall be logged
drivers/scsi/lpfc/lpfc_sli.c: * and just return. Otherwise, it will get to the corresponding completion
drivers/scsi/lpfc/lpfc_sli.c: * queue and process all the entries on the completion queue, rearm the
drivers/scsi/lpfc/lpfc_sli.c: * completion queue, and then return.
drivers/scsi/lpfc/lpfc_sli.c:				"0366 Not a valid completion "
drivers/scsi/lpfc/lpfc_sli.c:	/* Next check for NVMET completion */
drivers/scsi/lpfc/lpfc_sli.c:				"0368 Miss-matched fast-path completion "
drivers/scsi/lpfc/lpfc_sli.c:	 * the io path completion will only arm eq's when it
drivers/scsi/lpfc/lpfc_sli.c:	 * receives a completion.  But since eq's are in disa-
drivers/scsi/lpfc/lpfc_sli.c:	 * rmed state it doesn't receive a completion.  This
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_cq_create - Create a Completion Queue on the HBA
drivers/scsi/lpfc/lpfc_sli.c: * @cq: The queue structure to use to create the completion queue.
drivers/scsi/lpfc/lpfc_sli.c: * @eq: The event queue to bind this completion queue to.
drivers/scsi/lpfc/lpfc_sli.c: * This function creates a completion queue, as detailed in @wq, on a port,
drivers/scsi/lpfc/lpfc_sli.c: * is used to indicate which event queue to bind this completion queue to. This
drivers/scsi/lpfc/lpfc_sli.c: * completion queue. This function is asynchronous and will wait for the mailbox
drivers/scsi/lpfc/lpfc_sli.c:	/* Set up completion queue's type and subtype */
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_cq_create_set - Create a set of Completion Queues on the HBA for MRQ
drivers/scsi/lpfc/lpfc_sli.c: * @cqp: The queue structure array to use to create the completion queues.
drivers/scsi/lpfc/lpfc_sli.c: * @hdwq: The hardware queue array  with the EQ to bind completion queues to.
drivers/scsi/lpfc/lpfc_sli.c: * This function creates a set of  completion queue, s to support MRQ
drivers/scsi/lpfc/lpfc_sli.c: * is used to indicate which event queue to bind this completion queue to. This
drivers/scsi/lpfc/lpfc_sli.c: * completion queue. This function is asynchronous and will wait for the mailbox
drivers/scsi/lpfc/lpfc_sli.c:		/* Set up completion queue's type and subtype */
drivers/scsi/lpfc/lpfc_sli.c: * @cq: The completion queue to associate with this cq.
drivers/scsi/lpfc/lpfc_sli.c: * @cq: The completion queue to associate with this cq.
drivers/scsi/lpfc/lpfc_sli.c: * @cq: The completion queue to bind this work queue to.
drivers/scsi/lpfc/lpfc_sli.c: * is used to indicate which completion queue to bind this work queue to. This
drivers/scsi/lpfc/lpfc_sli.c: * @cq: The completion queue to bind this work queue to.
drivers/scsi/lpfc/lpfc_sli.c: * completion queue to bind received buffers that are posted to these queues to.
drivers/scsi/lpfc/lpfc_sli.c: * @cqp: The completion queue array to bind these receive queues to.
drivers/scsi/lpfc/lpfc_sli.c: * completion queue to bind received buffers that are posted to these queues to.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_cq_destroy - Destroy a Completion Queue on the HBA
drivers/scsi/lpfc/lpfc_sli.c: * @cmpl: completion call-back.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_mbx_cmpl_add_fcf_record - add fcf mbox completion handler.
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_mbx_cmpl_redisc_fcf_table - completion routine for rediscover FCF table
drivers/scsi/lpfc/lpfc_sli.c: * This routine is the completion routine for the rediscover FCF table mailbox
drivers/scsi/lpfc/lpfc_sli.c: * lpfc_log_fw_write_cmpl - logs firmware write completion status
drivers/scsi/lpfc/lpfc_sli.c:	/* Cleanup any mailbox completions which are not yet processed */
drivers/scsi/lpfc/lpfc_sli.c:	LIST_HEAD(completions);
drivers/scsi/lpfc/lpfc_sli.c:			list_add_tail(&piocbq->list, &completions);
drivers/scsi/lpfc/lpfc_sli.c:	lpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,
drivers/scsi/lpfc/lpfc_sli.c: * @cmpl: completion function.
drivers/scsi/lpfc/lpfc_sli.c: * This routine is hard coded to use a poll completion.  Unlike other
drivers/scsi/lpfc/lpfc_sli.c: * to use interrupt-based completions, code is needed to fully cleanup
drivers/scsi/lpfc/lpfc_sli.h:		struct completion *mbox_wait;	/* Used in issue_mbox_wait */
drivers/scsi/lpfc/lpfc_sli4.h:	 * while completion to check if the eq's needs to be rearmed.
drivers/scsi/lpfc/lpfc_vmid.c: * This routine reinitializes the vmid post flogi completion
drivers/scsi/lpfc/lpfc_vport.c:	 * mbox completion handler to take care of the cleanup.  This
drivers/scsi/lpfc/lpfc_vport.c:	 * Completion of unreg_vpi (lpfc_mbx_cmpl_unreg_vpi) does the
drivers/scsi/lpfc/lpfc_vport.c:			/* Send DA_ID and wait for a completion. */
drivers/scsi/lpfc/lpfc_vport.c:		 * Completion of unreg_vpi (lpfc_mbx_cmpl_unreg_vpi)
drivers/scsi/mac53c94.c:			printk(KERN_DEBUG "got intr %x on completion\n", intr);
drivers/scsi/megaraid.c:#include <linux/completion.h>
drivers/scsi/megaraid.c:	wait_for_completion(&adapter->int_waitq);
drivers/scsi/megaraid.c:	init_completion(&adapter->int_waitq);
drivers/scsi/megaraid.h:	struct completion	int_waitq;	/* wait queue for internal
drivers/scsi/megaraid/mega_common.h: * @status		: completion status
drivers/scsi/megaraid/megaraid_mbox.c:	// completion, firmware would write the valid id.
drivers/scsi/megaraid/megaraid_sas.h: * MFI command completion codes
drivers/scsi/megaraid/megaraid_sas.h:	u64 shieldDiagCompletionTime;
drivers/scsi/megaraid/megaraid_sas.h:	spinlock_t completion_lock;
drivers/scsi/megaraid/megaraid_sas_base.c:	spin_lock_irqsave(&instance->completion_lock, flags);
drivers/scsi/megaraid/megaraid_sas_base.c:	spin_unlock_irqrestore(&instance->completion_lock, flags);
drivers/scsi/megaraid/megaraid_sas_base.c:			 * Call cmd completion routine. Cmd to be
drivers/scsi/megaraid/megaraid_sas_base.c:		 * was via IOCTL, we will send it to internal completion.
drivers/scsi/megaraid/megaraid_sas_base.c: * completion of the internal reset sequence. if the internal reset
drivers/scsi/megaraid/megaraid_sas_base.c:	spin_lock_init(&instance->completion_lock);
drivers/scsi/megaraid/megaraid_sas_fusion.c:			dev_dbg(&instance->pdev->dev, "TM completion:"
drivers/scsi/megaraid/megaraid_sas_fusion.c:			} else	/* Optimal VD - R1 FP command completion. */
drivers/scsi/megaraid/megaraid_sas_fusion.c:	 * on completion. For cmds with this flag, don't call
drivers/scsi/megaraid/megaraid_sas_fusion.c:	u32 waittime_for_io_completion;
drivers/scsi/megaraid/megaraid_sas_fusion.c:	waittime_for_io_completion =
drivers/scsi/megaraid/megaraid_sas_fusion.c:	for (i = 0; i < waittime_for_io_completion; i++) {
drivers/scsi/megaraid/megaraid_sas_fusion.c:	init_completion(&cmd_fusion->done);
drivers/scsi/megaraid/megaraid_sas_fusion.c:	timeleft = wait_for_completion_timeout(&cmd_fusion->done, timeout * HZ);
drivers/scsi/megaraid/megaraid_sas_fusion.h:	struct completion done;
drivers/scsi/mesh.c:			dlog(ms, "Selecting phase at command completion",0);
drivers/scsi/mpi3mr/mpi/mpi30_cnfg.h:#define MPI3_DEVICE0_ASTATUS_NVME_COMPLETION_TIME                   (0x4e)
drivers/scsi/mpi3mr/mpi3mr.h:	struct completion done;
drivers/scsi/mpi3mr/mpi3mr_app.c: * and wait for the completion of it or time out.
drivers/scsi/mpi3mr/mpi3mr_app.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_app.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_app.c: * completion of it or time out.
drivers/scsi/mpi3mr/mpi3mr_app.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_app.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_app.c:	init_completion(&mrioc->pel_abort_cmd.done);
drivers/scsi/mpi3mr/mpi3mr_app.c:	wait_for_completion_timeout(&mrioc->pel_abort_cmd.done,
drivers/scsi/mpi3mr/mpi3mr_app.c:	init_completion(&mrioc->bsg_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_app.c:	wait_for_completion_timeout(&mrioc->bsg_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:		 * Exit completion loop to avoid CPU lockup
drivers/scsi/mpi3mr/mpi3mr_fw.c:		 * Ensure remaining completion happens from threaded ISR.
drivers/scsi/mpi3mr/mpi3mr_fw.c: * poll for pending I/O completions in a loop until pending I/Os
drivers/scsi/mpi3mr/mpi3mr_fw.c:	/* Poll for pending IOs completions */
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c: * the completion of it or time out.
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c: * the completion of it or time out.
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c: * wait for the completion of it or time out.
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done,
drivers/scsi/mpi3mr/mpi3mr_fw.c: * @async: Flag to wait for completion or not
drivers/scsi/mpi3mr/mpi3mr_fw.c: * async flag is not set wait for the completion of the port
drivers/scsi/mpi3mr/mpi3mr_fw.c:		init_completion(&mrioc->init_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->init_cmds.done, (pe_timeout * HZ));
drivers/scsi/mpi3mr/mpi3mr_fw.c: * mpi3mr_pel_wait_complete - PELWait Completion callback
drivers/scsi/mpi3mr/mpi3mr_fw.c: * and if the PELwait completion is not due to PELAbort then
drivers/scsi/mpi3mr/mpi3mr_fw.c: * mpi3mr_pel_get_seqnum_complete - PELGetSeqNum Completion callback
drivers/scsi/mpi3mr/mpi3mr_fw.c: * the firmware. This blocks for the completion of request for
drivers/scsi/mpi3mr/mpi3mr_fw.c: * On successful completion of the request this function returns
drivers/scsi/mpi3mr/mpi3mr_fw.c:	init_completion(&mrioc->cfg_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_fw.c:	wait_for_completion_timeout(&mrioc->cfg_cmds.done, (timeout * HZ));
drivers/scsi/mpi3mr/mpi3mr_fw.c: * For read/header actions, on successful completion of the
drivers/scsi/mpi3mr/mpi3mr_os.c: * mpi3mr_dev_rmhs_complete_iou - Device removal IOUC completion
drivers/scsi/mpi3mr/mpi3mr_os.c: * mpi3mr_dev_rmhs_complete_tm - Device removal TM completion
drivers/scsi/mpi3mr/mpi3mr_os.c: * mpi3mr_complete_evt_ack - event ack request completion
drivers/scsi/mpi3mr/mpi3mr_os.c: * This is the completion handler for non blocking event
drivers/scsi/mpi3mr/mpi3mr_os.c: * list so that it will be processed on a completion of a prior
drivers/scsi/mpi3mr/mpi3mr_os.c:inline void mpi3mr_poll_pend_io_completions(struct mpi3mr_ioc *mrioc)
drivers/scsi/mpi3mr/mpi3mr_os.c: * specified target, lun and command and wait for its completion
drivers/scsi/mpi3mr/mpi3mr_os.c:	init_completion(&drv_cmd->done);
drivers/scsi/mpi3mr/mpi3mr_os.c:	wait_for_completion_timeout(&drv_cmd->done, (timeout * HZ));
drivers/scsi/mpi3mr/mpi3mr_os.c:		mpi3mr_poll_pend_io_completions(mrioc);
drivers/scsi/mpi3mr/mpi3mr_os.c:		mpi3mr_poll_pend_io_completions(mrioc);
drivers/scsi/mpi3mr/mpi3mr_transport.c: * This blocks for the completion of request for timeout seconds
drivers/scsi/mpi3mr/mpi3mr_transport.c: * On successful completion of the request this function returns
drivers/scsi/mpi3mr/mpi3mr_transport.c:	init_completion(&mrioc->transport_cmds.done);
drivers/scsi/mpi3mr/mpi3mr_transport.c:	wait_for_completion_timeout(&mrioc->transport_cmds.done,
drivers/scsi/mpt3sas/mpi/mpi2_cnfg.h:		FastPathHostCompletions;            /*0x28 */
drivers/scsi/mpt3sas/mpi/mpi2_cnfg.h:		FastPathFirmwareCompletions;        /*0x2C */
drivers/scsi/mpt3sas/mpi/mpi2_cnfg.h:		NonFastPathHostCompletions;         /*0x30 */
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->scsih_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->scsih_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_base.c: * mpt3sas_base_wait_for_coredump_completion - Wait until coredump
drivers/scsi/mpt3sas/mpt3sas_base.c:mpt3sas_base_wait_for_coredump_completion(struct MPT3SAS_ADAPTER *ioc,
drivers/scsi/mpt3sas/mpt3sas_base.c: * mpt3sas_base_done - base internal command completion routine
drivers/scsi/mpt3sas/mpt3sas_base.c:		mpt3sas_base_wait_for_coredump_completion(ioc, __func__);
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->base_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->base_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_base.c:			mpt3sas_base_wait_for_coredump_completion(ioc,
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->base_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->base_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->base_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->base_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_base.c: * mpt3sas_port_enable_done - command completion routine for port enable
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->port_enable_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->port_enable_cmds.done, 300*HZ);
drivers/scsi/mpt3sas/mpt3sas_base.c:	init_completion(&ioc->base_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_base.c:	wait_for_completion_timeout(&ioc->base_cmds.done, 30*HZ);
drivers/scsi/mpt3sas/mpt3sas_base.c:			mpt3sas_base_wait_for_coredump_completion(ioc,
drivers/scsi/mpt3sas/mpt3sas_base.h: * @done: completion
drivers/scsi/mpt3sas/mpt3sas_base.h:	struct completion done;
drivers/scsi/mpt3sas/mpt3sas_base.h:int mpt3sas_base_wait_for_coredump_completion(struct MPT3SAS_ADAPTER *ioc,
drivers/scsi/mpt3sas/mpt3sas_config.c: * mpt3sas_config_done - config page completion routine
drivers/scsi/mpt3sas/mpt3sas_config.c:	init_completion(&ioc->config_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_config.c:	wait_for_completion_timeout(&ioc->config_cmds.done, timeout*HZ);
drivers/scsi/mpt3sas/mpt3sas_ctl.c: * mpt3sas_ctl_done - ctl module completion routine
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	init_completion(&ioc->ctl_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_ctl.c:		 * the Completion Queue Entry on return, or 0 if no Entry.
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	wait_for_completion_timeout(&ioc->ctl_cmds.done, timeout*HZ);
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	init_completion(&ioc->ctl_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	wait_for_completion_timeout(&ioc->ctl_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	init_completion(&ioc->ctl_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	wait_for_completion_timeout(&ioc->ctl_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	init_completion(&ioc->ctl_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_ctl.c:	wait_for_completion_timeout(&ioc->ctl_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * _scsih_tm_done - tm completion routine
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	    "Poll ReplyDescriptor queues for completion of"
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	init_completion(&ioc->tm_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	wait_for_completion_timeout(&ioc->tm_cmds.done, timeout*HZ);
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * control request (MPI2_SAS_OP_REMOVE_DEVICE) from this completion.
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * and process it in a future completion.
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * This is the target reset completion routine.
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * _scsih_sas_control_complete - completion routine
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * This is the sas iounit control completion routine.
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * and process it in a future completion.
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * _scsih_tm_volume_tr_complete - target reset completion
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * completion of the volume target reset.
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	init_completion(&ioc->scsih_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	wait_for_completion_timeout(&ioc->scsih_cmds.done, 10*HZ);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	init_completion(&ioc->scsih_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	wait_for_completion_timeout(&ioc->scsih_cmds.done,
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	init_completion(&ioc->scsih_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:	wait_for_completion_timeout(&ioc->scsih_cmds.done, 10*HZ);
drivers/scsi/mpt3sas/mpt3sas_scsih.c:			mpt3sas_base_wait_for_coredump_completion(ioc, __func__);
drivers/scsi/mpt3sas/mpt3sas_scsih.c: * OK to resume normal operation. Use completion to allow
drivers/scsi/mpt3sas/mpt3sas_transport.c:	init_completion(&ioc->transport_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	wait_for_completion_timeout(&ioc->transport_cmds.done, 10*HZ);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	init_completion(&ioc->transport_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	wait_for_completion_timeout(&ioc->transport_cmds.done, 10*HZ);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	init_completion(&ioc->transport_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	wait_for_completion_timeout(&ioc->transport_cmds.done, 10*HZ);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	init_completion(&ioc->transport_cmds.done);
drivers/scsi/mpt3sas/mpt3sas_transport.c:	wait_for_completion_timeout(&ioc->transport_cmds.done, 10*HZ);
drivers/scsi/mvsas/mv_64xx.c:	/* enable completion queue interrupt */
drivers/scsi/mvsas/mv_64xx.h:	MVS_RX_LO		= 0x138, /* RX (completion) ring addr */
drivers/scsi/mvsas/mv_94xx.c:	/* enable completion queue interrupt */
drivers/scsi/mvsas/mv_94xx.h:	MVS_RX_LO		= 0x138, /* RX (completion) ring addr */
drivers/scsi/mvsas/mv_defs.h:	CINT_DONE		= (1U << 0),	/* cmd completion */
drivers/scsi/mvsas/mv_defs.h:	/* RX (completion) ring bits */
drivers/scsi/mvsas/mv_sas.h:	/* RX (completion) DMA ring */
drivers/scsi/myrb.c: * myrb_exec_cmd - executes command block and waits for completion.
drivers/scsi/myrb.c:	DECLARE_COMPLETION_ONSTACK(cmpl);
drivers/scsi/myrb.c:	cmd_blk->completion = &cmpl;
drivers/scsi/myrb.c:	wait_for_completion(&cmpl);
drivers/scsi/myrb.c: * myrb_exec_type3 - executes a type 3 command and waits for completion.
drivers/scsi/myrb.c: * myrb_exec_type3D - executes a type 3D command and waits for completion.
drivers/scsi/myrb.c:	if (cmd_blk->completion) {
drivers/scsi/myrb.c:		complete(cmd_blk->completion);
drivers/scsi/myrb.c:		cmd_blk->completion = NULL;
drivers/scsi/myrb.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrb.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrb.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrb.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrb.h:	struct completion *completion;
drivers/scsi/myrs.c: * myrs_exec_cmd - executes V2 Command and waits for completion.
drivers/scsi/myrs.c:	DECLARE_COMPLETION_ONSTACK(complete);
drivers/scsi/myrs.c:	wait_for_completion(&complete);
drivers/scsi/myrs.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrs.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrs.c:				"Unhandled command completion %d\n", id);
drivers/scsi/myrs.h:	struct completion *complete;
drivers/scsi/ncr53c8xx.c:**	completion (ncr_wakeup()). Doing so, we are sure that the header 
drivers/scsi/ncr53c8xx.c:	**	Command completion handling.
drivers/scsi/ncr53c8xx.c:	**	... signal completion to the host
drivers/scsi/ncr53c8xx.c:	**	... signal completion to the host
drivers/scsi/ncr53c8xx.c:**	Signal completion to the generic SCSI driver.
drivers/scsi/ncr53c8xx.c:	**	signal completion to generic driver.
drivers/scsi/ncr53c8xx.c:**	since the INTFLY is likely used for command completion 
drivers/scsi/ncr53c8xx.h:#define	SCSI_NCR_PCIQ_MAY_MISS_COMPLETIONS
drivers/scsi/ncr53c8xx.h:#define	SCSI_NCR_PCIQ_MAY_MISS_COMPLETIONS
drivers/scsi/pm8001/pm8001_ctl.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_ctl.c:	pm8001_ha->nvmd_completion = &completion;
drivers/scsi/pm8001/pm8001_ctl.c:	wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_ctl.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_ctl.c:	pm8001_ha->nvmd_completion = &completion;
drivers/scsi/pm8001/pm8001_ctl.c:	wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_ctl.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_ctl.c:			pm8001_ha->nvmd_completion = &completion;
drivers/scsi/pm8001/pm8001_ctl.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_hwi.c:			ccb->open_retry = 1; /* Snub completion */
drivers/scsi/pm8001/pm8001_hwi.c:				if (pm8001_dev->dcompletion) {
drivers/scsi/pm8001/pm8001_hwi.c:					complete(pm8001_dev->dcompletion);
drivers/scsi/pm8001/pm8001_hwi.c:					pm8001_dev->dcompletion = NULL;
drivers/scsi/pm8001/pm8001_hwi.c:				complete(pm8001_ha->nvmd_completion);
drivers/scsi/pm8001/pm8001_hwi.c: * mpi_ssp_completion- process the event that FW response to the SSP request.
drivers/scsi/pm8001/pm8001_hwi.c:mpi_ssp_completion(struct pm8001_hba_info *pm8001_ha, void *piomb)
drivers/scsi/pm8001/pm8001_hwi.c:	struct ssp_completion_resp *psspPayload;
drivers/scsi/pm8001/pm8001_hwi.c:	psspPayload = (struct ssp_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm8001_hwi.c:		/* SSP Completion with error */
drivers/scsi/pm8001/pm8001_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm8001_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm8001_hwi.c:mpi_sata_completion(struct pm8001_hba_info *pm8001_ha, void *piomb)
drivers/scsi/pm8001/pm8001_hwi.c:	struct sata_completion_resp *psataPayload;
drivers/scsi/pm8001/pm8001_hwi.c:	psataPayload = (struct sata_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm8001_hwi.c:		/* SATA Completion with error */
drivers/scsi/pm8001/pm8001_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm8001_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm8001_hwi.c:mpi_smp_completion(struct pm8001_hba_info *pm8001_ha, void *piomb)
drivers/scsi/pm8001/pm8001_hwi.c:	struct smp_completion_resp *psmpPayload;
drivers/scsi/pm8001/pm8001_hwi.c:	psmpPayload = (struct smp_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm8001_hwi.c:	complete(pm8001_dev->setds_completion);
drivers/scsi/pm8001/pm8001_hwi.c:	complete(pm8001_ha->nvmd_completion);
drivers/scsi/pm8001/pm8001_hwi.c:		complete(pm8001_ha->nvmd_completion);
drivers/scsi/pm8001/pm8001_hwi.c:	complete(pm8001_ha->nvmd_completion);
drivers/scsi/pm8001/pm8001_hwi.c:	if (pm8001_ha->phy[phy_id].enable_completion) {
drivers/scsi/pm8001/pm8001_hwi.c:		complete(pm8001_ha->phy[phy_id].enable_completion);
drivers/scsi/pm8001/pm8001_hwi.c:		pm8001_ha->phy[phy_id].enable_completion = NULL;
drivers/scsi/pm8001/pm8001_hwi.c:	complete(pm8001_dev->dcompletion);
drivers/scsi/pm8001/pm8001_hwi.c:	complete(pm8001_ha->nvmd_completion);
drivers/scsi/pm8001/pm8001_hwi.c:				phy->enable_completion != NULL) {
drivers/scsi/pm8001/pm8001_hwi.c:			complete(phy->enable_completion);
drivers/scsi/pm8001/pm8001_hwi.c:			phy->enable_completion = NULL;
drivers/scsi/pm8001/pm8001_hwi.c:		mpi_ssp_completion(pm8001_ha, piomb);
drivers/scsi/pm8001/pm8001_hwi.c:		mpi_smp_completion(pm8001_ha, piomb);
drivers/scsi/pm8001/pm8001_hwi.c:		mpi_sata_completion(pm8001_ha, piomb);
drivers/scsi/pm8001/pm8001_hwi.h:	operation completion message */
drivers/scsi/pm8001/pm8001_hwi.h: * brief the data structure of SATA Completion Response
drivers/scsi/pm8001/pm8001_hwi.h:struct sata_completion_resp {
drivers/scsi/pm8001/pm8001_hwi.h: * use to notify the completion of the device registration  (64 bytes)
drivers/scsi/pm8001/pm8001_hwi.h: * brief the data structure of SSP Completion Response
drivers/scsi/pm8001/pm8001_hwi.h: * use to indicate a SSP Completion  (n bytes)
drivers/scsi/pm8001/pm8001_hwi.h:struct ssp_completion_resp {
drivers/scsi/pm8001/pm8001_hwi.h: * use to indicate a SATA Completion  (64 bytes)
drivers/scsi/pm8001/pm8001_hwi.h: * use to indicate a SSP Completion  (64 bytes)
drivers/scsi/pm8001/pm8001_hwi.h: * brief the data structure of SMP Completion Response
drivers/scsi/pm8001/pm8001_hwi.h: * use to describe MPI SMP Completion Response (64 bytes)
drivers/scsi/pm8001/pm8001_hwi.h:struct smp_completion_resp {
drivers/scsi/pm8001/pm8001_hwi.h: * SSP/SMP/SATA IO Completion Status values
drivers/scsi/pm8001/pm8001_init.c:	.lldd_tmf_exec_complete = pm8001_setds_completion,
drivers/scsi/pm8001/pm8001_init.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_init.c:	pm8001_ha->nvmd_completion = &completion;
drivers/scsi/pm8001/pm8001_init.c:	time_remaining = wait_for_completion_timeout(&completion,
drivers/scsi/pm8001/pm8001_init.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_init.c:	pm8001_ha->nvmd_completion = &completion;
drivers/scsi/pm8001/pm8001_init.c:	wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_init.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_init.c:		pm8001_ha->phy[i].enable_completion = &completion;
drivers/scsi/pm8001/pm8001_init.c:		wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_sas.c:			pm8001_ha->phy[phy_id].enable_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			pm8001_ha->phy[phy_id].enable_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			pm8001_ha->phy[phy_id].enable_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_sas.c:		pm8001_ha->phy[i].enable_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:		wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_sas.c:	pm8001_device->dcompletion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:	wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:* This function handle the IT_NEXUS_XXX event or completion
drivers/scsi/pm8001/pm8001_sas.c:		DECLARE_COMPLETION_ONSTACK(completion_setstate);
drivers/scsi/pm8001/pm8001_sas.c:		pm8001_dev->setds_completion = &completion_setstate;
drivers/scsi/pm8001/pm8001_sas.c:		wait_for_completion(&completion_setstate);
drivers/scsi/pm8001/pm8001_sas.c:	DECLARE_COMPLETION_ONSTACK(completion_setstate);
drivers/scsi/pm8001/pm8001_sas.c:		pm8001_dev->setds_completion = &completion_setstate;
drivers/scsi/pm8001/pm8001_sas.c:		wait_for_completion(&completion_setstate);
drivers/scsi/pm8001/pm8001_sas.c:		init_completion(&slow_task.completion);
drivers/scsi/pm8001/pm8001_sas.c:			DECLARE_COMPLETION_ONSTACK(completion_reset);
drivers/scsi/pm8001/pm8001_sas.c:			DECLARE_COMPLETION_ONSTACK(completion);
drivers/scsi/pm8001/pm8001_sas.c:			pm8001_dev->setds_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			reinit_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			phy->enable_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			phy->reset_completion = &completion_reset;
drivers/scsi/pm8001/pm8001_sas.c:				phy->enable_completion = NULL;
drivers/scsi/pm8001/pm8001_sas.c:				phy->reset_completion = NULL;
drivers/scsi/pm8001/pm8001_sas.c:			 * avoid getting a completion for this and either
drivers/scsi/pm8001/pm8001_sas.c:			ret = wait_for_completion_timeout(&completion,
drivers/scsi/pm8001/pm8001_sas.c:				phy->enable_completion = NULL;
drivers/scsi/pm8001/pm8001_sas.c:				phy->reset_completion = NULL;
drivers/scsi/pm8001/pm8001_sas.c:				ret = wait_for_completion_timeout(
drivers/scsi/pm8001/pm8001_sas.c:					&completion_reset,
drivers/scsi/pm8001/pm8001_sas.c:					phy->reset_completion = NULL;
drivers/scsi/pm8001/pm8001_sas.c:			ret = wait_for_completion_timeout(
drivers/scsi/pm8001/pm8001_sas.c:				&task->slow_task->completion,
drivers/scsi/pm8001/pm8001_sas.c:			reinit_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			pm8001_dev->setds_completion = &completion;
drivers/scsi/pm8001/pm8001_sas.c:			wait_for_completion(&completion);
drivers/scsi/pm8001/pm8001_sas.c:			 * Ensure that if we see a completion for the ccb
drivers/scsi/pm8001/pm8001_sas.c:void pm8001_setds_completion(struct domain_device *dev)
drivers/scsi/pm8001/pm8001_sas.c:	DECLARE_COMPLETION_ONSTACK(completion_setstate);
drivers/scsi/pm8001/pm8001_sas.c:		pm8001_dev->setds_completion = &completion_setstate;
drivers/scsi/pm8001/pm8001_sas.c:		wait_for_completion(&completion_setstate);
drivers/scsi/pm8001/pm8001_sas.h:	struct completion	*enable_completion;
drivers/scsi/pm8001/pm8001_sas.h:	struct completion	*reset_completion;
drivers/scsi/pm8001/pm8001_sas.h:	struct completion	*dcompletion;
drivers/scsi/pm8001/pm8001_sas.h:	struct completion	*setds_completion;
drivers/scsi/pm8001/pm8001_sas.h:	struct completion	*nvmd_completion;
drivers/scsi/pm8001/pm8001_sas.h:void pm8001_setds_completion(struct domain_device *dev);
drivers/scsi/pm8001/pm80xx_hwi.c:	/* Step 4.2: To check the completion of the transfer, poll the Fatal/Non
drivers/scsi/pm8001/pm80xx_hwi.c: * mpi_ssp_completion - process the event that FW response to the SSP request.
drivers/scsi/pm8001/pm80xx_hwi.c:mpi_ssp_completion(struct pm8001_hba_info *pm8001_ha, void *piomb)
drivers/scsi/pm8001/pm80xx_hwi.c:	struct ssp_completion_resp *psspPayload;
drivers/scsi/pm8001/pm80xx_hwi.c:	psspPayload = (struct ssp_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm80xx_hwi.c:		/* SSP Completion with error */
drivers/scsi/pm8001/pm80xx_hwi.c:			complete(&t->slow_task->completion);
drivers/scsi/pm8001/pm80xx_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm80xx_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm80xx_hwi.c:mpi_sata_completion(struct pm8001_hba_info *pm8001_ha,
drivers/scsi/pm8001/pm80xx_hwi.c:	struct sata_completion_resp *psataPayload;
drivers/scsi/pm8001/pm80xx_hwi.c:	psataPayload = (struct sata_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm80xx_hwi.c:		/* SATA Completion with error */
drivers/scsi/pm8001/pm80xx_hwi.c:			complete(&t->slow_task->completion);
drivers/scsi/pm8001/pm80xx_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm80xx_hwi.c:/*See the comments for mpi_ssp_completion */
drivers/scsi/pm8001/pm80xx_hwi.c:mpi_smp_completion(struct pm8001_hba_info *pm8001_ha, void *piomb)
drivers/scsi/pm8001/pm80xx_hwi.c:	struct smp_completion_resp *psmpPayload;
drivers/scsi/pm8001/pm80xx_hwi.c:	psmpPayload = (struct smp_completion_resp *)(piomb + 4);
drivers/scsi/pm8001/pm80xx_hwi.c:			phy->enable_completion != NULL) {
drivers/scsi/pm8001/pm80xx_hwi.c:		complete(phy->enable_completion);
drivers/scsi/pm8001/pm80xx_hwi.c:		phy->enable_completion = NULL;
drivers/scsi/pm8001/pm80xx_hwi.c:		if (!pm8001_ha->phy[phy_id].reset_completion) {
drivers/scsi/pm8001/pm80xx_hwi.c:		if (pm8001_ha->phy[phy_id].reset_completion) {
drivers/scsi/pm8001/pm80xx_hwi.c:			complete(pm8001_ha->phy[phy_id].reset_completion);
drivers/scsi/pm8001/pm80xx_hwi.c:			pm8001_ha->phy[phy_id].reset_completion = NULL;
drivers/scsi/pm8001/pm80xx_hwi.c:		if (pm8001_ha->phy[phy_id].reset_completion) {
drivers/scsi/pm8001/pm80xx_hwi.c:			complete(pm8001_ha->phy[phy_id].reset_completion);
drivers/scsi/pm8001/pm80xx_hwi.c:			pm8001_ha->phy[phy_id].reset_completion = NULL;
drivers/scsi/pm8001/pm80xx_hwi.c:		mpi_ssp_completion(pm8001_ha, piomb);
drivers/scsi/pm8001/pm80xx_hwi.c:		mpi_smp_completion(pm8001_ha, piomb);
drivers/scsi/pm8001/pm80xx_hwi.c:		mpi_sata_completion(pm8001_ha, circularQ, piomb);
drivers/scsi/pm8001/pm80xx_hwi.h:	operation completion message */
drivers/scsi/pm8001/pm80xx_hwi.h: * brief the data structure of SATA Completion Response
drivers/scsi/pm8001/pm80xx_hwi.h:struct sata_completion_resp {
drivers/scsi/pm8001/pm80xx_hwi.h: * use to notify the completion of the device registration (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h: * indicates the completion of PHY_START command (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h: * indicates the completion of PHY_STOP command (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h: * brief the data structure of SSP Completion Response
drivers/scsi/pm8001/pm80xx_hwi.h: * use to indicate a SSP Completion (n bytes)
drivers/scsi/pm8001/pm80xx_hwi.h:struct ssp_completion_resp {
drivers/scsi/pm8001/pm80xx_hwi.h: * use to indicate a SATA Completion (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h: * use to indicate a SSP Completion (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h: * brief the data structure of SMP Completion Response
drivers/scsi/pm8001/pm80xx_hwi.h: * use to describe MPI SMP Completion Response (64 bytes)
drivers/scsi/pm8001/pm80xx_hwi.h:struct smp_completion_resp {
drivers/scsi/pm8001/pm80xx_hwi.h: * SSP/SMP/SATA IO Completion Status values
drivers/scsi/pmcraid.c:	cmd->completion_req = 0;
drivers/scsi/pmcraid.c: * pmcraid_bist_done - completion function for PCI BIST
drivers/scsi/pmcraid.c: * pmcraid_reset_alert_done - completion routine for reset_alert
drivers/scsi/pmcraid.c: * pmcraid_internal_done - completion routine for internally generated cmds
drivers/scsi/pmcraid.c:	 * response. Same will be indicated as part of cmd->completion_req
drivers/scsi/pmcraid.c:	 * completion if this flag is set.
drivers/scsi/pmcraid.c:	if (cmd->completion_req) {
drivers/scsi/pmcraid.c:		cmd->completion_req = 0;
drivers/scsi/pmcraid.c:		complete(&cmd->wait_for_completion);
drivers/scsi/pmcraid.c: * pmcraid_erp_done - Process completion of SCSI error response from device
drivers/scsi/pmcraid.c: * This function also sets up timeout function, and command completion
drivers/scsi/pmcraid.c: * @cmd_done: command completion function, called once IOA responds
drivers/scsi/pmcraid.c: * @timeout: timeout to wait for this command completion
drivers/scsi/pmcraid.c: * pmcraid_ioa_shutdown_done - completion function for IOA shutdown command
drivers/scsi/pmcraid.c: * pmcraid_get_fwversion_done - completion function for get_fwversion
drivers/scsi/pmcraid.c: * Note: This command initiates reset and waits for its completion. Hence this
drivers/scsi/pmcraid.c:	init_completion(&cmd->wait_for_completion);
drivers/scsi/pmcraid.c:	cmd->completion_req = 1;
drivers/scsi/pmcraid.c:	 * will wake up the 'completion' queue.
drivers/scsi/pmcraid.c:	wait_for_completion(&cmd->wait_for_completion);
drivers/scsi/pmcraid.c: * pmcraid_io_done - SCSI completion function
drivers/scsi/pmcraid.c:	init_completion(&cancel_cmd->wait_for_completion);
drivers/scsi/pmcraid.c:	cancel_cmd->completion_req = 1;
drivers/scsi/pmcraid.c: * pmcraid_abort_complete - Waits for ABORT TASK completion
drivers/scsi/pmcraid.c: *	 returns SUCCESS if ABORT TASK has good completion
drivers/scsi/pmcraid.c:	wait_for_completion(&cancel_cmd->wait_for_completion);
drivers/scsi/pmcraid.c:	/* If the abort task is not timed out we will get a Good completion
drivers/scsi/pmcraid.c:	 * it, send ABORT_TASK to abort this and wait for its completion
drivers/scsi/pmcraid.c: * Issues an adapter shutdown to the card waits for its completion
drivers/scsi/pmcraid.c: *				completion of the ioa reset
drivers/scsi/pmcraid.c:	 * as part of set_supported_devs completion function.
drivers/scsi/pmcraid.h:#include <linux/completion.h>
drivers/scsi/pmcraid.h:#define PMCRAID_IOASC_GOOD_COMPLETION			0x00000000
drivers/scsi/pmcraid.h:	struct completion wait_for_completion;
drivers/scsi/pmcraid.h:	u8 completion_req;		/* for handling internal commands */
drivers/scsi/pmcraid.h:	u8 release;			/* for handling completions */
drivers/scsi/pmcraid.h:	/* Wait Q for  threads to wait for Reset IOA completion */
drivers/scsi/ppa.c:static int ppa_completion(struct scsi_cmnd *const cmd)
drivers/scsi/ppa.c:		retv = ppa_completion(cmd);
drivers/scsi/ppa.h: * Add ppa_wait() calls to ppa_completion()
drivers/scsi/ppa.h: * Busy wait for connected status bit in ppa_completion()
drivers/scsi/qedf/qedf.h:	struct completion tm_done;
drivers/scsi/qedf/qedf.h:	struct completion abts_done;
drivers/scsi/qedf/qedf.h:	struct completion cleanup_done;
drivers/scsi/qedf/qedf.h:	/* Keep track of number of completions on this fastpath */
drivers/scsi/qedf/qedf.h:	unsigned long completions;
drivers/scsi/qedf/qedf.h:	u64	hw_p_cq;	/* Completion queue PBL */
drivers/scsi/qedf/qedf.h:	u32 cq_cons_idx; /* Completion queue consumer index */
drivers/scsi/qedf/qedf.h:	struct completion flogi_compl;
drivers/scsi/qedf/qedf.h:	struct completion fipvlan_compl;
drivers/scsi/qedf/qedf.h:extern void qedf_scsi_completion(struct qedf_ctx *qedf, struct fcoe_cqe *cqe,
drivers/scsi/qedf/qedf_dbg.h:#define QEDF_LOG_IO		0x400		/* scsi cmd, completion */
drivers/scsi/qedf/qedf_debugfs.c:	cnt += scnprintf(cbuf + cnt, QEDF_DEBUGFS_LOG_LEN - cnt, "\nFastpath I/O completions\n\n");
drivers/scsi/qedf/qedf_debugfs.c:				 "#%d: %lu\n", id, fp->completions);
drivers/scsi/qedf/qedf_els.c:			"ELS completion xid=0x%x after flush event=0x%x",
drivers/scsi/qedf/qedf_els.c:			"Dropping ELS completion xid=0x%x as fcport is flushing",
drivers/scsi/qedf/qedf_els.c:	 * flushed but we get a completion on this xid.
drivers/scsi/qedf/qedf_els.c:	 * rrq completion handler is called directly from the timeout handler
drivers/scsi/qedf/qedf_els.c:	/* Take reference until SRR command completion */
drivers/scsi/qedf/qedf_els.c:	 * for the original I/O request since we will not do a SCSI completion
drivers/scsi/qedf/qedf_els.c:	/* Take reference until REC command completion */
drivers/scsi/qedf/qedf_fip.c:		if (!completion_done(&qedf->fipvlan_compl))
drivers/scsi/qedf/qedf_hsi.h: * FCoE CQ element Target completion information
drivers/scsi/qedf/qedf_hsi.h:	struct fcoe_cqe_rsp_info rsp_info /* Response completion information */;
drivers/scsi/qedf/qedf_hsi.h:	/* Target completion information */
drivers/scsi/qedf/qedf_hsi.h:	/* Error completion information */
drivers/scsi/qedf/qedf_hsi.h:	struct fcoe_abts_info abts_info /* ABTS completion information */;
drivers/scsi/qedf/qedf_hsi.h:	/* Middle path completion information */
drivers/scsi/qedf/qedf_hsi.h:	/* Unsolicited packet completion information */
drivers/scsi/qedf/qedf_hsi.h:	/* Warning completion information (Rec Tov expiration) */
drivers/scsi/qedf/qedf_hsi.h:	 * The CQE type: 0x0 Indicating on a pending work request completion.
drivers/scsi/qedf/qedf_hsi.h:	FCOE_GOOD_COMPLETION_CQE_TYPE,
drivers/scsi/qedf/qedf_io.c:void qedf_scsi_completion(struct qedf_ctx *qedf, struct fcoe_cqe *cqe,
drivers/scsi/qedf/qedf_io.c:			  "Dropping good completion xid=0x%x as fcport is flushing",
drivers/scsi/qedf/qedf_io.c:			/* Good I/O completion */
drivers/scsi/qedf/qedf_io.c:/* Return a SCSI command in some other context besides a normal completion */
drivers/scsi/qedf/qedf_io.c: * Handle warning type CQE completions. This is mainly used for REC timer
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:/* Cleanup a command when we receive an error detection completion */
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:			  "Dropping ABTS completion xid=0x%x as fcport is NULL",
drivers/scsi/qedf/qedf_io.c:			  "Dropping ABTS completion xid=0x%x as fcport is flushing",
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/qedf/qedf_io.c:	tmo = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->tm_done);
drivers/scsi/qedf/qedf_io.c:	tmo = wait_for_completion_timeout(&io_req->tm_done,
drivers/scsi/qedf/qedf_io.c:			   "work for I/O completion.\n");
drivers/scsi/qedf/qedf_main.c:MODULE_PARM_DESC(io_tracing, " Enable logging of SCSI requests/completions "
drivers/scsi/qedf/qedf_main.c:		init_completion(&qedf->fipvlan_compl);
drivers/scsi/qedf/qedf_main.c:		wait_for_completion_timeout(&qedf->fipvlan_compl, 1 * HZ);
drivers/scsi/qedf/qedf_main.c:	init_completion(&qedf->flogi_compl);
drivers/scsi/qedf/qedf_main.c:	/* Wait for FLOGI completion before proceeding with sending ADISCs */
drivers/scsi/qedf/qedf_main.c:	i = wait_for_completion_timeout(&qedf->flogi_compl,
drivers/scsi/qedf/qedf_main.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_main.c:	wait_for_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_main.c: * This event_callback is called after successful completion of libfc
drivers/scsi/qedf/qedf_main.c:	init_completion(&vport_qedf->flogi_compl);
drivers/scsi/qedf/qedf_main.c:	/* Get the pointer to the global CQ this completion is on */
drivers/scsi/qedf/qedf_main.c:/* Process completion queue and copy CQE contents for deferred processesing
drivers/scsi/qedf/qedf_main.c:static bool qedf_process_completions(struct qedf_fastpath *fp)
drivers/scsi/qedf/qedf_main.c:	/* Get the pointer to the global CQ this completion is on */
drivers/scsi/qedf/qedf_main.c:		fp->completions++;
drivers/scsi/qedf/qedf_main.c:				   "work for I/O completion.\n");
drivers/scsi/qedf/qedf_main.c:	 * completions
drivers/scsi/qedf/qedf_main.c:		qedf_process_completions(fp);
drivers/scsi/qedf/qedf_main.c:/* Main thread to process I/O completions */
drivers/scsi/qedf/qedf_main.c:	/* Completion not for a valid I/O anymore so just return */
drivers/scsi/qedf/qedf_main.c:	case FCOE_GOOD_COMPLETION_CQE_TYPE:
drivers/scsi/qedf/qedf_main.c:			qedf_scsi_completion(qedf, cqe, io_req);
drivers/scsi/qedf/qedf_main.c:		    "Local completion CQE.\n");
drivers/scsi/qedf/qedf_main.c:	 * The number of completion queues/fastpath interrupts/status blocks
drivers/scsi/qedf/qedf_main.c:		init_completion(&qedf->fipvlan_compl);
drivers/scsi/qedf/qedf_main.c:	init_completion(&qedf->flogi_compl);
drivers/scsi/qedi/qedi.h:	u64 hw_p_cq;	/* Completion queue PBL */
drivers/scsi/qedi/qedi.h:	u32 cq_cons_idx; /* Completion queue consumer index */
drivers/scsi/qedi/qedi_dbg.h:#define QEDI_LOG_IO		0x400		/* scsi cmd, completion */
drivers/scsi/qedi/qedi_fw.c:static void qedi_scsi_completion(struct qedi_ctx *qedi,
drivers/scsi/qedi/qedi_fw.c:static void qedi_mtask_completion(struct qedi_ctx *qedi,
drivers/scsi/qedi/qedi_fw.c:		qedi_scsi_completion(qedi, cqe, task, iscsi_conn);
drivers/scsi/qedi/qedi_fw.c:		/* Process NOPIN local completion */
drivers/scsi/qedi/qedi_fw.c:			qedi_mtask_completion(qedi, cqe, task, q_conn, que_idx);
drivers/scsi/qedi/qedi_fw_api.c:static void set_local_completion_context(struct iscsi_task_context *context)
drivers/scsi/qedi/qedi_fw_api.c:		set_local_completion_context(cxt);
drivers/scsi/qedi/qedi_fw_api.c:		set_local_completion_context(task_params->context);
drivers/scsi/qedi/qedi_iscsi.c:	{ ISCSI_CONN_ERROR_LOCAL_COMPLETION_ERROR,
drivers/scsi/qedi/qedi_iscsi.h:#include <linux/completion.h>
drivers/scsi/qedi/qedi_main.c:		 " Enable logging of SCSI requests/completions into trace buffer. (default off).");
drivers/scsi/qedi/qedi_main.c:static bool qedi_process_completions(struct qedi_fastpath *fp)
drivers/scsi/qedi/qedi_main.c:	/* Get the pointer to the global CQ this completion is on */
drivers/scsi/qedi/qedi_main.c:	wake_io_thread = qedi_process_completions(fp);
drivers/scsi/qla1280.c:	- Initialize completion queue to avoid OOPS on probe
drivers/scsi/qla1280.c:    	- use struct list_head for completion queue
drivers/scsi/qla1280.c:	- Delete completion queue from srb if mailbox command failed to
drivers/scsi/qla1280.c:	- Use completion queue for mailbox commands instead of busy wait
drivers/scsi/qla1280.c: * interrupt handler may call this routine as part of request-completion
drivers/scsi/qla1280.c:				 struct completion *wait)
drivers/scsi/qla1280.c:	wait_for_completion_timeout(wait, 4*HZ);
drivers/scsi/qla1280.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/qla1280.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/qla1280.c:	 * for completion.
drivers/scsi/qla1280.c: *      Issue mailbox command and waits for completion.
drivers/scsi/qla1280.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/qla1280.c:	wait_for_completion(&wait);
drivers/scsi/qla1280.c: *      Calls I/O done on command completion.
drivers/scsi/qla1280.c:		if (mailbox[0] != MBA_SCSI_COMPLETION) {
drivers/scsi/qla1280.c:		case MBA_SCSI_COMPLETION:	/* Response completion */
drivers/scsi/qla1280.c:				"completion\n");
drivers/scsi/qla1280.c:					/* Save ISP completion status */
drivers/scsi/qla1280.c:		/* Save ISP completion status */
drivers/scsi/qla1280.h:	/* NOTE: the sp->cmd will be NULL when this completion is
drivers/scsi/qla1280.h:	struct completion *wait;
drivers/scsi/qla1280.h:#define MBA_SCSI_COMPLETION	0x8020	/* Completion response. */
drivers/scsi/qla1280.h:	__le16 comp_status;	/* Completion status. */
drivers/scsi/qla1280.h: * ISP status entry - completion status definitions.
drivers/scsi/qla1280.h:	struct completion *mailbox_wait;
drivers/scsi/qla2xxx/qla_bsg.c:		if (wait && !wait_for_completion_timeout(&ha->dcbx_comp,
drivers/scsi/qla2xxx/qla_bsg.c:			    "DCBX completion not received.\n");
drivers/scsi/qla2xxx/qla_bsg.c:			    "DCBX completion received.\n");
drivers/scsi/qla2xxx/qla_bsg.c:		    !wait_for_completion_timeout(&ha->lb_portup_comp,
drivers/scsi/qla2xxx/qla_bsg.c:			    "Port up completion not received.\n");
drivers/scsi/qla2xxx/qla_bsg.c:			    "Port up completion received.\n");
drivers/scsi/qla2xxx/qla_bsg.c:		rem_tmo = wait_for_completion_timeout(&ha->dcbx_comp,
drivers/scsi/qla2xxx/qla_bsg.c:		    "DCBX completion not received.\n");
drivers/scsi/qla2xxx/qla_bsg.c:			    "Bad status in IDC Completion AEN\n");
drivers/scsi/qla2xxx/qla_bsg.c:			    "DCBX completion received.\n");
drivers/scsi/qla2xxx/qla_dbg.c:			/* error completion status */
drivers/scsi/qla2xxx/qla_dbg.c:			/* error completion status */
drivers/scsi/qla2xxx/qla_def.h:#include <linux/completion.h>
drivers/scsi/qla2xxx/qla_def.h:#define IDC_AUDIT_COMPLETION		0x1 /* IDC-AUDIT: Record duration of
drivers/scsi/qla2xxx/qla_def.h:					     * reset-recovery completion is
drivers/scsi/qla2xxx/qla_def.h:			struct completion comp;
drivers/scsi/qla2xxx/qla_def.h:			struct completion comp;
drivers/scsi/qla2xxx/qla_def.h:			struct completion comp;
drivers/scsi/qla2xxx/qla_def.h:			struct completion fxiocb_comp;
drivers/scsi/qla2xxx/qla_def.h:			struct completion comp;
drivers/scsi/qla2xxx/qla_def.h:			struct completion comp;
drivers/scsi/qla2xxx/qla_def.h:	struct completion *comp;
drivers/scsi/qla2xxx/qla_def.h:	 * Report completion status @res and call sp_put(@sp). @res is
drivers/scsi/qla2xxx/qla_def.h:	 * Report completion for asynchronous commands.
drivers/scsi/qla2xxx/qla_def.h:#define MBA_SCSI_COMPLETION	0x8020	/* SCSI Command Complete. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CTIO_COMPLETION	0x8021	/* CTIO Complete. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_IP_COMPLETION	0x8022	/* IP Transmit Command Complete. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_1_16BIT	0x8031	/* Completion 1 16bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_2_16BIT	0x8032	/* Completion 2 16bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_3_16BIT	0x8033	/* Completion 3 16bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_4_16BIT	0x8034	/* Completion 4 16bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_5_16BIT	0x8035	/* Completion 5 16bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:#define MBA_CMPLT_2_32BIT	0x8042	/* Completion 2 32bit IOSB. */
drivers/scsi/qla2xxx/qla_def.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_def.h: * Status entry completion status
drivers/scsi/qla2xxx/qla_def.h:	struct completion nvme_del_done;
drivers/scsi/qla2xxx/qla_def.h:	u32	cmd_completion_cnt;
drivers/scsi/qla2xxx/qla_def.h:	u32	prev_completion_cnt;
drivers/scsi/qla2xxx/qla_def.h:	struct completion mbx_cmd_comp; /* Serialize mbx access */
drivers/scsi/qla2xxx/qla_def.h:	struct completion mbx_intr_comp;  /* Used for completion notification */
drivers/scsi/qla2xxx/qla_def.h:	struct completion dcbx_comp;	/* For set port config notification */
drivers/scsi/qla2xxx/qla_def.h:	struct completion lb_portup_comp; /* Used to wait for link up during
drivers/scsi/qla2xxx/qla_def.h:	struct completion nvme_del_done;
drivers/scsi/qla2xxx/qla_edif.h:		__le16 comp_sts;              /* out: completion status */
drivers/scsi/qla2xxx/qla_fw.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h: * Status entry completion status
drivers/scsi/qla2xxx/qla_fw.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h:		__le16 comp_status;             /* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h:	__le16	comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_fw.h:        __le16	comp_status;           /* Completion status. */
drivers/scsi/qla2xxx/qla_gbl.h:extern void qla82xx_mbx_completion(scsi_qla_host_t *, uint16_t);
drivers/scsi/qla2xxx/qla_gs.c:				    "%s failed rejected request on port_id: %02x%02x%02x Completion status 0x%x, response 0x%x\n",
drivers/scsi/qla2xxx/qla_gs.c:			    "%s failed, completion status (%x) on port_id: "
drivers/scsi/qla2xxx/qla_gs.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/qla2xxx/qla_gs.c:	wait_for_completion(sp->comp);
drivers/scsi/qla2xxx/qla_init.c:	init_completion(&abt_iocb->u.abt.comp);
drivers/scsi/qla2xxx/qla_init.c:		wait_for_completion(&abt_iocb->u.abt.comp);
drivers/scsi/qla2xxx/qla_init.c:	qlt_logo_completion_handler(sp->fcport, sp->u.iocb_cmd.u.logio.data[0]);
drivers/scsi/qla2xxx/qla_init.c:	qlt_logo_completion_handler(fcport, data[0]);
drivers/scsi/qla2xxx/qla_init.c: * qla26xx_marker: send marker IOCB and wait for the completion of it.
drivers/scsi/qla2xxx/qla_init.c:	init_completion(&tm_iocb->u.tmf.comp);
drivers/scsi/qla2xxx/qla_init.c:	wait_for_completion(&tm_iocb->u.tmf.comp);
drivers/scsi/qla2xxx/qla_init.c:	init_completion(&tm_iocb->u.tmf.comp);
drivers/scsi/qla2xxx/qla_init.c:	wait_for_completion(&tm_iocb->u.tmf.comp);
drivers/scsi/qla2xxx/qla_init.c:	case IDC_AUDIT_COMPLETION:
drivers/scsi/qla2xxx/qla_init.c:		    (IDC_AUDIT_COMPLETION << 7) | (duration_secs << 8);
drivers/scsi/qla2xxx/qla_init.c:	/* For ISP82XX, driver waits for completion of the commands.
drivers/scsi/qla2xxx/qla_init.c:	 * Driver waits for the completion of the commands.
drivers/scsi/qla2xxx/qla_init.c:	ha->base_qpair->cmd_cnt = ha->base_qpair->cmd_completion_cnt = 0;
drivers/scsi/qla2xxx/qla_init.c:	ha->base_qpair->prev_completion_cnt = 0;
drivers/scsi/qla2xxx/qla_init.c:			    ha->queue_pair_map[i]->cmd_completion_cnt = 0;
drivers/scsi/qla2xxx/qla_init.c:			ha->base_qpair->prev_completion_cnt = 0;
drivers/scsi/qla2xxx/qla_inline.h:qla2x00_handle_mbx_completion(struct qla_hw_data *ha, int status)
drivers/scsi/qla2xxx/qla_iocb.c:	/* Specify response queue number where completion should happen */
drivers/scsi/qla2xxx/qla_iocb.c:		init_completion(&sp->u.iocb_cmd.u.fxiocb.fxiocb_comp);
drivers/scsi/qla2xxx/qla_iocb.c:	init_completion(&sp->u.iocb_cmd.u.els_logo.comp);
drivers/scsi/qla2xxx/qla_iocb.c:	wait_for_completion(&elsio->u.els_logo.comp);
drivers/scsi/qla2xxx/qla_iocb.c:		 * completion should happen
drivers/scsi/qla2xxx/qla_iocb.c:		 * completion should happen.
drivers/scsi/qla2xxx/qla_isr.c:static void qla2x00_mbx_completion(scsi_qla_host_t *, uint16_t);
drivers/scsi/qla2xxx/qla_isr.c:		    "%s: iocb failed to complete -> completion=%#x subcode=(%#x,%#x)\n",
drivers/scsi/qla2xxx/qla_isr.c:		    "%s: iocb failed to complete -> completion=%#x subcode=(%#x,%#x)\n",
drivers/scsi/qla2xxx/qla_isr.c:				qla2x00_mbx_completion(vha, mb[0]);
drivers/scsi/qla2xxx/qla_isr.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_isr.c:			qla2x00_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_isr.c:			mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_isr.c: * qla2x00_mbx_completion() - Process mailbox command completions.
drivers/scsi/qla2xxx/qla_isr.c:qla2x00_mbx_completion(scsi_qla_host_t *vha, uint16_t mb0)
drivers/scsi/qla2xxx/qla_isr.c:	/* Handle IDC Error completion case. */
drivers/scsi/qla2xxx/qla_isr.c:	/* Setup to process RIO completion. */
drivers/scsi/qla2xxx/qla_isr.c:	case MBA_SCSI_COMPLETION:
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:		mb[0] = MBA_SCSI_COMPLETION;
drivers/scsi/qla2xxx/qla_isr.c:	case MBA_SCSI_COMPLETION:	/* Fast Post */
drivers/scsi/qla2xxx/qla_isr.c:		    "[R|Z]IO update completion.\n");
drivers/scsi/qla2xxx/qla_isr.c:		/* Save ISP completion status */
drivers/scsi/qla2xxx/qla_isr.c:			"%s: Invalid completion handle (%x) -- timed-out.\n",
drivers/scsi/qla2xxx/qla_isr.c:		    "Async-%s error - hdl=%x completion status(%x).\n",
drivers/scsi/qla2xxx/qla_isr.c:		sp->qpair->cmd_completion_cnt++;
drivers/scsi/qla2xxx/qla_isr.c:		    "%s: Failed to complete IOCB -- completion status (%x) vpidx %x\n",
drivers/scsi/qla2xxx/qla_isr.c:		    "Invalid SCSI completion handle 0x%x.\n", index);
drivers/scsi/qla2xxx/qla_isr.c:		    "Req:%d: Invalid ISP SCSI completion handle(0x%x)\n",
drivers/scsi/qla2xxx/qla_isr.c:		    "Command completed with completion status=0x%x "
drivers/scsi/qla2xxx/qla_isr.c:	/* NVME completion. */
drivers/scsi/qla2xxx/qla_isr.c:	/* Task Management completion. */
drivers/scsi/qla2xxx/qla_isr.c:	/* Fast path completion. */
drivers/scsi/qla2xxx/qla_isr.c:	sp->qpair->cmd_completion_cnt++;
drivers/scsi/qla2xxx/qla_isr.c: * qla24xx_mbx_completion() - Process mailbox command completions.
drivers/scsi/qla2xxx/qla_isr.c:qla24xx_mbx_completion(scsi_qla_host_t *vha, uint16_t mb0)
drivers/scsi/qla2xxx/qla_isr.c:			qla24xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_isr.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_isr.c:			qla24xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_isr.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_mbx.c: *	Issue mailbox command and waits for completion.
drivers/scsi/qla2xxx/qla_mbx.c:	if (!wait_for_completion_timeout(&ha->mbx_cmd_comp, mcp->tov * HZ)) {
drivers/scsi/qla2xxx/qla_mbx.c:	/* Wait for mbx cmd completion until timeout */
drivers/scsi/qla2xxx/qla_mbx.c:		if (!wait_for_completion_timeout(&ha->mbx_intr_comp,
drivers/scsi/qla2xxx/qla_mbx.c:		    "Failed to complete IOCB -- completion  status (%x) "
drivers/scsi/qla2xxx/qla_mbx.c:			mb[10] |= BIT_7;	/* Confirmed Completion
drivers/scsi/qla2xxx/qla_mbx.c:		 * return ok even when the mailbox completion value is not
drivers/scsi/qla2xxx/qla_mbx.c: 		 * return ok even when the mailbox completion value is not
drivers/scsi/qla2xxx/qla_mbx.c:		    "Failed to complete IOCB -- completion status (%x) "
drivers/scsi/qla2xxx/qla_mbx.c:		    "Failed to complete IOCB -- completion status (%x).\n",
drivers/scsi/qla2xxx/qla_mbx.c:		    "Failed to complete IOCB -- completion status (%x).\n",
drivers/scsi/qla2xxx/qla_mbx.c:		    "Failed to complete IOCB -- completion status (%x).\n",
drivers/scsi/qla2xxx/qla_mbx.c:	init_completion(&c->u.mbx.comp);
drivers/scsi/qla2xxx/qla_mbx.c:	wait_for_completion(&c->u.mbx.comp);
drivers/scsi/qla2xxx/qla_mid.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/qla2xxx/qla_mid.c:	wait_for_completion(&comp);
drivers/scsi/qla2xxx/qla_mr.c: *	Issue mailbox command and waits for completion.
drivers/scsi/qla2xxx/qla_mr.c:	if (!wait_for_completion_timeout(&ha->mbx_cmd_comp, mcp->tov * HZ)) {
drivers/scsi/qla2xxx/qla_mr.c:	/* Wait for mbx cmd completion until timeout */
drivers/scsi/qla2xxx/qla_mr.c:		WARN_ON_ONCE(wait_for_completion_timeout(&ha->mbx_intr_comp,
drivers/scsi/qla2xxx/qla_mr.c:	wait_for_completion(&fdisc->u.fxiocb.fxiocb_comp);
drivers/scsi/qla2xxx/qla_mr.c:	/* Fast path completion. */
drivers/scsi/qla2xxx/qla_mr.c:	/* Setup to process RIO completion. */
drivers/scsi/qla2xxx/qla_mr.c: * qlafx00_mbx_completion() - Process mailbox command completions.
drivers/scsi/qla2xxx/qla_mr.c:qlafx00_mbx_completion(scsi_qla_host_t *vha, uint32_t mb0)
drivers/scsi/qla2xxx/qla_mr.c:			qlafx00_mbx_completion(vha, mb[0]);
drivers/scsi/qla2xxx/qla_mr.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_mr.c:	/* Specify response queue number where completion should happen */
drivers/scsi/qla2xxx/qla_mr.h:	__le16 comp_status;		/* Completion status. */
drivers/scsi/qla2xxx/qla_mr.h:	__le16 tgt_id_sts;		/* Completion status. */
drivers/scsi/qla2xxx/qla_nvme.c:	init_completion(&fcport->nvme_del_done);
drivers/scsi/qla2xxx/qla_nvme.c:	wait_for_completion(&fcport->nvme_del_done);
drivers/scsi/qla2xxx/qla_nvme.c:		init_completion(&vha->nvme_del_done);
drivers/scsi/qla2xxx/qla_nvme.c:			wait_for_completion(&vha->nvme_del_done);
drivers/scsi/qla2xxx/qla_nvme.c:		       "Invalid Abort IO IOCB Completion Status %x\n",
drivers/scsi/qla2xxx/qla_nx.c: * qla82xx_mbx_completion() - Process mailbox command completions.
drivers/scsi/qla2xxx/qla_nx.c:qla82xx_mbx_completion(scsi_qla_host_t *vha, uint16_t mb0)
drivers/scsi/qla2xxx/qla_nx.c:				qla82xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_nx.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_nx.c:				qla82xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_nx.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_nx.c:			qla82xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_nx.c:		    "Doing premature completion of mbx command.\n");
drivers/scsi/qla2xxx/qla_nx2.c:				qla82xx_mbx_completion(vha, MSW(stat));
drivers/scsi/qla2xxx/qla_nx2.c:	qla2x00_handle_mbx_completion(ha, status);
drivers/scsi/qla2xxx/qla_os.c:	struct completion *comp = sp->comp;
drivers/scsi/qla2xxx/qla_os.c:	struct completion *comp = sp->comp;
drivers/scsi/qla2xxx/qla_os.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/qla2xxx/qla_os.c:	/* Wait for the command completion. */
drivers/scsi/qla2xxx/qla_os.c:		if (!wait_for_completion_timeout(&comp, ratov_j)) {
drivers/scsi/qla2xxx/qla_os.c:	"Waiting for command completions",
drivers/scsi/qla2xxx/qla_os.c: * The caller must ensure that no completion interrupts will happen
drivers/scsi/qla2xxx/qla_os.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/qla2xxx/qla_os.c:		/* Wait for command completion. */
drivers/scsi/qla2xxx/qla_os.c:			if (wait_for_completion_timeout(&comp, ratov_j)) {
drivers/scsi/qla2xxx/qla_os.c: * The caller must ensure that no completion interrupts will happen
drivers/scsi/qla2xxx/qla_os.c: * The caller must ensure that no completion interrupts will happen
drivers/scsi/qla2xxx/qla_os.c:	init_completion(&ha->mbx_cmd_comp);
drivers/scsi/qla2xxx/qla_os.c:	init_completion(&ha->mbx_intr_comp);
drivers/scsi/qla2xxx/qla_os.c:	init_completion(&ha->dcbx_comp);
drivers/scsi/qla2xxx/qla_os.c:	init_completion(&ha->lb_portup_comp);
drivers/scsi/qla2xxx/qla_os.c:		    "%s: iocb failed to complete -> completion=%#x subcode=(%#x,%#x)\n",
drivers/scsi/qla2xxx/qla_os.c:				    IDC_AUDIT_COMPLETION);
drivers/scsi/qla2xxx/qla_os.c:				    IDC_AUDIT_COMPLETION);
drivers/scsi/qla2xxx/qla_os.c:	cmpl_cnt = ha->base_qpair->cmd_completion_cnt;
drivers/scsi/qla2xxx/qla_os.c:	if (cmpl_cnt == ha->base_qpair->prev_completion_cnt &&
drivers/scsi/qla2xxx/qla_os.c:	ha->base_qpair->prev_completion_cnt = cmpl_cnt;
drivers/scsi/qla2xxx/qla_os.c:			cmpl_cnt = ha->queue_pair_map[i]->cmd_completion_cnt;
drivers/scsi/qla2xxx/qla_os.c:			if (cmpl_cnt == ha->queue_pair_map[i]->prev_completion_cnt &&
drivers/scsi/qla2xxx/qla_os.c:			ha->queue_pair_map[i]->prev_completion_cnt = cmpl_cnt;
drivers/scsi/qla2xxx/qla_sup.c:	/* Enable flash write-protection and wait for completion. */
drivers/scsi/qla2xxx/qla_sup.c: * qla2x00_poll_flash() - Polls flash for completion.
drivers/scsi/qla2xxx/qla_target.c:		qlt_logo_completion_handler(sp->fcport, MBS_COMMAND_COMPLETE);
drivers/scsi/qla2xxx/qla_target.c:	    "s_id %x:%x:%x, confirmed completion %ssupported) added\n",
drivers/scsi/qla2xxx/qla_target.c:	ctio->handle = QLA_TGT_SKIP_HANDLE |	CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:	ctio->handle = QLA_TGT_SKIP_HANDLE | CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle |= CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle |= CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:		 * Will not wait for completion.
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle = QLA_TGT_SKIP_HANDLE | CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:		 *  1) XFER Rdy completion + CMD_T_ABORT
drivers/scsi/qla2xxx/qla_target.c:		    "qla_target(%d): CTIO completion with different QID %d handle %x\n",
drivers/scsi/qla2xxx/qla_target.c:static void qlt_do_ctio_completion(struct scsi_qla_host *vha,
drivers/scsi/qla2xxx/qla_target.c:void qlt_logo_completion_handler(fc_port_t *fcport, int rc)
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle = QLA_TGT_SKIP_HANDLE | CTIO_COMPLETION_HANDLE_MARK;
drivers/scsi/qla2xxx/qla_target.c:static void qlt_handle_abts_completion(struct scsi_qla_host *vha,
drivers/scsi/qla2xxx/qla_target.c:		qlt_do_ctio_completion(vha, rsp, entry->handle,
drivers/scsi/qla2xxx/qla_target.c:		qlt_do_ctio_completion(vha, rsp, entry->handle,
drivers/scsi/qla2xxx/qla_target.c:		qlt_do_ctio_completion(vha, rsp, entry->handle,
drivers/scsi/qla2xxx/qla_target.c:			qlt_handle_abts_completion(vha, rsp, pkt);
drivers/scsi/qla2xxx/qla_target.h: * Used to mark which completion handles (for RIO Status's) are for CTIO's
drivers/scsi/qla2xxx/qla_target.h:#define CTIO_COMPLETION_HANDLE_MARK	BIT_29
drivers/scsi/qla2xxx/qla_target.h:#if (CTIO_COMPLETION_HANDLE_MARK <= DEFAULT_OUTSTANDING_COMMANDS)
drivers/scsi/qla2xxx/qla_target.h:#error "CTIO_COMPLETION_HANDLE_MARK not larger than "
drivers/scsi/qla2xxx/qla_target.h:#define HANDLE_IS_CTIO_COMP(h) (h & CTIO_COMPLETION_HANDLE_MARK)
drivers/scsi/qla2xxx/qla_target.h: *		The ABTS response with completion status to the ABTS response
drivers/scsi/qla2xxx/qla_target.h:	 * This variable may be set from outside the LIO and I/O completion
drivers/scsi/qla2xxx/qla_target.h:extern void qlt_logo_completion_handler(fc_port_t *, int);
drivers/scsi/qla2xxx/tcm_qla2xxx.c: * Called from qla_target.c:qlt_do_ctio_completion()
drivers/scsi/qla4xxx/ql4_bsg.c:	if (!wait_for_completion_timeout(&ha->idc_comp, (IDC_COMP_TOV * HZ))) {
drivers/scsi/qla4xxx/ql4_bsg.c:			if (!wait_for_completion_timeout(&ha->idc_comp,
drivers/scsi/qla4xxx/ql4_bsg.c:		if (!wait_for_completion_timeout(&ha->link_up_comp,
drivers/scsi/qla4xxx/ql4_def.h:	struct completion mbx_intr_comp;
drivers/scsi/qla4xxx/ql4_def.h:	struct completion disable_acb_comp;
drivers/scsi/qla4xxx/ql4_def.h:	struct completion idc_comp;
drivers/scsi/qla4xxx/ql4_def.h:	struct completion link_up_comp;
drivers/scsi/qla4xxx/ql4_fw.h:	__le32 rsp_q_out;   /* SCSI Completion Queue Consumer Index */
drivers/scsi/qla4xxx/ql4_fw.h:#define CSR_SCSI_COMPLETION_INTR		0x00000010
drivers/scsi/qla4xxx/ql4_fw.h:#define INTR_PENDING				(CSR_SCSI_COMPLETION_INTR |\
drivers/scsi/qla4xxx/ql4_fw.h:	/* SCSI Completion Queue Producer Index */
drivers/scsi/qla4xxx/ql4_fw.h:#define MBOX_COMPLETION_STATUS			4
drivers/scsi/qla4xxx/ql4_fw.h:#define MBOX_STS_INTERMEDIATE_COMPLETION	0x1000
drivers/scsi/qla4xxx/ql4_fw.h:	uint8_t completionStatus;	/* 0B */
drivers/scsi/qla4xxx/ql4_fw.h:	uint8_t completionStatus;	/* 0C */
drivers/scsi/qla4xxx/ql4_glbl.h:void qla4xxx_mailbox_premature_completion(struct scsi_qla_host *ha);
drivers/scsi/qla4xxx/ql4_init.c:			writel(set_rmask(CSR_SCSI_COMPLETION_INTR),
drivers/scsi/qla4xxx/ql4_iocb.c: * This routine notifies the ISP that one or more response/completion
drivers/scsi/qla4xxx/ql4_iocb.c: * This routine is notifies the ISP that one or more response/completion
drivers/scsi/qla4xxx/ql4_isr.c:	switch (sts_entry->completionStatus) {
drivers/scsi/qla4xxx/ql4_isr.c:		     (sts_entry->completionStatus == SCS_DATA_OVERRUN)) {
drivers/scsi/qla4xxx/ql4_isr.c:		    cmd->device->lun, sts_entry->completionStatus));
drivers/scsi/qla4xxx/ql4_isr.c:			      sts_entry->completionStatus,
drivers/scsi/qla4xxx/ql4_isr.c:	srb->cc_stat = sts_entry->completionStatus;
drivers/scsi/qla4xxx/ql4_isr.c: * qla4xxx_process_response_queue - process response queue completions
drivers/scsi/qla4xxx/ql4_isr.c: * This routine process response queue completions in interrupt context.
drivers/scsi/qla4xxx/ql4_isr.c:		      sts_entry->completionStatus));
drivers/scsi/qla4xxx/ql4_isr.c:	    (mbox_status == MBOX_STS_INTERMEDIATE_COMPLETION) ||
drivers/scsi/qla4xxx/ql4_isr.c:	    (mbox_status >> 12 == MBOX_COMPLETION_STATUS)) {
drivers/scsi/qla4xxx/ql4_isr.c:	if (intr_status & CSR_SCSI_COMPLETION_INTR)
drivers/scsi/qla4xxx/ql4_isr.c:			intr_status = CSR_SCSI_COMPLETION_INTR;
drivers/scsi/qla4xxx/ql4_mbx.c: * This routine issue mailbox commands and waits for completion.
drivers/scsi/qla4xxx/ql4_mbx.c:	/* Wait for completion */
drivers/scsi/qla4xxx/ql4_mbx.c:	 * you must poll the inbound Interrupt Mask for completion.
drivers/scsi/qla4xxx/ql4_mbx.c:	 * Wait for completion: Poll or completion queue
drivers/scsi/qla4xxx/ql4_mbx.c:		/* Do not poll for completion. Use completion queue */
drivers/scsi/qla4xxx/ql4_mbx.c:		wait_for_completion_timeout(&ha->mbx_intr_comp, MBOX_TOV * HZ);
drivers/scsi/qla4xxx/ql4_mbx.c:	case MBOX_STS_INTERMEDIATE_COMPLETION:
drivers/scsi/qla4xxx/ql4_mbx.c:void qla4xxx_mailbox_premature_completion(struct scsi_qla_host *ha)
drivers/scsi/qla4xxx/ql4_mbx.c:			    "recovery, doing premature completion of "
drivers/scsi/qla4xxx/ql4_mbx.c:			    "recovery, doing premature completion of "
drivers/scsi/qla4xxx/ql4_mbx.c:	/* Do not wait for completion. The firmware will send us an
drivers/scsi/qla4xxx/ql4_mbx.c:	/* Firmware already posted completion on response queue */
drivers/scsi/qla4xxx/ql4_mbx.c:			if (!wait_for_completion_timeout(&ha->disable_acb_comp,
drivers/scsi/qla4xxx/ql4_mbx.c:				ql4_printk(KERN_WARNING, ha, "%s: Disable ACB Completion not received\n",
drivers/scsi/qla4xxx/ql4_os.c:	wait_for_completion_timeout(&ha->disable_acb_comp,
drivers/scsi/qla4xxx/ql4_os.c:	switch (sts->completionStatus) {
drivers/scsi/qla4xxx/ql4_os.c:			   sts->completionStatus);
drivers/scsi/qla4xxx/ql4_os.c: * completion handling).   Unfortunely, it sometimes calls the scheduler
drivers/scsi/qla4xxx/ql4_os.c:	qla4xxx_mailbox_premature_completion(ha);
drivers/scsi/qla4xxx/ql4_os.c:					qla4xxx_mailbox_premature_completion(
drivers/scsi/qla4xxx/ql4_os.c:				qla4xxx_mailbox_premature_completion(ha);
drivers/scsi/qla4xxx/ql4_os.c:		/* NOTE: AF_ONLINE flag set upon successful completion of
drivers/scsi/qla4xxx/ql4_os.c:	init_completion(&ha->mbx_intr_comp);
drivers/scsi/qla4xxx/ql4_os.c:	init_completion(&ha->disable_acb_comp);
drivers/scsi/qla4xxx/ql4_os.c:	init_completion(&ha->idc_comp);
drivers/scsi/qla4xxx/ql4_os.c:	init_completion(&ha->link_up_comp);
drivers/scsi/qla4xxx/ql4_os.c:	 * NOTE: interrupts enabled upon successful completion
drivers/scsi/qla4xxx/ql4_os.c:	wait_for_completion_timeout(&ha->disable_acb_comp,
drivers/scsi/qla4xxx/ql4_os.c:		qla4xxx_mailbox_premature_completion(ha);
drivers/scsi/qlogicpti.c: * request-completion handling).
drivers/scsi/qlogicpti.c:	switch (sts->completion_status) {
drivers/scsi/qlogicpti.c:		printk(KERN_EMERG "qlogicpti%d: unknown completion status 0x%04x\n",
drivers/scsi/qlogicpti.c:		       id, sts->completion_status);
drivers/scsi/qlogicpti.c:		if (sts->completion_status == CS_RESET_OCCURRED ||
drivers/scsi/qlogicpti.c:		    sts->completion_status == CS_ABORTED ||
drivers/scsi/qlogicpti.h:	u16			completion_status;
drivers/scsi/qlogicpti.h:/* status entry completion status definitions */
drivers/scsi/scsi.c:#include <linux/completion.h>
drivers/scsi/scsi.c:	 * 1: nothing (match completion)
drivers/scsi/scsi.c:void scsi_log_completion(struct scsi_cmnd *cmd, int disposition)
drivers/scsi/scsi.c:	 * 2: same as 1 but for all command completions.
drivers/scsi/scsi.c:				"Notifying upper driver of completion "
drivers/scsi/scsi.c:		 * change to the completion length.
drivers/scsi/scsi.c:	scsi_io_completion(cmd, good_bytes);
drivers/scsi/scsi_debug.c:static atomic_t sdebug_completions;  /* count of deferred completions */
drivers/scsi/scsi_debug.c:static atomic_t sdebug_miss_cpus;    /* submission + completion cpus differ */
drivers/scsi/scsi_debug.c: * command completion, they can mask their return value with
drivers/scsi/scsi_debug.c:/* Queued (deferred) command completions converge here. */
drivers/scsi/scsi_debug.c:		atomic_inc(&sdebug_completions);
drivers/scsi/scsi_debug.c: * finish. We cannot call scsi_done() as normal completion path may do that.
drivers/scsi/scsi_debug.c:	atomic_set(&sdebug_completions, 0);
drivers/scsi/scsi_debug.c:			 * The completion handler will try to grab sqcp->lock,
drivers/scsi/scsi_debug.c:			 * so there is no chance that the completion handler
drivers/scsi/scsi_debug.c:	seq_printf(m, "cmnd_count=%d, completions=%d, %s=%d, a_tsf=%d, mq_polls=%d\n",
drivers/scsi/scsi_debug.c:		   atomic_read(&sdebug_completions),
drivers/scsi/scsi_debug.c:		atomic_inc(&sdebug_completions);
drivers/scsi/scsi_dh.c: * @fn   - Function to be called upon completion of the activation.
drivers/scsi/scsi_dh.c: * @data - data passed to the function fn upon completion.
drivers/scsi/scsi_error.c: *     only in that the normal completion handling might run, but if the
drivers/scsi/scsi_error.c: *     normal completion function determines that the timer has already
drivers/scsi/scsi_error.c:	scsi_log_completion(scmd, TIMEOUT_ERROR);
drivers/scsi/scsi_error.c:		 * Pass the UA upwards for a determination in the completion
drivers/scsi/scsi_error.c: * scsi_eh_done - Completion function for error handling.
drivers/scsi/scsi_error.c:	struct completion *eh_action;
drivers/scsi/scsi_error.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/scsi/scsi_error.c:		timeleft = wait_for_completion_timeout(&done, timeout);
drivers/scsi/scsi_error.c:	scsi_log_completion(scmd, rtn);
drivers/scsi/scsi_error.c: *    We don't want to use the normal command completion while we are are
drivers/scsi/scsi_error.c: *    keep a list of pending commands for final completion, and once we
drivers/scsi/scsi_error.c: *    are ready to leave error handling we handle completion for real.
drivers/scsi/scsi_error.c:			 * finish this command, so force completion by setting
drivers/scsi/scsi_lib.c:#include <linux/completion.h>
drivers/scsi/scsi_lib.c: * because it's always called before the completion.  This function is
drivers/scsi/scsi_lib.c: * for a requeue after completion, which should only occur in this
drivers/scsi/scsi_lib.c: * Called for single_lun devices on IO completion. Clear starget_sdev_user,
drivers/scsi/scsi_lib.c:/* Helper for scsi_io_completion() when special action required. */
drivers/scsi/scsi_lib.c:static void scsi_io_completion_action(struct scsi_cmnd *cmd, int result)
drivers/scsi/scsi_lib.c:			 * in scsi_log_completion(), so avoid duplicate messages
drivers/scsi/scsi_lib.c: * Helper for scsi_io_completion() when cmd->result is non-zero. Returns a
drivers/scsi/scsi_lib.c:static int scsi_io_completion_nz_result(struct scsi_cmnd *cmd, int result,
drivers/scsi/scsi_lib.c: * scsi_io_completion - Completion processing for SCSI commands.
drivers/scsi/scsi_lib.c: *   b) We can call scsi_io_completion_action().  The request will be
drivers/scsi/scsi_lib.c:void scsi_io_completion(struct scsi_cmnd *cmd, unsigned int good_bytes)
drivers/scsi/scsi_lib.c:		result = scsi_io_completion_nz_result(cmd, result, &blk_stat);
drivers/scsi/scsi_lib.c:		scsi_io_completion_action(cmd, result);
drivers/scsi/scsi_lib.c: * Block layer request completion callback. May be called from interrupt
drivers/scsi/scsi_lib.c:	scsi_log_completion(cmd, disposition);
drivers/scsi/scsi_lib.c:	 * soon. Otherwise, completion of one of these requests will observe
drivers/scsi/scsi_priv.h:void scsi_log_completion(struct scsi_cmnd *cmd, int disposition);
drivers/scsi/scsi_priv.h:static inline void scsi_log_completion(struct scsi_cmnd *cmd, int disposition)
drivers/scsi/scsi_priv.h:extern void scsi_io_completion(struct scsi_cmnd *, unsigned int);
drivers/scsi/scsi_scan.c:	struct completion prev_finished;
drivers/scsi/scsi_scan.c:	init_completion(&data->prev_finished);
drivers/scsi/scsi_scan.c:	wait_for_completion(&data->prev_finished);
drivers/scsi/scsi_scan.c:	init_completion(&data->prev_finished);
drivers/scsi/scsi_scan.c:	wait_for_completion(&data->prev_finished);
drivers/scsi/scsi_transport_iscsi.c: * iscsi_session_event - send session destr. completion event
drivers/scsi/sd.c: *	This function is called by the SCSI midlayer upon completion of an
drivers/scsi/sd.c:		 * an unaligned partial completion. Check this here and force
drivers/scsi/sd.c:				"Unaligned partial completion (resid=%u, sector_sz=%u)\n",
drivers/scsi/sense_codes.h:SENSE_CODE(0x4B0F, "PCIe completion timeout")
drivers/scsi/smartpqi/smartpqi.h:#define PQI_DATA_IN_OUT_PCIE_COMPLETION_TIMEOUT			0x61
drivers/scsi/smartpqi/smartpqi_init.c:#define PQI_NO_COMPLETION	((void *)-1)
drivers/scsi/smartpqi/smartpqi_init.c:	case PQI_DATA_IN_OUT_PCIE_COMPLETION_TIMEOUT:
drivers/scsi/smartpqi/smartpqi_init.c:		 * returning from the I/O completion callback!
drivers/scsi/smartpqi/smartpqi_init.c:#define PQI_WAIT_FOR_COMPLETION_IO_TIMEOUT_SECS		10
drivers/scsi/smartpqi/smartpqi_init.c:static int pqi_wait_for_completion_io(struct pqi_ctrl_info *ctrl_info,
drivers/scsi/smartpqi/smartpqi_init.c:	struct completion *wait)
drivers/scsi/smartpqi/smartpqi_init.c:		if (wait_for_completion_io_timeout(wait,
drivers/scsi/smartpqi/smartpqi_init.c:			PQI_WAIT_FOR_COMPLETION_IO_TIMEOUT_SECS * HZ)) {
drivers/scsi/smartpqi/smartpqi_init.c:	struct completion *waiting = context;
drivers/scsi/smartpqi/smartpqi_init.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/smartpqi/smartpqi_init.c:	pqi_wait_for_completion_io(ctrl_info, &wait);
drivers/scsi/smartpqi/smartpqi_init.c:	struct completion *wait;
drivers/scsi/smartpqi/smartpqi_init.c:	wait = (struct completion *)xchg(&scmd->host_scribble, NULL);
drivers/scsi/smartpqi/smartpqi_init.c:	if (wait != PQI_NO_COMPLETION)
drivers/scsi/smartpqi/smartpqi_init.c:	scmd->host_scribble = PQI_NO_COMPLETION;
drivers/scsi/smartpqi/smartpqi_init.c:	struct completion *waiting = context;
drivers/scsi/smartpqi/smartpqi_init.c:#define PQI_LUN_RESET_POLL_COMPLETION_SECS	10
drivers/scsi/smartpqi/smartpqi_init.c:static int pqi_wait_for_lun_reset_completion(struct pqi_ctrl_info *ctrl_info,
drivers/scsi/smartpqi/smartpqi_init.c:	struct pqi_scsi_dev *device, u8 lun, struct completion *wait)
drivers/scsi/smartpqi/smartpqi_init.c:		if (wait_for_completion_io_timeout(wait,
drivers/scsi/smartpqi/smartpqi_init.c:			PQI_LUN_RESET_POLL_COMPLETION_SECS * HZ)) {
drivers/scsi/smartpqi/smartpqi_init.c:		wait_secs += PQI_LUN_RESET_POLL_COMPLETION_SECS;
drivers/scsi/smartpqi/smartpqi_init.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/smartpqi/smartpqi_init.c:	rc = pqi_wait_for_lun_reset_completion(ctrl_info, device, lun, &wait);
drivers/scsi/smartpqi/smartpqi_init.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/smartpqi/smartpqi_init.c:	if (cmpxchg(&scmd->host_scribble, PQI_NO_COMPLETION, (void *)&wait) == NULL) {
drivers/scsi/smartpqi/smartpqi_init.c:	wait_for_completion(&wait);
drivers/scsi/smartpqi/smartpqi_init.c:	case PQI_DATA_IN_OUT_PCIE_COMPLETION_TIMEOUT:
drivers/scsi/smartpqi/smartpqi_init.c:static int pqi_wait_for_pqi_reset_completion(struct pqi_ctrl_info *ctrl_info)
drivers/scsi/smartpqi/smartpqi_init.c:	rc = pqi_wait_for_pqi_reset_completion(ctrl_info);
drivers/scsi/smartpqi/smartpqi_init.c:			rc = sis_wait_for_fw_triage_completion(ctrl_info);
drivers/scsi/smartpqi/smartpqi_init.c:			rc = sis_wait_for_ctrl_logging_completion(ctrl_info);
drivers/scsi/smartpqi/smartpqi_init.c:static inline int pqi_set_pcie_completion_timeout(struct pci_dev *pci_dev, u16 timeout)
drivers/scsi/smartpqi/smartpqi_init.c:	/* Increase the PCIe completion timeout. */
drivers/scsi/smartpqi/smartpqi_init.c:	rc = pqi_set_pcie_completion_timeout(ctrl_info->pci_dev,
drivers/scsi/smartpqi/smartpqi_init.c:			"failed to set PCIe completion timeout\n");
drivers/scsi/smartpqi/smartpqi_sis.c:	 * Force the completion of the interrupt mask register write before
drivers/scsi/smartpqi/smartpqi_sis.c:	 * Poll for command completion.  Note that the call to msleep() is at
drivers/scsi/smartpqi/smartpqi_sis.c:int sis_wait_for_fw_triage_completion(struct pqi_ctrl_info *ctrl_info)
drivers/scsi/smartpqi/smartpqi_sis.c:int sis_wait_for_ctrl_logging_completion(struct pqi_ctrl_info *ctrl_info)
drivers/scsi/smartpqi/smartpqi_sis.h:int sis_wait_for_fw_triage_completion(struct pqi_ctrl_info *ctrl_info);
drivers/scsi/smartpqi/smartpqi_sis.h:int sis_wait_for_ctrl_logging_completion(struct pqi_ctrl_info *ctrl_info);
drivers/scsi/snic/cq_desc.h: * Completion queue descriptor types
drivers/scsi/snic/cq_desc.h:/* Completion queue descriptor: 16B
drivers/scsi/snic/cq_desc.h: * All completion queues have this basic layout.  The
drivers/scsi/snic/cq_desc.h: * type_specific area is unique for each completion
drivers/scsi/snic/cq_enet_desc.h:/* Ethernet completion queue descriptor: 16B */
drivers/scsi/snic/snic.h:	struct completion *wait;	/* protected by snic lock*/
drivers/scsi/snic/snic.h:	struct completion *remove_wait;
drivers/scsi/snic/snic.h:	/* completion queue cache line section */
drivers/scsi/snic/snic_ctl.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/snic/snic_ctl.c:		wait_for_completion_timeout(&wait, msecs_to_jiffies(2000));
drivers/scsi/snic/snic_debugfs.c:		 * and IO Completions stats. Skip incrementing No IO Compls
drivers/scsi/snic/snic_debugfs.c:		   "Max Completion Time         : %lld\n"
drivers/scsi/snic/snic_fwint.h:	SNIC_RSP_REPORT_TGTS_CMPL = 0x12,/* Report Targets Completion */
drivers/scsi/snic/snic_fwint.h:	SNIC_RSP_ICMND_CMPL,		/* SCSI IO Completion */
drivers/scsi/snic/snic_fwint.h:	SNIC_RSP_ITMF_CMPL,		/* Task Management Completion */
drivers/scsi/snic/snic_fwint.h:	SNIC_RSP_HBA_RESET_CMPL,	/* SNIC Reset Completion */
drivers/scsi/snic/snic_fwint.h:	SNIC_RSP_EXCH_VER_CMPL,		/* Exchange Version Completion*/
drivers/scsi/snic/snic_io.h:	u32	abts_status;	/* Abort completion status */
drivers/scsi/snic/snic_io.h:	u32	lr_status;	/* device reset completion status */
drivers/scsi/snic/snic_io.h:	struct completion *abts_done;
drivers/scsi/snic/snic_io.h:	struct completion *dr_done;
drivers/scsi/snic/snic_main.c: * snic_vdev_open_done : polls for svnic_dev_open cmd completion.
drivers/scsi/snic/snic_scsi.c:	/* Freeing cmd without marking completion, not okay */
drivers/scsi/snic/snic_scsi.c: * Routine to handle icmnd completions
drivers/scsi/snic/snic_scsi.c:	 * ignore completion of the IO. The abts path will clean it up
drivers/scsi/snic/snic_scsi.c:			      "itmf_cmpl:Dev Reset Completion Received after timeout. id %d cmpl status %s flags 0x%llx\n",
drivers/scsi/snic/snic_scsi.c: * snic_update_abort_stats : Updates abort stats based on completion status.
drivers/scsi/snic/snic_scsi.c:			/* This is a late completion. Ignore it. */
drivers/scsi/snic/snic_scsi.c:		 * signal completion to it. IO will be cleaned in the thread,
drivers/scsi/snic/snic_scsi.c:		/* Abort and terminate completion of device reset req */
drivers/scsi/snic/snic_scsi.c: * Routine to handle itmf completions.
drivers/scsi/snic/snic_scsi.c:		       "reset_cmpl:Tag %d ctx %lx cmpl status %s HBA Reset Completion received.\n",
drivers/scsi/snic/snic_scsi.c: * Routine to process CQ entries(IO Completions) posted by fw.
drivers/scsi/snic/snic_scsi.c:			      "Unknown Firmware completion request type %d\n",
drivers/scsi/snic/snic_scsi.c:	 * use try_wait_for_completion and completion_done() to check
drivers/scsi/snic/snic_scsi.c:	 * whether it queues aborts even after completion of abort issued
drivers/scsi/snic/snic_scsi.c:	 * prior.SNIC_BUG_ON(completion_done(&rqi->done));
drivers/scsi/snic/snic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/snic/snic_scsi.c:	 * happend, the completion wont actually complete the command
drivers/scsi/snic/snic_scsi.c:	 * the completion won't be done till mid-layer, since abot
drivers/scsi/snic/snic_scsi.c:	 * Queued an abort IO, wait for its completion.
drivers/scsi/snic/snic_scsi.c:	wait_for_completion_timeout(&tm_done, SNIC_ABTS_TIMEOUT);
drivers/scsi/snic/snic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/snic/snic_scsi.c:	wait_for_completion_timeout(&tm_done, SNIC_ABTS_TIMEOUT);
drivers/scsi/snic/snic_scsi.c:	DECLARE_COMPLETION_ONSTACK(tm_done);
drivers/scsi/snic/snic_scsi.c:	wait_for_completion_timeout(&tm_done, SNIC_LUN_RESET_TIMEOUT);
drivers/scsi/snic/snic_scsi.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/scsi/snic/snic_scsi.c:	wait_for_completion_timeout(snic->remove_wait,
drivers/scsi/snic/snic_scsi.c:	 * CASE : FW didn't post itmf completion due to PCIe Errors.
drivers/scsi/snic/snic_scsi.c:	 * Marking the abort status as Success to call scsi completion
drivers/scsi/snic/snic_scsi.c:			 * When FW Completes reset w/o sending completions
drivers/scsi/snic/snic_stats.h:	atomic64_t compl;		/* IO Completions */
drivers/scsi/snic/snic_stats.h:	atomic64_t hba_reset_cmpl;	/* hba/firmware reset completions */
drivers/scsi/snic/snic_stats.h:	atomic64_t snic_reset_compl;	/* snic reset completions */
drivers/scsi/snic/snic_stats.h:/* Auxillary function to update IO completion counter */
drivers/scsi/snic/vnic_cq.h:/* Completion queue control */
drivers/scsi/snic/vnic_devcmd.h:	u8  color;              /* 0 or 1 as with completion queues */
drivers/scsi/snic/vnic_resource.h:	RES_TYPE_CQ,			/* Completion queues */
drivers/scsi/snic/vnic_resource.h:	RES_TYPE_MQ_CQ,			/* MQ Completion queues */
drivers/scsi/st.c:	struct completion *waiting;
drivers/scsi/st.c:	init_completion(waiting);
drivers/scsi/st.c:		wait_for_completion(waiting);
drivers/scsi/st.c:/* Handle the write-behind checking (waits for completion). Returns -ENOSPC if
drivers/scsi/st.c:	wait_for_completion(&(STp->wait));
drivers/scsi/st.c:		cmd[1] = 1;	/* Don't wait for completion */
drivers/scsi/st.c:			cmd[1] = 1;	/* Don't wait for completion */
drivers/scsi/st.c:			cmd[1] = 1;	/* Don't wait for completion */
drivers/scsi/st.c:			cmd[1] |= 2;	/* Don't wait for completion */
drivers/scsi/st.c:		scmd[1] |= 1;		/* Don't wait for completion */
drivers/scsi/st.c:		scmd[1] |= 1;		/* Don't wait for completion */
drivers/scsi/st.h:#include <linux/completion.h>
drivers/scsi/st.h:	struct completion *waiting;
drivers/scsi/st.h:	struct completion wait;	/* For SCSI commands */
drivers/scsi/storvsc_drv.c:#include <linux/completion.h>
drivers/scsi/storvsc_drv.c: * This flag indicates that the server should send back a completion for this
drivers/scsi/storvsc_drv.c:#define REQUEST_COMPLETION_FLAG	0x1
drivers/scsi/storvsc_drv.c:	struct completion wait_event;
drivers/scsi/storvsc_drv.c:	init_completion(&request->wait_event);
drivers/scsi/storvsc_drv.c:	vstor_packet->flags = REQUEST_COMPLETION_FLAG;
drivers/scsi/storvsc_drv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/scsi/storvsc_drv.c:	t = wait_for_completion_timeout(&request->wait_event, 10*HZ);
drivers/scsi/storvsc_drv.c:	init_completion(&request->wait_event);
drivers/scsi/storvsc_drv.c:	vstor_packet->flags = REQUEST_COMPLETION_FLAG;
drivers/scsi/storvsc_drv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/scsi/storvsc_drv.c:	t = wait_for_completion_timeout(&request->wait_event, 5*HZ);
drivers/scsi/storvsc_drv.c:static void storvsc_command_completion(struct storvsc_cmd_request *cmd_request,
drivers/scsi/storvsc_drv.c:static void storvsc_on_io_completion(struct storvsc_device *stor_device,
drivers/scsi/storvsc_drv.c:	storvsc_command_completion(request, stor_device);
drivers/scsi/storvsc_drv.c:		storvsc_on_io_completion(stor_device, vstor_packet, request);
drivers/scsi/storvsc_drv.c:				 *   we call storvsc_on_io_completion(), and dereference the
drivers/scsi/storvsc_drv.c:				 *   storvsc_on_io_completion() with a guest memory address
drivers/scsi/storvsc_drv.c:	vstor_packet->flags |= REQUEST_COMPLETION_FLAG;
drivers/scsi/storvsc_drv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/scsi/storvsc_drv.c:	init_completion(&request->wait_event);
drivers/scsi/storvsc_drv.c:	vstor_packet->flags = REQUEST_COMPLETION_FLAG;
drivers/scsi/storvsc_drv.c:			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
drivers/scsi/storvsc_drv.c:	t = wait_for_completion_timeout(&request->wait_event, 5*HZ);
drivers/scsi/sym53c8xx_2/sym_fw1.h:	 *  We donnot want the CPU to deal with completions  
drivers/scsi/sym53c8xx_2/sym_fw1.h:	 *  completions.
drivers/scsi/sym53c8xx_2/sym_fw1.h:	 *  signal completion to the host.
drivers/scsi/sym53c8xx_2/sym_fw2.h:	 *  We donnot want the CPU to deal with completions  
drivers/scsi/sym53c8xx_2/sym_fw2.h:	 *  completions.
drivers/scsi/sym53c8xx_2/sym_fw2.h:	 *  signal completion to the host.
drivers/scsi/sym53c8xx_2/sym_glue.c:	struct completion *eh_done;		/* SCSI error handling */
drivers/scsi/sym53c8xx_2/sym_glue.c:#ifdef SYM_CONF_PCIQ_MAY_MISS_COMPLETIONS
drivers/scsi/sym53c8xx_2/sym_glue.c:	 *  completions being lost when the clearing 
drivers/scsi/sym53c8xx_2/sym_glue.c:	 *  If this ever happen, lost completions will 
drivers/scsi/sym53c8xx_2/sym_glue.c:	struct completion eh_done;
drivers/scsi/sym53c8xx_2/sym_glue.c:	/* This one is queued in some place -> to wait for completion */
drivers/scsi/sym53c8xx_2/sym_glue.c:		init_completion(&eh_done);
drivers/scsi/sym53c8xx_2/sym_glue.c:		if (!wait_for_completion_timeout(&eh_done, 5*HZ)) {
drivers/scsi/sym53c8xx_2/sym_glue.c:	struct completion eh_done;
drivers/scsi/sym53c8xx_2/sym_glue.c:			init_completion(&eh_done);
drivers/scsi/sym53c8xx_2/sym_glue.c:			if (!wait_for_completion_timeout(&eh_done, 5*HZ)) {
drivers/scsi/sym53c8xx_2/sym_glue.c:	struct completion eh_done;
drivers/scsi/sym53c8xx_2/sym_glue.c:		init_completion(&eh_done);
drivers/scsi/sym53c8xx_2/sym_glue.c:			finished_reset = wait_for_completion_timeout
drivers/scsi/sym53c8xx_2/sym_glue.c: * OK to resume normal operation. Use completion to allow
drivers/scsi/sym53c8xx_2/sym_glue.h:#include <linux/completion.h>
drivers/scsi/sym53c8xx_2/sym_glue.h:	struct completion *io_reset;		/* PCI error handling */
drivers/scsi/sym53c8xx_2/sym_hipd.c: *  device queue and the queue is frozen until a completion.
drivers/scsi/sym53c8xx_2/sym_hipd.c:		 *  The algorithm tries to prevent completion of any 
drivers/scsi/sym53c8xx_2/sym_hipd.h:	 *  Command completion queue.
drivers/scsi/sym53c8xx_2/sym_hipd.h:	u32	*dqueue;	/* Completion (done) queue	*/
drivers/scsi/sym53c8xx_2/sym_hipd.h:	 *  to the comp_ccbq prior to completion.
drivers/scsi/virtio_scsi.c:	struct completion *comp;
drivers/scsi/virtio_scsi.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/scsi/virtio_scsi.c:	wait_for_completion(&comp);
drivers/scsi/vmw_pvscsi.c:	 * 1-to-1 mapping completions back to requests.
drivers/scsi/vmw_pvscsi.c:	struct completion	*abort_cmp;
drivers/scsi/vmw_pvscsi.c: * Pull a completion descriptor off and pass the completion back
drivers/scsi/vmw_pvscsi.c:	struct completion *abort_cmp;
drivers/scsi/vmw_pvscsi.c:		 * the request completed and swallow the actual cmd completion
drivers/scsi/vmw_pvscsi.c:		 * here. The abort handler will post a completion for this
drivers/scsi/vmw_pvscsi.c:				    "Unknown completion status: 0x%x\n",
drivers/scsi/vmw_pvscsi.c:static void pvscsi_process_completion_ring(struct pvscsi_adapter *adapter)
drivers/scsi/vmw_pvscsi.c:	 * we might not have room on the completion ring for the response.
drivers/scsi/vmw_pvscsi.c:	DECLARE_COMPLETION_ONSTACK(abort_cmp);
drivers/scsi/vmw_pvscsi.c:	 * Poll the completion ring first - we might be trying to abort
drivers/scsi/vmw_pvscsi.c:	 * a command that is waiting to be dispatched in the completion ring.
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.c:	/* Wait for 2 secs for the completion. */
drivers/scsi/vmw_pvscsi.c:	done = wait_for_completion_timeout(&abort_cmp, msecs_to_jiffies(2000));
drivers/scsi/vmw_pvscsi.c:			    "Failed to get completion for aborted cmd %p\n",
drivers/scsi/vmw_pvscsi.c: * Abort all outstanding requests.  This is only safe to use if the completion
drivers/scsi/vmw_pvscsi.c:	 * up, so stalling new requests until all completions are flushed and
drivers/scsi/vmw_pvscsi.c:	 * Now process any completions.  Note we do this AFTER adapter reset,
drivers/scsi/vmw_pvscsi.c:	 * which is strange, but stops races where completions get posted
drivers/scsi/vmw_pvscsi.c:	 * completion ring state is still valid.
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.c:	 * Mark the completion page header with error values. If the device
drivers/scsi/vmw_pvscsi.c:	pvscsi_process_completion_ring(adapter);
drivers/scsi/vmw_pvscsi.h: *   completion of the i/o. For guest OSes that use lowest priority message
drivers/scsi/vmw_pvscsi.h: *   completion action to the proper vcpu. For now, we can use the vcpuId of
drivers/scsi/vmw_pvscsi.h: *   that will be waiting for the completion..
drivers/scsi/vmw_pvscsi.h: * Completion descriptor.
drivers/scsi/wd33c93.c: * is guaranteed to be in response to completion of
drivers/scsi/wd33c93.h:  /* successful completion interrupts */
drivers/scsi/wd719x.c:/* process a SCB-completion interrupt */
drivers/slimbus/core.c:	init_completion(&ctrl->sched.pause_comp);
drivers/slimbus/messaging.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/slimbus/messaging.c:		timeout = wait_for_completion_timeout(txn->comp,
drivers/slimbus/qcom-ctrl.c:	struct completion	**wr_comp;
drivers/slimbus/qcom-ctrl.c:	struct completion *comp;
drivers/slimbus/qcom-ctrl.c:			      struct completion *done)
drivers/slimbus/qcom-ctrl.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/slimbus/qcom-ctrl.c:	timeout = wait_for_completion_timeout(&done, msecs_to_jiffies(ms));
drivers/slimbus/qcom-ctrl.c:	ctrl->wr_comp = kcalloc(QCOM_TX_MSGS, sizeof(struct completion *),
drivers/slimbus/qcom-ngd-ctrl.c:	struct completion qmi_comp;
drivers/slimbus/qcom-ngd-ctrl.c:	struct completion *comp;
drivers/slimbus/qcom-ngd-ctrl.c:	struct completion reconf;
drivers/slimbus/qcom-ngd-ctrl.c:	struct completion qmi_up;
drivers/slimbus/qcom-ngd-ctrl.c:	complete(&txn->completion);
drivers/slimbus/qcom-ngd-ctrl.c:				     struct completion *comp)
drivers/slimbus/qcom-ngd-ctrl.c:	DECLARE_COMPLETION_ONSTACK(tx_sent);
drivers/slimbus/qcom-ngd-ctrl.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/slimbus/qcom-ngd-ctrl.c:	timeout = wait_for_completion_timeout(&tx_sent, HZ);
drivers/slimbus/qcom-ngd-ctrl.c:		timeout = wait_for_completion_timeout(&done, HZ);
drivers/slimbus/qcom-ngd-ctrl.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/slimbus/qcom-ngd-ctrl.c:	timeout = wait_for_completion_timeout(&done, HZ);
drivers/slimbus/qcom-ngd-ctrl.c:		timeout = wait_for_completion_timeout(&ctrl->qmi.qmi_comp, HZ);
drivers/slimbus/qcom-ngd-ctrl.c:	reinit_completion(&ctrl->reconf);
drivers/slimbus/qcom-ngd-ctrl.c:	timeout = wait_for_completion_timeout(&ctrl->reconf, HZ);
drivers/slimbus/qcom-ngd-ctrl.c:	reinit_completion(&ctrl->qmi_up);
drivers/slimbus/qcom-ngd-ctrl.c:	if (!wait_for_completion_interruptible_timeout(&ctrl->qmi_up,
drivers/slimbus/qcom-ngd-ctrl.c:	init_completion(&ctrl->reconf);
drivers/slimbus/qcom-ngd-ctrl.c:	init_completion(&ctrl->qmi.qmi_comp);
drivers/slimbus/qcom-ngd-ctrl.c:	init_completion(&ctrl->qmi_up);
drivers/slimbus/sched.c:		ret = wait_for_completion_timeout(&sched->pause_comp,
drivers/slimbus/slimbus.h:#include <linux/completion.h>
drivers/slimbus/slimbus.h: * @comp: completion if read/write is synchronous, used internally
drivers/slimbus/slimbus.h:	struct	completion	*comp;
drivers/slimbus/slimbus.h: * @pause_comp: Signals completion of clock pause sequence. This is useful when
drivers/slimbus/slimbus.h:	struct completion	pause_comp;
drivers/soc/apple/mailbox.c:		reinit_completion(&mbox->tx_empty);
drivers/soc/apple/mailbox.c:		t = wait_for_completion_interruptible_timeout(
drivers/soc/apple/mailbox.c:	init_completion(&mbox->tx_empty);
drivers/soc/apple/mailbox.h:	struct completion tx_empty;
drivers/soc/apple/rtkit-internal.h:#include <linux/completion.h>
drivers/soc/apple/rtkit-internal.h:	struct completion epmap_completion;
drivers/soc/apple/rtkit-internal.h:	struct completion iop_pwr_ack_completion;
drivers/soc/apple/rtkit-internal.h:	struct completion ap_pwr_ack_completion;
drivers/soc/apple/rtkit.c:	complete_all(&rtk->epmap_completion);
drivers/soc/apple/rtkit.c:	complete_all(&rtk->epmap_completion);
drivers/soc/apple/rtkit.c:	complete_all(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	complete_all(&rtk->ap_pwr_ack_completion);
drivers/soc/apple/rtkit.c:			     struct completion *completion, bool atomic)
drivers/soc/apple/rtkit.c:	init_completion(&rtk->epmap_completion);
drivers/soc/apple/rtkit.c:	init_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	init_completion(&rtk->ap_pwr_ack_completion);
drivers/soc/apple/rtkit.c:static int apple_rtkit_wait_for_completion(struct completion *c)
drivers/soc/apple/rtkit.c:	t = wait_for_completion_interruptible_timeout(c,
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->epmap_completion);
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->ap_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->ap_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	ret = apple_rtkit_wait_for_completion(&rtk->ap_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	ret = apple_rtkit_wait_for_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	ret = apple_rtkit_wait_for_completion(&rtk->epmap_completion);
drivers/soc/apple/rtkit.c:	ret = apple_rtkit_wait_for_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	reinit_completion(&rtk->iop_pwr_ack_completion);
drivers/soc/apple/rtkit.c:	 * will wait for the completion anyway.
drivers/soc/fsl/qbman/bman.c:		pr_crit("missing existing RCR completions\n");
drivers/soc/fsl/qbman/qman.c:		pr_crit("missing existing EQCR completions\n");
drivers/soc/fsl/qbman/qman.c:	 * NB we do this to "quiesce" EQCR. If we add enqueue-completions or
drivers/soc/fsl/qbman/qman.c:			/* Check for VDQCR completion */
drivers/soc/fsl/qe/qmc.c:	 *   0       1  : The BD is in used, waiting for completion
drivers/soc/fsl/qe/qmc.c:	 *   0       1  : The BD is in used, waiting for completion
drivers/soc/fsl/qe/qmc.c:	 *   0       1  : The BD is in used, waiting for completion
drivers/soc/fsl/qe/qmc.c:	 *   0       1  : The BD is in used, waiting for completion
drivers/soc/hisilicon/kunpeng_hccs.c:	init_completion(&cl_info->done);
drivers/soc/hisilicon/kunpeng_hccs.c:	if (!wait_for_completion_timeout(&cl_info->done,
drivers/soc/hisilicon/kunpeng_hccs.c:		.flags = PCC_CMD_COMPLETION_NOTIFY,
drivers/soc/hisilicon/kunpeng_hccs.c:		reinit_completion(&cl_info->done);
drivers/soc/hisilicon/kunpeng_hccs.h:	struct completion done;
drivers/soc/ixp4xx/ixp4xx-npe.c:	/* we need this value later to wait for completion of NPE execution
drivers/soc/mediatek/mtk-cmdq-helper.c:#include <linux/completion.h>
drivers/soc/mediatek/mtk-svs.c:#include <linux/completion.h>
drivers/soc/mediatek/mtk-svs.c: * @init_completion: the timeout completion for bank init
drivers/soc/mediatek/mtk-svs.c:	struct completion init_completion;
drivers/soc/mediatek/mtk-svs.c:		complete(&svsb->init_completion);
drivers/soc/mediatek/mtk-svs.c:		time_left = wait_for_completion_timeout(&svsb->init_completion,
drivers/soc/mediatek/mtk-svs.c:			dev_err(svsb->dev, "init01 completion timeout\n");
drivers/soc/mediatek/mtk-svs.c:		reinit_completion(&svsb->init_completion);
drivers/soc/mediatek/mtk-svs.c:		time_left = wait_for_completion_timeout(&svsb->init_completion,
drivers/soc/mediatek/mtk-svs.c:			dev_err(svsb->dev, "init02 completion timeout\n");
drivers/soc/mediatek/mtk-svs.c:		init_completion(&svsb->init_completion);
drivers/soc/microchip/mpfs-sys-controller.c:	struct completion c;
drivers/soc/microchip/mpfs-sys-controller.c:	reinit_completion(&sys_controller->c);
drivers/soc/microchip/mpfs-sys-controller.c:	if (!wait_for_completion_timeout(&sys_controller->c, timeout)) {
drivers/soc/microchip/mpfs-sys-controller.c:	init_completion(&sys_controller->c);
drivers/soc/qcom/pmic_glink_altmode.c:	struct completion pan_ack;
drivers/soc/qcom/pmic_glink_altmode.c:	left = wait_for_completion_timeout(&altmode->pan_ack, 5 * HZ);
drivers/soc/qcom/pmic_glink_altmode.c:	init_completion(&altmode->pan_ack);
drivers/soc/qcom/qcom-pbs.c: *    completion of the sequence.
drivers/soc/qcom/qmi_interface.c:#include <linux/completion.h>
drivers/soc/qcom/qmi_interface.c:	init_completion(&txn->completion);
drivers/soc/qcom/qmi_interface.c:	ret = wait_for_completion_timeout(&txn->completion, timeout);
drivers/soc/qcom/qmi_interface.c:			complete(&txn->completion);
drivers/soc/qcom/rpmh-internal.h: * @completion: triggered when request is done
drivers/soc/qcom/rpmh-internal.h:	struct completion *completion;
drivers/soc/qcom/rpmh.c:		.completion = q,			\
drivers/soc/qcom/rpmh.c:	struct completion *compl = rpm_msg->completion;
drivers/soc/qcom/rpmh.c:	DECLARE_COMPLETION_ONSTACK(compl);
drivers/soc/qcom/rpmh.c:	ret = wait_for_completion_timeout(&compl, RPMH_TIMEOUT_MS);
drivers/soc/qcom/rpmh.c: * state is ACTIVE, then the requests are treated as completion request
drivers/soc/qcom/rpmh.c:	struct completion *compls;
drivers/soc/qcom/rpmh.c:		struct completion *compl = &compls[i];
drivers/soc/qcom/rpmh.c:		init_completion(compl);
drivers/soc/qcom/rpmh.c:		rpm_msgs[i].completion = compl;
drivers/soc/qcom/rpmh.c:		time_left = wait_for_completion_timeout(&compls[i], time_left);
drivers/soc/qcom/rpmh.c:			 * the completion that we're going to free once
drivers/soc/qcom/smd-rpm.c: * @ack:		completion for acks
drivers/soc/qcom/smd-rpm.c:	struct completion ack;
drivers/soc/qcom/smd-rpm.c:	left = wait_for_completion_timeout(&rpm->ack, RPM_REQUEST_TIMEOUT);
drivers/soc/qcom/smd-rpm.c:	init_completion(&rpm->ack);
drivers/soc/qcom/wcnss_ctrl.c: * @ack:	completion for outstanding requests
drivers/soc/qcom/wcnss_ctrl.c: * @cbc:	completion for cbc complete indication
drivers/soc/qcom/wcnss_ctrl.c:	struct completion ack;
drivers/soc/qcom/wcnss_ctrl.c:	struct completion cbc;
drivers/soc/qcom/wcnss_ctrl.c:	ret = wait_for_completion_timeout(&wcnss->ack, WCNSS_CBC_TIMEOUT);
drivers/soc/qcom/wcnss_ctrl.c:	ret = wait_for_completion_timeout(&wcnss->ack, WCNSS_REQUEST_TIMEOUT);
drivers/soc/qcom/wcnss_ctrl.c:	/* Wait for pending cold boot completion if indicated by the nv downloader */
drivers/soc/qcom/wcnss_ctrl.c:		ret = wait_for_completion_timeout(&wcnss->cbc, WCNSS_REQUEST_TIMEOUT);
drivers/soc/qcom/wcnss_ctrl.c:			dev_err(wcnss->dev, "expected cold boot completion\n");
drivers/soc/qcom/wcnss_ctrl.c:	init_completion(&wcnss->ack);
drivers/soc/qcom/wcnss_ctrl.c:	init_completion(&wcnss->cbc);
drivers/soc/tegra/fuse/fuse-tegra20.c:#include <linux/completion.h>
drivers/soc/tegra/fuse/fuse-tegra20.c:	reinit_completion(&fuse->apbdma.wait);
drivers/soc/tegra/fuse/fuse-tegra20.c:	time_left = wait_for_completion_timeout(&fuse->apbdma.wait,
drivers/soc/tegra/fuse/fuse-tegra20.c:	init_completion(&fuse->apbdma.wait);
drivers/soc/tegra/fuse/fuse.h:		struct completion wait;
drivers/soc/ti/k3-ringacc.c:	 * DMA rings must be requested by ID, completion ring is the reverse
drivers/soc/ti/knav_dma.c:	/* then disconnect the completion side */
drivers/soc/ti/wkup_m3_ipc.c:	ret = wait_for_completion_timeout(&m3_ipc->sync_complete,
drivers/soc/ti/wkup_m3_ipc.c:	init_completion(&m3_ipc->sync_complete);
drivers/soc/ti/wkup_m3_ipc.c:	 * Wait for firmware loading completion in a thread so we
drivers/soundwire/amd_manager.c:#include <linux/completion.h>
drivers/soundwire/bus.c:	init_completion(&defer->complete);
drivers/soundwire/bus.c:			"initializing enumeration and init completion for Slave %d\n",
drivers/soundwire/bus.c:		reinit_completion(&slave->enumeration_complete);
drivers/soundwire/bus.c:		reinit_completion(&slave->initialization_complete);
drivers/soundwire/bus.c:			"signaling enumeration completion for Slave %d\n",
drivers/soundwire/bus.c:				"signaling initialization completion for Slave %d\n",
drivers/soundwire/cadence_master.c:	time = wait_for_completion_timeout(&cdns->tx_complete,
drivers/soundwire/cadence_master.c:	time = wait_for_completion_timeout(&cdns->tx_complete,
drivers/soundwire/cadence_master.c:	init_completion(&cdns->tx_complete);
drivers/soundwire/cadence_master.h: * @tx_complete: Tx completion
drivers/soundwire/cadence_master.h:	struct completion tx_complete;
drivers/soundwire/qcom.c:#include <linux/completion.h>
drivers/soundwire/qcom.c:	struct completion broadcast;
drivers/soundwire/qcom.c:	struct completion enumeration;
drivers/soundwire/qcom.c:		reinit_completion(&ctrl->broadcast);
drivers/soundwire/qcom.c:		ret = wait_for_completion_timeout(&ctrl->broadcast,
drivers/soundwire/qcom.c:	init_completion(&ctrl->broadcast);
drivers/soundwire/qcom.c:	init_completion(&ctrl->enumeration);
drivers/soundwire/qcom.c:	wait_for_completion_timeout(&ctrl->enumeration,
drivers/soundwire/qcom.c:		reinit_completion(&ctrl->enumeration);
drivers/soundwire/qcom.c:		wait_for_completion_timeout(&ctrl->enumeration,
drivers/soundwire/slave.c:	init_completion(&slave->enumeration_complete);
drivers/soundwire/slave.c:	init_completion(&slave->initialization_complete);
drivers/soundwire/slave.c:		init_completion(&slave->port_ready[i]);
drivers/soundwire/stream.c:	struct completion *port_ready;
drivers/soundwire/stream.c:		/* Wait for completion on port ready */
drivers/soundwire/stream.c:		wait_for_completion_timeout(port_ready,
drivers/soundwire/stream.c:	/* Wait for completion of transfer */
drivers/soundwire/stream.c:	time_left = wait_for_completion_timeout(&bus->defer_msg.complete,
drivers/spi/atmel-quadspi.c:	struct completion	cmd_completion;
drivers/spi/atmel-quadspi.c:	reinit_completion(&aq->cmd_completion);
drivers/spi/atmel-quadspi.c:	if (!wait_for_completion_timeout(&aq->cmd_completion,
drivers/spi/atmel-quadspi.c:		complete(&aq->cmd_completion);
drivers/spi/atmel-quadspi.c:	init_completion(&aq->cmd_completion);
drivers/spi/spi-armada-3700.c:#include <linux/completion.h>
drivers/spi/spi-armada-3700.c:	struct completion done;
drivers/spi/spi-armada-3700.c:static bool a3700_spi_wait_completion(struct spi_device *spi)
drivers/spi/spi-armada-3700.c:	reinit_completion(&a3700_spi->done);
drivers/spi/spi-armada-3700.c:	time_left = wait_for_completion_timeout(&a3700_spi->done,
drivers/spi/spi-armada-3700.c:	 * interrupt by wait_for_completion_timeout, the interrupt
drivers/spi/spi-armada-3700.c:	return a3700_spi_wait_completion(spi);
drivers/spi/spi-armada-3700.c:	init_completion(&spi->done);
drivers/spi/spi-at91-usart.c:	struct completion	xfer_completion;
drivers/spi/spi-at91-usart.c:	complete(&aus->xfer_completion);
drivers/spi/spi-at91-usart.c:	return wait_for_completion_timeout(&aus->xfer_completion,
drivers/spi/spi-at91-usart.c:		reinit_completion(&aus->xfer_completion);
drivers/spi/spi-at91-usart.c:	init_completion(&aus->xfer_completion);
drivers/spi/spi-atmel.c:	struct completion	xfer_completion;
drivers/spi/spi-atmel.c:	complete(&as->xfer_completion);
drivers/spi/spi-atmel.c:	 * transfer completion.
drivers/spi/spi-atmel.c:		complete(&as->xfer_completion);
drivers/spi/spi-atmel.c:			complete(&as->xfer_completion);
drivers/spi/spi-atmel.c:		complete(&as->xfer_completion);
drivers/spi/spi-atmel.c:		complete(&as->xfer_completion);
drivers/spi/spi-atmel.c:		reinit_completion(&as->xfer_completion);
drivers/spi/spi-atmel.c:		ret_timeout = wait_for_completion_timeout(&as->xfer_completion, dma_timeout);
drivers/spi/spi-atmel.c:	init_completion(&as->xfer_completion);
drivers/spi/spi-au1550.c:#include <linux/completion.h>
drivers/spi/spi-au1550.c:	struct completion host_done;
drivers/spi/spi-au1550.c:	wait_for_completion(&hw->host_done);
drivers/spi/spi-au1550.c:	wait_for_completion(&hw->host_done);
drivers/spi/spi-au1550.c:	init_completion(&hw->host_done);
drivers/spi/spi-axi-spi-engine.c:#include <linux/completion.h>
drivers/spi/spi-axi-spi-engine.c:	struct completion msg_complete;
drivers/spi/spi-axi-spi-engine.c:	reinit_completion(&spi_engine->msg_complete);
drivers/spi/spi-axi-spi-engine.c:	if (!wait_for_completion_timeout(&spi_engine->msg_complete,
drivers/spi/spi-axi-spi-engine.c:	init_completion(&spi_engine->msg_complete);
drivers/spi/spi-bcm-qspi.c:	struct completion mspi_done;
drivers/spi/spi-bcm-qspi.c:	struct completion bspi_done;
drivers/spi/spi-bcm-qspi.c:		reinit_completion(&qspi->bspi_done);
drivers/spi/spi-bcm-qspi.c:		if (!wait_for_completion_timeout(&qspi->bspi_done, timeo)) {
drivers/spi/spi-bcm-qspi.c:		reinit_completion(&qspi->mspi_done);
drivers/spi/spi-bcm-qspi.c:		if (!wait_for_completion_timeout(&qspi->mspi_done, timeo)) {
drivers/spi/spi-bcm-qspi.c:	init_completion(&qspi->mspi_done);
drivers/spi/spi-bcm-qspi.c:	init_completion(&qspi->bspi_done);
drivers/spi/spi-bcm2835.c:#include <linux/completion.h>
drivers/spi/spi-bcm2835.c:	/* signal that we need to wait for completion */
drivers/spi/spi-bcm2835.c:	 * Completion is signaled by the RX channel for bidirectional and
drivers/spi/spi-bcm2835.c:	/* and return without waiting for completion */
drivers/spi/spi-bcm2835aux.c:#include <linux/completion.h>
drivers/spi/spi-bcm2835aux.c:	/* and if rx_len is 0 then disable interrupts and wake up completion */
drivers/spi/spi-bcm2835aux.c:	/* and return without waiting for completion */
drivers/spi/spi-bcm63xx-hsspi.c:	struct completion done;
drivers/spi/spi-bcm63xx-hsspi.c:		if (wait_for_completion_timeout(&bs->done, HZ) == 0)
drivers/spi/spi-bcm63xx-hsspi.c:	reinit_completion(&bs->done);
drivers/spi/spi-bcm63xx-hsspi.c:		reinit_completion(&bs->done);
drivers/spi/spi-bcm63xx-hsspi.c:	init_completion(&bs->done);
drivers/spi/spi-bcm63xx.c:#include <linux/completion.h>
drivers/spi/spi-bcm63xx.c:	struct completion	done;
drivers/spi/spi-bcm63xx.c:	reinit_completion(&bs->done);
drivers/spi/spi-bcm63xx.c:	timeout = wait_for_completion_timeout(&bs->done, HZ);
drivers/spi/spi-bcm63xx.c:	init_completion(&bs->done);
drivers/spi/spi-bcmbca-hsspi.c:	struct completion done;
drivers/spi/spi-bcmbca-hsspi.c:		if (wait_for_completion_timeout(&bs->done, HZ) == 0)
drivers/spi/spi-bcmbca-hsspi.c:		reinit_completion(&bs->done);
drivers/spi/spi-bcmbca-hsspi.c:	init_completion(&bs->done);
drivers/spi/spi-cadence-quadspi.c:#include <linux/completion.h>
drivers/spi/spi-cadence-quadspi.c:#define CQSPI_NO_SUPPORT_WR_COMPLETION	BIT(3)
drivers/spi/spi-cadence-quadspi.c:	struct completion	transfer_complete;
drivers/spi/spi-cadence-quadspi.c:	struct completion	rx_dma_complete;
drivers/spi/spi-cadence-quadspi.c:	bool			wr_completion;
drivers/spi/spi-cadence-quadspi.c:#define CQSPI_REG_WR_COMPLETION_CTRL		0x38
drivers/spi/spi-cadence-quadspi.c:	/* Polling for completion. */
drivers/spi/spi-cadence-quadspi.c:	reinit_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:		    !wait_for_completion_timeout(&cqspi->transfer_complete,
drivers/spi/spi-cadence-quadspi.c:			reinit_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:		dev_err(dev, "Indirect read completion error (%i)\n", ret);
drivers/spi/spi-cadence-quadspi.c:	/* Clear indirect completion status */
drivers/spi/spi-cadence-quadspi.c:	reinit_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:	if (!wait_for_completion_timeout(&cqspi->transfer_complete,
drivers/spi/spi-cadence-quadspi.c:	/* Clear indirect completion status */
drivers/spi/spi-cadence-quadspi.c:	 * command when doing auto-HW polling. So, disable write completion
drivers/spi/spi-cadence-quadspi.c:	if (cqspi->wr_completion) {
drivers/spi/spi-cadence-quadspi.c:		reg = readl(reg_base + CQSPI_REG_WR_COMPLETION_CTRL);
drivers/spi/spi-cadence-quadspi.c:		writel(reg, reg_base + CQSPI_REG_WR_COMPLETION_CTRL);
drivers/spi/spi-cadence-quadspi.c:		 * for write completion in case of bubble in SPI transaction
drivers/spi/spi-cadence-quadspi.c:	reinit_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:		if (!wait_for_completion_timeout(&cqspi->transfer_complete,
drivers/spi/spi-cadence-quadspi.c:			reinit_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:		dev_err(dev, "Indirect write completion error (%i)\n", ret);
drivers/spi/spi-cadence-quadspi.c:	/* Clear indirect completion status */
drivers/spi/spi-cadence-quadspi.c:	 * the flash when it is polling the write completion register in DTR
drivers/spi/spi-cadence-quadspi.c:	reinit_completion(&cqspi->rx_dma_complete);
drivers/spi/spi-cadence-quadspi.c:	if (!wait_for_completion_timeout(&cqspi->rx_dma_complete,
drivers/spi/spi-cadence-quadspi.c:		dev_err(dev, "DMA wait_for_completion_timeout\n");
drivers/spi/spi-cadence-quadspi.c:	init_completion(&cqspi->rx_dma_complete);
drivers/spi/spi-cadence-quadspi.c:	init_completion(&cqspi->transfer_complete);
drivers/spi/spi-cadence-quadspi.c:	/* write completion is supported by default */
drivers/spi/spi-cadence-quadspi.c:	cqspi->wr_completion = true;
drivers/spi/spi-cadence-quadspi.c:		if (ddata->quirks & CQSPI_NO_SUPPORT_WR_COMPLETION)
drivers/spi/spi-cadence-quadspi.c:			cqspi->wr_completion = false;
drivers/spi/spi-cadence-quadspi.c:			| CQSPI_NO_SUPPORT_WR_COMPLETION
drivers/spi/spi-cadence-quadspi.c:	.quirks = CQSPI_DISABLE_DAC_MODE | CQSPI_NO_SUPPORT_WR_COMPLETION |
drivers/spi/spi-cadence-xspi.c:#include <linux/completion.h>
drivers/spi/spi-cadence-xspi.c:	struct completion cmd_complete;
drivers/spi/spi-cadence-xspi.c:	struct completion auto_cmd_complete;
drivers/spi/spi-cadence-xspi.c:	struct completion sdma_complete;
drivers/spi/spi-cadence-xspi.c:		wait_for_completion(&cdns_xspi->sdma_complete);
drivers/spi/spi-cadence-xspi.c:	wait_for_completion(&cdns_xspi->cmd_complete);
drivers/spi/spi-cadence-xspi.c:	init_completion(&cdns_xspi->cmd_complete);
drivers/spi/spi-cadence-xspi.c:	init_completion(&cdns_xspi->auto_cmd_complete);
drivers/spi/spi-cadence-xspi.c:	init_completion(&cdns_xspi->sdma_complete);
drivers/spi/spi-cadence.c: * returns a positive transfer count so that core will wait for completion.
drivers/spi/spi-davinci.c:	struct completion	done;
drivers/spi/spi-davinci.c: * of SPI controller and then wait until the completion will be marked
drivers/spi/spi-davinci.c:	reinit_completion(&dspi->done);
drivers/spi/spi-davinci.c:		if (wait_for_completion_timeout(&dspi->done, timeout) == 0)
drivers/spi/spi-davinci.c: * If transfer length is zero then it will indicate the COMPLETION so that
drivers/spi/spi-davinci.c:	init_completion(&dspi->done);
drivers/spi/spi-dln2.c:		u8 wait_for_completion;
drivers/spi/spi-dln2.c:		len -= sizeof(tx.wait_for_completion);
drivers/spi/spi-dln2.c:		tx.wait_for_completion = DLN2_TRANSFERS_WAIT_COMPLETE;
drivers/spi/spi-dw-dma.c:#include <linux/completion.h>
drivers/spi/spi-dw-dma.c:	init_completion(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:	init_completion(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:	complete(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:	ms = wait_for_completion_timeout(&dws->dma_completion,
drivers/spi/spi-dw-dma.c:	complete(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:	complete(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:	reinit_completion(&dws->dma_completion);
drivers/spi/spi-dw-dma.c:		reinit_completion(&dws->dma_completion);
drivers/spi/spi-dw.h:#include <linux/completion.h>
drivers/spi/spi-dw.h:	struct completion	dma_completion;
drivers/spi/spi-ep93xx.c:	/* signal that we need to wait for completion */
drivers/spi/spi-ep93xx.c:	/* signal that we need to wait for completion */
drivers/spi/spi-fsl-dspi.c:#define DMA_COMPLETION_TIMEOUT		msecs_to_jiffies(3000)
drivers/spi/spi-fsl-dspi.c:	struct completion			cmd_tx_complete;
drivers/spi/spi-fsl-dspi.c:	struct completion			cmd_rx_complete;
drivers/spi/spi-fsl-dspi.c:	struct completion			xfer_done;
drivers/spi/spi-fsl-dspi.c:	reinit_completion(&dspi->dma->cmd_rx_complete);
drivers/spi/spi-fsl-dspi.c:	reinit_completion(&dspi->dma->cmd_tx_complete);
drivers/spi/spi-fsl-dspi.c:		wait_for_completion_interruptible(&dspi->dma->cmd_rx_complete);
drivers/spi/spi-fsl-dspi.c:	time_left = wait_for_completion_timeout(&dspi->dma->cmd_tx_complete,
drivers/spi/spi-fsl-dspi.c:						DMA_COMPLETION_TIMEOUT);
drivers/spi/spi-fsl-dspi.c:	time_left = wait_for_completion_timeout(&dspi->dma->cmd_rx_complete,
drivers/spi/spi-fsl-dspi.c:						DMA_COMPLETION_TIMEOUT);
drivers/spi/spi-fsl-dspi.c:	init_completion(&dma->cmd_tx_complete);
drivers/spi/spi-fsl-dspi.c:	init_completion(&dma->cmd_rx_complete);
drivers/spi/spi-fsl-dspi.c:				wait_for_completion(&dspi->xfer_done);
drivers/spi/spi-fsl-dspi.c:				reinit_completion(&dspi->xfer_done);
drivers/spi/spi-fsl-dspi.c:	init_completion(&dspi->xfer_done);
drivers/spi/spi-fsl-espi.c:	struct completion done;
drivers/spi/spi-fsl-espi.c:	reinit_completion(&espi->done);
drivers/spi/spi-fsl-espi.c:	ret = wait_for_completion_timeout(&espi->done, 2 * HZ);
drivers/spi/spi-fsl-espi.c:	init_completion(&espi->done);
drivers/spi/spi-fsl-lib.c:	init_completion(&mpc8xxx_spi->done);
drivers/spi/spi-fsl-lib.h:	struct completion done;
drivers/spi/spi-fsl-lpspi.c:#include <linux/completion.h>
drivers/spi/spi-fsl-lpspi.c:	struct completion xfer_done;
drivers/spi/spi-fsl-lpspi.c:	struct completion dma_rx_completion;
drivers/spi/spi-fsl-lpspi.c:	struct completion dma_tx_completion;
drivers/spi/spi-fsl-lpspi.c:		complete(&fsl_lpspi->dma_tx_completion);
drivers/spi/spi-fsl-lpspi.c:		complete(&fsl_lpspi->dma_rx_completion);
drivers/spi/spi-fsl-lpspi.c:static int fsl_lpspi_wait_for_completion(struct spi_controller *controller)
drivers/spi/spi-fsl-lpspi.c:		if (wait_for_completion_interruptible(&fsl_lpspi->xfer_done) ||
drivers/spi/spi-fsl-lpspi.c:		if (!wait_for_completion_timeout(&fsl_lpspi->xfer_done, HZ)) {
drivers/spi/spi-fsl-lpspi.c:			dev_dbg(fsl_lpspi->dev, "wait for completion timeout\n");
drivers/spi/spi-fsl-lpspi.c:	complete(&fsl_lpspi->dma_rx_completion);
drivers/spi/spi-fsl-lpspi.c:	complete(&fsl_lpspi->dma_tx_completion);
drivers/spi/spi-fsl-lpspi.c:	reinit_completion(&fsl_lpspi->dma_rx_completion);
drivers/spi/spi-fsl-lpspi.c:	reinit_completion(&fsl_lpspi->dma_tx_completion);
drivers/spi/spi-fsl-lpspi.c:		time_left = wait_for_completion_timeout(&fsl_lpspi->dma_tx_completion,
drivers/spi/spi-fsl-lpspi.c:		time_left = wait_for_completion_timeout(&fsl_lpspi->dma_rx_completion,
drivers/spi/spi-fsl-lpspi.c:		if (wait_for_completion_interruptible(&fsl_lpspi->dma_tx_completion) ||
drivers/spi/spi-fsl-lpspi.c:		if (wait_for_completion_interruptible(&fsl_lpspi->dma_rx_completion) ||
drivers/spi/spi-fsl-lpspi.c:	init_completion(&fsl_lpspi->dma_rx_completion);
drivers/spi/spi-fsl-lpspi.c:	init_completion(&fsl_lpspi->dma_tx_completion);
drivers/spi/spi-fsl-lpspi.c:	reinit_completion(&fsl_lpspi->xfer_done);
drivers/spi/spi-fsl-lpspi.c:	ret = fsl_lpspi_wait_for_completion(controller);
drivers/spi/spi-fsl-lpspi.c:	init_completion(&fsl_lpspi->xfer_done);
drivers/spi/spi-fsl-qspi.c:#include <linux/completion.h>
drivers/spi/spi-fsl-qspi.c:	struct completion c;
drivers/spi/spi-fsl-qspi.c:	init_completion(&q->c);
drivers/spi/spi-fsl-qspi.c:	if (!wait_for_completion_timeout(&q->c, msecs_to_jiffies(1000)))
drivers/spi/spi-fsl-spi.c:	reinit_completion(&mpc8xxx_spi->done);
drivers/spi/spi-fsl-spi.c:	wait_for_completion(&mpc8xxx_spi->done);
drivers/spi/spi-geni-qcom.c:	struct completion cs_done;
drivers/spi/spi-geni-qcom.c:	struct completion cancel_done;
drivers/spi/spi-geni-qcom.c:	struct completion abort_done;
drivers/spi/spi-geni-qcom.c:	struct completion tx_reset_done;
drivers/spi/spi-geni-qcom.c:	struct completion rx_reset_done;
drivers/spi/spi-geni-qcom.c:	reinit_completion(&mas->cancel_done);
drivers/spi/spi-geni-qcom.c:	time_left = wait_for_completion_timeout(&mas->cancel_done, HZ);
drivers/spi/spi-geni-qcom.c:	reinit_completion(&mas->abort_done);
drivers/spi/spi-geni-qcom.c:	time_left = wait_for_completion_timeout(&mas->abort_done, HZ);
drivers/spi/spi-geni-qcom.c:				reinit_completion(&mas->tx_reset_done);
drivers/spi/spi-geni-qcom.c:				time_left = wait_for_completion_timeout(&mas->tx_reset_done, HZ);
drivers/spi/spi-geni-qcom.c:				reinit_completion(&mas->rx_reset_done);
drivers/spi/spi-geni-qcom.c:				time_left = wait_for_completion_timeout(&mas->rx_reset_done, HZ);
drivers/spi/spi-geni-qcom.c:			 * and handling transfer completion at that time.
drivers/spi/spi-geni-qcom.c:	reinit_completion(&mas->cs_done);
drivers/spi/spi-geni-qcom.c:	time_left = wait_for_completion_timeout(&mas->cs_done, HZ);
drivers/spi/spi-geni-qcom.c:	init_completion(&mas->cs_done);
drivers/spi/spi-geni-qcom.c:	init_completion(&mas->cancel_done);
drivers/spi/spi-geni-qcom.c:	init_completion(&mas->abort_done);
drivers/spi/spi-geni-qcom.c:	init_completion(&mas->tx_reset_done);
drivers/spi/spi-geni-qcom.c:	init_completion(&mas->rx_reset_done);
drivers/spi/spi-hisi-sfc-v3xx.c:#include <linux/completion.h>
drivers/spi/spi-hisi-sfc-v3xx.c:	struct completion *completion;
drivers/spi/spi-hisi-sfc-v3xx.c:static int hisi_sfc_v3xx_handle_completion(struct hisi_sfc_v3xx_host *host)
drivers/spi/spi-hisi-sfc-v3xx.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/spi/spi-hisi-sfc-v3xx.c:		host->completion = &done;
drivers/spi/spi-hisi-sfc-v3xx.c:		ret = wait_for_completion_timeout(host->completion,
drivers/spi/spi-hisi-sfc-v3xx.c:		host->completion = NULL;
drivers/spi/spi-hisi-sfc-v3xx.c:	if (hisi_sfc_v3xx_handle_completion(host) || ret)
drivers/spi/spi-hisi-sfc-v3xx.c:	complete(host->completion);
drivers/spi/spi-imx.c:#include <linux/completion.h>
drivers/spi/spi-imx.c:	struct completion xfer_done;
drivers/spi/spi-imx.c:	struct completion dma_rx_completion;
drivers/spi/spi-imx.c:	struct completion dma_tx_completion;
drivers/spi/spi-imx.c:	 * eCSPI burst completion by Chip Select signal in Target mode
drivers/spi/spi-imx.c:	init_completion(&spi_imx->dma_rx_completion);
drivers/spi/spi-imx.c:	init_completion(&spi_imx->dma_tx_completion);
drivers/spi/spi-imx.c:	complete(&spi_imx->dma_rx_completion);
drivers/spi/spi-imx.c:	complete(&spi_imx->dma_tx_completion);
drivers/spi/spi-imx.c:	reinit_completion(&spi_imx->dma_rx_completion);
drivers/spi/spi-imx.c:	reinit_completion(&spi_imx->dma_tx_completion);
drivers/spi/spi-imx.c:	time_left = wait_for_completion_timeout(&spi_imx->dma_tx_completion,
drivers/spi/spi-imx.c:	time_left = wait_for_completion_timeout(&spi_imx->dma_rx_completion,
drivers/spi/spi-imx.c:	reinit_completion(&spi_imx->xfer_done);
drivers/spi/spi-imx.c:	time_left = wait_for_completion_timeout(&spi_imx->xfer_done,
drivers/spi/spi-imx.c:	reinit_completion(&spi_imx->xfer_done);
drivers/spi/spi-imx.c:	if (wait_for_completion_interruptible(&spi_imx->xfer_done) ||
drivers/spi/spi-imx.c:	init_completion(&spi_imx->xfer_done);
drivers/spi/spi-lantiq-ssc.c:#include <linux/completion.h>
drivers/spi/spi-meson-spicc.c:	struct completion		done;
drivers/spi/spi-meson-spicc.c:	/* Setup wait for completion */
drivers/spi/spi-meson-spicc.c:	reinit_completion(&spicc->done);
drivers/spi/spi-meson-spicc.c:	if (!wait_for_completion_timeout(&spicc->done, msecs_to_jiffies(timeout)))
drivers/spi/spi-meson-spicc.c:	init_completion(&spicc->done);
drivers/spi/spi-microchip-core-qspi.c: * @data_completion:   completion structure
drivers/spi/spi-microchip-core-qspi.c:	struct completion data_completion;
drivers/spi/spi-microchip-core-qspi.c:		complete(&qspi->data_completion);
drivers/spi/spi-microchip-core-qspi.c:	reinit_completion(&qspi->data_completion);
drivers/spi/spi-microchip-core-qspi.c:	if (!wait_for_completion_timeout(&qspi->data_completion, msecs_to_jiffies(1000)))
drivers/spi/spi-microchip-core-qspi.c:	init_completion(&qspi->data_completion);
drivers/spi/spi-mpc512x-psc.c:#include <linux/completion.h>
drivers/spi/spi-mpc512x-psc.c:	struct completion txisrdone;
drivers/spi/spi-mpc512x-psc.c:			reinit_completion(&mps->txisrdone);
drivers/spi/spi-mpc512x-psc.c:			wait_for_completion(&mps->txisrdone);
drivers/spi/spi-mpc512x-psc.c:	init_completion(&mps->txisrdone);
drivers/spi/spi-mpc52xx-psc.c:#include <linux/completion.h>
drivers/spi/spi-mpc52xx-psc.c:	struct completion done;
drivers/spi/spi-mpc52xx-psc.c:		wait_for_completion(&mps->done);
drivers/spi/spi-mpc52xx-psc.c:	init_completion(&mps->done);
drivers/spi/spi-mpc52xx.c:#define FSM_POLL	1	/* need to poll for completion, an IRQ is */
drivers/spi/spi-mt65xx.c: * @spimem_done:	SPI-MEM operation completion
drivers/spi/spi-mt65xx.c:	struct completion spimem_done;
drivers/spi/spi-mt65xx.c:	if (!wait_for_completion_timeout(&mdata->spimem_done,
drivers/spi/spi-mt65xx.c:	reinit_completion(&mdata->spimem_done);
drivers/spi/spi-mt65xx.c:		init_completion(&mdata->spimem_done);
drivers/spi/spi-mt65xx.c:	if (mdata->use_spimem && !completion_done(&mdata->spimem_done))
drivers/spi/spi-mtk-nor.c:#include <linux/completion.h>
drivers/spi/spi-mtk-nor.c:	struct completion op_done;
drivers/spi/spi-mtk-nor.c:		reinit_completion(&sp->op_done);
drivers/spi/spi-mtk-nor.c:		if (!wait_for_completion_timeout(&sp->op_done,
drivers/spi/spi-mtk-nor.c:			init_completion(&sp->op_done);
drivers/spi/spi-mtk-snfi.c:	struct completion op_done;
drivers/spi/spi-mtk-snfi.c:	reinit_completion(&snf->op_done);
drivers/spi/spi-mtk-snfi.c:	if (!wait_for_completion_timeout(
drivers/spi/spi-mtk-snfi.c:	reinit_completion(&snf->op_done);
drivers/spi/spi-mtk-snfi.c:	if (!wait_for_completion_timeout(
drivers/spi/spi-mtk-snfi.c:	init_completion(&ms->op_done);
drivers/spi/spi-mxs.c:#include <linux/completion.h>
drivers/spi/spi-mxs.c:	struct completion	c;
drivers/spi/spi-mxs.c:	reinit_completion(&spi->c);
drivers/spi/spi-mxs.c:	if (!wait_for_completion_timeout(&spi->c,
drivers/spi/spi-mxs.c:	init_completion(&spi->c);
drivers/spi/spi-npcm-pspi.c:	struct completion xfer_done;
drivers/spi/spi-npcm-pspi.c:	reinit_completion(&priv->xfer_done);
drivers/spi/spi-npcm-pspi.c:	status = wait_for_completion_timeout(&priv->xfer_done,
drivers/spi/spi-npcm-pspi.c:	init_completion(&priv->xfer_done);
drivers/spi/spi-nxp-fspi.c:#include <linux/completion.h>
drivers/spi/spi-nxp-fspi.c:	struct completion c;
drivers/spi/spi-nxp-fspi.c:	init_completion(&f->c);
drivers/spi/spi-nxp-fspi.c:	if (!wait_for_completion_timeout(&f->c, msecs_to_jiffies(1000)))
drivers/spi/spi-oc-tiny.c:	struct completion done;
drivers/spi/spi-oc-tiny.c:		wait_for_completion(&hw->done);
drivers/spi/spi-oc-tiny.c:		init_completion(&hw->done);
drivers/spi/spi-omap2-mcspi.c:	struct completion dma_tx_completion;
drivers/spi/spi-omap2-mcspi.c:	struct completion dma_rx_completion;
drivers/spi/spi-omap2-mcspi.c:	struct completion	txdone;
drivers/spi/spi-omap2-mcspi.c:static int mcspi_wait_for_completion(struct  omap2_mcspi *mcspi,
drivers/spi/spi-omap2-mcspi.c:				     struct completion *x)
drivers/spi/spi-omap2-mcspi.c:		if (wait_for_completion_interruptible(x) ||
drivers/spi/spi-omap2-mcspi.c:		wait_for_completion(x);
drivers/spi/spi-omap2-mcspi.c:	complete(&mcspi_dma->dma_rx_completion);
drivers/spi/spi-omap2-mcspi.c:	complete(&mcspi_dma->dma_tx_completion);
drivers/spi/spi-omap2-mcspi.c:	ret = mcspi_wait_for_completion(mcspi, &mcspi_dma->dma_rx_completion);
drivers/spi/spi-omap2-mcspi.c:	reinit_completion(&mcspi_dma->dma_tx_completion);
drivers/spi/spi-omap2-mcspi.c:	reinit_completion(&mcspi_dma->dma_rx_completion);
drivers/spi/spi-omap2-mcspi.c:	reinit_completion(&mcspi->txdone);
drivers/spi/spi-omap2-mcspi.c:		ret = mcspi_wait_for_completion(mcspi, &mcspi_dma->dma_tx_completion);
drivers/spi/spi-omap2-mcspi.c:			ret = mcspi_wait_for_completion(mcspi, &mcspi->txdone);
drivers/spi/spi-omap2-mcspi.c:	init_completion(&mcspi_dma->dma_rx_completion);
drivers/spi/spi-omap2-mcspi.c:	init_completion(&mcspi_dma->dma_tx_completion);
drivers/spi/spi-omap2-mcspi.c:	complete(&mcspi_dma->dma_rx_completion);
drivers/spi/spi-omap2-mcspi.c:	complete(&mcspi_dma->dma_tx_completion);
drivers/spi/spi-omap2-mcspi.c:	init_completion(&mcspi->txdone);
drivers/spi/spi-pci1xxxx.c:	struct completion spi_xfer_done;
drivers/spi/spi-pci1xxxx.c:			reinit_completion(&p->spi_xfer_done);
drivers/spi/spi-pci1xxxx.c:			result = wait_for_completion_timeout(&p->spi_xfer_done,
drivers/spi/spi-pci1xxxx.c:	reinit_completion(&p->spi_xfer_done);
drivers/spi/spi-pci1xxxx.c:	ret = wait_for_completion_timeout(&p->spi_xfer_done, PCI1XXXX_SPI_TIMEOUT);
drivers/spi/spi-pci1xxxx.c:			init_completion(&spi_sub_ptr->spi_xfer_done);
drivers/spi/spi-pci1xxxx.c:			init_completion(&spi_sub_ptr->spi_xfer_done);
drivers/spi/spi-pic32-sqi.c:	struct completion	xfer_done;
drivers/spi/spi-pic32-sqi.c:	reinit_completion(&sqi->xfer_done);
drivers/spi/spi-pic32-sqi.c:	/* wait for xfer completion */
drivers/spi/spi-pic32-sqi.c:	time_left = wait_for_completion_timeout(&sqi->xfer_done, 5 * HZ);
drivers/spi/spi-pic32-sqi.c:	init_completion(&sqi->xfer_done);
drivers/spi/spi-pic32.c:	struct completion	xfer_done;
drivers/spi/spi-pic32.c:	reinit_completion(&pic32s->xfer_done);
drivers/spi/spi-pic32.c:	/* wait for completion */
drivers/spi/spi-pic32.c:	time_left = wait_for_completion_timeout(&pic32s->xfer_done, 2 * HZ);
drivers/spi/spi-pic32.c:	 * completion of the ongoing transfer. This might result into
drivers/spi/spi-pic32.c:	init_completion(&pic32s->xfer_done);
drivers/spi/spi-ppc4xx.c:	struct completion done;
drivers/spi/spi-ppc4xx.c:	wait_for_completion(&hw->done);
drivers/spi/spi-ppc4xx.c:	init_completion(&hw->done);
drivers/spi/spi-pxa2xx-dma.c:	 * just gets DMA completion. Calling pump_transfers() twice for the
drivers/spi/spi-qup.c:	struct completion	done;
drivers/spi/spi-qup.c:		if (!wait_for_completion_timeout(&qup->done, timeout))
drivers/spi/spi-qup.c:		if (!wait_for_completion_timeout(&qup->done, timeout))
drivers/spi/spi-qup.c:		reinit_completion(&controller->done);
drivers/spi/spi-qup.c:	reinit_completion(&controller->done);
drivers/spi/spi-qup.c:	init_completion(&controller->done);
drivers/spi/spi-rockchip-sfc.c:#include <linux/completion.h>
drivers/spi/spi-rockchip-sfc.c:	struct completion cp;
drivers/spi/spi-rockchip-sfc.c:	if (!wait_for_completion_timeout(&sfc->cp, msecs_to_jiffies(2000))) {
drivers/spi/spi-rockchip-sfc.c:			init_completion(&sfc->cp);
drivers/spi/spi-rockchip.c:	/* Zero length transfers won't trigger an interrupt on completion */
drivers/spi/spi-s3c64xx.c: * @xfer_completion: To indicate completion of xfer task.
drivers/spi/spi-s3c64xx.c:	struct completion               xfer_completion;
drivers/spi/spi-s3c64xx.c:			complete(&sdd->xfer_completion);
drivers/spi/spi-s3c64xx.c:			complete(&sdd->xfer_completion);
drivers/spi/spi-s3c64xx.c:	val = wait_for_completion_timeout(&sdd->xfer_completion, val);
drivers/spi/spi-s3c64xx.c:		if (!wait_for_completion_timeout(&sdd->xfer_completion, val))
drivers/spi/spi-s3c64xx.c:	reinit_completion(&sdd->xfer_completion);
drivers/spi/spi-s3c64xx.c:			reinit_completion(&sdd->xfer_completion);
drivers/spi/spi-s3c64xx.c:		complete(&sdd->xfer_completion);
drivers/spi/spi-s3c64xx.c:	init_completion(&sdd->xfer_completion);
drivers/spi/spi-sh-msiof.c:#include <linux/completion.h>
drivers/spi/spi-sh-msiof.c:	struct completion done;
drivers/spi/spi-sh-msiof.c:	struct completion done_txdma;
drivers/spi/spi-sh-msiof.c:static int sh_msiof_wait_for_completion(struct sh_msiof_spi_priv *p,
drivers/spi/spi-sh-msiof.c:					struct completion *x)
drivers/spi/spi-sh-msiof.c:		if (wait_for_completion_interruptible(x) ||
drivers/spi/spi-sh-msiof.c:		if (!wait_for_completion_timeout(x, HZ)) {
drivers/spi/spi-sh-msiof.c:	reinit_completion(&p->done);
drivers/spi/spi-sh-msiof.c:	ret = sh_msiof_wait_for_completion(p, &p->done);
drivers/spi/spi-sh-msiof.c:	reinit_completion(&p->done);
drivers/spi/spi-sh-msiof.c:		reinit_completion(&p->done_txdma);
drivers/spi/spi-sh-msiof.c:		/* wait for tx DMA completion */
drivers/spi/spi-sh-msiof.c:		ret = sh_msiof_wait_for_completion(p, &p->done_txdma);
drivers/spi/spi-sh-msiof.c:		/* wait for rx DMA completion */
drivers/spi/spi-sh-msiof.c:		ret = sh_msiof_wait_for_completion(p, &p->done);
drivers/spi/spi-sh-msiof.c:		ret = sh_msiof_wait_for_completion(p, &p->done);
drivers/spi/spi-sh-msiof.c:	init_completion(&p->done);
drivers/spi/spi-sh-msiof.c:	init_completion(&p->done_txdma);
drivers/spi/spi-sifive.c:	struct completion done;         /* wake-up from interrupt */
drivers/spi/spi-sifive.c:		reinit_completion(&spi->done);
drivers/spi/spi-sifive.c:		wait_for_completion(&spi->done);
drivers/spi/spi-sifive.c:	init_completion(&spi->done);
drivers/spi/spi-slave-mt27xx.c:	struct completion xfer_done;
drivers/spi/spi-slave-mt27xx.c:static int mtk_spi_slave_wait_for_completion(struct mtk_spi_slave *mdata)
drivers/spi/spi-slave-mt27xx.c:	if (wait_for_completion_interruptible(&mdata->xfer_done) ||
drivers/spi/spi-slave-mt27xx.c:	ret = mtk_spi_slave_wait_for_completion(mdata);
drivers/spi/spi-slave-mt27xx.c:	ret = mtk_spi_slave_wait_for_completion(mdata);
drivers/spi/spi-slave-mt27xx.c:	reinit_completion(&mdata->xfer_done);
drivers/spi/spi-slave-mt27xx.c:	init_completion(&mdata->xfer_done);
drivers/spi/spi-slave-system-control.c:#include <linux/completion.h>
drivers/spi/spi-slave-system-control.c:	struct completion finished;
drivers/spi/spi-slave-system-control.c:	init_completion(&priv->finished);
drivers/spi/spi-slave-system-control.c:	wait_for_completion(&priv->finished);
drivers/spi/spi-slave-time.c:#include <linux/completion.h>
drivers/spi/spi-slave-time.c:	struct completion finished;
drivers/spi/spi-slave-time.c:	init_completion(&priv->finished);
drivers/spi/spi-slave-time.c:	wait_for_completion(&priv->finished);
drivers/spi/spi-sn-f-ospi.c:	/* E7-8: Wait for completion and clear */
drivers/spi/spi-sn-f-ospi.c:	/* F8-9: Wait for completion and clear */
drivers/spi/spi-sprd.c:	struct completion xfer_completion;
drivers/spi/spi-sprd.c:	reinit_completion(&ss->xfer_completion);
drivers/spi/spi-sprd.c:	wait_for_completion(&(ss->xfer_completion));
drivers/spi/spi-sprd.c:			complete(&ss->xfer_completion);
drivers/spi/spi-sprd.c:		complete(&ss->xfer_completion);
drivers/spi/spi-sprd.c:	init_completion(&ss->xfer_completion);
drivers/spi/spi-st-ssc4.c:	struct completion	done;
drivers/spi/spi-st-ssc4.c:	reinit_completion(&spi_st->done);
drivers/spi/spi-st-ssc4.c:	wait_for_completion(&spi_st->done);
drivers/spi/spi-st-ssc4.c:	init_completion(&spi_st->done);
drivers/spi/spi-stm32-qspi.c:	struct completion data_completion;
drivers/spi/spi-stm32-qspi.c:	struct completion match_completion;
drivers/spi/spi-stm32-qspi.c:	struct completion dma_completion;
drivers/spi/spi-stm32-qspi.c:		complete(&qspi->match_completion);
drivers/spi/spi-stm32-qspi.c:		complete(&qspi->data_completion);
drivers/spi/spi-stm32-qspi.c:	struct completion *dma_completion = arg;
drivers/spi/spi-stm32-qspi.c:	complete(dma_completion);
drivers/spi/spi-stm32-qspi.c:	reinit_completion(&qspi->dma_completion);
drivers/spi/spi-stm32-qspi.c:	desc->callback_param = &qspi->dma_completion;
drivers/spi/spi-stm32-qspi.c:	if (!wait_for_completion_timeout(&qspi->dma_completion,
drivers/spi/spi-stm32-qspi.c:	reinit_completion(&qspi->data_completion);
drivers/spi/spi-stm32-qspi.c:	if (!wait_for_completion_timeout(&qspi->data_completion,
drivers/spi/spi-stm32-qspi.c:	reinit_completion(&qspi->match_completion);
drivers/spi/spi-stm32-qspi.c:	if (!wait_for_completion_timeout(&qspi->match_completion,
drivers/spi/spi-stm32-qspi.c:	init_completion(&qspi->dma_completion);
drivers/spi/spi-stm32-qspi.c:	init_completion(&qspi->data_completion);
drivers/spi/spi-stm32-qspi.c:	init_completion(&qspi->match_completion);
drivers/spi/spi-sun4i.c:	struct completion	done;
drivers/spi/spi-sun4i.c:	reinit_completion(&sspi->done);
drivers/spi/spi-sun4i.c:	time_left = wait_for_completion_timeout(&sspi->done,
drivers/spi/spi-sun4i.c:	init_completion(&sspi->done);
drivers/spi/spi-sun6i.c:	struct completion	done;
drivers/spi/spi-sun6i.c:	struct completion	dma_rx_done;
drivers/spi/spi-sun6i.c:	reinit_completion(&sspi->done);
drivers/spi/spi-sun6i.c:	reinit_completion(&sspi->dma_rx_done);
drivers/spi/spi-sun6i.c:	time_left = wait_for_completion_timeout(&sspi->done,
drivers/spi/spi-sun6i.c:			time_left = wait_for_completion_timeout(&sspi->dma_rx_done,
drivers/spi/spi-sun6i.c:	init_completion(&sspi->done);
drivers/spi/spi-sun6i.c:	init_completion(&sspi->dma_rx_done);
drivers/spi/spi-sunplus-sp7021.c:	struct completion isr_done;
drivers/spi/spi-sunplus-sp7021.c:	struct completion target_isr;
drivers/spi/spi-sunplus-sp7021.c:	reinit_completion(&pspim->target_isr);
drivers/spi/spi-sunplus-sp7021.c:	if (wait_for_completion_interruptible(&pspim->isr_done)) {
drivers/spi/spi-sunplus-sp7021.c:		dev_err(&spi->dev, "%s() wait_for_completion err\n", __func__);
drivers/spi/spi-sunplus-sp7021.c:	reinit_completion(&pspim->isr_done);
drivers/spi/spi-sunplus-sp7021.c:	if (wait_for_completion_interruptible(&pspim->isr_done)) {
drivers/spi/spi-sunplus-sp7021.c:		dev_err(&spi->dev, "%s() wait_for_completion err\n", __func__);
drivers/spi/spi-sunplus-sp7021.c:		reinit_completion(&pspim->isr_done);
drivers/spi/spi-sunplus-sp7021.c:		if (!wait_for_completion_interruptible_timeout(&pspim->isr_done, timeout)) {
drivers/spi/spi-sunplus-sp7021.c:			dev_err(&spi->dev, "wait_for_completion err\n");
drivers/spi/spi-sunplus-sp7021.c:	init_completion(&pspim->isr_done);
drivers/spi/spi-sunplus-sp7021.c:	init_completion(&pspim->target_isr);
drivers/spi/spi-synquacer.c:	struct completion transfer_done;
drivers/spi/spi-synquacer.c:	reinit_completion(&sspi->transfer_done);
drivers/spi/spi-synquacer.c:		status = wait_for_completion_timeout(&sspi->transfer_done,
drivers/spi/spi-synquacer.c:		status = wait_for_completion_timeout(&sspi->transfer_done,
drivers/spi/spi-synquacer.c:	init_completion(&sspi->transfer_done);
drivers/spi/spi-tegra114.c:#include <linux/completion.h>
drivers/spi/spi-tegra114.c:	struct completion			rx_dma_complete;
drivers/spi/spi-tegra114.c:	struct completion			tx_dma_complete;
drivers/spi/spi-tegra114.c:	struct completion			xfer_completion;
drivers/spi/spi-tegra114.c:	struct completion *dma_complete = args;
drivers/spi/spi-tegra114.c:	reinit_completion(&tspi->tx_dma_complete);
drivers/spi/spi-tegra114.c:	reinit_completion(&tspi->rx_dma_complete);
drivers/spi/spi-tegra114.c:		reinit_completion(&tspi->xfer_completion);
drivers/spi/spi-tegra114.c:		ret = wait_for_completion_timeout(&tspi->xfer_completion,
drivers/spi/spi-tegra114.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra114.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra114.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra114.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra114.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra114.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra114.c:	init_completion(&tspi->tx_dma_complete);
drivers/spi/spi-tegra114.c:	init_completion(&tspi->rx_dma_complete);
drivers/spi/spi-tegra114.c:	init_completion(&tspi->xfer_completion);
drivers/spi/spi-tegra20-sflash.c:#include <linux/completion.h>
drivers/spi/spi-tegra20-sflash.c:	struct completion			xfer_completion;
drivers/spi/spi-tegra20-sflash.c:		reinit_completion(&tsd->xfer_completion);
drivers/spi/spi-tegra20-sflash.c:		ret = wait_for_completion_timeout(&tsd->xfer_completion,
drivers/spi/spi-tegra20-sflash.c:		complete(&tsd->xfer_completion);
drivers/spi/spi-tegra20-sflash.c:		complete(&tsd->xfer_completion);
drivers/spi/spi-tegra20-sflash.c:	init_completion(&tsd->xfer_completion);
drivers/spi/spi-tegra20-slink.c:#include <linux/completion.h>
drivers/spi/spi-tegra20-slink.c:	struct completion			rx_dma_complete;
drivers/spi/spi-tegra20-slink.c:	struct completion			tx_dma_complete;
drivers/spi/spi-tegra20-slink.c:	struct completion			xfer_completion;
drivers/spi/spi-tegra20-slink.c:	struct completion *dma_complete = args;
drivers/spi/spi-tegra20-slink.c:	reinit_completion(&tspi->tx_dma_complete);
drivers/spi/spi-tegra20-slink.c:	reinit_completion(&tspi->rx_dma_complete);
drivers/spi/spi-tegra20-slink.c:	reinit_completion(&tspi->xfer_completion);
drivers/spi/spi-tegra20-slink.c:	ret = wait_for_completion_timeout(&tspi->xfer_completion,
drivers/spi/spi-tegra20-slink.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra20-slink.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra20-slink.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra20-slink.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra20-slink.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra20-slink.c:		complete(&tspi->xfer_completion);
drivers/spi/spi-tegra20-slink.c:	init_completion(&tspi->tx_dma_complete);
drivers/spi/spi-tegra20-slink.c:	init_completion(&tspi->rx_dma_complete);
drivers/spi/spi-tegra20-slink.c:	init_completion(&tspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:#include <linux/completion.h>
drivers/spi/spi-tegra210-quad.c:	struct completion			rx_dma_complete;
drivers/spi/spi-tegra210-quad.c:	struct completion			tx_dma_complete;
drivers/spi/spi-tegra210-quad.c:	struct completion			xfer_completion;
drivers/spi/spi-tegra210-quad.c:	struct completion *dma_complete = args;
drivers/spi/spi-tegra210-quad.c:	reinit_completion(&tqspi->tx_dma_complete);
drivers/spi/spi-tegra210-quad.c:	reinit_completion(&tqspi->rx_dma_complete);
drivers/spi/spi-tegra210-quad.c:			reinit_completion(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:			ret = wait_for_completion_timeout
drivers/spi/spi-tegra210-quad.c:					(&tqspi->xfer_completion,
drivers/spi/spi-tegra210-quad.c:		reinit_completion(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:		ret = wait_for_completion_timeout(&tqspi->xfer_completion,
drivers/spi/spi-tegra210-quad.c:		complete(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:		complete(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra210-quad.c:			wait_status = wait_for_completion_interruptible_timeout(
drivers/spi/spi-tegra210-quad.c:		complete(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:		complete(&tqspi->xfer_completion);
drivers/spi/spi-tegra210-quad.c:	init_completion(&tqspi->tx_dma_complete);
drivers/spi/spi-tegra210-quad.c:	init_completion(&tqspi->rx_dma_complete);
drivers/spi/spi-tegra210-quad.c:	init_completion(&tqspi->xfer_completion);
drivers/spi/spi-ti-qspi.c:	struct completion	transfer_complete;
drivers/spi/spi-ti-qspi.c:#define QSPI_COMPLETION_TIMEOUT		msecs_to_jiffies(2000)
drivers/spi/spi-ti-qspi.c:	unsigned long timeout = jiffies + QSPI_COMPLETION_TIMEOUT;
drivers/spi/spi-ti-qspi.c:	unsigned long timeout = jiffies + QSPI_COMPLETION_TIMEOUT;
drivers/spi/spi-ti-qspi.c:	reinit_completion(&qspi->transfer_complete);
drivers/spi/spi-ti-qspi.c:	time_left = wait_for_completion_timeout(&qspi->transfer_complete,
drivers/spi/spi-ti-qspi.c:		dev_err(qspi->dev, "DMA wait_for_completion_timeout\n");
drivers/spi/spi-ti-qspi.c:	init_completion(&qspi->transfer_complete);
drivers/spi/spi-uniphier.c:	struct completion xfer_done;
drivers/spi/spi-uniphier.c:	/* signal that we need to wait for completion */
drivers/spi/spi-uniphier.c:	reinit_completion(&priv->xfer_done);
drivers/spi/spi-uniphier.c:	time_left = wait_for_completion_timeout(&priv->xfer_done,
drivers/spi/spi-uniphier.c:	init_completion(&priv->xfer_done);
drivers/spi/spi-xilinx.c:	struct completion done;
drivers/spi/spi-xilinx.c:		reinit_completion(&xspi->done);
drivers/spi/spi-xilinx.c:			wait_for_completion(&xspi->done);
drivers/spi/spi-xilinx.c:	init_completion(&xspi->done);
drivers/spi/spi-xlp.c:	struct completion	done;		/* completion notification */
drivers/spi/spi-xlp.c:	time_left = wait_for_completion_timeout(&xs->done,
drivers/spi/spi-xlp.c:	init_completion(&xspi->done);
drivers/spi/spi-zynq-qspi.c: * @data_completion:	completion structure
drivers/spi/spi-zynq-qspi.c:	struct completion data_completion;
drivers/spi/spi-zynq-qspi.c:				complete(&xqspi->data_completion);
drivers/spi/spi-zynq-qspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynq-qspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynq-qspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynq-qspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynq-qspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynq-qspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynq-qspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynq-qspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynq-qspi.c:	init_completion(&xqspi->data_completion);
drivers/spi/spi-zynqmp-gqspi.c: * @data_completion:	completion structure
drivers/spi/spi-zynqmp-gqspi.c:	struct completion data_completion;
drivers/spi/spi-zynqmp-gqspi.c:		complete(&xqspi->data_completion);
drivers/spi/spi-zynqmp-gqspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynqmp-gqspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynqmp-gqspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynqmp-gqspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion,
drivers/spi/spi-zynqmp-gqspi.c:		reinit_completion(&xqspi->data_completion);
drivers/spi/spi-zynqmp-gqspi.c:		if (!wait_for_completion_timeout(&xqspi->data_completion, timeout))
drivers/spi/spi-zynqmp-gqspi.c:	init_completion(&xqspi->data_completion);
drivers/spi/spi.c:		if (wait_for_completion_interruptible(&ctlr->xfer_completion)) {
drivers/spi/spi.c:		ms = wait_for_completion_timeout(&ctlr->xfer_completion,
drivers/spi/spi.c:			reinit_completion(&ctlr->xfer_completion);
drivers/spi/spi.c: * spi_finalize_current_transfer - report completion of a transfer
drivers/spi/spi.c: * @ctlr: the controller reporting completion
drivers/spi/spi.c:	complete(&ctlr->xfer_completion);
drivers/spi/spi.c:	 * completion is used to guarantee that this function does not return
drivers/spi/spi.c:	 * use of the completion since its use involves expensive spin locks.
drivers/spi/spi.c:	 * spi_finalize_current_message() the completion will always be used,
drivers/spi/spi.c:	WRITE_ONCE(ctlr->cur_msg_need_completion, false);
drivers/spi/spi.c:	reinit_completion(&ctlr->cur_msg_completion);
drivers/spi/spi.c:	WRITE_ONCE(ctlr->cur_msg_need_completion, true);
drivers/spi/spi.c:		wait_for_completion(&ctlr->cur_msg_completion);
drivers/spi/spi.c:	if (READ_ONCE(ctlr->cur_msg_need_completion))
drivers/spi/spi.c:		complete(&ctlr->cur_msg_completion);
drivers/spi/spi.c:	init_completion(&ctlr->xfer_completion);
drivers/spi/spi.c:	init_completion(&ctlr->cur_msg_completion);
drivers/spi/spi.c: * @message: describes the data transfers, including completion callback
drivers/spi/spi.c: * The completion callback is invoked in a context which can't sleep.
drivers/spi/spi.c: * Until returning from the associated message completion callback,
drivers/spi/spi.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/spi/spi.c:		wait_for_completion(&done);
drivers/staging/fbtft/fb_st7789v.c:#include <linux/completion.h>
drivers/staging/fbtft/fb_st7789v.c:static struct completion panel_te; /* completion for panel TE line */
drivers/staging/fbtft/fb_st7789v.c:	init_completion(&panel_te);
drivers/staging/fbtft/fb_st7789v.c:		reinit_completion(&panel_te);
drivers/staging/fbtft/fb_st7789v.c:		ret = wait_for_completion_timeout(&panel_te,
drivers/staging/fieldbus/anybuss/host.c: * "tasks" (i.e. 1, 2 above) into a task queue, waits for their completion,
drivers/staging/fieldbus/anybuss/host.c: * and the kernel thread runs them to completion.
drivers/staging/fieldbus/anybuss/host.c: * and wait for task completion:
drivers/staging/fieldbus/anybuss/host.c: * queue thread, but also completes the card_boot completion.
drivers/staging/fieldbus/anybuss/host.c:	struct completion	done;
drivers/staging/fieldbus/anybuss/host.c:	init_completion(&t->done);
drivers/staging/fieldbus/anybuss/host.c:	ret = wait_for_completion_interruptible(&t->done);
drivers/staging/fieldbus/anybuss/host.c:	struct completion card_boot;
drivers/staging/fieldbus/anybuss/host.c:	if (completion_done(&cd->card_boot)) {
drivers/staging/fieldbus/anybuss/host.c:	reinit_completion(&cd->card_boot);
drivers/staging/fieldbus/anybuss/host.c:	init_completion(&cd->card_boot);
drivers/staging/fieldbus/anybuss/host.c:	if (!wait_for_completion_timeout(&cd->card_boot, TIMEOUT)) {
drivers/staging/greybus/fw-management.c:#include <linux/completion.h>
drivers/staging/greybus/fw-management.c:	struct completion	completion;
drivers/staging/greybus/fw-management.c:	complete(&fw_mgmt->completion);
drivers/staging/greybus/fw-management.c:	complete(&fw_mgmt->completion);
drivers/staging/greybus/fw-management.c:		if (!wait_for_completion_timeout(&fw_mgmt->completion,
drivers/staging/greybus/fw-management.c:		if (!wait_for_completion_timeout(&fw_mgmt->completion,
drivers/staging/greybus/fw-management.c:	init_completion(&fw_mgmt->completion);
drivers/staging/greybus/loopback.c:	int (*completion)(struct gb_loopback_async_operation *op_async);
drivers/staging/greybus/loopback.c:	wait_queue_head_t wq_completion;
drivers/staging/greybus/loopback.c:	wait_event(gb->wq_completion,
drivers/staging/greybus/loopback.c:	if (!result && op_async->completion)
drivers/staging/greybus/loopback.c:		result = op_async->completion(op_async);
drivers/staging/greybus/loopback.c:	wake_up(&gb->wq_completion);
drivers/staging/greybus/loopback.c:				       void *completion)
drivers/staging/greybus/loopback.c:	op_async->completion = completion;
drivers/staging/greybus/loopback.c:	wait_event_interruptible(gb->wq_completion,
drivers/staging/greybus/loopback.c:			/* Wait for synchronous and asynchronous completion */
drivers/staging/greybus/loopback.c:	init_waitqueue_head(&gb->wq_completion);
drivers/staging/greybus/uart.c:#include <linux/completion.h>
drivers/staging/greybus/uart.c:	struct completion credits_complete;
drivers/staging/greybus/uart.c:	ret = wait_for_completion_timeout(&gb_tty->credits_complete,
drivers/staging/greybus/uart.c:	init_completion(&gb_tty->credits_complete);
drivers/staging/ks7010/ks7010_sdio.c:	init_completion(&priv->confirm_wait);
drivers/staging/ks7010/ks7010_sdio.c:	if (!wait_for_completion_interruptible_timeout
drivers/staging/ks7010/ks7010_sdio.c:	if (!wait_for_completion_interruptible_timeout
drivers/staging/ks7010/ks_hostif.c:		time_left = wait_for_completion_interruptible_timeout(&priv->psstatus.wakeup_wait,
drivers/staging/ks7010/ks_hostif.c:	init_completion(&priv->psstatus.wakeup_wait);
drivers/staging/ks7010/ks_wlan.h:#include <linux/completion.h>
drivers/staging/ks7010/ks_wlan.h:	struct completion wakeup_wait;
drivers/staging/ks7010/ks_wlan.h:	struct completion confirm_wait;
drivers/staging/ks7010/ks_wlan_net.c:#include <linux/completion.h>
drivers/staging/ks7010/ks_wlan_net.c:	if (!wait_for_completion_interruptible_timeout
drivers/staging/media/atomisp/i2c/atomisp-mt9m114.c: * @poll: completion polling requirement
drivers/staging/media/atomisp/i2c/mt9m114.h:/* completion status polling requirements, usage based on Aptina .INI Rev2 */
drivers/staging/media/deprecated/atmel/atmel-isc-base.c:	reinit_completion(&isc->comp);
drivers/staging/media/deprecated/atmel/atmel-isc-base.c:	if (isc->cur_frm && !wait_for_completion_timeout(&isc->comp, 5 * HZ))
drivers/staging/media/deprecated/atmel/atmel-isc-base.c:	init_completion(&isc->comp);
drivers/staging/media/deprecated/atmel/atmel-isc.h: * @comp:		completion reference that signals frame completion
drivers/staging/media/deprecated/atmel/atmel-isc.h:	struct completion	comp;
drivers/staging/media/imx/imx-ic-prpencvf.c:	struct completion last_eof_comp;
drivers/staging/media/imx/imx-ic-prpencvf.c:	/* init EOF completion waitq */
drivers/staging/media/imx/imx-ic-prpencvf.c:	init_completion(&priv->last_eof_comp);
drivers/staging/media/imx/imx-ic-prpencvf.c:	 * and then wait for interrupt handler to mark completion.
drivers/staging/media/imx/imx-ic-prpencvf.c:	ret = wait_for_completion_timeout(
drivers/staging/media/imx/imx-media-csi.c:	struct completion last_eof_comp;
drivers/staging/media/imx/imx-media-csi.c:	/* init EOF completion waitq */
drivers/staging/media/imx/imx-media-csi.c:	init_completion(&priv->last_eof_comp);
drivers/staging/media/imx/imx-media-csi.c:	 * and then wait for interrupt handler to mark completion.
drivers/staging/media/imx/imx-media-csi.c:	ret = wait_for_completion_timeout(
drivers/staging/media/imx/imx-media-dev.c:	/* call the imx5/6/7 common probe completion handler */
drivers/staging/media/imx/imx-media-fim.c:	struct completion icap_first_event;
drivers/staging/media/imx/imx-media-fim.c:	ret = wait_for_completion_timeout(
drivers/staging/media/omap4iss/iss_video.c: * field count and state fields before waking up its completion handler.
drivers/staging/media/tegra-video/vi.h: *		MW_ACK_DONE event which indicates completion of writing frame
drivers/staging/most/dim2/dim2.c: * Return back the completed buffers to mostcore, using completion callback
drivers/staging/most/dim2/dim2.c: * completion call back.
drivers/staging/most/dim2/hal.c:	/* wait for transfer completion */
drivers/staging/most/net/net.c:	.tx_completion = comp_resume_tx_channel,
drivers/staging/most/net/net.c:	.rx_completion = comp_rx_data,
drivers/staging/most/video/video.c:	 * From the other hand mostcore still calling rx_completion()
drivers/staging/most/video/video.c:	.rx_completion = comp_rx_data,
drivers/staging/nvec/nvec.c:#include <linux/completion.h>
drivers/staging/nvec/nvec.c:	if (!(wait_for_completion_timeout(&nvec->sync_write,
drivers/staging/nvec/nvec.c:		err = wait_for_completion_interruptible_timeout(&nvec->ec_transfer,
drivers/staging/nvec/nvec.c:	init_completion(&nvec->sync_write);
drivers/staging/nvec/nvec.c:	init_completion(&nvec->ec_transfer);
drivers/staging/nvec/nvec.h:#include <linux/completion.h>
drivers/staging/nvec/nvec.h: * @ec_transfer: A completion that will be completed once a message has been
drivers/staging/nvec/nvec.h: * @sync_write: A completion to signal that a synchronous message is complete
drivers/staging/nvec/nvec.h:	struct completion ec_transfer;
drivers/staging/nvec/nvec.h:	struct completion sync_write;
drivers/staging/rtl8192e/rtllib_softmac.c:			 * as for the completion function, it does not need
drivers/staging/rtl8192e/rtllib_softmac.c:			 * as for the completion function, it does not need
drivers/staging/rtl8712/drv_types.h:#include <linux/completion.h>
drivers/staging/rtl8712/drv_types.h:	struct completion rtl8712_fw_ready;
drivers/staging/rtl8712/drv_types.h:	struct completion rx_filter_ready;
drivers/staging/rtl8712/hal_init.c:	init_completion(&padapter->rtl8712_fw_ready);
drivers/staging/rtl8712/os_intfs.c:	struct completion *completion =
drivers/staging/rtl8712/os_intfs.c:		wait_for_completion_interruptible(completion);
drivers/staging/rtl8712/osdep_intf.h:	struct completion io_retevt_comp;
drivers/staging/rtl8712/rtl8712_cmd.c:	struct completion *cmd_queue_comp =
drivers/staging/rtl8712/rtl8712_cmd.c:		if (wait_for_completion_interruptible(cmd_queue_comp))
drivers/staging/rtl8712/rtl871x_cmd.c:	init_completion(&pcmdpriv->cmd_queue_comp);
drivers/staging/rtl8712/rtl871x_cmd.c:	init_completion(&pcmdpriv->terminate_cmdthread_comp);
drivers/staging/rtl8712/rtl871x_cmd.h:	struct completion cmd_queue_comp;
drivers/staging/rtl8712/rtl871x_cmd.h:	struct completion terminate_cmdthread_comp;
drivers/staging/rtl8712/usb_intf.c:	init_completion(&padapter->rx_filter_ready);
drivers/staging/rtl8712/usb_intf.c:	wait_for_completion(&padapter->rtl8712_fw_ready);
drivers/staging/rtl8712/usb_ops_linux.c:	init_completion(&pintfpriv->io_retevt_comp);
drivers/staging/rtl8712/usb_ops_linux.c:	wait_for_completion_interruptible(&pintfpriv->io_retevt_comp);
drivers/staging/rtl8712/xmit_linux.c:	wait_for_completion(&adapter->rx_filter_ready);
drivers/staging/rtl8723bs/core/rtw_cmd.c:	init_completion(&pcmdpriv->cmd_queue_comp);
drivers/staging/rtl8723bs/core/rtw_cmd.c:	init_completion(&pcmdpriv->terminate_cmdthread_comp);
drivers/staging/rtl8723bs/core/rtw_cmd.c:		wait_for_completion(&adapter->cmdpriv.terminate_cmdthread_comp);
drivers/staging/rtl8723bs/core/rtw_cmd.c:		if (wait_for_completion_interruptible(&pcmdpriv->cmd_queue_comp)) {
drivers/staging/rtl8723bs/core/rtw_cmd.c:				   FUNC_ADPT_FMT " wait_for_completion_interruptible(&pcmdpriv->cmd_queue_comp) return != 0, break\n",
drivers/staging/rtl8723bs/core/rtw_xmit.c:	init_completion(&pxmitpriv->xmit_comp);
drivers/staging/rtl8723bs/core/rtw_xmit.c:	init_completion(&pxmitpriv->terminate_xmitthread_comp);
drivers/staging/rtl8723bs/core/rtw_xmit.c:	init_completion(&sctx->done);
drivers/staging/rtl8723bs/core/rtw_xmit.c:	if (!wait_for_completion_timeout(&sctx->done, expire))
drivers/staging/rtl8723bs/hal/rtl8723b_hal_init.c:		wait_for_completion(&xmitpriv->SdioXmitTerminate);
drivers/staging/rtl8723bs/hal/rtl8723bs_xmit.c:	if (wait_for_completion_interruptible(&pxmitpriv->xmit_comp)) {
drivers/staging/rtl8723bs/hal/rtl8723bs_xmit.c:	if (wait_for_completion_interruptible(&pxmitpriv->SdioXmitStart)) {
drivers/staging/rtl8723bs/hal/rtl8723bs_xmit.c:	init_completion(&xmitpriv->SdioXmitStart);
drivers/staging/rtl8723bs/hal/rtl8723bs_xmit.c:	init_completion(&xmitpriv->SdioXmitTerminate);
drivers/staging/rtl8723bs/include/rtw_cmd.h:#include <linux/completion.h>
drivers/staging/rtl8723bs/include/rtw_cmd.h:		struct completion cmd_queue_comp;
drivers/staging/rtl8723bs/include/rtw_cmd.h:		struct completion terminate_cmdthread_comp;
drivers/staging/rtl8723bs/include/rtw_xmit.h:#include <linux/completion.h>
drivers/staging/rtl8723bs/include/rtw_xmit.h:	struct completion done;
drivers/staging/rtl8723bs/include/rtw_xmit.h:	struct completion xmit_comp;
drivers/staging/rtl8723bs/include/rtw_xmit.h:	struct completion terminate_xmitthread_comp;
drivers/staging/rtl8723bs/include/rtw_xmit.h:	struct completion SdioXmitStart;
drivers/staging/rtl8723bs/include/rtw_xmit.h:	struct completion SdioXmitTerminate;
drivers/staging/rtl8723bs/os_dep/os_intfs.c:		wait_for_completion(&padapter->cmdpriv.terminate_cmdthread_comp); /* wait for cmd_thread to run */
drivers/staging/rtl8723bs/os_dep/os_intfs.c:	wait_for_completion(&padapter->xmitpriv.terminate_xmitthread_comp);
drivers/staging/rts5208/rtsx.c:	wait_for_completion(&dev->notify);
drivers/staging/rts5208/rtsx.c:		if (wait_for_completion_interruptible(&dev->cmnd_ready))
drivers/staging/rts5208/rtsx.c:	 * complete()/wait_for_completion() is similar to up()/down(),
drivers/staging/rts5208/rtsx.c:		wait_for_completion(&dev->control_exit);
drivers/staging/rts5208/rtsx.c:		wait_for_completion(&dev->polling_exit);
drivers/staging/rts5208/rtsx.c:	wait_for_completion(&dev->scanning_done);
drivers/staging/rts5208/rtsx.c:	init_completion(&dev->cmnd_ready);
drivers/staging/rts5208/rtsx.c:	init_completion(&dev->control_exit);
drivers/staging/rts5208/rtsx.c:	init_completion(&dev->polling_exit);
drivers/staging/rts5208/rtsx.c:	init_completion(&dev->notify);
drivers/staging/rts5208/rtsx.c:	init_completion(&dev->scanning_done);
drivers/staging/rts5208/rtsx.c:	wait_for_completion(&dev->control_exit);
drivers/staging/rts5208/rtsx.h:	struct completion	cmnd_ready;	 /* to sleep thread on	    */
drivers/staging/rts5208/rtsx.h:	struct completion	control_exit;	 /* control thread exit	    */
drivers/staging/rts5208/rtsx.h:	struct completion	polling_exit;	 /* polling thread exit	    */
drivers/staging/rts5208/rtsx.h:	struct completion	notify;		 /* thread begin/end	    */
drivers/staging/rts5208/rtsx.h:	struct completion	scanning_done;	 /* wait for scan thread    */
drivers/staging/rts5208/rtsx.h:	struct completion	*done;
drivers/staging/rts5208/rtsx_transport.c:	struct completion trans_done;
drivers/staging/rts5208/rtsx_transport.c:	init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:	timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/rts5208/rtsx_transport.c:	struct completion trans_done;
drivers/staging/rts5208/rtsx_transport.c:	init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:	timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/rts5208/rtsx_transport.c:		init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:		timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/rts5208/rtsx_transport.c:	struct completion trans_done;
drivers/staging/rts5208/rtsx_transport.c:		init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:		timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/rts5208/rtsx_transport.c:		init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:		timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/rts5208/rtsx_transport.c:	struct completion trans_done;
drivers/staging/rts5208/rtsx_transport.c:	init_completion(&trans_done);
drivers/staging/rts5208/rtsx_transport.c:	timeleft = wait_for_completion_interruptible_timeout(&trans_done,
drivers/staging/vc04_services/bcm2835-audio/bcm2835-vchiq.c:#include <linux/completion.h>
drivers/staging/vc04_services/bcm2835-audio/bcm2835-vchiq.c:	struct completion msg_avail_comp;
drivers/staging/vc04_services/bcm2835-audio/bcm2835-vchiq.c:		init_completion(&instance->msg_avail_comp);
drivers/staging/vc04_services/bcm2835-audio/bcm2835-vchiq.c:		if (!wait_for_completion_timeout(&instance->msg_avail_comp,
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.c:			 * return buffer, and signal frame completion
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.c:		/* signal frame completion */
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.c:	/*init_completion(&dev->capture.frame_cmplt); */
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.c:	init_completion(&dev->capture.frame_cmplt);
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.c:		time_left = wait_for_completion_timeout(&dev->capture.frame_cmplt,
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.h:		/* last frame completion */
drivers/staging/vc04_services/bcm2835-camera/bcm2835-camera.h:		struct completion frame_cmplt;
drivers/staging/vc04_services/include/linux/raspberrypi/vchiq.h:struct vchiq_completion_data_kernel {
drivers/staging/vc04_services/interface/TESTING:       DEBUG: AWAIT_COMPLETION_LINE = 0(0x0)
drivers/staging/vc04_services/interface/TESTING:       DEBUG: COMPLETION_QUEUE_FULL_COUNT = 0(0x0)
drivers/staging/vc04_services/interface/TESTING:       DEBUG: AWAIT_COMPLETION_LINE = 0(0x0)
drivers/staging/vc04_services/interface/TESTING:       DEBUG: COMPLETION_QUEUE_FULL_COUNT = 0(0x0)
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:#include <linux/completion.h>
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	struct completion ka_evt;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	init_completion(&platform_state->ka_evt);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:add_completion(struct vchiq_instance *instance, enum vchiq_reason reason,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	struct vchiq_completion_data_kernel *completion;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	insert = instance->completion_insert;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	while ((insert - instance->completion_remove) >= MAX_COMPLETIONS) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		dev_dbg(instance->state->dev, "core: completion queue full\n");
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		DEBUG_COUNT(COMPLETION_QUEUE_FULL_COUNT);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		if (wait_for_completion_interruptible(&instance->remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	completion = &instance->completions[insert & (MAX_COMPLETIONS - 1)];
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	completion->header = header;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	completion->reason = reason;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	/* N.B. service_userdata is updated while processing AWAIT_COMPLETION */
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	completion->service_userdata = user_service->service;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	completion->bulk_userdata = bulk_userdata;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	 * A write barrier is needed here to ensure that the entire completion
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	instance->completion_insert = insert;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	 * If there is no MESSAGE_AVAILABLE in the completion
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	     instance->completion_remove) < 0) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		ret = add_completion(instance, reason, NULL, user_service,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	if (wait_for_completion_interruptible(&user_service->remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	 * contains a circular buffer for completion records.
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	bool skip_completion = false;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		 * there is a MESSAGE_AVAILABLE in the completion queue then
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		 * bypass the completion queue.
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:			instance->completion_remove) >= 0) ||
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:			skip_completion = true;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	if (skip_completion)
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:	return add_completion(instance, reason, header, user_service,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		seq_printf(f, "Instance %pK: pid %d,%s completions %d/%d\n",
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:			   instance->completion_insert -
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:			   instance->completion_remove,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:			   MAX_COMPLETIONS);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.c:		if (wait_for_completion_interruptible(&arm_state->ka_evt)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:#define MAX_COMPLETIONS 128
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct completion insert_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct completion remove_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct completion close_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct vchiq_completion_data_kernel completions[MAX_COMPLETIONS];
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	int completion_insert;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	int completion_remove;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct completion insert_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct completion remove_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_arm.h:	struct mutex completion_mutex;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:#include <linux/completion.h>
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (!try_wait_for_completion(&state->slot_available_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:			    (wait_for_completion_interruptible(&state->slot_available_event)))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:			if (wait_for_completion_interruptible(&state->data_quota_event))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:			if (wait_for_completion_interruptible(&quota->quota_event))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&state->connect);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&state->slot_available_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&state->data_quota_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		init_completion(&quota->quota_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&service->msg_queue_pop))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&service->msg_queue_push))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&service->remove_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&service->bulk_remove_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&service->msg_queue_pop);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	init_completion(&service->msg_queue_push);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:	if (wait_for_completion_interruptible(&service->remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&state->connect))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&service->remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&service->remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		init_completion(&bulk_waiter->event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:			if (wait_for_completion_interruptible(&service->bulk_remove_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		if (wait_for_completion_interruptible(&bulk_waiter->event))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		"AWAIT_COMPLETION_LINE",
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.c:		"COMPLETION_QUEUE_FULL_COUNT"
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:#include <linux/completion.h>
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	DEBUG_AWAIT_COMPLETION_LINE,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	DEBUG_COMPLETION_QUEUE_FULL_COUNT,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion remove_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion bulk_remove_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion msg_queue_pop;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion msg_queue_push;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion quota_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion connect;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion slot_available_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion data_quota_event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_core.h:	struct completion event;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	"AWAIT_COMPLETION",
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	user_service->message_available_pos = instance->completion_remove - 1;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	init_completion(&user_service->insert_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	init_completion(&user_service->remove_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	init_completion(&user_service->close_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			if (wait_for_completion_interruptible(&user_service->insert_event)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:struct vchiq_completion_data32 {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:static int vchiq_put_completion(struct vchiq_completion_data __user *buf,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:				struct vchiq_completion_data *completion,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	struct vchiq_completion_data32 __user *buf32 = (void __user *)buf;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_completion_data32 tmp = {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			.reason		  = completion->reason,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			.header		  = ptr_to_compat(completion->header),
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			.service_userdata = ptr_to_compat(completion->service_userdata),
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			.bulk_userdata	  = ptr_to_compat(completion->bulk_userdata),
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		if (copy_to_user(&buf[index], completion, sizeof(*completion)))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:static int vchiq_ioc_await_completion(struct vchiq_instance *instance,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:				      struct vchiq_await_completion *args,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	mutex_lock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	while ((instance->completion_remove == instance->completion_insert) && !instance->closing) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		mutex_unlock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		rc = wait_for_completion_interruptible(&instance->insert_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		mutex_lock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			dev_dbg(instance->state->dev, "arm: AWAIT_COMPLETION interrupted\n");
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	remove = instance->completion_remove;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_completion_data_kernel *completion;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_completion_data user_completion;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		if (remove == instance->completion_insert)
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		completion = &instance->completions[remove & (MAX_COMPLETIONS - 1)];
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		 * prefetch of a stale completion record
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		service = completion->service_userdata;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		memset(&user_completion, 0, sizeof(user_completion));
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		user_completion = (struct vchiq_completion_data) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			.reason = completion->reason,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		header = completion->header;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			/* The completion must point to the msgbuf. */
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			user_completion.header = msgbuf;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		if ((completion->reason == VCHIQ_SERVICE_CLOSED) &&
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		user_completion.bulk_userdata = completion->bulk_userdata;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		if (vchiq_put_completion(args->buf, &user_completion, ret)) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		instance->completion_remove = remove;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	mutex_unlock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	DEBUG_TRACE(AWAIT_COMPLETION_LINE);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:			/* Wake the completion thread and ask it to exit */
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		    wait_for_completion_interruptible(&user_service->close_event))
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	case VCHIQ_IOC_AWAIT_COMPLETION: {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_await_completion args;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_await_completion __user *argp;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		ret = vchiq_ioc_await_completion(instance, &args,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:struct vchiq_await_completion32 {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:#define VCHIQ_IOC_AWAIT_COMPLETION32 \
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	_IOWR(VCHIQ_IOC_MAGIC, 7, struct vchiq_await_completion32)
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:vchiq_compat_ioctl_await_completion(struct file *file,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:				    struct vchiq_await_completion32 __user *argp)
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	struct vchiq_await_completion args;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	struct vchiq_await_completion32 args32;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	args = (struct vchiq_await_completion) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	return vchiq_ioc_await_completion(file->private_data, &args,
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	case VCHIQ_IOC_AWAIT_COMPLETION32:
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		return vchiq_compat_ioctl_await_completion(file, cmd, argp);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	init_completion(&instance->insert_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	init_completion(&instance->remove_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	mutex_init(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	mutex_lock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	/* Wake the completion thread and ask it to exit */
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	mutex_unlock(&instance->completion_mutex);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	/* Wake the slot handler if the completion queue is full. */
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		wait_for_completion(&service->remove_event);
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:	while (instance->completion_remove != instance->completion_insert) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		struct vchiq_completion_data_kernel *completion;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		completion = &instance->completions[instance->completion_remove
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:						    & (MAX_COMPLETIONS - 1)];
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		service = completion->service_userdata;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		if (completion->reason == VCHIQ_SERVICE_CLOSED) {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_dev.c:		instance->completion_remove++;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_ioctl.h:struct vchiq_completion_data {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_ioctl.h:struct vchiq_await_completion {
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_ioctl.h:	struct vchiq_completion_data __user *buf;
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_ioctl.h:#define VCHIQ_IOC_AWAIT_COMPLETION \
drivers/staging/vc04_services/interface/vchiq_arm/vchiq_ioctl.h:	_IOWR(VCHIQ_IOC_MAGIC, 7, struct vchiq_await_completion)
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:#include <linux/completion.h>
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:			/* completion upon reply */
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:			struct completion cmplt;
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:					 * completion will trigger callback
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:				 * completion will trigger callback
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:			/* todo: should this check (completion_done()
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:			 * flag to tell us the completion has been
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:	init_completion(&msg_context->u.sync.cmplt);
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:	time_left = wait_for_completion_timeout(&msg_context->u.sync.cmplt,
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.c:		pr_err("timed out waiting for sync completion\n");
drivers/staging/vc04_services/vchiq-mmal/mmal-vchiq.h:	/* callback on buffer completion */
drivers/staging/vme_user/vme_tsi148.c:	dev_err(tsi148_bridge->parent, "PCI-X attribute reg: %08x, PCI-X split completion reg: %08x\n",
drivers/staging/vme_user/vme_tsi148.h:#define TSI148_PCFS_PCIXSTAT_SCD       BIT(18)	/* Split completion discard */
drivers/target/iscsi/cxgbit/cxgbit.h:#include <linux/completion.h>
drivers/target/iscsi/cxgbit/cxgbit.h:	SKCBF_TX_FLAG_COMPL	= (1 << 1), /* wr completion flag */
drivers/target/iscsi/cxgbit/cxgbit.h:	struct completion completion;
drivers/target/iscsi/cxgbit/cxgbit.h:	struct completion accept_comp;
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	reinit_completion(&wr_waitp->completion);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	complete(&wr_waitp->completion);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	ret = wait_for_completion_timeout(&wr_waitp->completion, timeout * HZ);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	init_completion(&cnp->com.wr_wait.completion);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	init_completion(&cnp->accept_comp);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	ret = wait_for_completion_interruptible(&cnp->accept_comp);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	init_completion(&csk->com.wr_wait.completion);
drivers/target/iscsi/cxgbit/cxgbit_lro.h:	PDUCBF_RX_DDP_CMP	= (1 << 4), /* ddp completion */
drivers/target/iscsi/cxgbit/cxgbit_target.c:			wait_for_completion_timeout(&conn->conn_logout_comp,
drivers/target/iscsi/iscsi_target.c:#include <linux/completion.h>
drivers/target/iscsi/iscsi_target.c:	init_completion(&np->np_restart_comp);
drivers/target/iscsi/iscsi_target.c:		wait_for_completion(&np->np_restart_comp);
drivers/target/iscsi/iscsi_target.c:		wait_for_completion(&tpg_np->tpg_np_comp);
drivers/target/iscsi/iscsi_target.c:		wait_for_completion_interruptible_timeout(
drivers/target/iscsi/iscsi_target.c:		wait_for_completion_interruptible_timeout(
drivers/target/iscsi/iscsi_target.c:			wait_for_completion_timeout(&conn->conn_logout_comp,
drivers/target/iscsi/iscsi_target.c:	rc = wait_for_completion_interruptible(&conn->rx_login_comp);
drivers/target/iscsi/iscsi_target.c:			 * to tell LIO to perform the completion process.
drivers/target/iscsi/iscsi_target.c:	 * to signal logout response TX interrupt completion.  Go ahead and skip
drivers/target/iscsi/iscsi_target.c:		wait_for_completion(&conn->conn_post_wait_comp);
drivers/target/iscsi/iscsi_target.c:		wait_for_completion(&conn->conn_post_wait_comp);
drivers/target/iscsi/iscsi_target.c:		wait_for_completion(&sess->session_wait_comp);
drivers/target/iscsi/iscsi_target_erl0.c:	wait_for_completion(&conn->conn_wait_rcfr_comp);
drivers/target/iscsi/iscsi_target_erl0.c:	wait_for_completion(&conn->conn_wait_comp);
drivers/target/iscsi/iscsi_target_erl1.c:		" completion of %sDataOUT Sequence Offset: %u, Length: %u\n",
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&sess->async_msg_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&sess->reinstatement_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&sess->session_wait_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&sess->session_waiting_on_uc_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->conn_post_wait_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->conn_wait_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->conn_wait_rcfr_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->conn_waiting_on_uc_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->conn_logout_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->rx_half_close_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->tx_half_close_comp);
drivers/target/iscsi/iscsi_target_login.c:	init_completion(&conn->rx_login_comp);
drivers/target/iscsi/iscsi_target_tpg.c:	init_completion(&tpg_np->tpg_np_comp);
drivers/target/iscsi/iscsi_target_util.c:		wait_for_completion(&sess->session_waiting_on_uc_comp);
drivers/target/iscsi/iscsi_target_util.c:		wait_for_completion(&conn->conn_waiting_on_uc_comp);
drivers/target/loopback/tcm_loop.c:	init_completion(&tl_cmd->tmr_done);
drivers/target/loopback/tcm_loop.c:	wait_for_completion(&tl_cmd->tmr_done);
drivers/target/loopback/tcm_loop.h:	struct completion tmr_done;
drivers/target/target_core_device.c:	init_completion(&new->pr_comp);
drivers/target/target_core_device.c:		wait_for_completion(&orig->pr_comp);
drivers/target/target_core_device.c:	wait_for_completion(&orig->pr_comp);
drivers/target/target_core_device.c:	init_completion(&xcopy_lun->lun_shutdown_comp);
drivers/target/target_core_fabric_configfs.c:target_fabric_wwn_cmd_completion_affinity_show(struct config_item *item,
drivers/target/target_core_fabric_configfs.c:target_fabric_wwn_cmd_completion_affinity_store(struct config_item *item,
drivers/target/target_core_fabric_configfs.c:			pr_err("Command completion value must be between %d and %d or an online CPU.\n",
drivers/target/target_core_fabric_configfs.c:CONFIGFS_ATTR(target_fabric_wwn_, cmd_completion_affinity);
drivers/target/target_core_fabric_configfs.c:	&target_fabric_wwn_attr_cmd_completion_affinity,
drivers/target/target_core_pr.c:			 * completion of adding ALL_TG_PT=1 registrations in
drivers/target/target_core_sbc.c:	 * upon MISCOMPARE, or in compare_and_write_done() upon completion
drivers/target/target_core_tpg.c:	init_completion(&acl->acl_free_comp);
drivers/target/target_core_tpg.c:	wait_for_completion(&acl->acl_free_comp);
drivers/target/target_core_tpg.c:	init_completion(&lun->lun_shutdown_comp);
drivers/target/target_core_transport.c:static struct workqueue_struct *target_completion_wq;
drivers/target/target_core_transport.c:	target_completion_wq = alloc_workqueue("target_completion",
drivers/target/target_core_transport.c:	if (!target_completion_wq)
drivers/target/target_core_transport.c:		goto out_free_completion_wq;
drivers/target/target_core_transport.c:out_free_completion_wq:
drivers/target/target_core_transport.c:	destroy_workqueue(target_completion_wq);
drivers/target/target_core_transport.c:	destroy_workqueue(target_completion_wq);
drivers/target/target_core_transport.c:	init_completion(&cmd_cnt->stop_done);
drivers/target/target_core_transport.c:		queue_work(target_completion_wq, &cmd->work);
drivers/target/target_core_transport.c:	queue_work_on(cpu, target_completion_wq, &cmd->work);
drivers/target/target_core_transport.c:	init_completion(&cmd->t_transport_stop_comp);
drivers/target/target_core_transport.c:		queue_work(target_completion_wq, &cmd->work);
drivers/target/target_core_transport.c: * Called from I/O completion to determine which dormant/delayed
drivers/target/target_core_transport.c:	DECLARE_COMPLETION_ONSTACK(compl);
drivers/target/target_core_transport.c:	wait_for_completion(&compl);
drivers/target/target_core_transport.c:	DECLARE_COMPLETION_ONSTACK(compl);
drivers/target/target_core_transport.c:		wait_for_completion(&compl);
drivers/target/target_core_transport.c:	struct completion *free_compl = se_cmd->free_compl;
drivers/target/target_core_transport.c:	struct completion *abrt_compl = se_cmd->abrt_compl;
drivers/target/target_core_transport.c:	wait_for_completion(&cmd_cnt->stop_done);
drivers/target/target_core_transport.c:	wait_for_completion(&lun->lun_shutdown_comp);
drivers/target/target_core_transport.c:	while (!wait_for_completion_timeout(&cmd->t_transport_stop_comp,
drivers/target/target_core_transport.c:	pr_debug("wait_for_tasks: Stopped wait_for_completion(&cmd->"
drivers/target/target_core_user.c:	struct completion complete;
drivers/target/target_core_user.c:		pr_err("tcmu nl cmd %u/%d completion could not find device with dev id %u.\n",
drivers/target/target_core_user.c:static bool tcmu_handle_completion(struct tcmu_cmd *cmd,
drivers/target/target_core_user.c:		 * Keep this command after completion, since userspace still
drivers/target/target_core_user.c:		 * a second completion later.
drivers/target/target_core_user.c:static bool tcmu_handle_completions(struct tcmu_dev *udev)
drivers/target/target_core_user.c:		pr_err("ring broken, not handling completions\n");
drivers/target/target_core_user.c:		if (!tcmu_handle_completion(cmd, entry, keep_buf))
drivers/target/target_core_user.c:	if (tcmu_handle_completions(udev))
drivers/target/target_core_user.c:	init_completion(&nl_cmd->complete);
drivers/target/target_core_user.c:	wait_for_completion(&nl_cmd->complete);
drivers/target/target_core_user.c:	tcmu_handle_completions(udev);
drivers/target/target_core_user.c:		if (tcmu_handle_completions(udev))
drivers/target/target_core_xcopy.c:	struct completion xpt_passthrough_sem;
drivers/target/target_core_xcopy.c:	wait_for_completion_interruptible(&xpt_cmd->xpt_passthrough_sem);
drivers/target/target_core_xcopy.c:	init_completion(&xpt_cmd.xpt_passthrough_sem);
drivers/target/target_core_xcopy.c:	init_completion(&xpt_cmd.xpt_passthrough_sem);
drivers/tee/optee/call.c:	 * optee_cq_wait_for_completion().
drivers/tee/optee/call.c:	 * guarantees that we don't lose a completion if secure world
drivers/tee/optee/call.c:	init_completion(&w->c);
drivers/tee/optee/call.c:		optee_cq_wait_for_completion(cq, w);
drivers/tee/optee/call.c:void optee_cq_wait_for_completion(struct optee_call_queue *cq,
drivers/tee/optee/call.c:	wait_for_completion(&w->c);
drivers/tee/optee/call.c:	reinit_completion(&w->c);
drivers/tee/optee/call.c:		if (w->sys_thread && !completion_done(&w->c)) {
drivers/tee/optee/call.c:		if (!completion_done(&w->c)) {
drivers/tee/optee/call.c:	 * If we're completed we've got a completion from another task that
drivers/tee/optee/call.c:	if (completion_done(&w->c))
drivers/tee/optee/ffa_abi.c:			optee_cq_wait_for_completion(&optee->call_queue, &w);
drivers/tee/optee/notif.c:	struct completion c;
drivers/tee/optee/notif.c:	init_completion(&entry->c);
drivers/tee/optee/notif.c:	 * Unlock temporarily and wait for completion.
drivers/tee/optee/notif.c:		if (!wait_for_completion_timeout(&entry->c, timeout))
drivers/tee/optee/notif.c:		wait_for_completion(&entry->c);
drivers/tee/optee/optee_private.h: * @c			Waiting completion reference
drivers/tee/optee/optee_private.h:	struct completion c;
drivers/tee/optee/optee_private.h: * @reqs_c:		completion used by supplicant when waiting for a
drivers/tee/optee/optee_private.h:	struct completion reqs_c;
drivers/tee/optee/optee_private.h:void optee_cq_wait_for_completion(struct optee_call_queue *cq,
drivers/tee/optee/smc_abi.c:		optee_cq_wait_for_completion(&optee->call_queue, &w);
drivers/tee/optee/smc_abi.c:			optee_cq_wait_for_completion(&optee->call_queue, &w);
drivers/tee/optee/smc_abi.c:			optee_cq_wait_for_completion(&optee->call_queue, &w);
drivers/tee/optee/supp.c:	struct completion c;
drivers/tee/optee/supp.c:	init_completion(&supp->reqs_c);
drivers/tee/optee/supp.c:	init_completion(&req->c);
drivers/tee/optee/supp.c:	 * returned from wait_for_completion(&req->c) successfully we have
drivers/tee/optee/supp.c:	while (wait_for_completion_interruptible(&req->c)) {
drivers/tee/optee/supp.c:		 * wait_for_completion() to avoid needless spinning.
drivers/tee/optee/supp.c:		if (wait_for_completion_interruptible(&supp->reqs_c))
drivers/tee/tee_core.c:	init_completion(&teedev->c_no_users);
drivers/tee/tee_core.c:	wait_for_completion(&teedev->c_no_users);
drivers/tee/tee_private.h:#include <linux/completion.h>
drivers/thermal/qcom/tsens.c:		 * Disable cycle completion monitoring
drivers/thermal/qcom/tsens.c:		 * Disable cycle completion monitoring
drivers/thermal/qcom/tsens.h:	/* CYCLE COMPLETION MONITOR */
drivers/thermal/thermal_core.c:	init_completion(&tz->removal);
drivers/thermal/thermal_core.c:	init_completion(&tz->resume);
drivers/thermal/thermal_core.c:	wait_for_completion(&tz->removal);
drivers/thermal/thermal_core.c:				wait_for_completion(&tz->resume);
drivers/thermal/thermal_core.c:			reinit_completion(&tz->resume);
drivers/thermal/thermal_core.h: * @removal:	removal completion
drivers/thermal/thermal_core.h: * @resume:	resume completion
drivers/thermal/thermal_core.h:	struct completion removal;
drivers/thermal/thermal_core.h:	struct completion resume;
drivers/thunderbolt/ctl.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/thunderbolt/ctl.c:	if (!wait_for_completion_timeout(&done, timeout))
drivers/thunderbolt/ctl.c:		name = "router operation completion";
drivers/thunderbolt/ctl.c:		name = "port operation completion";
drivers/thunderbolt/dma_port.c:static int dma_port_wait_for_completion(struct tb_dma_port *dma,
drivers/thunderbolt/dma_port.c:	ret = dma_port_wait_for_completion(dma, timeout);
drivers/thunderbolt/dma_test.c:#include <linux/completion.h>
drivers/thunderbolt/dma_test.c:	struct completion complete;
drivers/thunderbolt/dma_test.c:		reinit_completion(&dt->complete);
drivers/thunderbolt/dma_test.c:		ret = wait_for_completion_interruptible(&dt->complete);
drivers/thunderbolt/dma_test.c:	init_completion(&dt->complete);
drivers/thunderbolt/dma_test.c:	 * wait_for_completion_interruptible() with -ERESTARTSYS and the
drivers/thunderbolt/icm.c:static int pci2cio_wait_completion(struct icm *icm, unsigned long timeout_msec)
drivers/thunderbolt/icm.c:	ret = pci2cio_wait_completion(icm, 5000);
drivers/thunderbolt/icm.c:	return pci2cio_wait_completion(icm, 5000);
drivers/thunderbolt/icm.c:	init_completion(&sw->rpm_complete);
drivers/thunderbolt/icm.c:		reinit_completion(&sw->rpm_complete);
drivers/thunderbolt/icm.c:		if (!wait_for_completion_timeout(&sw->rpm_complete,
drivers/thunderbolt/tb.h: * @rpm_complete: Completion used to wait for runtime resume to
drivers/thunderbolt/tb.h:	struct completion rpm_complete;
drivers/thunderbolt/tmu.c:	 * the completion of the post_time register becomes 0.
drivers/thunderbolt/usb4.c: * usb4_port_asym_start() - Start symmetry change and wait for completion
drivers/thunderbolt/usb4.c: * Wait for completion of the change.
drivers/thunderbolt/usb4.c: * completion metadata (the result) is then stored into @status. If
drivers/tty/goldfish.c:			 * the completion of the read/write operation.
drivers/tty/hvc/hvc_iucv.c:	wait_queue_head_t	sndbuf_waitq;	/* wait for send completion */
drivers/tty/hvc/hvc_iucv.c: * flush_sndbuf_sync() - Flush send buffer and wait for completion
drivers/tty/hvc/hvc_iucv.c: * to flush any buffered terminal output data and waits for completion.
drivers/tty/hvc/hvc_iucv.c: * hvc_iucv_msg_complete() - IUCV handler to process message completion
drivers/tty/hvc/hvc_iucv.c: * The function is called upon completion of message delivery to remove the
drivers/tty/hvc/hvcs.c:#include <linux/completion.h>
drivers/tty/hvc/hvcs.c:	struct completion *destroyed;
drivers/tty/hvc/hvcs.c:	struct completion *comp;
drivers/tty/hvc/hvcs.c:	DECLARE_COMPLETION_ONSTACK(comp);
drivers/tty/hvc/hvcs.c:	wait_for_completion(&comp);
drivers/tty/mips_ejtag_fdc.c:#include <linux/completion.h>
drivers/tty/mips_ejtag_fdc.c: * @xmit_empty:		Completion for xmit buffer being empty.
drivers/tty/mips_ejtag_fdc.c:	struct completion		 xmit_empty;
drivers/tty/mips_ejtag_fdc.c:		wait_for_completion(&dport->xmit_empty);
drivers/tty/mips_ejtag_fdc.c:		reinit_completion(&dport->xmit_empty);
drivers/tty/mips_ejtag_fdc.c:		init_completion(&dport->xmit_empty);
drivers/tty/n_gsm.c: *	us from colliding with another sender or a receive completion event.
drivers/tty/serdev/core.c:		reinit_completion(&serdev->write_comp);
drivers/tty/serdev/core.c:		timeout = wait_for_completion_interruptible_timeout(&serdev->write_comp,
drivers/tty/serdev/core.c:	init_completion(&serdev->write_comp);
drivers/tty/serial/8250/8250_dma.c:	 * New DMA Rx can be started during the completion handler before it
drivers/tty/serial/8250/8250_omap.c:	 * completion callback. A previous RX timeout flush would have
drivers/tty/serial/8250/8250_omap.c:			 * Disable RX interrupts to allow RX DMA completion
drivers/tty/serial/amba-pl011.c:	struct completion	complete;
drivers/tty/serial/amba-pl011.c:	 * This completion interrupt occurs typically when the
drivers/tty/serial/msm_serial.c:			 * trigger DMA RX completion
drivers/tty/serial/mxs-auart.c: * automatically cleared after auto-baud completion.
drivers/tty/serial/rp2.c:#include <linux/completion.h>
drivers/tty/serial/serial-tegra.c:	 * completion.
drivers/tty/serial/sunzilog.c: * completion.
drivers/ufs/core/ufs-fault-injection.c:bool ufs_fail_completion(struct ufs_hba *hba)
drivers/ufs/core/ufs-fault-injection.h:bool ufs_fail_completion(struct ufs_hba *hba);
drivers/ufs/core/ufs-fault-injection.h:static inline bool ufs_fail_completion(struct ufs_hba *hba)
drivers/ufs/core/ufs-mcq.c: * the Completion Queue Entry. Find the Task Tag using an indirect method.
drivers/ufs/core/ufs-mcq.c:		/* Completion Queue Lower Base Address */
drivers/ufs/core/ufs-mcq.c:		/* Completion Queue Upper Base Address */
drivers/ufs/core/ufs-mcq.c:		/* Completion Queue Doorbell Address Offset */
drivers/ufs/core/ufs-mcq.c:		/* Completion Queue Interrupt Status Address Offset */
drivers/ufs/core/ufs-mcq.c:		/* Completion Queue Enable|Size to Completion Queue Attribute */
drivers/ufs/core/ufs-mcq.c:		 * Submission Qeueue Enable|Size|Completion Queue ID to
drivers/ufs/core/ufs-mcq.c:	 * in the completion queue either. Query the device to see if
drivers/ufs/core/ufshcd.c: * @cqe: pointer to the completion queue entry
drivers/ufs/core/ufshcd.c: * This function gets the result of UIC command completion
drivers/ufs/core/ufshcd.c: * ufshcd_wait_for_uic_cmd - Wait for completion of an UIC command
drivers/ufs/core/ufshcd.c:	if (wait_for_completion_timeout(&uic_cmd->done,
drivers/ufs/core/ufshcd.c:			"uic cmd 0x%x with arg3 0x%x completion timeout\n",
drivers/ufs/core/ufshcd.c: * @completion: initialize the completion only if this is set to true
drivers/ufs/core/ufshcd.c:		      bool completion)
drivers/ufs/core/ufshcd.c:	if (completion)
drivers/ufs/core/ufshcd.c:		init_completion(&uic_cmd->done);
drivers/ufs/core/ufshcd.c:	 * updates OCS on command completion, with the command
drivers/ufs/core/ufshcd.c: * ufshcd_dev_cmd_completion() - handles device management command responses
drivers/ufs/core/ufshcd.c:ufshcd_dev_cmd_completion(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)
drivers/ufs/core/ufshcd.c:	time_left = wait_for_completion_timeout(hba->dev_cmd.complete,
drivers/ufs/core/ufshcd.c:		 * The completion handler called complete() and the caller of
drivers/ufs/core/ufshcd.c:			err = ufshcd_dev_cmd_completion(hba, lrbp);
drivers/ufs/core/ufshcd.c:				 * The completion handler ran while we tried to
drivers/ufs/core/ufshcd.c:				 * The completion handler ran while we tried to
drivers/ufs/core/ufshcd.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/ufs/core/ufshcd.c: * and device UniPro link and hence it's final completion would be indicated by
drivers/ufs/core/ufshcd.c: * addition to normal UIC command completion Status (UCCS). This function only
drivers/ufs/core/ufshcd.c: * returns after the relevant status bits indicate the completion.
drivers/ufs/core/ufshcd.c:	DECLARE_COMPLETION_ONSTACK(uic_async_done);
drivers/ufs/core/ufshcd.c:		 * Make sure UIC command completion interrupt is disabled before
drivers/ufs/core/ufshcd.c:	if (!wait_for_completion_timeout(hba->uic_async_done,
drivers/ufs/core/ufshcd.c:			"pwr ctrl cmd 0x%x with mode 0x%x completion timeout\n",
drivers/ufs/core/ufshcd.c: * @cqe: pointer to the completion queue entry
drivers/ufs/core/ufshcd.c: * ufshcd_uic_cmd_compl - handle completion of uic command
drivers/ufs/core/ufshcd.c: * ufshcd_compl_one_cqe - handle a completion queue entry
drivers/ufs/core/ufshcd.c: * @cqe: pointer to the completion queue entry
drivers/ufs/core/ufshcd.c: * __ufshcd_transfer_req_compl - handle SCSI and query command completion
drivers/ufs/core/ufshcd.c: * ufshcd_transfer_req_compl - handle SCSI and query command completion
drivers/ufs/core/ufshcd.c:	if (ufs_fail_completion(hba))
drivers/ufs/core/ufshcd.c: * ufshcd_tmc_handler - handle task management function completion
drivers/ufs/core/ufshcd.c:		struct completion *c = req->end_io_data;
drivers/ufs/core/ufshcd.c: * ufshcd_handle_mcq_cq_events - handle MCQ completion queue events
drivers/ufs/core/ufshcd.c:	DECLARE_COMPLETION_ONSTACK(wait);
drivers/ufs/core/ufshcd.c:	err = wait_for_completion_io_timeout(&wait,
drivers/ufs/core/ufshcd.c:	/* Initiate UFS initialization, and waiting until completion */
drivers/ufs/host/ufs-qcom.c:	/* Completion Queue DAO */
drivers/ufs/host/ufs-qcom.c:	/* Completion Queue Interrupt Status */
drivers/usb/atm/cxacru.c:	struct completion rcv_done;
drivers/usb/atm/cxacru.c:	struct completion snd_done;
drivers/usb/atm/cxacru.c:static void cxacru_blocking_completion(struct urb *urb)
drivers/usb/atm/cxacru.c:static int cxacru_start_wait_urb(struct urb *urb, struct completion *done,
drivers/usb/atm/cxacru.c:	wait_for_completion(done);
drivers/usb/atm/cxacru.c:	return urb->status; /* must read status after completion */
drivers/usb/atm/cxacru.c:	init_completion(&instance->rcv_done);
drivers/usb/atm/cxacru.c:	init_completion(&instance->snd_done);
drivers/usb/atm/cxacru.c:			cxacru_blocking_completion, &instance->rcv_done, 1);
drivers/usb/atm/cxacru.c:			cxacru_blocking_completion, &instance->snd_done, 4);
drivers/usb/atm/cxacru.c:			cxacru_blocking_completion, &instance->rcv_done);
drivers/usb/atm/cxacru.c:			cxacru_blocking_completion, &instance->snd_done);
drivers/usb/atm/usbatm.c:	wait_for_completion(&instance->thread_started);
drivers/usb/atm/usbatm.c:	init_completion(&instance->thread_started);
drivers/usb/atm/usbatm.c:	init_completion(&instance->thread_exited);
drivers/usb/atm/usbatm.c:	wait_for_completion(&instance->thread_exited);
drivers/usb/atm/usbatm.h:#include <linux/completion.h>
drivers/usb/atm/usbatm.h:	struct completion thread_started;
drivers/usb/atm/usbatm.h:	struct completion thread_exited;
drivers/usb/c67x00/c67x00-hcd.c:	init_completion(&c67x00->endpoint_disable);
drivers/usb/c67x00/c67x00-hcd.h:	struct completion endpoint_disable;
drivers/usb/c67x00/c67x00-ll-hpi.c:	res = wait_for_completion_timeout(&dev->hpi.lcp.msg_received, 5 * HZ);
drivers/usb/c67x00/c67x00-ll-hpi.c:	init_completion(&dev->hpi.lcp.msg_received);
drivers/usb/c67x00/c67x00-sched.c:		/* it could happen that we reinitialize this completion, while
drivers/usb/c67x00/c67x00-sched.c:		 * somebody was waiting for that completion.  The timeout and
drivers/usb/c67x00/c67x00-sched.c:		reinit_completion(&c67x00->endpoint_disable);
drivers/usb/c67x00/c67x00-sched.c:		wait_for_completion_timeout(&c67x00->endpoint_disable, 1 * HZ);
drivers/usb/c67x00/c67x00.h:#include <linux/completion.h>
drivers/usb/c67x00/c67x00.h:	struct completion msg_received;
drivers/usb/cdns3/cdns3-ep0.c:	if (priv_dev->status_completion_no_call && request &&
drivers/usb/cdns3/cdns3-ep0.c:		priv_dev->status_completion_no_call = 0;
drivers/usb/cdns3/cdns3-ep0.c:		priv_dev->status_completion_no_call = true;
drivers/usb/cdns3/cdns3-ep0.c:		 * Since there is no completion interrupt for status stage,
drivers/usb/cdns3/cdns3-ep0.c:		 * it needs to call ->completion in software after
drivers/usb/cdns3/cdns3-gadget.c:		 * Driver will wait for completion DESCMISS transfer,
drivers/usb/cdns3/cdns3-gadget.c: * @status: completion code for the request
drivers/usb/cdns3/cdns3-gadget.h:/* Interrupt on completion */
drivers/usb/cdns3/cdns3-gadget.h: * @status_completion_no_call: indicate that driver is waiting for status s
drivers/usb/cdns3/cdns3-gadget.h: *     stage completion. It's used in deferred SET_CONFIGURATION request.
drivers/usb/cdns3/cdns3-gadget.h:	unsigned			status_completion_no_call:1;
drivers/usb/cdns3/cdnsp-debug.h:	case TRB_COMPLETION:
drivers/usb/cdns3/cdnsp-debug.h:		return "Command Completion Event";
drivers/usb/cdns3/cdnsp-debug.h:	case TRB_COMPLETION:
drivers/usb/cdns3/cdnsp-gadget.c:			"ERR: unexpected command completion code 0x%x.\n", ret);
drivers/usb/cdns3/cdnsp-gadget.c:		 * Check whether the completion event is for last queued
drivers/usb/cdns3/cdnsp-gadget.c:		if (TRB_FIELD_TO_TYPE(flags) != TRB_COMPLETION ||
drivers/usb/cdns3/cdnsp-gadget.h: * @status: Command Completion Code for last command.
drivers/usb/cdns3/cdnsp-gadget.h:/* Completion Code - only applicable for some types of TRBs */
drivers/usb/cdns3/cdnsp-gadget.h: * struct cdnsp_event_cmd - Command completion event TRB.
drivers/usb/cdns3/cdnsp-gadget.h: * status: Command completion parameters and error code.
drivers/usb/cdns3/cdnsp-gadget.h:/* Interrupter Target - which MSI-X vector to target the completion event at. */
drivers/usb/cdns3/cdnsp-gadget.h:/* Interrupt on completion. */
drivers/usb/cdns3/cdnsp-gadget.h:/* Command Completion Event. */
drivers/usb/cdns3/cdnsp-gadget.h:#define TRB_COMPLETION		33
drivers/usb/cdns3/cdnsp-ring.c:	 * The event handler won't see a completion for this TD anymore,
drivers/usb/cdns3/cdnsp-ring.c:	/* Port status change events always have a successful completion code */
drivers/usb/cdns3/cdnsp-ring.c:		 * The Endpoint Stop Command completion will take care of any
drivers/usb/cdns3/cdnsp-ring.c:	/* handle completion code */
drivers/usb/cdns3/cdnsp-ring.c:			 * endpoint generating an extra completion event, or
drivers/usb/cdns3/cdnsp-ring.c:		 * completion handle will take care the rest.
drivers/usb/cdns3/cdnsp-ring.c:	case TRB_TYPE(TRB_COMPLETION):
drivers/usb/chipidea/ci.h: * @setaddr: if we should set the address on status completion
drivers/usb/class/cdc-wdm.c:		 * against the completion handler
drivers/usb/class/cdc-wdm.c:	else /* One transfer at a time, stop TX until URB completion */
drivers/usb/core/devices.c: * file_offset - the offset into the devices file on completion
drivers/usb/core/devio.c:			spin_unlock(&ps->lock);		/* Allow completions */
drivers/usb/core/devio.c:		/* drop the spinlock so the completion handler can run */
drivers/usb/core/devio.c:static void usbfs_blocking_completion(struct urb *urb)
drivers/usb/core/devio.c:	complete((struct completion *) urb->context);
drivers/usb/core/devio.c:	DECLARE_COMPLETION_ONSTACK(ctx);
drivers/usb/core/devio.c:	urb->complete = usbfs_blocking_completion;
drivers/usb/core/devio.c:	rc = wait_for_completion_killable_timeout(&ctx, expire);
drivers/usb/core/driver.c: * Typically a driver would call this routine during an URB's completion
drivers/usb/core/hcd.c:#include <linux/completion.h>
drivers/usb/core/hcd.c:	/* any errors get returned through the urb completion */
drivers/usb/core/hcd.c: * Completion handler may not sleep. See usb_hcd_giveback_urb() for details.
drivers/usb/core/hcd.c: *		The completion function may not have been called yet.
drivers/usb/core/hcd.c: * for URB completion.
drivers/usb/core/hcd.c: * and the urb's completion function return
drivers/usb/core/hcd.c:	/* pass ownership to the completion handler */
drivers/usb/core/hcd.c: * @status: completion status code for the URB.
drivers/usb/core/hcd.c: * Context: atomic. The completion callback is invoked in caller's context.
drivers/usb/core/hcd.c: * For HCDs with HCD_BH flag set, the completion callback is invoked in BH
drivers/usb/core/hcd.c: * completion function.  The HCD has freed all per-urb resources
drivers/usb/core/hcd.c:static void usb_ehset_completion(struct urb *urb)
drivers/usb/core/hcd.c:	struct completion  *done = urb->context;
drivers/usb/core/hcd.c:	struct completion	*done)
drivers/usb/core/hcd.c:	urb->complete = usb_ehset_completion;
drivers/usb/core/hcd.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/usb/core/hcd.c:	if (!wait_for_completion_timeout(&done, msecs_to_jiffies(2000))) {
drivers/usb/core/hcd.c:	if (!retval && !wait_for_completion_timeout(&done,
drivers/usb/core/hub.c:#include <linux/completion.h>
drivers/usb/core/hub.c:/* completion function, fires on port status changes and various faults */
drivers/usb/core/hub.c:	/* info for completion callback */
drivers/usb/core/message.c:	struct completion	done;
drivers/usb/core/message.c:static void usb_api_blocking_completion(struct urb *urb)
drivers/usb/core/message.c: * Starts urb and waits for completion or timeout. Note that this call
drivers/usb/core/message.c:	init_completion(&ctx.done);
drivers/usb/core/message.c:	if (!wait_for_completion_timeout(&ctx.done, expire)) {
drivers/usb/core/message.c:			     len, usb_api_blocking_completion, NULL);
drivers/usb/core/message.c: * usb_control_msg - Builds a control urb, sends it off and waits for completion
drivers/usb/core/message.c: * usb_control_msg_send - Builds a control "send" message, sends it off and waits for completion
drivers/usb/core/message.c: * usb_control_msg_recv - Builds a control "receive" message, sends it off and waits for completion
drivers/usb/core/message.c: * usb_interrupt_msg - Builds an interrupt urb, sends it off and waits for completion
drivers/usb/core/message.c: * usb_bulk_msg - Builds a bulk urb, sends it off and waits for completion
drivers/usb/core/message.c:				usb_api_blocking_completion, NULL,
drivers/usb/core/message.c:				usb_api_blocking_completion, NULL);
drivers/usb/core/message.c:	 * reports, until the completion callback (this!) returns.  That lets
drivers/usb/core/message.c:	/* on the last completion, signal usb_sg_wait() */
drivers/usb/core/message.c:	init_completion(&io->complete);
drivers/usb/core/message.c: * There are three kinds of completion for this function.
drivers/usb/core/message.c:	wait_for_completion(&io->complete);
drivers/usb/core/message.c: * as reported by URB completion status.  Endpoints that are halted are
drivers/usb/core/message.c: * underlying call that failed.  On successful completion, each interface
drivers/usb/core/urb.c: * describing that request to the USB subsystem.  Request completion will
drivers/usb/core/urb.c: * be indicated later, asynchronously, by calling the completion handler.
drivers/usb/core/urb.c: * The three types of completion are success, error, and unlink
drivers/usb/core/urb.c: * (HCD) are finished with the URB.  When the completion function is called,
drivers/usb/core/urb.c: * request.  The completion handler may then immediately free or reuse that
drivers/usb/core/urb.c: * completion processing for earlier (successful) requests.
drivers/usb/core/urb.c: * periods during completion callbacks).  When there is no longer an urb
drivers/usb/core/urb.c: * drivers can use their completion handlers to ensure they keep bandwidth
drivers/usb/core/urb.c: *   (a) you are inside a completion handler, an interrupt, bottom half,
drivers/usb/core/urb.c: * and the completion handler will be called with a status code
drivers/usb/core/urb.c: * must not hold any locks that may be taken by the completion function.
drivers/usb/core/urb.c: * eventually called, the completion function will see @urb->status ==
drivers/usb/core/urb.c: * finished with it), even if the completion handler has not yet run.
drivers/usb/core/urb.c: * completion handler cannot deallocate the URB.
drivers/usb/core/urb.c: * completion routine returns.  It is guaranteed that a stopped queue
drivers/usb/core/urb.c: * with their completion routines run, even if that's not until some time
drivers/usb/core/urb.c: * after the original completion handler returns.  The same behavior and
drivers/usb/core/urb.c: * upon return all completion handlers will have finished and the URB
drivers/usb/core/urb.c: * the completion handler will see urb->status == -ENOENT.
drivers/usb/core/urb.c: * with error -EPERM.  Thus even if the URB's completion handler always
drivers/usb/core/urb.c: * completion handler cannot deallocate the URB.
drivers/usb/core/urb.c: * half or a completion handler), or when holding a spinlock, or in other
drivers/usb/core/urb.c: * upon return all completion handlers will have finished and the URB
drivers/usb/core/urb.c: * the completion handler will see urb->status == -ENOENT.
drivers/usb/core/urb.c: * with error -EPERM.  Thus even if the URB's completion handler always
drivers/usb/core/urb.c: * completion handler cannot deallocate the URB.
drivers/usb/core/urb.c: * half or a completion handler), or when holding a spinlock, or in other
drivers/usb/core/urb.c: * with error -EPERM.  Thus even if the URB's completion handler always
drivers/usb/core/urb.c: * completion handler cannot deallocate the URB.
drivers/usb/core/urb.c: * back path to delay waking up until after the completion handler has run.
drivers/usb/core/usb.c: * hardware during URB completion/resubmit.  The implementation varies between
drivers/usb/dwc2/gadget.c: * This is the reverse of dwc2_hsotg_map_dma(), called for the completion
drivers/usb/dwc2/gadget.c: * cleanup on completion.
drivers/usb/dwc2/gadget.c: * dwc2_hsotg_complete_oursetup - setup completion callback
drivers/usb/dwc2/gadget.c: * Called on completion of any requests the driver itself
drivers/usb/dwc2/gadget.c: * dwc2_hsotg_complete_setup - completion of a setup transfer
drivers/usb/dwc2/gadget.c: * Called on completion of any requests the driver itself submitted for
drivers/usb/dwc2/gadget.c: * The given request has finished, so call the necessary completion
drivers/usb/dwc2/gadget.c:	 * Look to see if there is anything else to do. Note, the completion
drivers/usb/dwc2/gadget.c:		/* Check completion status */
drivers/usb/dwc2/gadget.c: * on the completion interrupts to get notifications of transfer completion.
drivers/usb/dwc2/gadget.c: * call the relevant completion routines.
drivers/usb/dwc2/hcd.c:/* Handles hub TT buffer clear completions */
drivers/usb/dwc2/hcd_ddma.c:		 * function called from XferCompletion - QTDs was queued during
drivers/usb/dwc2/hcd_ddma.c:		 * Pass error code to completion routine as well, to update
drivers/usb/dwc2/hcd_ddma.c: * status and calls completion routine for the URB if it's done. Called from
drivers/usb/dwc2/hcd_ddma.c:			 * completion
drivers/usb/dwc2/hcd_intr.c:		 * halted before its normal completion. (Can't use the
drivers/usb/dwc3/core.h:	struct completion	ep0_in_setup;
drivers/usb/dwc3/gadget.c: * @status: completion code for the request
drivers/usb/dwc3/gadget.c: * and wait for its completion.
drivers/usb/dwc3/gadget.c: * @params to @dep and wait for its completion.
drivers/usb/dwc3/gadget.c:	 * With this, we don't need to wait for command completion and can
drivers/usb/dwc3/gadget.c: * @must_interrupt: set to interrupt on TRB completion
drivers/usb/dwc3/gadget.c: * completion. It also won't clear the HWO bit in the TRB.
drivers/usb/dwc3/gadget.c:	 * may prevent the command's completion. Let's retry when the
drivers/usb/dwc3/gadget.c:	 * be modified after completion of END_TRANSFER
drivers/usb/dwc3/gadget.c:	 * END_TRANSFER completion and only after that, we jump
drivers/usb/dwc3/gadget.c:		reinit_completion(&dwc->ep0_in_setup);
drivers/usb/dwc3/gadget.c:		ret = wait_for_completion_timeout(&dwc->ep0_in_setup,
drivers/usb/dwc3/gadget.c:	 * For the requests that don't set interrupt on completion, the driver
drivers/usb/dwc3/gadget.c:	 * EndTransfer Command Completion IRQ, but that's causing too
drivers/usb/dwc3/gadget.c:	init_completion(&dwc->ep0_in_setup);
drivers/usb/early/xhci-dbc.c:	/* Check completion of the previous request: */
drivers/usb/fotg210/fotg210-hcd.c:		 * qtd is updated in qh_completions(). Update the QH
drivers/usb/fotg210/fotg210-hcd.c: * Chases up to qh->hw_current.  Returns number of completions called,
drivers/usb/fotg210/fotg210-hcd.c:static unsigned qh_completions(struct fotg210_hcd *fotg210,
drivers/usb/fotg210/fotg210-hcd.c:	/* completions (or tasks on other cpus) must never clobber HALT
drivers/usb/fotg210/fotg210-hcd.c:		/* ignore urbs submitted during completions we reported */
drivers/usb/fotg210/fotg210-hcd.c:		/* remove qtd; it's recycled after possible urb completion */
drivers/usb/fotg210/fotg210-hcd.c:	/* last urb's completion might still need calling */
drivers/usb/fotg210/fotg210-hcd.c:	/* by default, enable interrupt on urb completion */
drivers/usb/fotg210/fotg210-hcd.c:	/* qtd completions reported later by interrupt */
drivers/usb/fotg210/fotg210-hcd.c:		qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c:	 * qh_completions() has to deal with it.
drivers/usb/fotg210/fotg210-hcd.c:			 * Unlinks could happen here; completion reporting
drivers/usb/fotg210/fotg210-hcd.c:			temp = qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c:	 * qh_completions() has to deal with it.
drivers/usb/fotg210/fotg210-hcd.c:	qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c:			 * Unlinks could happen here; completion reporting
drivers/usb/fotg210/fotg210-hcd.c:			temp = qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c: * and hence its completion callback probably added things to the hardware
drivers/usb/fotg210/fotg210-hcd.c: * completion callback runs, so that it won't be reused quickly.  That is,
drivers/usb/fotg210/fotg210-hcd.c: * (b) only this endpoint's completions submit URBs.  It seems some silicon
drivers/usb/fotg210/fotg210-hcd.c:	/* handle completion now? */
drivers/usb/fotg210/fotg210-hcd.c:	/* give urb back to the driver; completion often (re)submits */
drivers/usb/fotg210/fotg210-hcd.c:	/* scan each element in frame's queue for completions */
drivers/usb/fotg210/fotg210-hcd.c:			 * URB completion.  HC won't cache the
drivers/usb/fotg210/fotg210-hcd.c:		/* assume completion callbacks modify the queue */
drivers/usb/fotg210/fotg210-hcd.c: * it calls driver completion functions, after dropping fotg210->lock.
drivers/usb/fotg210/fotg210-hcd.c:	 * it reports urb completions.  this flag guards against bogus
drivers/usb/fotg210/fotg210-hcd.c:	/* normal [4.15.1.2] or error [4.15.1.1] completion */
drivers/usb/fotg210/fotg210-hcd.c:		/* Handle completions when the controller stops */
drivers/usb/fotg210/fotg210-hcd.c:		/* qh_completions() code doesn't handle all the fault cases
drivers/usb/fotg210/fotg210-hcd.c: * completions normally happen asynchronously
drivers/usb/fotg210/fotg210-hcd.c:			qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c:			qh_completions(fotg210, qh);
drivers/usb/fotg210/fotg210-hcd.c:		/* wait till next completion, do it then. */
drivers/usb/fotg210/fotg210-hcd.c:		/* completion irqs can wait up to 1024 msec, */
drivers/usb/fotg210/fotg210-hcd.c:	 * accelerate iso completions ... so spin a while.
drivers/usb/fotg210/fotg210-hcd.h:#define STS_ERR		(1<<1)		/* "error" completion (overflow, ...) */
drivers/usb/fotg210/fotg210-hcd.h:#define STS_INT		(1<<0)		/* "normal" completion (short, ...) */
drivers/usb/fotg210/fotg210-hcd.h:	u8			c_usecs;	/* ... split completion bw */
drivers/usb/fotg210/fotg210-hcd.h: * makes the HC jump (back) to a QH to scan for fs/ls QH completions until
drivers/usb/fotg210/fotg210-udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/composite.c: * remote wakeup. On completion, function wake notification is sent. If
drivers/usb/gadget/composite.c:	 * gadget might need to intercept e.g. a control-OUT completion
drivers/usb/gadget/function/f_acm.c:		dev_dbg(&cdev->gadget->dev, "acm ttyGS%d completion, err %d\n",
drivers/usb/gadget/function/f_acm.c:	/* normal completion */
drivers/usb/gadget/function/f_fs.c:	struct completion done;
drivers/usb/gadget/function/f_fs.c:	complete(&ffs->ep0req_completion);
drivers/usb/gadget/function/f_fs.c:	reinit_completion(&ffs->ep0req_completion);
drivers/usb/gadget/function/f_fs.c:	ret = wait_for_completion_interruptible(&ffs->ep0req_completion);
drivers/usb/gadget/function/f_fs.c:	queue_work(ffs->io_completion_wq, &io_data->work);
drivers/usb/gadget/function/f_fs.c:		init_completion(&io_data->done);
drivers/usb/gadget/function/f_fs.c:		if (wait_for_completion_interruptible(&io_data->done)) {
drivers/usb/gadget/function/f_fs.c:			wait_for_completion(&io_data->done);
drivers/usb/gadget/function/f_fs.c:	queue_work(priv->ffs->io_completion_wq, &dma_fence->work);
drivers/usb/gadget/function/f_fs.c:		       swait_active(&ffs->ep0req_completion.wait) ||
drivers/usb/gadget/function/f_fs.c:		destroy_workqueue(ffs->io_completion_wq);
drivers/usb/gadget/function/f_fs.c:	ffs->io_completion_wq = alloc_ordered_workqueue("%s", 0, dev_name);
drivers/usb/gadget/function/f_fs.c:	if (!ffs->io_completion_wq) {
drivers/usb/gadget/function/f_fs.c:	init_completion(&ffs->ep0req_completion);
drivers/usb/gadget/function/f_fs.c:	/* Drain any pending AIO completions */
drivers/usb/gadget/function/f_fs.c:	drain_workqueue(ffs->io_completion_wq);
drivers/usb/gadget/function/f_loopback.c:	case 0:				/* normal completion? */
drivers/usb/gadget/function/f_mass_storage.c: * completion notifications, endpoint-0 events, and disconnect events.
drivers/usb/gadget/function/f_mass_storage.c: * Completion events are passed to the main thread by wakeup calls.  Many
drivers/usb/gadget/function/f_mass_storage.c: * finally marked EMPTY again (possibly by a completion routine).
drivers/usb/gadget/function/f_mass_storage.c: * driver should not notify the host about completion of the original
drivers/usb/gadget/function/f_mass_storage.c:#include <linux/completion.h>
drivers/usb/gadget/function/f_mass_storage.c:	struct completion	thread_notifier;
drivers/usb/gadget/function/f_mass_storage.c:/* Completion handlers. These always run in_irq. */
drivers/usb/gadget/function/f_mass_storage.c:	init_completion(&common->thread_notifier);
drivers/usb/gadget/function/f_mass_storage.c:		wait_for_completion(&common->thread_notifier);
drivers/usb/gadget/function/f_mass_storage.c:		wait_for_completion(&fsg->common->thread_notifier);
drivers/usb/gadget/function/f_midi.c:	case 0:			 /* normal completion */
drivers/usb/gadget/function/f_midi.c:	 * just disable endpoints, forcing completion of pending i/o.
drivers/usb/gadget/function/f_midi.c:	 * all our completion handlers free their requests in this case.
drivers/usb/gadget/function/f_ncm.c:	 * completion callback can be called right after the call,
drivers/usb/gadget/function/f_printer.c:	/* normal completion */
drivers/usb/gadget/function/f_sourcesink.c:	case 0:				/* normal completion? */
drivers/usb/gadget/function/f_tcm.c:	init_completion(&cmd->write_complete);
drivers/usb/gadget/function/f_tcm.c:	wait_for_completion(&cmd->write_complete);
drivers/usb/gadget/function/f_tcm.c:	init_completion(&cmd->write_complete);
drivers/usb/gadget/function/f_tcm.c:	wait_for_completion(&cmd->write_complete);
drivers/usb/gadget/function/f_uac1.c:		dev_dbg(&cdev->gadget->dev, "completion err %d\n", req->status);
drivers/usb/gadget/function/f_uac1_legacy.c:	case 0:				/* normal completion? */
drivers/usb/gadget/function/f_uac2.c:		dev_dbg(&cdev->gadget->dev, "completion err %d\n", req->status);
drivers/usb/gadget/function/tcm.h:	struct completion write_complete;
drivers/usb/gadget/function/u_audio.c:	/* pre-calculated values for playback iso completion */
drivers/usb/gadget/function/u_audio.c:			 * request, the request will be freed by the completion
drivers/usb/gadget/function/u_ether.c:	/* normal completion */
drivers/usb/gadget/function/u_ether.c:	/* disable endpoints, forcing (synchronous) completion
drivers/usb/gadget/function/u_fs.h:	struct completion		ep0req_completion;	/* P: mutex */
drivers/usb/gadget/function/u_fs.h:	struct workqueue_struct *io_completion_wq;
drivers/usb/gadget/function/u_serial.c:		/* Drop lock while we call out of driver; completions
drivers/usb/gadget/function/u_serial.c:			/* normal completion */
drivers/usb/gadget/function/u_serial.c:		/* normal completion */
drivers/usb/gadget/function/u_serial.c:		/* normal completion */
drivers/usb/gadget/function/uvc.h:	/* Context data used by the completion handler */
drivers/usb/gadget/legacy/inode.c:	complete ((struct completion *)req->context);
drivers/usb/gadget/legacy/inode.c:	DECLARE_COMPLETION_ONSTACK (done);
drivers/usb/gadget/legacy/inode.c:		value = wait_for_completion_interruptible(&done);
drivers/usb/gadget/legacy/inode.c:				wait_for_completion(&done);
drivers/usb/gadget/legacy/inode.c:				wait_for_completion(&done);
drivers/usb/gadget/legacy/raw_gadget.c:	struct completion		ep0_done;
drivers/usb/gadget/legacy/raw_gadget.c:	init_completion(&dev->ep0_done);
drivers/usb/gadget/legacy/raw_gadget.c:	ret = wait_for_completion_interruptible(&dev->ep0_done);
drivers/usb/gadget/legacy/raw_gadget.c:		wait_for_completion(&dev->ep0_done);
drivers/usb/gadget/legacy/raw_gadget.c:				"fail, waiting for urb completion\n");
drivers/usb/gadget/legacy/raw_gadget.c:				"fail, waiting for urb completion\n");
drivers/usb/gadget/legacy/raw_gadget.c:	complete((struct completion *)req->context);
drivers/usb/gadget/legacy/raw_gadget.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/usb/gadget/legacy/raw_gadget.c:	ret = wait_for_completion_interruptible(&done);
drivers/usb/gadget/legacy/raw_gadget.c:		wait_for_completion(&done);
drivers/usb/gadget/udc/aspeed-vhub/core.c:	 * to call the gadget completion.
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		/* 0-len request, send completion as rx */
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		EPVDBG(ep, "0-length rx completion\n");
drivers/usb/gadget/udc/aspeed_udc.c:			/* 0 len request, send tx as completion */
drivers/usb/gadget/udc/atmel_usba_udc.c:	 * completion function returns.
drivers/usb/gadget/udc/bcm63xx_udc.c: * iudma_read - Check for IUDMA buffer completion.
drivers/usb/gadget/udc/bcm63xx_udc.c: * bcm63xx_ep0_complete - Set completion status and "stage" the callback.
drivers/usb/gadget/udc/bcm63xx_udc.c:		 * completion to the gadget driver, then REQUEUE->IDLE.
drivers/usb/gadget/udc/bcm63xx_udc.c:		 * calling the completion, because it originated from this
drivers/usb/gadget/udc/bcm63xx_udc.c: * or invoke the completion callback (complete transactions).
drivers/usb/gadget/udc/bdc/bdc.h:/* CMD completion status */
drivers/usb/gadget/udc/bdc/bdc_cmd.c:/* Issues a cmd to cmd processor and waits for cmd completion */
drivers/usb/gadget/udc/bdc/bdc_cmd.c:		dev_dbg(bdc->dev, "Unknown command completion code:%x\n", ret);
drivers/usb/gadget/udc/bdc/bdc_ep.c:/* xfr completion status report handler */
drivers/usb/gadget/udc/cdns2/cdns2-ep0.c:	if (pdev->status_completion_no_call && request && request->complete) {
drivers/usb/gadget/udc/cdns2/cdns2-ep0.c:		pdev->status_completion_no_call = 0;
drivers/usb/gadget/udc/cdns2/cdns2-ep0.c:		pdev->status_completion_no_call = true;
drivers/usb/gadget/udc/cdns2/cdns2-ep0.c:		 * Since there is no completion interrupt for status stage,
drivers/usb/gadget/udc/cdns2/cdns2-ep0.c:		 * it needs to call ->completion in software after
drivers/usb/gadget/udc/cdns2/cdns2-gadget.h:/* Interrupt on completion. */
drivers/usb/gadget/udc/cdns2/cdns2-gadget.h: * @status_completion_no_call: indicate that driver is waiting for status
drivers/usb/gadget/udc/cdns2/cdns2-gadget.h: *      stage completion. It's used in deferred SET_CONFIGURATION request.
drivers/usb/gadget/udc/cdns2/cdns2-gadget.h:	bool status_completion_no_call;
drivers/usb/gadget/udc/core.c: * completion callback.  Free requests with usb_ep_free_request(), when
drivers/usb/gadget/udc/core.c: * including being canceled by usb_ep_dequeue(), the request's completion
drivers/usb/gadget/udc/core.c: * is given back to that driver through the completion callback.
drivers/usb/gadget/udc/core.c: * data stage is over, that is, from within the response's completion
drivers/usb/gadget/udc/core.c: * UDC are finished with the request.  When the completion function is called,
drivers/usb/gadget/udc/core.c: * The completion handler may then immediately free or reuse @req.
drivers/usb/gadget/udc/core.c: * eventually its completion routine is called (with status -ECONNRESET);
drivers/usb/gadget/udc/core.c: * that is, it may return before the completion routine runs.
drivers/usb/gadget/udc/core.c: * completion).  The gadget driver may not have collected all the data
drivers/usb/gadget/udc/core.c: * Request completion callbacks must still be issued.  However, it's okay
drivers/usb/gadget/udc/dummy_hcd.c:		 * (so completion handlers can clean up the queue) but we don't
drivers/usb/gadget/udc/dummy_hcd.c:		/* device side completion --> continuable */
drivers/usb/gadget/udc/dummy_hcd.c:		/* host side completion --> terminate */
drivers/usb/gadget/udc/fsl_qe_udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/fsl_qe_udc.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/usb/gadget/udc/fsl_qe_udc.c:	wait_for_completion(&done);
drivers/usb/gadget/udc/fsl_qe_udc.h:	struct completion *done;	/* to make sure release() is done */
drivers/usb/gadget/udc/fsl_qe_udc.h:#define T_I           0x10000000         /* interrupt on completion */
drivers/usb/gadget/udc/fsl_udc_core.c:/* Process a DTD completion interrupt */
drivers/usb/gadget/udc/fsl_udc_core.c:		/* completion of dtd */
drivers/usb/gadget/udc/fsl_udc_core.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/usb/gadget/udc/fsl_udc_core.c:	wait_for_completion(&done);
drivers/usb/gadget/udc/fsl_usb2_udc.h:	struct completion *done;	/* to make sure release() is done */
drivers/usb/gadget/udc/fusb300_udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/goku_udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/goku_udc.c:		/* completion */
drivers/usb/gadget/udc/goku_udc.c:	/* normal hw dma completion (not abort) */
drivers/usb/gadget/udc/goku_udc.c:		/* dma:  done after dma completion IRQ (or error)
drivers/usb/gadget/udc/goku_udc.c:	/* dma completion */
drivers/usb/gadget/udc/gr_udc.c: * Frees allocated resources and calls the appropriate completion function/setup
drivers/usb/gadget/udc/gr_udc.c:	 * instead of the default ep0in. Completion functions might use
drivers/usb/gadget/udc/gr_udc.c:			dev->ep0reqo = req; /* Completion treated separately */
drivers/usb/gadget/udc/lpc32xx_udc.c:#define DD_STATUS_STS_NC	0x04 /* Normal completion */
drivers/usb/gadget/udc/lpc32xx_udc.c: * Handle EP completion for ZLP
drivers/usb/gadget/udc/lpc32xx_udc.c:/* DMA end of transfer completion */
drivers/usb/gadget/udc/lpc32xx_udc.c:		ep_err(ep, "DMA critical EP error: EOT prior to service completion (0x%x)!\n",
drivers/usb/gadget/udc/m66592-udc.c:			/* Wait for the completion of status stage */
drivers/usb/gadget/udc/m66592-udc.c:static void nop_completion(struct usb_ep *ep, struct usb_request *r)
drivers/usb/gadget/udc/m66592-udc.c:	m66592->ep0_req->complete = nop_completion;
drivers/usb/gadget/udc/mv_u3d.h:	struct completion		*done;
drivers/usb/gadget/udc/mv_u3d_core.c:		/* remove req out of ep request list after completion */
drivers/usb/gadget/udc/mv_u3d_core.c:			/* ep0 request completion */
drivers/usb/gadget/udc/mv_udc.h:	struct completion		*done;
drivers/usb/gadget/udc/mv_udc_core.c:static DECLARE_COMPLETION(release_done);
drivers/usb/gadget/udc/mv_udc_core.c:			/* ep0 request completion */
drivers/usb/gadget/udc/mv_udc_core.c:	wait_for_completion(udc->done);
drivers/usb/gadget/udc/net2272.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/net2272.c:		/* completion */
drivers/usb/gadget/udc/net2272.c:/* handle ep-a/ep-b dma completions */
drivers/usb/gadget/udc/net2280.c:		tmp = BIT((8 + ep->num));	/* completion */
drivers/usb/gadget/udc/net2280.c:		/* for short OUT transfers, dma completions can't
drivers/usb/gadget/udc/net2280.c:		tmp &= ~BIT((8 + ep->num));	/* completion */
drivers/usb/gadget/udc/net2280.c:			tmp &= ~BIT((8 + ep->num));	/* completion */
drivers/usb/gadget/udc/net2280.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/net2280.c:static int scan_dma_completions(struct net2280_ep *ep)
drivers/usb/gadget/udc/net2280.c:		 * all non-abort DMA completions.
drivers/usb/gadget/udc/net2280.c:	scan_dma_completions(ep);
drivers/usb/gadget/udc/net2280.c:		scan_dma_completions(ep);
drivers/usb/gadget/udc/net2280.c:				num_completed = scan_dma_completions(ep);
drivers/usb/gadget/udc/net2280.c:		/* stream endpoints often resubmit/unlink in completion */
drivers/usb/gadget/udc/net2280.c:		scan_dma_completions(ep);
drivers/usb/gadget/udc/net2280.h: *  - This state indicates workaround completion. Workarounds no longer
drivers/usb/gadget/udc/omap_udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/omap_udc.c: * When DMA completion isn't request completion, the UDC continues with
drivers/usb/gadget/udc/omap_udc.c:	/* tx completion */
drivers/usb/gadget/udc/omap_udc.c:	/* rx completion */
drivers/usb/gadget/udc/omap_udc.c:	 * requests is during their request completion callback.
drivers/usb/gadget/udc/omap_udc.c:	/* DMA transfer completion */
drivers/usb/gadget/udc/omap_udc.c:	DECLARE_COMPLETION_ONSTACK(done);
drivers/usb/gadget/udc/omap_udc.c:	wait_for_completion(&done);
drivers/usb/gadget/udc/omap_udc.h:	struct completion		*done;
drivers/usb/gadget/udc/pch_udc.c: * @status:	Indicates the success/failure of completion
drivers/usb/gadget/udc/pxa25x_udc.c:	/* don't modify queue heads during completion callback */
drivers/usb/gadget/udc/pxa25x_udc.c:		/* completion */
drivers/usb/gadget/udc/pxa25x_udc.c:	/* completion */
drivers/usb/gadget/udc/pxa27x_udc.c:		/* completion */
drivers/usb/gadget/udc/pxa27x_udc.c:		 * All the following endpoints are only for completion.  They
drivers/usb/gadget/udc/r8a66597-udc.c:			/* Wait for the completion of status stage */
drivers/usb/gadget/udc/r8a66597-udc.c:static void nop_completion(struct usb_ep *ep, struct usb_request *r)
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597->ep0_req->complete = nop_completion;
drivers/usb/gadget/udc/renesas_usb3.c:#define USB3_PRD1_U		BIT(29)		/* completion of transfer */
drivers/usb/gadget/udc/renesas_usb3.c:static void usb3_pipe0_get_status_completion(struct usb_ep *ep,
drivers/usb/gadget/udc/renesas_usb3.c:					 usb3_pipe0_get_status_completion);
drivers/usb/gadget/udc/renesas_usb3.c:static void usb3_pipe0_set_sel_completion(struct usb_ep *ep,
drivers/usb/gadget/udc/renesas_usb3.c:	usb3_pipe0_internal_xfer(usb3, NULL, 6, usb3_pipe0_set_sel_completion);
drivers/usb/gadget/udc/renesas_usbf.c:	 *   completion. The WAIT time depends on the system, especially AHB
drivers/usb/gadget/udc/renesas_usbf.c:	 * if a new request is queued during the request completion
drivers/usb/gadget/udc/snps_udc_core.c:static DECLARE_COMPLETION(on_exit);
drivers/usb/gadget/udc/snps_udc_core.c:static DECLARE_COMPLETION(on_pollstall_exit);
drivers/usb/gadget/udc/snps_udc_core.c:				 * called by gadget drivers completion
drivers/usb/gadget/udc/snps_udc_core.c:	/* DMA completion */
drivers/usb/gadget/udc/snps_udc_core.c:		VDBG(dev, "TDC set- completion\n");
drivers/usb/gadget/udc/snps_udc_core.c:	/* DMA completion */
drivers/usb/gadget/udc/snps_udc_core.c:		wait_for_completion(&on_exit);
drivers/usb/gadget/udc/snps_udc_core.c:		wait_for_completion(&on_pollstall_exit);
drivers/usb/gadget/udc/tegra-xudc.c:#include <linux/completion.h>
drivers/usb/gadget/udc/tegra-xudc.c:	struct completion disconnect_complete;
drivers/usb/gadget/udc/tegra-xudc.c:	reinit_completion(&xudc->disconnect_complete);
drivers/usb/gadget/udc/tegra-xudc.c:		wait_for_completion(&xudc->disconnect_complete);
drivers/usb/gadget/udc/tegra-xudc.c:		 * completion event yet.
drivers/usb/gadget/udc/tegra-xudc.c:static void tegra_xudc_handle_transfer_completion(struct tegra_xudc *xudc,
drivers/usb/gadget/udc/tegra-xudc.c:		 * on short packet completion.
drivers/usb/gadget/udc/tegra-xudc.c:		tegra_xudc_handle_transfer_completion(xudc, ep, event);
drivers/usb/gadget/udc/tegra-xudc.c:		dev_err(xudc->dev, "completion error %#x on EP %u\n",
drivers/usb/gadget/udc/tegra-xudc.c:		dev_dbg(xudc->dev, "stop completion code on EP %u\n",
drivers/usb/gadget/udc/tegra-xudc.c:		dev_dbg(xudc->dev, "completion event %#x on EP %u\n",
drivers/usb/gadget/udc/tegra-xudc.c:	init_completion(&xudc->disconnect_complete);
drivers/usb/gadget/udc/udc-xilinx.c:/* Buffers  completion Mask */
drivers/usb/gadget/udc/udc-xilinx.c:/* Mask for buffer 0 and buffer 1 completion for all Endpoints */
drivers/usb/gadget/udc/udc-xilinx.c: * DMA transfer completion.
drivers/usb/gadget/udc/udc-xilinx.c: * xudc_done - Exeutes the endpoint data transfer completion tasks.
drivers/usb/gadget/udc/udc-xilinx.c: * Deletes the message from the queue and updates data transfer completion
drivers/usb/gadget/udc/udc-xilinx.c:		/* Completion */
drivers/usb/gadget/udc/udc-xilinx.c:		/* completion */
drivers/usb/gadget/udc/udc-xilinx.c:	/* Enable buffer completion interrupts for endpoint */
drivers/usb/gadget/udc/udc-xilinx.c: * Processes the buffer completion interrupts.
drivers/usb/gadget/udc/udc-xilinx.c:	/* Check the buffer completion interrupts */
drivers/usb/host/ehci-hcd.c: * it calls driver completion functions, after dropping ehci->lock.
drivers/usb/host/ehci-hcd.c:	 * it reports urb completions.  this flag guards against bogus
drivers/usb/host/ehci-hcd.c:	/* normal [4.15.1.2] or error [4.15.1.1] completion */
drivers/usb/host/ehci-hcd.c:		/* Handle completions when the controller stops */
drivers/usb/host/ehci-hcd.c:		/* qh_completions() code doesn't handle all the fault cases
drivers/usb/host/ehci-hcd.c: * completions normally happen asynchronously
drivers/usb/host/ehci-hcd.c:			qh_completions(ehci, qh);
drivers/usb/host/ehci-hcd.c:	 * accelerate iso completions ... so spin a while.
drivers/usb/host/ehci-q.c:	 * qtd is updated in qh_completions(). Update the QH
drivers/usb/host/ehci-q.c:qh_completions (struct ehci_hcd *ehci, struct ehci_qh *qh)
drivers/usb/host/ehci-q.c:	/* completions (or tasks on other cpus) must never clobber HALT
drivers/usb/host/ehci-q.c:		/* ignore urbs submitted during completions we reported */
drivers/usb/host/ehci-q.c:		/* remove qtd; it's recycled after possible urb completion */
drivers/usb/host/ehci-q.c:	/* last urb's completion might still need calling */
drivers/usb/host/ehci-q.c:	/* by default, enable interrupt on urb completion */
drivers/usb/host/ehci-q.c:	/* qtd completions reported later by interrupt */
drivers/usb/host/ehci-q.c:		/* SETUP pid, and interrupt after SETUP completion */
drivers/usb/host/ehci-q.c:	/* Interrupt after STATUS completion */
drivers/usb/host/ehci-q.c:			qh_completions(ehci, qh);
drivers/usb/host/ehci-q.c:			 * Unlinks could happen here; completion reporting
drivers/usb/host/ehci-q.c:			temp = qh_completions(ehci, qh);
drivers/usb/host/ehci-sched.c:		qh_completions(ehci, qh);
drivers/usb/host/ehci-sched.c:			 * Unlinks could happen here; completion reporting
drivers/usb/host/ehci-sched.c:			temp = qh_completions(ehci, qh);
drivers/usb/host/ehci-sched.c:	if (unlikely(empty && !hcd_periodic_completion_in_progress(
drivers/usb/host/ehci-sched.c: * and hence its completion callback probably added things to the hardware
drivers/usb/host/ehci-sched.c: * completion callback runs, so that it won't be reused quickly.  That is,
drivers/usb/host/ehci-sched.c: * (b) only this endpoint's completions submit URBs.  It seems some silicon
drivers/usb/host/ehci-sched.c:	/* handle completion now? */
drivers/usb/host/ehci-sched.c:	/* give urb back to the driver; completion often (re)submits */
drivers/usb/host/ehci-sched.c: * and hence its completion callback probably added things to the hardware
drivers/usb/host/ehci-sched.c: * completion callback runs, so that it won't be reused quickly.  That is,
drivers/usb/host/ehci-sched.c: * (b) only this endpoint's completions submit URBs.  It seems some silicon
drivers/usb/host/ehci-sched.c:	/* handle completion now? */
drivers/usb/host/ehci-sched.c:	/* give urb back to the driver; completion often (re)submits */
drivers/usb/host/ehci-sched.c:	/* Scan each element in frame's queue for completions */
drivers/usb/host/ehci-sched.c:			 * URB completion.  HC won't cache the
drivers/usb/host/ehci-sched.c:			 * URB completion.
drivers/usb/host/ehci-sched.c:		/* Assume completion callbacks modify the queue */
drivers/usb/host/ehci.h:#define	SITD_IOC	(1 << 31)	/* interrupt on completion */
drivers/usb/host/ehci.h: * makes the HC jump (back) to a QH to scan for fs/ls QH completions until
drivers/usb/host/fhci-sched.c: * Process normal completions(error or success) and clean the schedule.
drivers/usb/host/fhci-tds.c:#define TD_I		0x1000 /* interrupt on completion */
drivers/usb/host/fhci.h:	bool ioc;		 /* Inform On Completion */
drivers/usb/host/isp1362-hcd.c: * completion.
drivers/usb/host/max3421-hcd.c:			/* BUSEVENT due to completion of Bus Reset */
drivers/usb/host/max3421-hcd.c:			/* BUSEVENT due to completion of Bus Resume */
drivers/usb/host/octeon-hcd.c: * Signal the completion of a transaction and free it. The
drivers/usb/host/octeon-hcd.c: *		 Completion code
drivers/usb/host/octeon-hcd.h:	 *	completion.
drivers/usb/host/ohci-q.c:		 * we call a completion since it might have unlinked
drivers/usb/host/ohci-q.c: * Process normal completions (error or success) and clean the schedules.
drivers/usb/host/oxu210hp-hcd.c:#define STS_ERR		(1<<1)		/* "error" completion (overflow, ...) */
drivers/usb/host/oxu210hp-hcd.c:#define STS_INT		(1<<0)		/* "normal" completion (short, ...) */
drivers/usb/host/oxu210hp-hcd.c:	u8			c_usecs;	/* ... split completion bw */
drivers/usb/host/oxu210hp-hcd.c: * Chases up to qh->hw_current.  Returns number of completions called,
drivers/usb/host/oxu210hp-hcd.c:static unsigned qh_completions(struct oxu_hcd *oxu, struct ehci_qh *qh)
drivers/usb/host/oxu210hp-hcd.c:	/* completions (or tasks on other cpus) must never clobber HALT
drivers/usb/host/oxu210hp-hcd.c:		/* ignore urbs submitted during completions we reported */
drivers/usb/host/oxu210hp-hcd.c:			 * patch the qh later and so that completions can't
drivers/usb/host/oxu210hp-hcd.c:	/* last urb's completion might still need calling */
drivers/usb/host/oxu210hp-hcd.c:	/* by default, enable interrupt on urb completion */
drivers/usb/host/oxu210hp-hcd.c:	/* qtd completions reported later by interrupt */
drivers/usb/host/oxu210hp-hcd.c:	qh_completions(oxu, qh);
drivers/usb/host/oxu210hp-hcd.c:				/* unlinks could happen here; completion
drivers/usb/host/oxu210hp-hcd.c:				temp = qh_completions(oxu, qh);
drivers/usb/host/oxu210hp-hcd.c:		/* scan each element in frame's queue for completions */
drivers/usb/host/oxu210hp-hcd.c:				/* handle any completions */
drivers/usb/host/oxu210hp-hcd.c:				modified = qh_completions(oxu, temp.qh);
drivers/usb/host/oxu210hp-hcd.c:			/* assume completion callbacks modify the queue */
drivers/usb/host/oxu210hp-hcd.c: * It calls driver completion functions, after dropping oxu->lock.
drivers/usb/host/oxu210hp-hcd.c:	 * it reports urb completions.  this flag guards against bogus
drivers/usb/host/oxu210hp-hcd.c:	/* normal [4.15.1.2] or error [4.15.1.1] completion */
drivers/usb/host/oxu210hp-hcd.c: * Completions normally happen asynchronously
drivers/usb/host/oxu210hp-hcd.c:			qh_completions(oxu, qh);
drivers/usb/host/oxu210hp-hcd.c:	 * accelerate iso completions ... so spin a while.
drivers/usb/host/sl811-hcd.c: * and may start I/O.  Endpoint queues are scanned during completion irq
drivers/usb/host/uhci-hcd.c:	 * Some architectures require a full mb() to enforce completion of
drivers/usb/host/uhci-hcd.h: * advance on an error completion status, which makes them totally
drivers/usb/host/uhci-hub.c:		 * we'll poll for completion. */
drivers/usb/host/uhci-q.c:	/* Set the interrupt-on-completion flag on the last packet.
drivers/usb/host/uhci-q.c:	/* Set the interrupt-on-completion flag on the last packet. */
drivers/usb/host/uhci-q.c:		 * completion before reactivating the QH. */
drivers/usb/host/uhci-q.c:		 * completion.  That way we'll know as soon as the queue
drivers/usb/host/xen-hcd.c:		/* resume completion */
drivers/usb/host/xen-hcd.c:		/* reset completion */
drivers/usb/host/xhci-hub.c:	wait_for_completion(cmd->completion);
drivers/usb/host/xhci-hub.c:		reinit_completion(&port->rexit_done);
drivers/usb/host/xhci-hub.c:		time_left = wait_for_completion_timeout(
drivers/usb/host/xhci-hub.c:			 * U3: set link to U0 and wait for u3exit completion.
drivers/usb/host/xhci-hub.c:			 * completion
drivers/usb/host/xhci-hub.c:					reinit_completion(&port->u3exit_done);
drivers/usb/host/xhci-hub.c:				if (!wait_for_completion_timeout(&port->u3exit_done,
drivers/usb/host/xhci-mem.c:		bool allocate_completion, gfp_t mem_flags)
drivers/usb/host/xhci-mem.c:	if (allocate_completion) {
drivers/usb/host/xhci-mem.c:		command->completion =
drivers/usb/host/xhci-mem.c:			kzalloc_node(sizeof(struct completion), mem_flags,
drivers/usb/host/xhci-mem.c:		if (!command->completion) {
drivers/usb/host/xhci-mem.c:		init_completion(command->completion);
drivers/usb/host/xhci-mem.c:		bool allocate_completion, gfp_t mem_flags)
drivers/usb/host/xhci-mem.c:	command = xhci_alloc_command(xhci, allocate_completion, mem_flags);
drivers/usb/host/xhci-mem.c:		kfree(command->completion);
drivers/usb/host/xhci-mem.c:	kfree(command->completion);
drivers/usb/host/xhci-mem.c:		init_completion(&xhci->hw_ports[i].rexit_done);
drivers/usb/host/xhci-mem.c:		init_completion(&xhci->hw_ports[i].u3exit_done);
drivers/usb/host/xhci-mem.c:	init_completion(&xhci->cmd_ring_stop_completion);
drivers/usb/host/xhci-rcar.c:	 * According to the datasheet, "Upon the completion of FW Download,
drivers/usb/host/xhci-ring.c:		 * caller waiting for completion is called when command
drivers/usb/host/xhci-ring.c:		 *  completion event is received for these no-op commands
drivers/usb/host/xhci-ring.c:	reinit_completion(&xhci->cmd_ring_stop_completion);
drivers/usb/host/xhci-ring.c:	 * completion of the Command Abort operation. If CRR is not negated in 5
drivers/usb/host/xhci-ring.c:	 * Writing the CMD_RING_ABORT bit should cause a cmd completion event,
drivers/usb/host/xhci-ring.c:	 * but the completion event in never sent. Wait 2 secs (arbitrary
drivers/usb/host/xhci-ring.c:	ret = wait_for_completion_timeout(&xhci->cmd_ring_stop_completion,
drivers/usb/host/xhci-ring.c: * When we get a command completion for a Stop Endpoint Command, we need to
drivers/usb/host/xhci-ring.c:			xhci_warn(xhci, "Stop endpoint command completion for disabled slot %u\n",
drivers/usb/host/xhci-ring.c:			xhci_dbg(xhci, "Stop ep completion raced with stall, reset ep\n");
drivers/usb/host/xhci-ring.c:			xhci_dbg(xhci, "Stop ep completion ctx error, ep is running\n");
drivers/usb/host/xhci-ring.c:static void update_ring_for_set_deq_completion(struct xhci_hcd *xhci,
drivers/usb/host/xhci-ring.c: * When we get a completion for a Set Transfer Ring Dequeue Pointer command,
drivers/usb/host/xhci-ring.c:			xhci_warn(xhci, "WARN Set TR Deq Ptr cmd with unknown completion code of %u.\n",
drivers/usb/host/xhci-ring.c:			update_ring_for_set_deq_completion(xhci, ep->vdev,
drivers/usb/host/xhci-ring.c:		"Ignoring reset ep completion code of %u", cmd_comp_code);
drivers/usb/host/xhci-ring.c:		xhci_warn(xhci, "Reset device command completion for disabled slot %u\n",
drivers/usb/host/xhci-ring.c:	if (cmd->completion) {
drivers/usb/host/xhci-ring.c:		complete(cmd->completion);
drivers/usb/host/xhci-ring.c:	 * raced with command completion. Command is handled so just return.
drivers/usb/host/xhci-ring.c:static void handle_cmd_completion(struct xhci_hcd *xhci,
drivers/usb/host/xhci-ring.c:	 * Check whether the completion event is for our internal kept
drivers/usb/host/xhci-ring.c:			  "ERROR mismatched command completion event\n");
drivers/usb/host/xhci-ring.c:		complete_all(&xhci->cmd_ring_stop_completion);
drivers/usb/host/xhci-ring.c:			 "Command completion event does not match command\n");
drivers/usb/host/xhci-ring.c:		if (!cmd->completion)
drivers/usb/host/xhci-ring.c:		if (!cmd->completion)
drivers/usb/host/xhci-ring.c:		/* SLOT_ID field in reset device cmd completion event TRB is 0.
drivers/usb/host/xhci-ring.c:		handle_cmd_completion(xhci, &event->event_cmd);
drivers/usb/host/xhci-ring.c:	/* Port status change events always have a successful completion code */
drivers/usb/host/xhci-ring.c:	/* TRB completion codes that may require internal halt cleanup */
drivers/usb/host/xhci-ring.c:		/* Vendor defined "informational" completion code,
drivers/usb/host/xhci-ring.c:		xhci_dbg(xhci, "Vendor defined info completion code %u\n",
drivers/usb/host/xhci-ring.c:		 * The "Stop Endpoint" completion will take care of any
drivers/usb/host/xhci-ring.c:		 * stop endpoint completion (context error). In that case the
drivers/usb/host/xhci-ring.c:			 * ep command completion
drivers/usb/host/xhci-ring.c:	/* handle completion code */
drivers/usb/host/xhci-ring.c:		xhci_dbg(xhci, "Error mid isoc TD, wait for final completion event\n");
drivers/usb/host/xhci-ring.c:			xhci_warn(xhci, "WARN Successful completion on short TX\n");
drivers/usb/host/xhci-ring.c:			xhci_dbg(xhci, "Successful completion on short TX for slot %u ep %u with last td short %d\n",
drivers/usb/host/xhci-ring.c:	/* Completion codes for endpoint stopped state */
drivers/usb/host/xhci-ring.c:	/* Completion codes for endpoint halted state */
drivers/usb/host/xhci-ring.c:	/* Completion codes for endpoint error state */
drivers/usb/host/xhci-ring.c:	/* completion codes not indicating endpoint state change */
drivers/usb/host/xhci-ring.c:			 * generating an extra completion event if the device
drivers/usb/host/xhci-ring.c:			 * completion handle will take care the rest.
drivers/usb/host/xhci-ring.c:					xhci_dbg(xhci, "Missing TD completion event after mid TD error\n");
drivers/usb/host/xhci-ring.c:	case TRB_COMPLETION:
drivers/usb/host/xhci-ring.c:		handle_cmd_completion(xhci, &event->event_cmd);
drivers/usb/host/xhci-ring.c:			/* Event on completion */
drivers/usb/host/xhci.c:	kfree(command->completion);
drivers/usb/host/xhci.c:		xhci_err(xhci, "ERROR: unexpected command completion code 0x%x.\n",
drivers/usb/host/xhci.c:		xhci_err(xhci, "ERROR: unexpected command completion code 0x%x.\n",
drivers/usb/host/xhci.c:	wait_for_completion(command->completion);
drivers/usb/host/xhci.c:	kfree(command->completion);
drivers/usb/host/xhci.c:	wait_for_completion(stop_cmd->completion);
drivers/usb/host/xhci.c:	wait_for_completion(cfg_cmd->completion);
drivers/usb/host/xhci.c:	/* Allocate the command structure that holds the struct completion.
drivers/usb/host/xhci.c:	wait_for_completion(reset_device_cmd->completion);
drivers/usb/host/xhci.c:	case COMP_SLOT_NOT_ENABLED_ERROR: /* 0.95 completion for bad slot ID */
drivers/usb/host/xhci.c:	case COMP_CONTEXT_STATE_ERROR: /* 0.96 completion code for same thing */
drivers/usb/host/xhci.c:		xhci_warn(xhci, "Unknown completion code %u for "
drivers/usb/host/xhci.c:	wait_for_completion(command->completion);
drivers/usb/host/xhci.c:	wait_for_completion(command->completion);
drivers/usb/host/xhci.c:	wait_for_completion(command->completion);
drivers/usb/host/xhci.c:		kfree(command->completion);
drivers/usb/host/xhci.c:			 "ERROR: unexpected setup %s command completion code 0x%x.\n",
drivers/usb/host/xhci.c:		kfree(command->completion);
drivers/usb/host/xhci.h:/* stop ring operation after completion of the currently executing command */
drivers/usb/host/xhci.h:	/* If completion is null, no one is waiting on this command
drivers/usb/host/xhci.h:	struct completion		*completion;
drivers/usb/host/xhci.h:/* Transfer event flags bitfield, also for select command completion events */
drivers/usb/host/xhci.h:/* Completion Code - only applicable for some types of TRBs */
drivers/usb/host/xhci.h:/* Command completion event TRB */
drivers/usb/host/xhci.h:/* Interrupter Target - which MSI-X vector to target the completion event at */
drivers/usb/host/xhci.h:/* Interrupt on completion */
drivers/usb/host/xhci.h:/* Command Completion Event */
drivers/usb/host/xhci.h:#define TRB_COMPLETION		33
drivers/usb/host/xhci.h:/* Nec vendor-specific command completion event. */
drivers/usb/host/xhci.h:	case TRB_COMPLETION:
drivers/usb/host/xhci.h:		return "Command Completion Event";
drivers/usb/host/xhci.h:		return "NEC Command Completion Event";
drivers/usb/host/xhci.h:	struct completion	rexit_done;
drivers/usb/host/xhci.h:	struct completion	u3exit_done;
drivers/usb/host/xhci.h:	struct completion	cmd_ring_stop_completion;
drivers/usb/host/xhci.h:		bool allocate_completion, gfp_t mem_flags);
drivers/usb/host/xhci.h:		bool allocate_completion, gfp_t mem_flags);
drivers/usb/host/xhci.h:	case TRB_COMPLETION:
drivers/usb/image/microtek.h:	u8 *scsi_status; /* status returned from ep_response after command completion */
drivers/usb/isp1760/isp1760-hcd.c: * Sometimes interrupts are not generated when ATL (not INT?) completion occurs.
drivers/usb/isp1760/isp1760-hcd.c: * If we use SOF interrupts only, we get latency between ptd completion and the
drivers/usb/misc/idmouse.c:#include <linux/completion.h>
drivers/usb/misc/isight_firmware.c:		printk(KERN_ERR "isight firmware loading completion failed\n");
drivers/usb/misc/legousbtower.c: *   - wait for completion of write urb in release (needed for remotecontrol)
drivers/usb/misc/legousbtower.c:#include <linux/completion.h>
drivers/usb/misc/sisusbvga/sisusbvga.c:/* completion callback */
drivers/usb/misc/sisusbvga/sisusbvga.c:	/* If OK, and if timeout > 0, wait for completion */
drivers/usb/misc/sisusbvga/sisusbvga.c:/* completion callback */
drivers/usb/misc/sisusbvga/sisusbvga.c: * completion of the previous URB.
drivers/usb/misc/usb-ljca.c: * @cmd_completion: completion object as the command receives ack
drivers/usb/misc/usb-ljca.c:	struct completion cmd_completion;
drivers/usb/misc/usb-ljca.c:	complete(&adap->cmd_completion);
drivers/usb/misc/usb-ljca.c:			complete(&adap->cmd_completion);
drivers/usb/misc/usb-ljca.c:	reinit_completion(&adap->cmd_completion);
drivers/usb/misc/usb-ljca.c:		ret = wait_for_completion_timeout(&adap->cmd_completion,
drivers/usb/misc/usb-ljca.c:	init_completion(&adap->cmd_completion);
drivers/usb/misc/usbtest.c:	struct completion	completion;
drivers/usb/misc/usbtest.c:	urb->context = &completion;
drivers/usb/misc/usbtest.c:		init_completion(&completion);
drivers/usb/misc/usbtest.c:		if (!wait_for_completion_timeout(&completion, expire)) {
drivers/usb/misc/usbtest.c:	struct completion	complete;
drivers/usb/misc/usbtest.c:	/* signal completion when nothing's queued */
drivers/usb/misc/usbtest.c:	init_completion(&context.complete);
drivers/usb/misc/usbtest.c:		wait_for_completion(&context.complete);
drivers/usb/misc/usbtest.c:	struct completion	completion;
drivers/usb/misc/usbtest.c:	init_completion(&completion);
drivers/usb/misc/usbtest.c:	urb->context = &completion;
drivers/usb/misc/usbtest.c:		while (!completion_done(&completion)) {
drivers/usb/misc/usbtest.c:	wait_for_completion(&completion);
drivers/usb/misc/usbtest.c:	struct completion	complete;
drivers/usb/misc/usbtest.c:	init_completion(&ctx.complete);
drivers/usb/misc/usbtest.c:	wait_for_completion(&ctx.complete);
drivers/usb/misc/usbtest.c:	struct completion	done;
drivers/usb/misc/usbtest.c:	init_completion(&context.done);
drivers/usb/misc/usbtest.c:	wait_for_completion(&context.done);
drivers/usb/misc/usbtest.c: * threads and request completion.  But the only way to know that for sure
drivers/usb/misc/uss720.c:#include <linux/completion.h>
drivers/usb/misc/uss720.c:	struct completion compl;
drivers/usb/misc/uss720.c:	init_completion(&rq->compl);
drivers/usb/misc/uss720.c:	if (wait_for_completion_timeout(&rq->compl, HZ)) {
drivers/usb/mtu3/mtu3.h: *		waits for its completion interrupt
drivers/usb/mtu3/mtu3.h: *	bit7: Interrupt On Completion (IOC)
drivers/usb/mtu3/mtu3_gadget_ep0.c:	/* no TX completion interrupt, and need restart platform after test */
drivers/usb/musb/musb_core.c:void musb_dma_completion(struct musb *musb, u8 epnum, u8 transmit)
drivers/usb/musb/musb_core.c:EXPORT_SYMBOL_GPL(musb_dma_completion);
drivers/usb/musb/musb_cppi41.c:		musb_dma_completion(musb, hw_ep->epnum, cppi41_channel->is_tx);
drivers/usb/musb/musb_dma.h: * @dma_callback: invoked on DMA completion, useful to run platform
drivers/usb/musb/musb_dma.h:extern void musb_dma_completion(struct musb *musb, u8 epnum, u8 transmit);
drivers/usb/musb/musb_gadget.c:			 * On DMA completion, FIFO may not be
drivers/usb/musb/musb_gadget.c:	 * completion. We only get interrupts from DMA controller.
drivers/usb/musb/musb_gadget.c:	 * we don't get DMA completion interrupt for short packets.
drivers/usb/musb/musb_gadget_ep0.c:	/* Completion handler may choose to stall, e.g. because the
drivers/usb/musb/musb_gadget_ep0.c:	/* report completions as soon as the fifo's loaded; there's no
drivers/usb/musb/musb_gadget_ep0.c:		/* NOTE:  request may need completion */
drivers/usb/musb/musb_host.c:	/* call completion handler if done */
drivers/usb/musb/musb_host.c:/* Service a Tx-Available or dma completion irq for the endpoint */
drivers/usb/musb/musb_host.c:		 * We may get here from a DMA completion or TXPKTRDY interrupt.
drivers/usb/musb/musb_host.c:	 * while processing this irq for earlier completions.
drivers/usb/musb/musbhsdma.c:				musb_dma_completion(musb, musb_channel->epnum,
drivers/usb/musb/tusb6010.c:	 * Just clear the DMA interrupt if it comes as the completion for both
drivers/usb/musb/tusb6010_omap.c: * See also musb_dma_completion in plat_uds.c and musb_g_[tx|rx]() in
drivers/usb/musb/tusb6010_omap.c:	musb_dma_completion(musb, chdat->epnum, chdat->tx);
drivers/usb/musb/ux500_dma.c:	musb_dma_completion(musb, hw_ep->epnum, ux500_channel->is_tx);
drivers/usb/renesas_usbhs/mod_host.c:	struct completion	setup_ack_done;
drivers/usb/renesas_usbhs/mod_host.c:	init_completion(&hpriv->setup_ack_done);
drivers/usb/renesas_usbhs/mod_host.c:	wait_for_completion(&hpriv->setup_ack_done);
drivers/usb/serial/io_ti.c:			 * Save the LSR event for bulk read completion routine
drivers/usb/serial/io_ti.c:	 * The bulkreadcompletion routine will check
drivers/usb/serial/keyspan_pda.c:	 * Stop the interrupt URB first as its completion handler may submit
drivers/usb/serial/keyspan_usa26msg.h:	completion of transmit; 0x00 otherwise), followed by data:
drivers/usb/serial/keyspan_usa28msg.h:	completion of transmit; 0x00 otherwise), followed by data.
drivers/usb/serial/keyspan_usa49msg.h:	completion of transmit; 0x00 otherwise), followed by data:
drivers/usb/serial/keyspan_usa67msg.h:	completion of transmit; 0x00 otherwise), followed by data:
drivers/usb/serial/mos7720.c:	struct completion       syncmsg_compl; /* usb sync call completed */
drivers/usb/serial/mos7720.c:	reinit_completion(&mos_parport->syncmsg_compl);
drivers/usb/serial/mos7720.c:	init_completion(&mos_parport->syncmsg_compl);
drivers/usb/serial/mos7720.c:			wait_for_completion_timeout(&mos_parport->syncmsg_compl,
drivers/usb/storage/scsiglue.c:	wait_for_completion(&us->notify);
drivers/usb/storage/transport.c: * This is the completion handler which will wake us up when an URB
drivers/usb/storage/transport.c:static void usb_stor_blocking_completion(struct urb *urb)
drivers/usb/storage/transport.c:	struct completion *urb_done_ptr = urb->context;
drivers/usb/storage/transport.c:	struct completion urb_done;
drivers/usb/storage/transport.c:	init_completion(&urb_done);
drivers/usb/storage/transport.c:	/* wait for the completion of the URB */
drivers/usb/storage/transport.c:	timeleft = wait_for_completion_interruptible_timeout(
drivers/usb/storage/transport.c:			 usb_stor_blocking_completion, NULL);
drivers/usb/storage/transport.c:			 usb_stor_blocking_completion, NULL);
drivers/usb/storage/transport.c:			maxp, usb_stor_blocking_completion, NULL,
drivers/usb/storage/transport.c:		      usb_stor_blocking_completion, NULL);
drivers/usb/storage/transport.c:	/* wait for the completion of the transfer */
drivers/usb/storage/transport.c:			 * the command completion status, and often devices
drivers/usb/storage/usb.c:		if (wait_for_completion_interruptible(&us->cmnd_ready))
drivers/usb/storage/usb.c:	init_completion(&us->cmnd_ready);
drivers/usb/storage/usb.c:	init_completion(&(us->notify));
drivers/usb/storage/usb.h:#include <linux/completion.h>
drivers/usb/storage/usb.h:	struct completion	cmnd_ready;	 /* to sleep thread on	    */
drivers/usb/storage/usb.h:	struct completion	notify;		 /* thread begin/end	    */
drivers/usb/typec/rt1719.c:#include <linux/completion.h>
drivers/usb/typec/rt1719.c:	struct completion req_completion;
drivers/usb/typec/rt1719.c:	reinit_completion(&data->req_completion);
drivers/usb/typec/rt1719.c:	ret = wait_for_completion_timeout(&data->req_completion,
drivers/usb/typec/rt1719.c:	reinit_completion(&data->req_completion);
drivers/usb/typec/rt1719.c:	ret = wait_for_completion_timeout(&data->req_completion,
drivers/usb/typec/rt1719.c:		complete(&data->req_completion);
drivers/usb/typec/rt1719.c:	init_completion(&data->req_completion);
drivers/usb/typec/tcpm/tcpm.c:#include <linux/completion.h>
drivers/usb/typec/tcpm/tcpm.c:	struct completion tx_complete;
drivers/usb/typec/tcpm/tcpm.c:	struct completion swap_complete;
drivers/usb/typec/tcpm/tcpm.c:	struct completion pps_complete;
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->tx_complete);
drivers/usb/typec/tcpm/tcpm.c:	time_left = wait_for_completion_timeout(&port->tx_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->swap_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->swap_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->swap_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->swap_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->swap_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->swap_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->pps_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->pps_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->pps_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->pps_complete,
drivers/usb/typec/tcpm/tcpm.c:	reinit_completion(&port->pps_complete);
drivers/usb/typec/tcpm/tcpm.c:	if (!wait_for_completion_timeout(&port->pps_complete,
drivers/usb/typec/tcpm/tcpm.c:	init_completion(&port->tx_complete);
drivers/usb/typec/tcpm/tcpm.c:	init_completion(&port->swap_complete);
drivers/usb/typec/tcpm/tcpm.c:	init_completion(&port->pps_complete);
drivers/usb/typec/tipd/core.c:		dev_err(tps->dev, "Update completion failed (%d)\n", ret);
drivers/usb/typec/ucsi/ucsi.c:#include <linux/completion.h>
drivers/usb/typec/ucsi/ucsi.c:	if (!wait_for_completion_timeout(&ucsi->complete, 5 * HZ))
drivers/usb/typec/ucsi/ucsi.c:		if (!completion_done(&con->complete))
drivers/usb/typec/ucsi/ucsi.c:		if (!completion_done(&con->complete))
drivers/usb/typec/ucsi/ucsi.c:	reinit_completion(&con->complete);
drivers/usb/typec/ucsi/ucsi.c:	if (!wait_for_completion_timeout(&con->complete,
drivers/usb/typec/ucsi/ucsi.c:	reinit_completion(&con->complete);
drivers/usb/typec/ucsi/ucsi.c:	if (!wait_for_completion_timeout(&con->complete,
drivers/usb/typec/ucsi/ucsi.c:	init_completion(&con->complete);
drivers/usb/typec/ucsi/ucsi.c:	init_completion(&ucsi->complete);
drivers/usb/typec/ucsi/ucsi.h:#include <linux/completion.h>
drivers/usb/typec/ucsi/ucsi.h: * Command Completion Event from the PPM before returning, and @async_write must
drivers/usb/typec/ucsi/ucsi.h:	struct completion complete;
drivers/usb/typec/ucsi/ucsi.h:	struct completion complete;
drivers/usb/typec/ucsi/ucsi_glink.c:	struct completion read_ack;
drivers/usb/typec/ucsi/ucsi_glink.c:	struct completion write_ack;
drivers/usb/typec/ucsi/ucsi_glink.c:	reinit_completion(&ucsi->read_ack);
drivers/usb/typec/ucsi/ucsi_glink.c:	left = wait_for_completion_timeout(&ucsi->read_ack, 5 * HZ);
drivers/usb/typec/ucsi/ucsi_glink.c:	reinit_completion(&ucsi->write_ack);
drivers/usb/typec/ucsi/ucsi_glink.c:	left = wait_for_completion_timeout(&ucsi->write_ack, 5 * HZ);
drivers/usb/typec/ucsi/ucsi_glink.c:	init_completion(&ucsi->read_ack);
drivers/usb/typec/ucsi/ucsi_glink.c:	init_completion(&ucsi->write_ack);
drivers/usb/typec/ucsi/ucsi_yoga_c630.c:#include <linux/completion.h>
drivers/usb/usbip/stub.h:	 *	priv_tx  : linked to this after the completion of a urb.
drivers/usb/usbip/stub_rx.c: * process coming urbs.  Even if the urb is unlinked, its completion
drivers/usb/usbip/stub_tx.c: * stub_complete - completion handler of a usbip urb
drivers/usb/usbip/stub_tx.c:			 "urb completion with non-zero status %d\n",
drivers/usb/usbip/stub_tx.c:		 * looks at only priv_init queue. If the completion of a URB is
drivers/usb/usbip/stub_tx.c:		 * completion of the unlink request. The request of the
drivers/usb/usbip/usbip_event.c:		usbip_dbg_eh("usbip_eh waiting completion %lx\n", pending);
drivers/usb/usbip/vhci_hcd.c: * not important, but the calling to its completion handler is important; the
drivers/usb/usbip/vhci_hcd.c: * completion of unlinking is notified by the completion handler.
drivers/usb/usbip/vudc_dev.c:		usbip_stop_eh(&udc->ud); /* Wait for eh completion */
drivers/usb/usbip/vudc_transfer.c:		 * (so completion handlers can clean up the queue) but we don't
drivers/usb/usbip/vudc_transfer.c:		/* device side completion --> continuable */
drivers/usb/usbip/vudc_transfer.c:		/* host side completion --> terminate */
drivers/vdpa/mlx5/net/mlx5_vnet.c:	 * other end is vqqp used by the driver. cq is where completions are
drivers/vdpa/mlx5/net/mlx5_vnet.c:static void mlx5_vdpa_handle_completions(struct mlx5_vdpa_virtqueue *mvq, int num)
drivers/vdpa/mlx5/net/mlx5_vnet.c:			/* If completions keep coming while we poll, we want to
drivers/vdpa/mlx5/net/mlx5_vnet.c:			mlx5_vdpa_handle_completions(mvq, num);
drivers/vdpa/mlx5/net/mlx5_vnet.c:		mlx5_vdpa_handle_completions(mvq, num);
drivers/vdpa/solidrun/snet_ctrl.c:static int snet_wait_for_dpu_completion(struct snet_ctrl_regs __iomem *ctrl_regs)
drivers/vdpa/solidrun/snet_ctrl.c:	ret = snet_wait_for_dpu_completion(regs);
drivers/vdpa/solidrun/snet_ctrl.c:	ret = snet_wait_for_dpu_completion(regs);
drivers/vfio/fsl-mc/vfio_fsl_mc.c:#define MC_CMD_COMPLETION_TIMEOUT_MS    5000
drivers/vfio/fsl-mc/vfio_fsl_mc.c:#define MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS    500
drivers/vfio/fsl-mc/vfio_fsl_mc.c:	unsigned long timeout_usecs = MC_CMD_COMPLETION_TIMEOUT_MS * 1000;
drivers/vfio/fsl-mc/vfio_fsl_mc.c:		udelay(MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
drivers/vfio/fsl-mc/vfio_fsl_mc.c:		timeout_usecs -= MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS;
drivers/vfio/pci/mlx5/cmd.c:		err = wait_for_completion_interruptible(&migf->save_comp);
drivers/vfio/pci/mlx5/cmd.c:		ret = wait_for_completion_interruptible(&mvdev->saving_migf->save_comp);
drivers/vfio/pci/mlx5/cmd.c:	init_completion(&mvdev->tracker_comp);
drivers/vfio/pci/mlx5/cmd.c:	err = wait_for_completion_interruptible(&migf->save_comp);
drivers/vfio/pci/mlx5/cmd.c:				wait_for_completion(&mvdev->tracker_comp);
drivers/vfio/pci/mlx5/cmd.h:	struct completion save_comp;
drivers/vfio/pci/mlx5/cmd.h:	struct completion tracker_comp;
drivers/vfio/pci/mlx5/main.c:	init_completion(&migf->save_comp);
drivers/vfio/pci/mlx5/main.c:	 * a completion. A normal mutex cannot be used because the lock is
drivers/vfio/pci/vfio_pci_config.c:	 * signal completion.  If an error occurs above, we assume that not
drivers/vfio/pci/vfio_pci_config.c:		PCI_ERR_UNC_COMP_TIME |		/* Completion Timeout */
drivers/vfio/pci/vfio_pci_config.c:		PCI_ERR_UNC_UNX_COMP |		/* Unexpected Completion */
drivers/vfio/vfio_main.c:	init_completion(&device->comp);
drivers/vfio/vfio_main.c:	rc = try_wait_for_completion(&device->comp);
drivers/vfio/vfio_main.c:			rc = wait_for_completion_timeout(&device->comp,
drivers/vfio/vfio_main.c:			rc = wait_for_completion_interruptible_timeout(
drivers/vhost/scsi.c:	struct completion comp;
drivers/vhost/scsi.c:	struct llist_node tvc_completion_list;
drivers/vhost/scsi.c:	struct vhost_work completion_work;
drivers/vhost/scsi.c:	struct llist_head completion_list;
drivers/vhost/scsi.c:		init_completion(&new_inflight->comp);
drivers/vhost/scsi.c:	llnode = llist_del_all(&svq->completion_list);
drivers/vhost/scsi.c:	llist_for_each_entry_safe(cmd, t, llnode, tvc_completion_list)
drivers/vhost/scsi.c:		llist_add(&cmd->tvc_completion_list, &svq->completion_list);
drivers/vhost/scsi.c:		if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
drivers/vhost/scsi.c:				struct vhost_scsi_virtqueue, completion_work);
drivers/vhost/scsi.c:	llnode = llist_del_all(&svq->completion_list);
drivers/vhost/scsi.c:	llist_for_each_entry_safe(cmd, t, llnode, tvc_completion_list) {
drivers/vhost/scsi.c:		wait_for_completion(&vs->old_inflight[i]->comp);
drivers/vhost/scsi.c:		init_llist_head(&svq->completion_list);
drivers/vhost/scsi.c:		vhost_work_init(&svq->completion_work,
drivers/vhost/vdpa.c:	struct completion completion;
drivers/vhost/vdpa.c:	complete(&v->completion);
drivers/vhost/vdpa.c:	init_completion(&v->completion);
drivers/vhost/vdpa.c:		wait_for_completion(&v->completion);
drivers/vhost/vhost.c:	struct completion wait_event;
drivers/vhost/vhost.c:	init_completion(&flush.wait_event);
drivers/vhost/vhost.c:	wait_for_completion(&flush.wait_event);
drivers/video/fbdev/da8xx-fb.c:		/* Disable PL completion interrupt */
drivers/video/fbdev/da8xx-fb.c:		/* Disable PL completion inerrupt */
drivers/video/fbdev/da8xx-fb.c:	 * user immediately after a frame completion which is all that is
drivers/video/fbdev/hyperv_fb.c:#include <linux/completion.h>
drivers/video/fbdev/hyperv_fb.c:	struct completion wait;
drivers/video/fbdev/hyperv_fb.c:	t = wait_for_completion_timeout(&par->wait, VSP_TIMEOUT);
drivers/video/fbdev/hyperv_fb.c:	t = wait_for_completion_timeout(&par->wait, VSP_TIMEOUT);
drivers/video/fbdev/hyperv_fb.c:	t = wait_for_completion_timeout(&par->wait, VSP_TIMEOUT);
drivers/video/fbdev/hyperv_fb.c:	init_completion(&par->wait);
drivers/video/fbdev/omap/hwa742.c:		struct completion	*sync;
drivers/video/fbdev/omap/hwa742.c:	struct completion comp;
drivers/video/fbdev/omap/hwa742.c:	init_completion(&comp);
drivers/video/fbdev/omap/hwa742.c:	wait_for_completion(&comp);
drivers/video/fbdev/omap/lcdc.c:	struct completion	last_frame_complete;
drivers/video/fbdev/omap/lcdc.c:	struct completion	palette_load_complete;
drivers/video/fbdev/omap/lcdc.c:	init_completion(&lcdc.last_frame_complete);
drivers/video/fbdev/omap/lcdc.c:	if (!wait_for_completion_timeout(&lcdc.last_frame_complete,
drivers/video/fbdev/omap/lcdc.c:	init_completion(&lcdc.palette_load_complete);
drivers/video/fbdev/omap/lcdc.c:	if (!wait_for_completion_timeout(&lcdc.palette_load_complete,
drivers/video/fbdev/omap/omapfb_main.c:	/* FIXME: wait till completion of pending events */
drivers/video/fbdev/omap2/omapfb/displays/encoder-tpd12s015.c:#include <linux/completion.h>
drivers/video/fbdev/omap2/omapfb/dss/apply.c:static DECLARE_COMPLETION(extra_updated_completion);
drivers/video/fbdev/omap2/omapfb/dss/apply.c:	init_completion(&extra_updated_completion);
drivers/video/fbdev/omap2/omapfb/dss/apply.c:	r = wait_for_completion_timeout(&extra_updated_completion, t);
drivers/video/fbdev/omap2/omapfb/dss/apply.c:		complete_all(&extra_updated_completion);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	struct completion *compl = data;
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	DECLARE_COMPLETION_ONSTACK(framedone_compl);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	if (!wait_for_completion_timeout(&framedone_compl,
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	struct completion *compl = data;
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	DECLARE_COMPLETION_ONSTACK(vsync_compl);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	if (!wait_for_completion_timeout(&vsync_compl, msecs_to_jiffies(100)))
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	DECLARE_COMPLETION_ONSTACK(framedone_compl);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:		 * wait_for_completion.
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:		if (!wait_for_completion_timeout(&framedone_compl,
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	complete((struct completion *)data);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	r = omap_dispc_register_isr(dispc_irq_wait_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	time_left = wait_for_completion_interruptible_timeout(&completion,
drivers/video/fbdev/omap2/omapfb/dss/dispc-compat.c:	omap_dispc_unregister_isr(dispc_irq_wait_handler, &completion, irqmask);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	struct completion *completion;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:static void dsi_completion_handler(void *data, u32 mask)
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	complete((struct completion *)data);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		complete(vp_data->completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		.completion = &completion
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	/* Wait for completion only if TE_EN/TE_START is still set */
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		if (wait_for_completion_timeout(&completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		complete(l4_data->completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		.completion = &completion
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	/* Wait for completion only if TX_FIFO_NOT_EMPTY is still set */
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		if (wait_for_completion_timeout(&completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	r = dsi_register_isr_vc(dsidev, channel, dsi_completion_handler,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:			&completion, DSI_VC_IRQ_BTA);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	r = dsi_register_isr(dsidev, dsi_completion_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	if (wait_for_completion_timeout(&completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dsi_unregister_isr(dsidev, dsi_completion_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dsi_unregister_isr_vc(dsidev, channel, dsi_completion_handler,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:			&completion, DSI_VC_IRQ_BTA);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	DECLARE_COMPLETION_ONSTACK(completion);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	r = dsi_register_isr_cio(dsidev, dsi_completion_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	if (wait_for_completion_timeout(&completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dsi_unregister_isr_cio(dsidev, dsi_completion_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dsi_unregister_isr_cio(dsidev, dsi_completion_handler, &completion,
drivers/video/fbdev/omap2/omapfb/dss/venc.c:#include <linux/completion.h>
drivers/video/fbdev/omap2/omapfb/omapfb-main.c:	/* FIXME: wait till completion of pending events */
drivers/video/fbdev/ps3fb.c:				 L1GPU_FB_BLIT_WAIT_FOR_COMPLETION |
drivers/video/fbdev/pvr2fb.c:		dma_wait_for_completion(pvr2dma);
drivers/video/fbdev/pvr2fb.c:		dma_wait_for_completion(pvr2dma);
drivers/video/fbdev/pxafb.c:#include <linux/completion.h>
drivers/video/fbdev/pxafb.c:	if (wait_for_completion_timeout(&ofb->branch_done, 1 * HZ) == 0)
drivers/video/fbdev/pxafb.c:	if (wait_for_completion_timeout(&ofb->branch_done, 1 * HZ) == 0)
drivers/video/fbdev/pxafb.c:	init_completion(&ofb->branch_done);
drivers/video/fbdev/pxafb.c:	if (wait_for_completion_timeout(&fbi->command_done, HZ/2) == 0) {
drivers/video/fbdev/pxafb.c:	init_completion(&fbi->command_done);
drivers/video/fbdev/pxafb.c:	init_completion(&fbi->refresh_done);
drivers/video/fbdev/pxafb.c:		wait_for_completion_timeout(&fbi->refresh_done,
drivers/video/fbdev/pxafb.c:	wait_for_completion_timeout(&fbi->disable_done, msecs_to_jiffies(200));
drivers/video/fbdev/pxafb.c:	init_completion(&fbi->disable_done);
drivers/video/fbdev/pxafb.h:	struct completion	branch_done;
drivers/video/fbdev/pxafb.h:	struct completion	disable_done;
drivers/video/fbdev/pxafb.h:	struct completion	command_done;
drivers/video/fbdev/pxafb.h:	struct completion	refresh_done;
drivers/video/fbdev/sh7760fb.c:#include <linux/completion.h>
drivers/video/fbdev/sh7760fb.c:	struct completion vsync;	/* vsync irq event */
drivers/video/fbdev/sh7760fb.c:	struct completion *c = data;
drivers/video/fbdev/sh_mobile_lcdcfb.c:			complete(&ch->vsync_completion);
drivers/video/fbdev/sh_mobile_lcdcfb.c:	ret = wait_for_completion_interruptible_timeout(&ch->vsync_completion,
drivers/video/fbdev/sh_mobile_lcdcfb.c:		init_completion(&ch->vsync_completion);
drivers/video/fbdev/sh_mobile_lcdcfb.h:#include <linux/completion.h>
drivers/video/fbdev/sh_mobile_lcdcfb.h:	struct completion vsync_completion;
drivers/video/fbdev/smscufx.c:static void ufx_urb_completion(struct urb *urb);
drivers/video/fbdev/smscufx.c:static void ufx_urb_completion(struct urb *urb)
drivers/video/fbdev/smscufx.c:			buf, size, ufx_urb_completion, unode);
drivers/video/fbdev/smscufx.c:		ufx_urb_completion(urb); /* because no one else will */
drivers/video/fbdev/udlfb.c:static void dlfb_urb_completion(struct urb *urb);
drivers/video/fbdev/udlfb.c:		dlfb_urb_completion(urb);
drivers/video/fbdev/udlfb.c:		dlfb_urb_completion(urb);
drivers/video/fbdev/udlfb.c:static void dlfb_urb_completion(struct urb *urb)
drivers/video/fbdev/udlfb.c:			buf, size, dlfb_urb_completion, unode);
drivers/video/fbdev/udlfb.c:		dlfb_urb_completion(urb); /* because no one else will */
drivers/video/fbdev/uvesafb.c:#include <linux/completion.h>
drivers/video/fbdev/uvesafb.c:	init_completion(task->done);
drivers/video/fbdev/uvesafb.c:		err = !wait_for_completion_timeout(task->done,
drivers/video/fbdev/uvesafb.c:	struct completion *cpl = task->done;
drivers/video/fbdev/via/via-core.c:static DECLARE_COMPLETION(viafb_dma_completion);
drivers/video/fbdev/via/via-core.c: * The completion IRQ handler.
drivers/video/fbdev/via/via-core.c:		complete(&viafb_dma_completion);
drivers/video/fbdev/via/via-core.c:	init_completion(&viafb_dma_completion);
drivers/video/fbdev/via/via-core.c:	wait_for_completion_timeout(&viafb_dma_completion, 1);
drivers/virt/acrn/hypercall.h: * hcall_notify_req_finish() - Notify ACRN Hypervisor of I/O request completion.
drivers/virt/acrn/ioreq.c:	polling_mode = acrn_req->completion_polling;
drivers/virt/acrn/ioreq.c:	/* Add barrier() to make sure the writes are done before completion */
drivers/virt/acrn/ioreq.c:	 * I/O request's completion. Once an I/O request is marked as
drivers/virt/acrn/ioreq.c:	 * to continue the I/O request flow. Thus, the completion notification
drivers/virt/acrn/ioreq.c:	 * completion_polling needs to be read before the I/O request being
drivers/virt/acrn/ioreq.c:	 * wait 100ms in total for the IO requests' completion.
drivers/virt/coco/tdx-guest/tdx-guest.c: * wait_for_quote_completion() - Wait for Quote request completion
drivers/virt/coco/tdx-guest/tdx-guest.c:static int wait_for_quote_completion(struct tdx_quote_buf *quote_buf, u32 timeout)
drivers/virt/coco/tdx-guest/tdx-guest.c:	ret = wait_for_quote_completion(quote_buf, getquote_timeout);
drivers/virt/vboxguest/vboxguest_core.h:	/** Wait-for-event list for threads waiting on HGCM async completion. */
drivers/virt/vboxguest/vboxguest_utils.c: * vbg_hgcm_do_call - Performs the call and completion wait.
drivers/virt/vboxguest/vboxguest_utils.c:	 * race with normal completion, wait while the host completes it.
drivers/virtio/virtio_pci_modern.c:			complete(&cmd->completion);
drivers/virtio/virtio_pci_modern.c:	init_completion(&cmd->completion);
drivers/virtio/virtio_pci_modern.c:	wait_for_completion(&cmd->completion);
drivers/virtio/virtio_pci_modern.c:		complete(&cmd->completion);
drivers/virtio/virtio_pci_modern.c:	 * wait for completion.
drivers/w1/masters/w1-uart.c:#include <linux/completion.h>
drivers/w1/masters/w1-uart.c:/* Timeout to wait for completion of serdev-receive */
drivers/w1/masters/w1-uart.c: * @rx_byte_received: completion for serdev receive
drivers/w1/masters/w1-uart.c:	struct completion rx_byte_received;
drivers/w1/masters/w1-uart.c:	reinit_completion(&w1dev->rx_byte_received);
drivers/w1/masters/w1-uart.c:	ret = wait_for_completion_interruptible_timeout(
drivers/w1/masters/w1-uart.c:	init_completion(&w1dev->rx_byte_received);
drivers/w1/slaves/w1_therm.c:#define W1_THERM_POLL_COMPLETION 2	/* Poll for conversion completion */
drivers/w1/slaves/w1_therm.c: * @features: bit mask - enable temperature validity check, poll for completion
drivers/w1/slaves/w1_therm.c: * w1_poll_completion - Poll for operation completion, with timeout
drivers/w1/slaves/w1_therm.c:static int w1_poll_completion(struct w1_master *dev_master, int tout_ms)
drivers/w1/slaves/w1_therm.c:	if (strong_pullup && SLAVE_FEATURES(sl) & W1_THERM_POLL_COMPLETION) {
drivers/w1/slaves/w1_therm.c:			"%s: Disabling W1_THERM_POLL_COMPLETION in parasite power mode.\n",
drivers/w1/slaves/w1_therm.c:		SLAVE_FEATURES(sl) &= ~W1_THERM_POLL_COMPLETION;
drivers/w1/slaves/w1_therm.c:			if (SLAVE_FEATURES(sl) & W1_THERM_POLL_COMPLETION) {
drivers/w1/slaves/w1_therm.c:				ret = w1_poll_completion(dev_master, W1_POLL_CONVERT_TEMP);
drivers/w1/slaves/w1_therm.c:			ret = w1_poll_completion(dev_master, W1_POLL_CONVERT_TEMP);
drivers/w1/slaves/w1_therm.c:			ret = w1_poll_completion(dev_master, W1_POLL_RECALL_EEPROM);
drivers/w1/slaves/w1_therm.c:	if (strong_pullup && SLAVE_FEATURES(sl) & W1_THERM_POLL_COMPLETION) {
drivers/w1/slaves/w1_therm.c:			 "%s: W1_THERM_POLL_COMPLETION disabled in parasite power mode.\n",
drivers/w1/slaves/w1_therm.c:		SLAVE_FEATURES(sl) &= ~W1_THERM_POLL_COMPLETION;
drivers/w1/w1_internal.h:#include <linux/completion.h>
drivers/watchdog/cpu5wdt.c:#include <linux/completion.h>
drivers/watchdog/cpu5wdt.c:	struct completion stop;
drivers/watchdog/cpu5wdt.c:	init_completion(&cpu5wdt_device.stop);
drivers/watchdog/cpu5wdt.c:		wait_for_completion(&cpu5wdt_device.stop);
drivers/watchdog/mei_wdt.c:#include <linux/completion.h>
drivers/watchdog/mei_wdt.c: * @response: ping response completion
drivers/watchdog/mei_wdt.c:	struct completion response;
drivers/watchdog/mei_wdt.c:		init_completion(&wdt->response);
drivers/watchdog/mei_wdt.c:		ret = wait_for_completion_killable(&wdt->response);
drivers/watchdog/mei_wdt.c:	 * run only after ping completion, otherwise the flow will
drivers/watchdog/mei_wdt.c:	if (!completion_done(&wdt->response))
drivers/watchdog/mei_wdt.c:	init_completion(&wdt->response);
drivers/watchdog/mei_wdt.c:	if (!completion_done(&wdt->response))
drivers/watchdog/mtx-1_wdt.c:#include <linux/completion.h>
drivers/watchdog/mtx-1_wdt.c:	struct completion stop;
drivers/watchdog/mtx-1_wdt.c:	init_completion(&mtx1_wdt_device.stop);
drivers/watchdog/mtx-1_wdt.c:		wait_for_completion(&mtx1_wdt_device.stop);
drivers/watchdog/rdc321x_wdt.c:#include <linux/completion.h>
drivers/watchdog/rdc321x_wdt.c:	struct completion stop;
drivers/watchdog/rdc321x_wdt.c:	init_completion(&rdc321x_wdt_device.stop);
drivers/watchdog/rdc321x_wdt.c:		wait_for_completion(&rdc321x_wdt_device.stop);
drivers/xen/gntdev-dmabuf.c:	struct completion completion;
drivers/xen/gntdev-dmabuf.c:	init_completion(&obj->completion);
drivers/xen/gntdev-dmabuf.c:	if (wait_for_completion_timeout(&obj->completion,
drivers/xen/gntdev-dmabuf.c:			complete_all(&obj->completion);
drivers/xen/grant-table.c:	struct completion completion;
drivers/xen/grant-table.c:	complete(&d->completion);
drivers/xen/grant-table.c:	init_completion(&data.completion);
drivers/xen/grant-table.c:	wait_for_completion(&data.completion);
drivers/xen/xen-scsiback.c:	struct completion tmr_done;
drivers/xen/xen-scsiback.c:	init_completion(&pending_req->tmr_done);
drivers/xen/xen-scsiback.c:	wait_for_completion(&pending_req->tmr_done);
drivers/xen/xenbus/xenbus_probe.c:	init_completion(&xendev->down);
drivers/xen/xenbus/xenbus_probe_frontend.c:	timeout = wait_for_completion_timeout(&dev->down, timeout);
fs/afs/flock.c: * In the case of successful completion of a lock operation, record the time
fs/afs/fs_probe.c: * Handle the completion of a set of probes.
fs/afs/fs_probe.c: * Handle the completion of a probe.
fs/afs/fs_probe.c:	 * one of the queues on the completion of the probe.
fs/afs/internal.h:	wait_queue_head_t	waitq;		/* processes awaiting completion */
fs/afs/main.c:#include <linux/completion.h>
fs/afs/rotate.c:			 * could still be processed to completion by the fileserver.  This
fs/afs/vl_probe.c: * Handle the completion of a set of probes.
fs/afs/vl_probe.c: * Handle the completion of a probe RPC call.
fs/afs/write.c: * completion of write to server
fs/aio.c:	struct completion comp;
fs/aio.c:		spinlock_t	completion_lock;
fs/aio.c:	/* Take completion_lock to prevent other writes to the ring buffer
fs/aio.c:	spin_lock_irqsave(&ctx->completion_lock, flags);
fs/aio.c:	spin_unlock_irqrestore(&ctx->completion_lock, flags);
fs/aio.c:	spin_lock_init(&ctx->completion_lock);
fs/aio.c:	init_completion(&wait.comp);
fs/aio.c:		wait_for_completion(&wait.comp);
fs/aio.c: *	number of free slots in the completion ring.  This can be called
fs/aio.c: *	called holding ctx->completion_lock.
fs/aio.c: *	out of space in the completion ring.
fs/aio.c:	spin_lock_irq(&ctx->completion_lock);
fs/aio.c:		 * ctx->completion_lock.  Even if head is invalid, the check
fs/aio.c:	spin_unlock_irq(&ctx->completion_lock);
fs/aio.c: * The refcount is initialized to 2 - one for the async op completion,
fs/aio.c:	 * Add a completion event to the ring buffer. Must be done holding
fs/aio.c:	 * ctx->completion_lock to prevent other code from messing with the tail
fs/aio.c:	spin_lock_irqsave(&ctx->completion_lock, flags);
fs/aio.c:	spin_unlock_irqrestore(&ctx->completion_lock, flags);
fs/aio.c: *	AIOs and block on completion.  Will fail with -ENOSYS if not
fs/aio.c:		init_completion(&wait.comp);
fs/aio.c:			wait_for_completion(&wait.comp);
fs/aio.c:			 * Reschedule completion if another wakeup came in.
fs/aio.c:	 *	the events, so inline completion isn't possible.
fs/aio.c:	 *   2. The completion work must not have already been scheduled.
fs/aio.c:		 * Schedule the completion work if needed.  If it was already
fs/aio.c:		 * completion work (done above).  Also mark the request as
fs/aio.c:			 * completion work, or completed the request inline.
fs/aio.c: *	into the completion queue and 0 is returned.  May fail with
fs/aio.c: *	the completion queue for the aio_context specified by ctx_id. If
fs/autofs/autofs_i.h:#include <linux/completion.h>
fs/autofs/autofs_i.h:	struct completion expire_complete;
fs/autofs/expire.c:			init_completion(&ino->expire_complete);
fs/autofs/expire.c:	init_completion(&ino->expire_complete);
fs/autofs/expire.c:		wait_for_completion(&ino->expire_complete);
fs/autofs/root.c:	 * completion.
fs/backing-file.c:	/* used for aio completion */
fs/backing-file.c:static void backing_aio_queue_completion(struct kiocb *iocb, long res)
fs/backing-file.c:	 * Stacked filesystems don't support deferred completions, don't copy
fs/backing-file.c:		aio->iocb.ki_complete = backing_aio_queue_completion;
fs/bcachefs/bcachefs.h:	struct completion	ref_completion;
fs/bcachefs/bcachefs.h:	struct completion	io_ref_completion;
fs/bcachefs/fs-io-buffered.c:	DECLARE_COMPLETION_ONSTACK(done);
fs/bcachefs/fs-io-buffered.c:	wait_for_completion(&done);
fs/bcachefs/io_read.c:	 * We need to rework the narrow_crcs path to deliver the read completion
fs/bcachefs/journal_io.c:		 * Must come before signaling write completion, for
fs/bcachefs/sb-members.h:		complete(&ca->ref_completion);
fs/bcachefs/super.c:	reinit_completion(&ca->io_ref_completion);
fs/bcachefs/super.c:	wait_for_completion(&ca->io_ref_completion);
fs/bcachefs/super.c:	complete(&ca->ref_completion);
fs/bcachefs/super.c:	complete(&ca->io_ref_completion);
fs/bcachefs/super.c:	init_completion(&ca->ref_completion);
fs/bcachefs/super.c:	init_completion(&ca->io_ref_completion);
fs/bcachefs/super.c:	wait_for_completion(&ca->ref_completion);
fs/bcachefs/tests.c:	struct completion		done_completion;
fs/bcachefs/tests.c:		complete(&j->done_completion);
fs/bcachefs/tests.c:	init_completion(&j.done_completion);
fs/bcachefs/tests.c:	while (wait_for_completion_interruptible(&j.done_completion))
fs/btrfs/bio.c: * At IO completion time the csums attached on the ordered extent record are
fs/btrfs/bio.c: * At IO completion time the csums attached on the ordered extent record are
fs/btrfs/bio.c:			 * iteration only happens in the completion path, which
fs/btrfs/bio.c: * The I/O is issued synchronously to block the repair read completion from
fs/btrfs/btrfs_inode.h:	  * fsync racing with ordered extent completion).
fs/btrfs/btrfs_inode.h:	 * have a concurrent ordered extent completion update it. Also set
fs/btrfs/delalloc-space.c:	 * racing with an ordered completion or some such that would think it
fs/btrfs/direct-io.c:	 * The best way to handle this would be to allow for partial completions
fs/btrfs/disk-io.c: * Write superblock @sb to the @device. Do not wait for completion, all the
fs/btrfs/disk-io.c: * Wait for write completion of superblocks done by write_dev_supers,
fs/btrfs/disk-io.c:	init_completion(&device->flush_wait);
fs/btrfs/disk-io.c:	wait_for_completion_io(&device->flush_wait);
fs/btrfs/disk-io.c:	btrfs_qgroup_wait_for_completion(fs_info, false);
fs/btrfs/disk-io.c:	 * This will just short circuit the ordered completion stuff which will
fs/btrfs/extent-io-tree.h:	 * Must be cleared only during ordered extent completion or on error
fs/btrfs/extent-io-tree.h:	 * that is left for the ordered extent completion.
fs/btrfs/extent_io.c:		 * completion.
fs/btrfs/fiemap.c: *   ordered extent completion, which is needed in order to reliably detect
fs/btrfs/fiemap.c:	 * triggering writeback and waiting for the completion of IO and ordered
fs/btrfs/file-item.c: * record the updated logical address on Zone Append completion.
fs/btrfs/file.c:	 * update the last_trans of the inode during ordered extent completion,
fs/btrfs/file.c:	 * races between hole detection during logging and completion of ordered
fs/btrfs/file.c:	 * commit waits for their completion, to avoid data loss if we fsync,
fs/btrfs/fs.h:#include <linux/completion.h>
fs/btrfs/fs.h:	struct completion qgroup_rescan_completion;
fs/btrfs/inode.c: * at IO completion time based on sums calculated at bio submission time.
fs/btrfs/inode.c:	 * EXTENT_DELALLOC_BIT bit through the ordered extent completion.
fs/btrfs/inode.c:		 * here, must leave that up for the ordered extent completion.
fs/btrfs/inode.c:	struct completion completion;
fs/btrfs/inode.c:	complete(&delalloc_work->completion);
fs/btrfs/inode.c:	init_completion(&work->completion);
fs/btrfs/inode.c:		wait_for_completion(&work->completion);
fs/btrfs/ioctl.c:	return btrfs_qgroup_wait_for_completion(fs_info, true);
fs/btrfs/ordered-data.c:	init_completion(&entry->completion);
fs/btrfs/ordered-data.c:	 * are queuing its completion below. During completion, at
fs/btrfs/ordered-data.c:	 * However because completion runs in a work queue we can end up having
fs/btrfs/ordered-data.c:	 * unlock the inode the fsync might start, and we queue the completion
fs/btrfs/ordered-data.c:	 * finishes (end_bbio_data_write()) we queue the completion, so if the
fs/btrfs/ordered-data.c:	 * logging before ordered extent completion runs in the work queue.
fs/btrfs/ordered-data.c:	 * completion didn't happen yet, it will log file extent items that
fs/btrfs/ordered-data.c:	 * wait for completion of ordered extents in order to reduce latency.
fs/btrfs/ordered-data.c:	complete(&ordered->completion);
fs/btrfs/ordered-data.c:		wait_for_completion(&ordered->completion);
fs/btrfs/ordered-data.c: * Wait on page writeback for all the pages in the extent and the IO completion
fs/btrfs/ordered-data.c: * to completion.
fs/btrfs/ordered-data.c: * to completion in nowait mode.
fs/btrfs/ordered-data.h:#include <linux/completion.h>
fs/btrfs/ordered-data.h:	struct completion completion;
fs/btrfs/qgroup.c:	btrfs_qgroup_wait_for_completion(fs_info, false);
fs/btrfs/qgroup.c: * elements, 1 is returned to signal completion of the search.
fs/btrfs/qgroup.c:	complete_all(&fs_info->qgroup_rescan_completion);
fs/btrfs/qgroup.c:	init_completion(&fs_info->qgroup_rescan_completion);
fs/btrfs/qgroup.c:int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,
fs/btrfs/qgroup.c:		ret = wait_for_completion_interruptible(
fs/btrfs/qgroup.c:					&fs_info->qgroup_rescan_completion);
fs/btrfs/qgroup.c:		wait_for_completion(&fs_info->qgroup_rescan_completion);
fs/btrfs/qgroup.h:int btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,
fs/btrfs/raid56.c:	 * This is a special bio which is used to hold the completion handler
fs/btrfs/reflink.c:	 * write to the same leaf or an ordered extent completion needs to write
fs/btrfs/reflink.c:		 * extent completion for a file range that is outside our source
fs/btrfs/relocation.c:	 * e.g. when syncfs() is waiting for their completion but they can't
fs/btrfs/scrub.c:	DECLARE_COMPLETION_ONSTACK(io_done);
fs/btrfs/scrub.c:	wait_for_completion_io(&io_done);
fs/btrfs/super.c:	btrfs_qgroup_wait_for_completion(fs_info, false);
fs/btrfs/sysfs.c:#include <linux/completion.h>
fs/btrfs/sysfs.c:		wait_for_completion(&fs_devs->kobj_unregister);
fs/btrfs/sysfs.c:		wait_for_completion(&device->kobj_unregister);
fs/btrfs/sysfs.c:	init_completion(&device->kobj_unregister);
fs/btrfs/sysfs.c:	init_completion(&fs_devs->kobj_unregister);
fs/btrfs/tree-log.c:	 * for ordered extent completion, which is where we update nbytes, it
fs/btrfs/tree-log.c:		 * an ordered extent completion modifies the subvolume tree
fs/btrfs/volumes.h:#include <linux/completion.h>
fs/btrfs/volumes.h:	struct completion flush_wait;
fs/btrfs/volumes.h:	struct completion kobj_unregister;
fs/btrfs/volumes.h:	struct completion kobj_unregister;
fs/buffer.c: * I/O completion handler for block_read_full_folio() - pages
fs/buffer.c: * Completion handler for block_write_full_folio() - folios which are unlocked
fs/buffer.c: * during I/O, and which have the writeback flag cleared upon I/O completion.
fs/buffer.c: * completion) then there is a possibility that another thread of
fs/buffer.c: * completion.  Any other dirty buffers which are not yet queued for
fs/cachefiles/daemon.c:#include <linux/completion.h>
fs/cachefiles/internal.h:	struct completion done;
fs/cachefiles/io.c: * Handle completion of a read from the cache.
fs/cachefiles/io.c: * Handle completion of a write to the cache.
fs/cachefiles/main.c:#include <linux/completion.h>
fs/cachefiles/ondemand.c: * OPEN request Completion (copen)
fs/cachefiles/ondemand.c:	init_completion(&req->done);
fs/cachefiles/ondemand.c:	ret = wait_for_completion_killable(&req->done);
fs/ceph/addr.c: * async writeback completion handler.
fs/ceph/caps.c:		ret = !wait_for_completion_timeout(&req1->r_safe_completion,
fs/ceph/caps.c:		ret = !wait_for_completion_timeout(&req2->r_safe_completion,
fs/ceph/inode.c:			/* set dir completion flag? */
fs/ceph/locks.c:static int ceph_lock_wait_for_completion(struct ceph_mds_client *mdsc,
fs/ceph/locks.c:					ceph_lock_wait_for_completion : NULL);
fs/ceph/locks.c:static int ceph_lock_wait_for_completion(struct ceph_mds_client *mdsc,
fs/ceph/locks.c:	err = wait_for_completion_interruptible(&req->r_completion);
fs/ceph/locks.c:	wait_for_completion_killable(&req->r_safe_completion);
fs/ceph/mds_client.c:	complete_all(&req->r_safe_completion);
fs/ceph/mds_client.c:	init_completion(&req->r_completion);
fs/ceph/mds_client.c:	init_completion(&req->r_safe_completion);
fs/ceph/mds_client.c:	complete_all(&req->r_completion);
fs/ceph/mds_client.c:		long timeleft = wait_for_completion_killable_timeout(
fs/ceph/mds_client.c:					&req->r_completion,
fs/ceph/mds_client.c:	init_completion(&mdsc->safe_umount_waiters);
fs/ceph/mds_client.c:	init_completion(&mdsc->stopping_waiter);
fs/ceph/mds_client.c:		wait_for_completion_timeout(&mdsc->safe_umount_waiters,
fs/ceph/mds_client.c:			wait_for_completion(&req->r_safe_completion);
fs/ceph/mds_client.h:#include <linux/completion.h>
fs/ceph/mds_client.h: * request completion callback
fs/ceph/mds_client.h: * wait for request completion callback
fs/ceph/mds_client.h:	struct completion r_completion;
fs/ceph/mds_client.h:	struct completion r_safe_completion;
fs/ceph/mds_client.h:	struct completion       safe_umount_waiters;
fs/ceph/mds_client.h:	struct completion	stopping_waiter;
fs/ceph/super.c:		long timeleft = wait_for_completion_killable_timeout(
fs/ceph/super.h:#include <linux/completion.h>
fs/coredump.c:	init_completion(&core_state->startup);
fs/coredump.c:		wait_for_completion_state(&core_state->startup,
fs/crypto/bio.c: * Decrypt the contents of a "read" bio following successful completion of the
fs/dax.c: * on persistent storage prior to completion of the operation.
fs/debugfs/file.c:		init_completion(&fsd->active_users_drained);
fs/debugfs/file.c: * to wait for hardware or completion of some asynchronous process
fs/debugfs/inode.c:	 *    to wait for debugfs_file_put() which signals the completion;
fs/debugfs/inode.c:	 *    but debugfs_enter_cancellation() signals the completion
fs/debugfs/inode.c:		wait_for_completion(&fsd->active_users_drained);
fs/debugfs/internal.h:			struct completion active_users_drained;
fs/direct-io.c: *		added IO completion notifier.
fs/direct-io.c:	dio_iodone_t *end_io;		/* IO completion function */
fs/direct-io.c:	/* BIO completion state */
fs/direct-io.c:	bool defer_completion;		/* defer AIO completion to workqueue? */
fs/direct-io.c:	int io_error;			/* IO error in completion path */
fs/direct-io.c:		struct work_struct complete_work;/* deferred AIO completion */
fs/direct-io.c:	 * AIO submission can race with bio completion to get here while
fs/direct-io.c:	 * expecting to have the last io completed by bio completion.
fs/direct-io.c:	bool defer_completion = false;
fs/direct-io.c:		 * Defer completion when defer_completion is set or
fs/direct-io.c:		 * went in between AIO submission and completion into the
fs/direct-io.c:			defer_completion = dio->defer_completion ||
fs/direct-io.c:		if (defer_completion) {
fs/direct-io.c: * The BIO completion handler simply queues the BIO up for the process-context
fs/direct-io.c: * During IO completion, any of these pages which happen to have been written
fs/direct-io.c:	 * completion drops the count, maybe adds to the list, and wakes while
fs/direct-io.c:static void dio_await_completion(struct dio *dio)
fs/direct-io.c:static int dio_set_defer_completion(struct dio *dio)
fs/direct-io.c:	if (dio->defer_completion)
fs/direct-io.c:	dio->defer_completion = true;
fs/direct-io.c:		/* Store for completion */
fs/direct-io.c:		if (ret == 0 && buffer_defer_completion(map_bh))
fs/direct-io.c:			ret = dio_set_defer_completion(dio);
fs/direct-io.c:	 * completion paths can drop their ref and use the remaining count to
fs/direct-io.c:	 * In that case we need to wait for I/O completion even if asked
fs/direct-io.c:	 * For AIO O_(D)SYNC writes we need to defer completions to a workqueue
fs/direct-io.c:			retval = dio_set_defer_completion(dio);
fs/direct-io.c:			 * need to defer completion. We can't decide this now,
fs/direct-io.c:	 * Will be decremented at I/O completion time.
fs/direct-io.c:	 * bio completion will call aio_complete.  The only time it's safe to
fs/direct-io.c:		dio_await_completion(dio);
fs/dlm/dlm_internal.h: * the caller's lksb.sb_flags prior to the dlm_lock/dlm_unlock completion
fs/dlm/dlm_internal.h:	struct completion	ls_recovery_done;
fs/dlm/lockspace.c:	init_completion(&ls->ls_recovery_done);
fs/dlm/lockspace.c:	wait_for_completion(&ls->ls_recovery_done);
fs/dlm/recover.c:			   lvb/VALNOTVALID is presented in the completion */
fs/dlm/user.c:	   for cases where a completion ast is received for an operation that
fs/ecryptfs/kthread.c:	struct completion done;
fs/ecryptfs/kthread.c:	init_completion(&req.done);
fs/ecryptfs/kthread.c:	wait_for_completion(&req.done);
fs/erofs/fscache.c:	/* The request completion will drop refs on the folios. */
fs/erofs/internal.h:	struct completion s_kobj_unregister;
fs/erofs/sysfs.c:	init_completion(&sbi->s_kobj_unregister);
fs/erofs/sysfs.c:		wait_for_completion(&sbi->s_kobj_unregister);
fs/erofs/sysfs.c:		wait_for_completion(&sbi->s_kobj_unregister);
fs/erofs/zdata.c:		struct completion done;
fs/erofs/zdata.c:		init_completion(&fgq->u.done);
fs/erofs/zdata.c:	wait_for_completion_io(&io[JQ_SUBMIT].u.done);
fs/ext2/inode.c:	 * Writes that span EOF might trigger an IO size update on completion,
fs/ext4/ext4.h:	struct completion s_kobj_unregister;
fs/ext4/ext4.h:	struct completion f_kobj_unregister;
fs/ext4/ext4_jbd2.h: * I/O completion handler, and this conflicts with the jbd's use of
fs/ext4/fast_commit.c: * complete. The completion of such an update is marked by
fs/ext4/fast_commit.c:/* Wait for completion of data for all the fast commit inodes */
fs/ext4/inline.c:	 * completion of syscall, but too many callers depend
fs/ext4/inode.c:	 * Writes that span EOF might trigger an I/O size update on completion,
fs/ext4/mballoc.c:	/* wait for I/O completion */
fs/ext4/mballoc.c:	 * Wait for completion of call_rcu()'s on ext4_pspace_cachep
fs/ext4/namei.c:	 * completion of syscall, but too many callers depend
fs/ext4/page-io.c:/* BIO completion function for page writeback */
fs/ext4/page-io.c:		 * atomically as bio completions can be racing against each
fs/ext4/readpage.c: * I/O completion handler for multipage BIOs.
fs/ext4/readpage.c: * Why is this?  If a page's completion depends on a number of different BIOs
fs/ext4/super.c:	wait_for_completion(&sbi->s_kobj_unregister);
fs/ext4/sysfs.c:	init_completion(&sbi->s_kobj_unregister);
fs/ext4/sysfs.c:		wait_for_completion(&sbi->s_kobj_unregister);
fs/f2fs/checkpoint.c:			wait_for_completion(&wait_req->wait);
fs/f2fs/checkpoint.c:	init_completion(&req->wait);
fs/f2fs/checkpoint.c:		wait_for_completion(&req.wait);
fs/f2fs/compress.c:	 * for I/O completion.
fs/f2fs/data.c:			init_completion(&io->zone_wait);
fs/f2fs/data.c:		wait_for_completion_io(&io->zone_wait);
fs/f2fs/data.c:		reinit_completion(&io->zone_wait);
fs/f2fs/data.c:	/* wait for read completion */
fs/f2fs/data.c:	 * its completion to see the correct decrypted data.
fs/f2fs/f2fs.h:	struct completion wait;		/* completion for checkpoint done */
fs/f2fs/f2fs.h:	struct completion wait;		/* compleation */
fs/f2fs/f2fs.h:	struct completion wait;
fs/f2fs/f2fs.h: *			with waiting the bio's completion
fs/f2fs/f2fs.h:	struct completion zone_wait;	/* condition value for the previous open zone to close */
fs/f2fs/f2fs.h:	 * One reference is held for I/O completion.  This reference is dropped
fs/f2fs/f2fs.h:	struct completion s_kobj_unregister;
fs/f2fs/f2fs.h:	struct completion s_stat_kobj_unregister;
fs/f2fs/f2fs.h:	struct completion s_feature_list_kobj_unregister;
fs/f2fs/file.c:	 * here we don't need to wait for node write completion, since we use
fs/f2fs/file.c:		 * IO completion.
fs/f2fs/file.c:	 * completion.
fs/f2fs/file.c:	/* In LFS mode, if there is inflight dio, wait for its completion */
fs/f2fs/segment.c:	init_completion(&cmd.wait);
fs/f2fs/segment.c:		wait_for_completion(&cmd.wait);
fs/f2fs/segment.c:			wait_for_completion(&cmd.wait);
fs/f2fs/segment.c:	init_completion(&dc->wait);
fs/f2fs/segment.c:	wait_for_completion_io(&dc->wait);
fs/f2fs/segment.c:			wait_for_completion_io(&iter->wait);
fs/f2fs/sysfs.c:	init_completion(&sbi->s_kobj_unregister);
fs/f2fs/sysfs.c:	init_completion(&sbi->s_stat_kobj_unregister);
fs/f2fs/sysfs.c:	init_completion(&sbi->s_feature_list_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_feature_list_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_stat_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_stat_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_feature_list_kobj_unregister);
fs/f2fs/sysfs.c:	wait_for_completion(&sbi->s_kobj_unregister);
fs/file.c: * Return <0 error code on error; 1 on successful completion.
fs/file_table.c: * risking deadlocks), need to wait for completion of __fput() and know
fs/fs-writeback.c:	unsigned int auto_free:1;	/* free on completion */
fs/fs-writeback.c:	struct wb_completion *done;	/* set if the caller waits */
fs/fs-writeback.c:	struct wb_completion *done = work->done;
fs/fs-writeback.c: * wb_wait_for_completion - wait for completion of bdi_writeback_works
fs/fs-writeback.c: * @done: target wb_completion
fs/fs-writeback.c: * DEFINE_WB_COMPLETION().  This function returns after all such work items
fs/fs-writeback.c: * automatically on completion.
fs/fs-writeback.c:void wb_wait_for_completion(struct wb_completion *done)
fs/fs-writeback.c: * writeback completion, wbc_detach_inode() should be called.  This is used
fs/fs-writeback.c:		DEFINE_WB_COMPLETION(fallback_work_done, bdi);
fs/fs-writeback.c:		wb_wait_for_completion(&fallback_work_done);
fs/fs-writeback.c: * @done: target wb_completion
fs/fs-writeback.c:			   enum wb_reason reason, struct wb_completion *done)
fs/fs-writeback.c:		 * updates after data IO completion.
fs/fs-writeback.c:	 * I/O completion. We don't do it for sync(2) writeback because it has a
fs/fs-writeback.c:	 * separate, external IO completion path and ->sync_fs for guaranteeing
fs/fs-writeback.c:		 * The completion of the current batch does not necessarily
fs/fs-writeback.c:	 * completion.
fs/fs-writeback.c:		 * writeback tag. Writeback completion is responsible to remove
fs/fs-writeback.c:		 * do not have the mapping lock. Skip it here, wb completion
fs/fs-writeback.c:	DEFINE_WB_COMPLETION(done, bdi);
fs/fs-writeback.c:	wb_wait_for_completion(&done);
fs/fs-writeback.c: * for IO completion of submitted IO.
fs/fs-writeback.c: * for IO completion of submitted IO.
fs/fs-writeback.c:	DEFINE_WB_COMPLETION(done, bdi);
fs/fs-writeback.c:	wb_wait_for_completion(&done);
fs/fs-writeback.c: * Write an inode to disk and adjust its dirty state after completion.
fs/fuse/file.c:		 * now for completion of all in-flight requests.  This happens
fs/fuse/file.c:	DECLARE_COMPLETION_ONSTACK(wait);
fs/fuse/file.c:		wait_for_completion(&wait);
fs/fuse/fuse_i.h:			/* Waitq for writepage completion */
fs/fuse/fuse_i.h:			/* waitq for direct-io completion */
fs/fuse/fuse_i.h:	struct completion *done;
fs/fuse/fuse_i.h:	/** Used to wake up the task waiting for completion of request*/
fs/fuse/fuse_i.h:	/** The number of requests waiting for completion */
fs/fuse/inode.c:	 * Completion of new bucket depends on completion of this bucket, so add
fs/fuse/iomode.c:	 * dio write completion.
fs/fuse/virtio_fs.c:	struct completion in_flight_zero; /* No inflight requests */
fs/fuse/virtio_fs.c:		 * waiters waiting for completion.
fs/fuse/virtio_fs.c:		reinit_completion(&fsvq->in_flight_zero);
fs/fuse/virtio_fs.c:		wait_for_completion(&fsvq->in_flight_zero);
fs/fuse/virtio_fs.c:	 * same time. Current completion logic reinits completion
fs/fuse/virtio_fs.c:	 * doing reinit or waiting for completion already.
fs/fuse/virtio_fs.c:/* Work function for hiprio completion */
fs/fuse/virtio_fs.c:/* Work function for request completion */
fs/fuse/virtio_fs.c:	init_completion(&fsvq->in_flight_zero);
fs/gfs2/acl.c:#include <linux/completion.h>
fs/gfs2/aops.c:#include <linux/completion.h>
fs/gfs2/bmap.c:#include <linux/completion.h>
fs/gfs2/dentry.c:#include <linux/completion.h>
fs/gfs2/export.c:#include <linux/completion.h>
fs/gfs2/file.c:#include <linux/completion.h>
fs/gfs2/glops.c:#include <linux/completion.h>
fs/gfs2/incore.h:#include <linux/completion.h>
fs/gfs2/incore.h:	struct completion ls_sync_wait; /* {control,mounted}_{lock,unlock} */
fs/gfs2/incore.h:	struct completion sd_kobj_unregister;
fs/gfs2/incore.h:	struct completion sd_locking_init;
fs/gfs2/incore.h:	struct completion sd_wdack;
fs/gfs2/incore.h:	struct completion sd_journal_ready;
fs/gfs2/inode.c:#include <linux/completion.h>
fs/gfs2/lock_dlm.c:	wait_for_completion(&ls->ls_sync_wait);
fs/gfs2/lock_dlm.c:	wait_for_completion(&ls->ls_sync_wait);
fs/gfs2/lock_dlm.c:	init_completion(&ls->ls_sync_wait);
fs/gfs2/log.c:#include <linux/completion.h>
fs/gfs2/log.c:			       buffer_defer_completion(bh),
fs/gfs2/lops.c:#include <linux/completion.h>
fs/gfs2/main.c:#include <linux/completion.h>
fs/gfs2/meta_io.c:#include <linux/completion.h>
fs/gfs2/ops_fstype.c:#include <linux/completion.h>
fs/gfs2/ops_fstype.c:	init_completion(&sdp->sd_locking_init);
fs/gfs2/ops_fstype.c:	init_completion(&sdp->sd_wdack);
fs/gfs2/ops_fstype.c:	init_completion(&sdp->sd_journal_ready);
fs/gfs2/quota.c:#include <linux/completion.h>
fs/gfs2/recovery.c:#include <linux/completion.h>
fs/gfs2/rgrp.c:#include <linux/completion.h>
fs/gfs2/super.c:#include <linux/completion.h>
fs/gfs2/super.c: * @wait: true to wait for completion
fs/gfs2/sys.c:#include <linux/completion.h>
fs/gfs2/sys.c:	int val = completion_done(&sdp->sd_wdack) ? 1 : 0;
fs/gfs2/sys.c:	rv = wait_for_completion_killable(&sdp->sd_locking_init);
fs/gfs2/sys.c:	wait_for_completion(&sdp->sd_journal_ready);
fs/gfs2/sys.c:	 * queue work to the recovery workqueue, and so its completion would
fs/gfs2/sys.c:	rv = wait_for_completion_killable(&sdp->sd_locking_init);
fs/gfs2/sys.c:	init_completion(&sdp->sd_kobj_unregister);
fs/gfs2/sys.c:	wait_for_completion(&sdp->sd_kobj_unregister);
fs/gfs2/sys.c:	wait_for_completion(&sdp->sd_kobj_unregister);
fs/gfs2/trans.c:#include <linux/completion.h>
fs/gfs2/util.c:#include <linux/completion.h>
fs/gfs2/util.c:			wait_for_completion(&sdp->sd_wdack);
fs/gfs2/xattr.c:#include <linux/completion.h>
fs/iomap/buffered-io.c: * and I/O completions.
fs/iomap/buffered-io.c:	 * completion before this write reaches this file offset) and hence we
fs/iomap/buffered-io.c:		 * updated size to disk, preferably after I/O completion so that
fs/iomap/buffered-io.c: * Ioend completion routine for merged bios. This can only be called from task
fs/iomap/buffered-io.c: * the writeback completions into manageable chunks to avoid long scheduler
fs/iomap/buffered-io.c:	u32 completions;
fs/iomap/buffered-io.c:	completions = iomap_finish_ioend(ioend, error);
fs/iomap/buffered-io.c:		if (completions > IOEND_BATCH_SIZE * 8) {
fs/iomap/buffered-io.c:			completions = 0;
fs/iomap/buffered-io.c:		completions += iomap_finish_ioend(ioend, error);
fs/iomap/buffered-io.c:	 * completion functions will have to iterate the physical
fs/iomap/buffered-io.c:	 * completion.
fs/iomap/buffered-io.c: * with the error status here to run the normal I/O completion handler to clear
fs/iomap/buffered-io.c:	 * Limit ioend bio chain lengths to minimise IO completion latency. This
fs/iomap/buffered-io.c:	 * completion to mark the error state of the pages under writeback
fs/iomap/buffered-io.c:		 * Keep the I/O completion handler from clearing the writeback
fs/iomap/buffered-io.c:	 * Set the writeback bit ASAP, as the I/O completion for the single
fs/iomap/buffered-io.c:	 * Usually the writeback bit is cleared by the I/O completion handler.
fs/iomap/direct-io.c:	bool			wait_for_completion;
fs/iomap/direct-io.c:		/* used during submission and for synchronous completion: */
fs/iomap/direct-io.c:		/* used for aio completion: */
fs/iomap/direct-io.c: * as the submission context and the completion context(s) can race to
fs/iomap/direct-io.c:	 * Synchronous dio, task itself will handle any completion work
fs/iomap/direct-io.c:	if (dio->wait_for_completion) {
fs/iomap/direct-io.c:	 * our completion that way to avoid an async punt to a workqueue.
fs/iomap/direct-io.c:		 * for this case. The actual completion value of the request
fs/iomap/direct-io.c:	 * Async DIO completion that requires filesystem level completion work
fs/iomap/direct-io.c:		 * after IO completion such as unwritten extent conversion) and
fs/iomap/direct-io.c:		 * on IO completion. If we can't use writethrough and need to
fs/iomap/direct-io.c:		 * sync, disable in-task completions as dio completion will
fs/iomap/direct-io.c:	 * We can only do deferred completion for pure overwrites that
fs/iomap/direct-io.c:	 * don't require additional IO at completion. This rules out
fs/iomap/direct-io.c:	 * during completion processing.
fs/iomap/direct-io.c:	 * The rules for polled IO completions follow the guidelines as the
fs/iomap/direct-io.c:	 * ones we set for inline and deferred completions. If none of those
fs/iomap/direct-io.c: * completion.
fs/iomap/direct-io.c:	bool wait_for_completion =
fs/iomap/direct-io.c:		 * Flag as supporting deferred completions, if the issuer
fs/iomap/direct-io.c:		 * as part of this IO completion.
fs/iomap/direct-io.c:		/* for data sync or sync, we need sync completion processing */
fs/iomap/direct-io.c:			* will clear this flag, hence we know before completion
fs/iomap/direct-io.c:		if (!wait_for_completion && !inode->i_sb->s_dio_done_wq) {
fs/iomap/direct-io.c:			wait_for_completion = true;
fs/iomap/direct-io.c:		wait_for_completion = true;
fs/iomap/direct-io.c:	 * media, we don't need to flush the cache on IO completion. Clear the
fs/iomap/direct-io.c:	 *	I/O completion handler will complete and free it.
fs/iomap/direct-io.c:	 *	iocb, the I/O completion handler will wake us up on the drop
fs/iomap/direct-io.c:	 *	after we got woken by the I/O completion handler.
fs/iomap/direct-io.c:	dio->wait_for_completion = wait_for_completion;
fs/iomap/direct-io.c:		if (!wait_for_completion) {
fs/jbd2/commit.c:                           completion later */
fs/jbd2/journal.c:		 * completion of that transaction.
fs/jbd2/journal.c: * for completion.
fs/jbd2/revoke.c:		/* Record it so that we can wait for IO completion later */
fs/jbd2/transaction.c:	 * atomically wrt. completion of any outstanding commits.
fs/jffs2/README.Locking:upon write completion (jffs2_complete_reservation()). Note that
fs/jffs2/README.Locking:erase_completion_lock), etc.
fs/jffs2/README.Locking:	erase_completion_lock spinlock
fs/jffs2/README.Locking:As the MTD API no longer permits erase-completion callback functions
fs/jffs2/README.Locking:erase_completion_lock. So you can walk the list only while holding the
fs/jffs2/README.Locking:erase_completion_lock, and can drop the lock temporarily mid-walk as
fs/jffs2/README.Locking:The erase_completion_lock is also used to protect the c->gc_task
fs/jffs2/README.Locking:	If both erase_completion_lock and inocache_lock are needed, the
fs/jffs2/README.Locking:	c->erase_completion has to be acquired first.
fs/jffs2/README.Locking:erase_completion_lock cannot be held, so an alternative, more
fs/jffs2/background.c:#include <linux/completion.h>
fs/jffs2/background.c:	assert_spin_locked(&c->erase_completion_lock);
fs/jffs2/background.c:	init_completion(&c->gc_thread_start);
fs/jffs2/background.c:	init_completion(&c->gc_thread_exit);
fs/jffs2/background.c:		wait_for_completion(&c->gc_thread_start);
fs/jffs2/background.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/background.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/background.c:		wait_for_completion(&c->gc_thread_exit);
fs/jffs2/background.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/background.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/background.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/background.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/background.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/debug.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/erase.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/fs.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/fs.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:/* Called with erase_completion_lock held */
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/gc.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:	/* We need to hold the inocache. Either the erase_completion_lock or
fs/jffs2/gc.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/gc.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/gc.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/jffs2_fs_sb.h:#include <linux/completion.h>
fs/jffs2/jffs2_fs_sb.h:	struct completion gc_thread_start; /* GC thread start completion */
fs/jffs2/jffs2_fs_sb.h:	struct completion gc_thread_exit; /* GC thread exit completion port */
fs/jffs2/jffs2_fs_sb.h:	spinlock_t erase_completion_lock;	/* Protect free_list and erasing_list
fs/jffs2/jffs2_fs_sb.h:						   against erase completion handler */
fs/jffs2/jffs2_fs_sb.h:	   drop the erase_completion_lock while it's holding a pointer
fs/jffs2/nodemgmt.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:				spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:				spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:				spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:					spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:					spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:/* Called with alloc sem _and_ erase_completion_lock */
fs/jffs2/nodemgmt.c:				spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:				spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			   we hold c->erase_completion_lock in the majority of this function...
fs/jffs2/nodemgmt.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		   jffs2_raw_node_ref without the erase_completion_lock. */
fs/jffs2/nodemgmt.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/nodemgmt.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/readinode.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/readinode.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/readinode.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/readinode.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/readinode.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/readinode.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/readinode.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/readinode.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/readinode.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/readinode.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/scan.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/scan.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/summary.c:			spin_lock(&c->erase_completion_lock);
fs/jffs2/summary.c:			spin_unlock(&c->erase_completion_lock);
fs/jffs2/summary.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/summary.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/summary.c:	__must_hold(&c->erase_completion_block)
fs/jffs2/summary.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/summary.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/super.c:	spin_lock_init(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/wbuf.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	if (atomic_dec_and_lock(&xd->refcnt, &c->erase_completion_lock)) {
fs/jffs2/xattr.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:					spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:					spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:		spin_lock(&c->erase_completion_lock);
fs/jffs2/xattr.c:		spin_unlock(&c->erase_completion_lock);
fs/jffs2/xattr.c:	/* must be called under spin_lock(&c->erase_completion_lock) */
fs/jffs2/xattr.c:	/* must be called under spin_lock(&c->erase_completion_lock) */
fs/jfs/jfs_imap.c: *	read lock on the map is held on successful completion;
fs/jfs/jfs_logmgr.c:#include <linux/completion.h>
fs/jfs/jfs_logmgr.c:				 * at completion of pageout;
fs/jfs/jfs_logmgr.c:				 * at completion of pageout;
fs/jfs/jfs_logmgr.c:	/* upcount transaction waiting for completion
fs/jfs/jfs_logmgr.c: * buffer at head of pageout queue stays after completion of
fs/jfs/jfs_logmgr.c: * queue is released at the completion of its full-page pageout.
fs/jfs/jfs_logmgr.c:	 *	pagein completion
fs/jfs/jfs_logmgr.c:	 *	pageout completion
fs/jfs/jfs_txnmgr.c:#include <linux/completion.h>
fs/jfs/jfs_txnmgr.c: *	completion
fs/jfs/jfs_txnmgr.h:					 * event for group commit completion.
fs/jfs/jfs_xtree.c:			/* page will be invalidated at tx completion
fs/jfs/jfs_xtree.c:				/* page will be invalidated at tx completion
fs/jfs/resize.c:	 * block any new transactions and wait for completion of
fs/jfs/resize.c:	 * for crash before completion of write
fs/jfs/resize.c:	 * for crash after completion of write,
fs/jfs/resize.c:	/* mark extendfs() completion */
fs/jfs/super.c:#include <linux/completion.h>
fs/jfs/super.c:	 * I/O completion thread (endio)
fs/kernfs/dir.c: * for the completion of not only the winning kernfs_remove_self() but also
fs/lockd/clntproc.c: *      completion in order to be able to correctly track the lock
fs/lockd/clntproc.c:	err = rpc_wait_for_completion_task(task);
fs/mpage.c: * I/O completion handler for multipage BIOs.
fs/mpage.c: * Why is this?  If a page's completion depends on a number of different BIOs
fs/namei.c: * complete_walk - successful completion of path walk
fs/netfs/fscache_io.c: * Deal with the completion of writing the data to the cache.
fs/netfs/read_collect.c: * Handle the completion of all outstanding I/O operations on a read request.
fs/netfs/read_collect.c: * @error: Error code indicating type of completion.
fs/netfs/write_collect.c: * Successful completion of write of a folio to the server and/or cache.  Note
fs/netfs/write_collect.c:	 * advance the completion point on each stream.  We stop when we hit
fs/netfs/write_collect.c:		/* Cache write failure doesn't prevent writeback completion
fs/nfs/cache_lib.c:	complete(&dreq->completion);
fs/nfs/cache_lib.c:		init_completion(&dreq->completion);
fs/nfs/cache_lib.c:	if (wait_for_completion_timeout(&dreq->completion,
fs/nfs/cache_lib.h:#include <linux/completion.h>
fs/nfs/cache_lib.h:	struct completion completion;
fs/nfs/callback.c:#include <linux/completion.h>
fs/nfs/callback_proc.c:			complete(&tmp_copy->completion);
fs/nfs/delegation.c:#include <linux/completion.h>
fs/nfs/dir.c:	error = rpc_wait_for_completion_task(task);
fs/nfs/dir.c:		 * The d_move() should be here instead of in an async RPC completion
fs/nfs/dir.c:		 * we're interrupted by a signal, the async RPC completion handler
fs/nfs/direct.c:static const struct nfs_pgio_completion_ops nfs_direct_write_completion_ops;
fs/nfs/direct.c:static const struct nfs_commit_completion_ops nfs_direct_commit_completion_ops;
fs/nfs/direct.c:	cinfo->completion_ops = &nfs_direct_commit_completion_ops;
fs/nfs/direct.c:	init_completion(&dreq->completion);
fs/nfs/direct.c:	result = wait_for_completion_killable(&dreq->completion);
fs/nfs/direct.c:	complete(&dreq->completion);
fs/nfs/direct.c:static void nfs_direct_read_completion(struct nfs_pgio_header *hdr)
fs/nfs/direct.c:static const struct nfs_pgio_completion_ops nfs_direct_read_completion_ops = {
fs/nfs/direct.c:	.completion = nfs_direct_read_completion,
fs/nfs/direct.c:			     &nfs_direct_read_completion_ops);
fs/nfs/direct.c:	 * generic layer handle the completion.
fs/nfs/direct.c:			      &nfs_direct_write_completion_ops);
fs/nfs/direct.c:static const struct nfs_commit_completion_ops nfs_direct_commit_completion_ops = {
fs/nfs/direct.c:	.completion = nfs_direct_commit_complete,
fs/nfs/direct.c:static void nfs_direct_write_completion(struct nfs_pgio_header *hdr)
fs/nfs/direct.c:	trace_nfs_direct_write_completion(dreq);
fs/nfs/direct.c:static const struct nfs_pgio_completion_ops nfs_direct_write_completion_ops = {
fs/nfs/direct.c:	.completion = nfs_direct_write_completion,
fs/nfs/direct.c:			      &nfs_direct_write_completion_ops);
fs/nfs/direct.c:	 * generic layer handle the completion.
fs/nfs/flexfilelayout/flexfilelayout.c:	ktime_t completion_time = ktime_sub(time_completed, time_started);
fs/nfs/flexfilelayout/flexfilelayout.c:	iostat->aggregate_completion_time =
fs/nfs/flexfilelayout/flexfilelayout.c:			ktime_add(iostat->aggregate_completion_time,
fs/nfs/flexfilelayout/flexfilelayout.c:					completion_time);
fs/nfs/flexfilelayout/flexfilelayout.c:		hdr->completion_ops->reschedule_io(hdr);
fs/nfs/flexfilelayout/flexfilelayout.c:	ff_layout_encode_nfstime(xdr, stat->aggregate_completion_time);
fs/nfs/flexfilelayout/flexfilelayout.h:	ktime_t				aggregate_completion_time;
fs/nfs/fscache.c:			     &nfs_async_read_completion_ops);
fs/nfs/fscache.c:	pgio.pg_netfs = netfs; /* used in completion */
fs/nfs/fscache.c:void nfs_netfs_read_completion(struct nfs_pgio_header *hdr)
fs/nfs/fscache.h:	 * with their own read completion.  In netfs, we can only call
fs/nfs/fscache.h:	 * refcount here to double as a marker of the last RPC completion,
fs/nfs/fscache.h:	/* Only the last RPC completion should call netfs_subreq_terminated() */
fs/nfs/fscache.h:extern void nfs_netfs_read_completion(struct nfs_pgio_header *hdr);
fs/nfs/fscache.h:static inline void nfs_netfs_read_completion(struct nfs_pgio_header *hdr) {}
fs/nfs/internal.h:struct nfs_pgio_completion_ops;
fs/nfs/internal.h:extern const struct nfs_pgio_completion_ops nfs_async_read_completion_ops;
fs/nfs/internal.h:			const struct nfs_pgio_completion_ops *compl_ops);
fs/nfs/internal.h:			const struct nfs_pgio_completion_ops *compl_ops);
fs/nfs/internal.h:	/* completion state */
fs/nfs/internal.h:	spinlock_t		lock;		/* protect completion state */
fs/nfs/internal.h:	struct completion	completion;	/* wait for i/o completion */
fs/nfs/localio.c:	struct completion	*done;
fs/nfs/localio.c:		DECLARE_COMPLETION_ONSTACK(done);
fs/nfs/localio.c:		wait_for_completion(&done);
fs/nfs/nfs42proc.c:	init_completion(&copy->completion);
fs/nfs/nfs42proc.c:	status = wait_for_completion_interruptible(&copy->completion);
fs/nfs/nfs42proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:		status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	ret = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	ret = rpc_wait_for_completion_task(task);
fs/nfs/nfs4proc.c:	status = rpc_wait_for_completion_task(task);
fs/nfs/nfs4session.c:	init_completion(&tbl->complete);
fs/nfs/nfs4session.h:	wait_queue_head_t	slot_waitq;	/* Completion wait on slot */
fs/nfs/nfs4session.h:	struct completion complete;
fs/nfs/nfs4state.c:		reinit_completion(&tbl->complete);
fs/nfs/nfs4state.c:		return wait_for_completion_interruptible(&tbl->complete);
fs/nfs/nfs4state.c:			complete(&copy->completion);
fs/nfs/nfs4state.c:			complete(&copy->completion);
fs/nfs/nfstrace.h:DEFINE_NFS_DIRECT_REQ_EVENT(nfs_direct_write_completion);
fs/nfs/pagelist.c:	hdr->io_completion = desc->pg_io_completion;
fs/nfs/pagelist.c:	hdr->completion_ops = desc->pg_completion_ops;
fs/nfs/pagelist.c:	if (hdr->completion_ops->init_hdr)
fs/nfs/pagelist.c:		hdr->completion_ops->init_hdr(hdr);
fs/nfs/pagelist.c:	hdr->completion_ops->completion(hdr);
fs/nfs/pagelist.c:	hdr->completion_ops->completion(hdr);
fs/nfs/pagelist.c: * @compl_ops: pointer to pageio completion operations
fs/nfs/pagelist.c:		     const struct nfs_pgio_completion_ops *compl_ops,
fs/nfs/pagelist.c:	desc->pg_completion_ops = compl_ops;
fs/nfs/pagelist.c:	desc->pg_io_completion = NULL;
fs/nfs/pagelist.c:	desc->pg_completion_ops->error_cleanup(&head, desc->pg_error);
fs/nfs/pagelist.c:		desc->pg_completion_ops->error_cleanup(&mirror->pg_list,
fs/nfs/pagelist.c:	desc->pg_io_completion = hdr->io_completion;
fs/nfs/pagelist.c:		hdr->completion_ops->error_cleanup(&pages, err);
fs/nfs/pagelist.c: * nfs_pageio_cond_complete - Conditional I/O completion
fs/nfs/pnfs.c:			      hdr->completion_ops);
fs/nfs/pnfs.c:	hdr->completion_ops->completion(hdr);
fs/nfs/pnfs.c:	nfs_pageio_init_read(&pgio, hdr->inode, true, hdr->completion_ops);
fs/nfs/pnfs.c:	hdr->completion_ops->completion(hdr);
fs/nfs/pnfs.c:					hdr->completion_ops);
fs/nfs/pnfs_nfs.c:	data->completion_ops->completion(data);
fs/nfs/pnfs_nfs.c:	cinfo->completion_ops->resched_write(cinfo, req);
fs/nfs/read.c:const struct nfs_pgio_completion_ops nfs_async_read_completion_ops;
fs/nfs/read.c:			      const struct nfs_pgio_completion_ops *compl_ops)
fs/nfs/read.c:static void nfs_read_completion(struct nfs_pgio_header *hdr)
fs/nfs/read.c:	nfs_netfs_read_completion(hdr);
fs/nfs/read.c:const struct nfs_pgio_completion_ops nfs_async_read_completion_ops = {
fs/nfs/read.c:	.completion = nfs_read_completion,
fs/nfs/read.c:			     &nfs_async_read_completion_ops);
fs/nfs/read.c:			     &nfs_async_read_completion_ops);
fs/nfs/unlink.c: * nfs_complete_unlink - Initialize completion of the sillydelete
fs/nfs/unlink.c: * @complete: Function to run on successful completion
fs/nfs/unlink.c:	error = rpc_wait_for_completion_task(task);
fs/nfs/write.c:struct nfs_io_completion {
fs/nfs/write.c:static const struct nfs_pgio_completion_ops nfs_async_write_completion_ops;
fs/nfs/write.c:static const struct nfs_commit_completion_ops nfs_commit_completion_ops;
fs/nfs/write.c:static struct nfs_io_completion *nfs_io_completion_alloc(gfp_t gfp_flags)
fs/nfs/write.c:	return kmalloc(sizeof(struct nfs_io_completion), gfp_flags);
fs/nfs/write.c:static void nfs_io_completion_init(struct nfs_io_completion *ioc,
fs/nfs/write.c:static void nfs_io_completion_release(struct kref *kref)
fs/nfs/write.c:	struct nfs_io_completion *ioc = container_of(kref,
fs/nfs/write.c:			struct nfs_io_completion, refcount);
fs/nfs/write.c:static void nfs_io_completion_get(struct nfs_io_completion *ioc)
fs/nfs/write.c:static void nfs_io_completion_put(struct nfs_io_completion *ioc)
fs/nfs/write.c:		kref_put(&ioc->refcount, nfs_io_completion_release);
fs/nfs/write.c:			      &nfs_async_write_completion_ops);
fs/nfs/write.c:static void nfs_io_completion_commit(void *inode)
fs/nfs/write.c:	struct nfs_io_completion *ioc = NULL;
fs/nfs/write.c:		ioc = nfs_io_completion_alloc(GFP_KERNEL);
fs/nfs/write.c:			nfs_io_completion_init(ioc, nfs_io_completion_commit,
fs/nfs/write.c:				      &nfs_async_write_completion_ops);
fs/nfs/write.c:		pgio.pg_io_completion = ioc;
fs/nfs/write.c:	nfs_io_completion_put(ioc);
fs/nfs/write.c:	cinfo->completion_ops = &nfs_commit_completion_ops;
fs/nfs/write.c:	nfs_io_completion_get(hdr->io_completion);
fs/nfs/write.c:static void nfs_write_completion(struct nfs_pgio_header *hdr)
fs/nfs/write.c:	nfs_io_completion_put(hdr->io_completion);
fs/nfs/write.c:static const struct nfs_pgio_completion_ops nfs_async_write_completion_ops = {
fs/nfs/write.c:	.completion = nfs_write_completion,
fs/nfs/write.c:			       const struct nfs_pgio_completion_ops *compl_ops)
fs/nfs/write.c:		rpc_wait_for_completion_task(task);
fs/nfs/write.c:	data->completion_ops = cinfo->completion_ops;
fs/nfs/write.c:	data->completion_ops->completion(data);
fs/nfs/write.c:static const struct nfs_commit_completion_ops nfs_commit_completion_ops = {
fs/nfs/write.c:	.completion = nfs_commit_release_pages,
fs/nfsd/netns.h:	struct completion nfsd_serv_confirm_done;
fs/nfsd/netns.h:	struct completion nfsd_serv_free_done;
fs/nfsd/nfs4proc.c:	 * hangs waiting for COPY completion.
fs/nfsd/nfs4recover.c:	struct completion	 cu_done;
fs/nfsd/nfs4recover.c:	wait_for_completion(&cup->cu_done);
fs/nfsd/nfs4recover.c:	init_completion(&new->cu_done);
fs/nfsd/nfssvc.c:	wait_for_completion(&nn->nfsd_serv_confirm_done);
fs/nfsd/nfssvc.c:	wait_for_completion(&nn->nfsd_serv_free_done);
fs/nfsd/nfssvc.c:	init_completion(&nn->nfsd_serv_free_done);
fs/nfsd/nfssvc.c:	init_completion(&nn->nfsd_serv_confirm_done);
fs/nilfs2/segbuf.c:	init_completion(&segbuf->sb_bio_event);
fs/nilfs2/segbuf.c: * nilfs_segbuf_wait - wait for completion of requested BIOs
fs/nilfs2/segbuf.c:		wait_for_completion(&segbuf->sb_bio_event);
fs/nilfs2/segbuf.h:#include <linux/completion.h>
fs/nilfs2/segbuf.h: * @sb_bio_event: Completion event of log writing
fs/nilfs2/segbuf.h:	struct completion	sb_bio_event;
fs/nilfs2/segment.c:#include <linux/completion.h>
fs/nilfs2/segment.c:	 * To prevent a race issue where completion notifications from the
fs/nilfs2/segment.h: * @sc_seq_done: Completion counter
fs/nilfs2/sysfs.c:	struct completion *kobj_unregister; \
fs/nilfs2/sysfs.c:	init_completion(kobj_unregister); \
fs/nilfs2/sysfs.c:	init_completion(&root->snapshot_kobj_unregister);
fs/nilfs2/sysfs.c:	init_completion(&nilfs->ns_dev_kobj_unregister);
fs/nilfs2/sysfs.h: * @sg_superblock_kobj_unregister: completion state
fs/nilfs2/sysfs.h: * @sg_segctor_kobj_unregister: completion state
fs/nilfs2/sysfs.h: * @sg_mounted_snapshots_kobj_unregister: completion state
fs/nilfs2/sysfs.h: * @sg_checkpoints_kobj_unregister: completion state
fs/nilfs2/sysfs.h: * @sg_segments_kobj_unregister: completion state
fs/nilfs2/sysfs.h:	struct completion sg_superblock_kobj_unregister;
fs/nilfs2/sysfs.h:	struct completion sg_segctor_kobj_unregister;
fs/nilfs2/sysfs.h:	struct completion sg_mounted_snapshots_kobj_unregister;
fs/nilfs2/sysfs.h:	struct completion sg_checkpoints_kobj_unregister;
fs/nilfs2/sysfs.h:	struct completion sg_segments_kobj_unregister;
fs/nilfs2/the_nilfs.h: * @ns_dev_kobj_unregister: completion state
fs/nilfs2/the_nilfs.h:	struct completion ns_dev_kobj_unregister;
fs/nilfs2/the_nilfs.h: * @snapshot_kobj_unregister: completion state for kernel object
fs/nilfs2/the_nilfs.h:	struct completion snapshot_kobj_unregister;
fs/ocfs2/aops.c:	set_buffer_defer_completion(bh_result);
fs/ocfs2/cluster/heartbeat.c:	struct completion wc_io_complete;
fs/ocfs2/cluster/heartbeat.c:	init_completion(&wc->wc_io_complete);
fs/ocfs2/cluster/heartbeat.c:	wait_for_completion(&wc->wc_io_complete);
fs/ocfs2/cluster/tcp.c:	/* handshake completion will set nn->nn_sc_valid */
fs/ocfs2/dlmglue.c:	struct completion	mw_complete;
fs/ocfs2/dlmglue.c:	init_completion(&mw->mw_complete);
fs/ocfs2/dlmglue.c:	wait_for_completion(&mw->mw_complete);
fs/ocfs2/dlmglue.c:	/* Re-arm the completion in case we want to wait on it again */
fs/ocfs2/dlmglue.c:	reinit_completion(&mw->mw_complete);
fs/ocfs2/dlmglue.c:		init_completion(&mw->mw_complete);
fs/ocfs2/dlmglue.c:	ret = wait_for_completion_interruptible(&mw->mw_complete);
fs/ocfs2/dlmglue.c:	/* Re-arm the completion in case we want to wait on it again */
fs/ocfs2/dlmglue.c:	reinit_completion(&mw->mw_complete);
fs/ocfs2/file.c:		 * both two cases mean the completion of hole punching.
fs/ocfs2/filecheck.c:	init_completion(&entry->fs_kobj_unregister);
fs/ocfs2/filecheck.c:	wait_for_completion(&osb->osb_fc_ent.fs_kobj_unregister);
fs/ocfs2/filecheck.h:	struct completion fs_kobj_unregister;
fs/ocfs2/inode.c:static void ocfs2_signal_wipe_completion(struct ocfs2_super *osb,
fs/ocfs2/inode.c:		 * recovery completion on other nodes. */
fs/ocfs2/inode.c:	ocfs2_signal_wipe_completion(osb, orphaned_slot);
fs/ocfs2/journal.c:static void ocfs2_queue_recovery_completion(struct ocfs2_journal *journal,
fs/ocfs2/journal.c:			ocfs2_queue_recovery_completion(osb->journal, i, NULL,
fs/ocfs2/journal.c:	 * launched, so wait for any recovery completion work to
fs/ocfs2/journal.c:static void ocfs2_queue_recovery_completion(struct ocfs2_journal *journal,
fs/ocfs2/journal.c:	ocfs2_queue_recovery_completion(journal, osb->slot_num,
fs/ocfs2/journal.c:		ocfs2_queue_recovery_completion(osb->journal,
fs/ocfs2/journal.c:	ocfs2_queue_recovery_completion(osb->journal, osb->slot_num, NULL,
fs/ocfs2/journal.c:			ocfs2_queue_recovery_completion(osb->journal,
fs/ocfs2/journal.c:	ocfs2_queue_recovery_completion(osb->journal, slot_num, la_copy,
fs/ocfs2/journal.c: * ocfs2_queue_orphan_scan calls ocfs2_queue_recovery_completion for
fs/ocfs2/journal.c:		ocfs2_queue_recovery_completion(osb->journal, i, NULL, NULL,
fs/ocfs2/stack_user.c:	struct completion               oc_sync_wait;
fs/ocfs2/stack_user.c:	wait_for_completion(&lc->oc_sync_wait);
fs/ocfs2/stack_user.c:	wait_for_completion(&lc->oc_sync_wait);
fs/ocfs2/stack_user.c:	init_completion(&lc->oc_sync_wait);
fs/orangefs/orangefs-cache.c:		init_completion(&new_op->waitq);
fs/orangefs/orangefs-kernel.h:	struct completion waitq;
fs/orangefs/waitqueue.c:		wait_for_completion(&op->waitq);
fs/orangefs/waitqueue.c:	reinit_completion(&op->waitq);
fs/orangefs/waitqueue.c:		n = wait_for_completion_io_timeout(&op->waitq, timeout);
fs/orangefs/waitqueue.c:		n = wait_for_completion_interruptible_timeout(&op->waitq,
fs/orangefs/waitqueue.c:		n = wait_for_completion_killable_timeout(&op->waitq, timeout);
fs/overlayfs/copy_up.c:	 * temp wasn't moved before copy up completion or cleanup.
fs/overlayfs/file.c:	 * Overlayfs doesn't support deferred completions, don't copy
fs/proc/generic.c:#include <linux/completion.h>
fs/proc/inode.c:#include <linux/completion.h>
fs/proc/inode.c:		complete(pde->pde_unload_completion);
fs/proc/inode.c: * First to enter calls ->proc_release hook and signals its completion
fs/proc/inode.c:		DECLARE_COMPLETION_ONSTACK(c);
fs/proc/inode.c:		wait_for_completion(&c);
fs/proc/inode.c:		struct completion *c;
fs/proc/inode.c:	DECLARE_COMPLETION_ONSTACK(c);
fs/proc/inode.c:	de->pde_unload_completion = &c;
fs/proc/inode.c:		wait_for_completion(&c);
fs/proc/internal.h:	struct completion *pde_unload_completion;
fs/proc/internal.h:	struct completion *c;
fs/proc/proc_sysctl.c:		struct completion wait;
fs/proc/proc_sysctl.c:		init_completion(&wait);
fs/proc/proc_sysctl.c:		wait_for_completion(&wait);
fs/read_write.c: * Caller is responsible for calling kiocb_end_write() on completion
fs/reiserfs/super.c: * completion on
fs/reiserfs/super.c:				 "completion. If that fails\n"
fs/remap_range.c:	/* Wait for the completion of any pending IOs on both files */
fs/smb/client/cifs_ioctl.h:	__u32	completion_filter;
fs/smb/client/cifs_ioctl.h:	__u32	completion_filter;
fs/smb/client/cifsglob.h:	mid_callback_t *callback; /* call completion callback */
fs/smb/client/cifsglob.h:	__u32 filter; /* CompletionFilter (for multishot) */
fs/smb/client/cifspdu.h:					  /* synchronize with the completion  */
fs/smb/client/cifspdu.h:	__le32 CompletionFilter;  /* operation to monitor */
fs/smb/client/cifspdu.h:/* Completion Filter flags for Notify */
fs/smb/client/cifssmb.c: * workqueue completion task.
fs/smb/client/connect.c:#include <linux/completion.h>
fs/smb/client/file.c: * Completion of a request operation.
fs/smb/client/smb2maperror.c:	{STATUS_ALPC_CHECK_COMPLETION_LIST, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_ALPC_CHECK_COMPLETION_LIST"},
fs/smb/client/smb2maperror.c:	{STATUS_THREADPOOL_SET_EVENT_ON_COMPLETION_FAILED, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_THREADPOOL_SET_EVENT_ON_COMPLETION_FAILED"},
fs/smb/client/smb2maperror.c:	{STATUS_THREADPOOL_RELEASE_SEMAPHORE_ON_COMPLETION_FAILED, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_THREADPOOL_RELEASE_SEMAPHORE_ON_COMPLETION_FAILED"},
fs/smb/client/smb2maperror.c:	{STATUS_THREADPOOL_RELEASE_MUTEX_ON_COMPLETION_FAILED, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_THREADPOOL_RELEASE_MUTEX_ON_COMPLETION_FAILED"},
fs/smb/client/smb2maperror.c:	{STATUS_THREADPOOL_FREE_LIBRARY_ON_COMPLETION_FAILED, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_THREADPOOL_FREE_LIBRARY_ON_COMPLETION_FAILED"},
fs/smb/client/smb2maperror.c:	{STATUS_PORT_ALREADY_HAS_COMPLETION_LIST, -EIO,
fs/smb/client/smb2maperror.c:	"STATUS_PORT_ALREADY_HAS_COMPLETION_LIST"},
fs/smb/client/smb2ops.c:				notify.watch_tree, notify.completion_filter,
fs/smb/client/smb2pdu.c:		 u32 completion_filter, bool watch_tree)
fs/smb/client/smb2pdu.c:	req->CompletionFilter = cpu_to_le32(completion_filter);
fs/smb/client/smb2pdu.c:		u32 completion_filter, u32 max_out_data_len, char **out_data,
fs/smb/client/smb2pdu.c:			      completion_filter, watch_tree);
fs/smb/client/smb2pdu.c:				(u8)watch_tree, completion_filter);
fs/smb/client/smb2pdu.c:				(u8)watch_tree, completion_filter, rc);
fs/smb/client/smb2pdu.c:			ses->Suid, (u8)watch_tree, completion_filter);
fs/smb/client/smb2pdu.c: * workqueue completion task.
fs/smb/client/smb2proto.h:			u32 completion_filter, u32 max_out_data_len,
fs/smb/client/smbdirect.c:		complete(&info->negotiate_completion);
fs/smb/client/smbdirect.c:	init_completion(&info->ri_done);
fs/smb/client/smbdirect.c:	rc = wait_for_completion_interruptible_timeout(
fs/smb/client/smbdirect.c:	rc = wait_for_completion_interruptible_timeout(
fs/smb/client/smbdirect.c:	init_completion(&info->negotiate_completion);
fs/smb/client/smbdirect.c:	rc = wait_for_completion_interruptible_timeout(
fs/smb/client/smbdirect.c:		&info->negotiate_completion, SMBD_NEGOTIATE_TIMEOUT * HZ);
fs/smb/client/smbdirect.c:	log_rdma_event(INFO, "wait_for_completion_timeout rc=%d\n", rc);
fs/smb/client/smbdirect.c:		init_completion(&smbdirect_mr->invalidate_done);
fs/smb/client/smbdirect.c:		wait_for_completion(&smbdirect_mr->invalidate_done);
fs/smb/client/smbdirect.h:	struct completion ri_done;
fs/smb/client/smbdirect.h:	struct completion negotiate_completion;
fs/smb/client/smbdirect.h:	struct completion	invalidate_done;
fs/smb/common/smb2pdu.h:/* notify completion filter flags. See MS-FSCC 2.6 and MS-SMB2 2.2.35 */
fs/smb/common/smb2pdu.h:	__le32	CompletionFilter;
fs/smb/common/smb2status.h:#define STATUS_ALPC_CHECK_COMPLETION_LIST cpu_to_le32(0x40000030)
fs/smb/common/smb2status.h:#define STATUS_THREADPOOL_SET_EVENT_ON_COMPLETION_FAILED cpu_to_le32(0xC000070B)
fs/smb/common/smb2status.h:#define STATUS_THREADPOOL_RELEASE_SEMAPHORE_ON_COMPLETION_FAILED cpu_to_le32(0xC000070C)
fs/smb/common/smb2status.h:#define STATUS_THREADPOOL_RELEASE_MUTEX_ON_COMPLETION_FAILED cpu_to_le32(0xC000070D)
fs/smb/common/smb2status.h:#define STATUS_THREADPOOL_FREE_LIBRARY_ON_COMPLETION_FAILED cpu_to_le32(0xC000070E)
fs/smb/common/smb2status.h:#define STATUS_PORT_ALREADY_HAS_COMPLETION_LIST cpu_to_le32(0xC000071A)
fs/smb/server/smb_common.h:/* synchronize with the completion  */
fs/smb/server/transport_rdma.c:	struct completion	*completion;
fs/smb/server/transport_rdma.c:	complete(msg->completion);
fs/smb/server/transport_rdma.c:	DECLARE_COMPLETION_ONSTACK(completion);
fs/smb/server/transport_rdma.c:		msg->completion = &completion;
fs/smb/server/transport_rdma.c:	wait_for_completion(&completion);
fs/super.c: * Create workqueue for deferred direct IO completions. We allocate the
fs/sync.c:		laptop_sync_completion();
fs/sync.c: * completion of writeout of all pages in the range.  This will be used after an
fs/ubifs/sysfs.c:	init_completion(&c->kobj_unregister);
fs/ubifs/sysfs.c:	wait_for_completion(&c->kobj_unregister);
fs/ubifs/sysfs.c:	wait_for_completion(&c->kobj_unregister);
fs/ubifs/ubifs.h:#include <linux/completion.h>
fs/ubifs/ubifs.h: * @kobj_unregister: completion to unregister sysfs kobject
fs/ubifs/ubifs.h:	struct completion kobj_unregister;
fs/userfaultfd.c:static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,
fs/userfaultfd.c:	userfaultfd_event_wait_completion(ctx, &ewq);
fs/userfaultfd.c:	userfaultfd_event_wait_completion(ctx, &ewq);
fs/userfaultfd.c:	userfaultfd_event_wait_completion(ctx, &ewq);
fs/userfaultfd.c:		userfaultfd_event_wait_completion(ctx->ctx, &ewq);
fs/xfs/libxfs/xfs_attr.c: * Handle the state change on completion of a multi-state attr operation.
fs/xfs/libxfs/xfs_attr.c: * completion of the second half of the attr replace operation we correctly
fs/xfs/libxfs/xfs_attr.h: * -EAGAIN. Once that subroutine signals completion (by returning anything other
fs/xfs/libxfs/xfs_attr.h:	 * When called from the completion of a attr remove to determine the
fs/xfs/libxfs/xfs_btree.c:	struct completion	*done;
fs/xfs/libxfs/xfs_btree.c: * locked is unwritten extent conversion at IO completion, but that has already
fs/xfs/libxfs/xfs_btree.c:	DECLARE_COMPLETION_ONSTACK(done);
fs/xfs/libxfs/xfs_btree.c:	wait_for_completion(&done);
fs/xfs/libxfs/xfs_btree.c: * recovery completion writes the changes to disk.
fs/xfs/libxfs/xfs_refcount.c: * periodically relogged to avoid filling up the log.  Second, CoW completions
fs/xfs/xfs_aops.c: * IO write completion.
fs/xfs/xfs_aops.c: * Finish all pending IO completions that require transactional modifications.
fs/xfs/xfs_aops.c: * We try to merge physical and logically contiguous ioends before completion to
fs/xfs/xfs_aops.c: * minimise the number of transactions we need to perform during IO completion.
fs/xfs/xfs_aops.c:	/* send ioends that might require a transaction to the completion wq */
fs/xfs/xfs_bmap_util.c:		 * Take the flush completion as being a point-in-time snapshot
fs/xfs/xfs_bmap_util.c:/* Caller must first wait for the completion of any pending DIOs if required. */
fs/xfs/xfs_bmap_util.c:	 * completion could race with an insert, front merge with the start
fs/xfs/xfs_buf.c:	init_completion(&bp->b_iowait);
fs/xfs/xfs_buf.c: * completion. There are two scenarios that can lead to in-core buffers without
fs/xfs/xfs_buf.c: * normal I/O completion handling.
fs/xfs/xfs_buf.c:	 * Pull in IO completion errors now. We are guaranteed to be running
fs/xfs/xfs_buf.c: * by the caller and is dropped on I/O completion if the buffer is XBF_ASYNC.
fs/xfs/xfs_buf.c: * Wait for I/O completion of a sync buffer and return the I/O error code.
fs/xfs/xfs_buf.c:	wait_for_completion(&bp->b_iowait);
fs/xfs/xfs_buf.c:	 * async buffers, I/O completion drops the callers reference, which
fs/xfs/xfs_buf.c:	 * Set the count to 1 initially, this will stop an I/O completion
fs/xfs/xfs_buf.c:	 * reference we took above. If we drop it to zero, run completion so
fs/xfs/xfs_buf.c:	 * that we don't return to the caller with completion still pending.
fs/xfs/xfs_buf.c:	 * Next, flush the buffer workqueue to ensure all completion processing
fs/xfs/xfs_buf.c:	 * was thrown away. This should only ever happen after I/O completion
fs/xfs/xfs_buf.c: * at I/O completion time. In either case, buffers remain locked until I/O
fs/xfs/xfs_buf.c: * out and not wait for I/O completion on any of the buffers.  This interface
fs/xfs/xfs_buf.c: * is only safely useable for callers that can track I/O completion by higher
fs/xfs/xfs_buf.c: * completion on all of the buffers. @buffer_list is consumed by the function,
fs/xfs/xfs_buf.c:	 * after I/O completion, reuse the original list as the wait list.
fs/xfs/xfs_buf.c:	 * delwri queue. Wait for I/O completion, restore the DELWRI_Q flag and
fs/xfs/xfs_buf.h:#define XBF_ASYNC	 (1u << 4) /* initiator will not wait for completion */
fs/xfs/xfs_buf.h:	struct completion	b_iowait;	/* queue for I/O waiters */
fs/xfs/xfs_buf_item.c: * completion freeing the buffer while we are still trying to access it here.
fs/xfs/xfs_buf_item.c: * unpin buffers from contexts other that journal IO completion.
fs/xfs/xfs_buf_item.c:		 * that we only have one reference to drop once item completion
fs/xfs/xfs_buf_item.c:		 * the correct error completion is run on this buffer. This
fs/xfs/xfs_buf_item.c:		 * wait for the lock and then run the IO failure completion.
fs/xfs/xfs_buf_item.c:	 * that case, the bli is freed on buffer writeback completion.
fs/xfs/xfs_discard.c: * Queue up the actual completion to a thread to avoid IRQ-safe locking for
fs/xfs/xfs_discard.c: * list. We plug and chain the bios so that we only need a single completion
fs/xfs/xfs_discard.c: * list. We plug and chain the bios so that we only need a single completion
fs/xfs/xfs_dquot.c:	 * Because we want to use a counting completion, complete
fs/xfs/xfs_dquot.c:	 * the flush completion once to allow a single access to
fs/xfs/xfs_dquot.c:	 * the flush completion without blocking.
fs/xfs/xfs_dquot.c:	init_completion(&dqp->q_flush);
fs/xfs/xfs_dquot.c: * This is the dquot flushing I/O completion routine.  It is called
fs/xfs/xfs_dquot.c:	ASSERT(!completion_done(&dqp->q_flush));
fs/xfs/xfs_dquot.h:	struct completion	q_flush;
fs/xfs/xfs_dquot.h: * Manage the q_flush completion queue embedded in the dquot. This completion
fs/xfs/xfs_dquot.h:	wait_for_completion(&dqp->q_flush);
fs/xfs/xfs_dquot.h:	return try_wait_for_completion(&dqp->q_flush);
fs/xfs/xfs_error.c:	 * Code paths like I/O completion can be called before the
fs/xfs/xfs_exchrange.c:	/* Wait for the completion of any pending IOs on both files */
fs/xfs/xfs_extent_busy.h: * to discard completion.
fs/xfs/xfs_file.c:	 * We need to serialise against EOF updates that occur in IO completions
fs/xfs/xfs_file.c:	 * We can do an unlocked check here safely as IO completion can only
fs/xfs/xfs_file.c:			 * AIO can do EOF updates during IO completion and hence
fs/xfs/xfs_file.c:	 * Capture amount written on completion as we can't reliably account
fs/xfs/xfs_file.c:	 * other IO completions here to update the EOF. Failing to serialise
fs/xfs/xfs_file.c:	 * As IO completion only ever extends EOF, we can do an unlocked check
fs/xfs/xfs_file.c:	 * change the file size on completion without holding any locks we
fs/xfs/xfs_fsops.c: * submission and IO completion of the list as a whole. This allows the
fs/xfs/xfs_icache.c: * completion of the work.
fs/xfs/xfs_icache.c: * still may be under IO and hence we have wait for IO completion to occur
fs/xfs/xfs_inode.c:	 * completion, and can result in leaving dirty stale inodes hanging
fs/xfs/xfs_inode.c:	 * we needed to do here is mark the inode stale so buffer IO completion
fs/xfs/xfs_inode.h:	/* pending io completions */
fs/xfs/xfs_inode_item.c: * stale. In that case, flush completions are run from the buffer unpin call,
fs/xfs/xfs_inode_item.c:	 * reference for that completion because otherwise we don't get a
fs/xfs/xfs_inode_item.c: * Inode buffer IO completion routine.  It is responsible for removing inodes
fs/xfs/xfs_inode_item.c: * flushing or buffer IO completion encounters a log shutdown situation.
fs/xfs/xfs_inode_item.h:	 * inode completion, but these all hold different combinations of
fs/xfs/xfs_iomap.c:	 * Writes that span EOF might trigger an IO size update on completion,
fs/xfs/xfs_linux.h:	struct completion	complete;
fs/xfs/xfs_log.c: * completion.
fs/xfs/xfs_log.c: * the iclog hits stable storage before any completion waiters are woken.
fs/xfs/xfs_log.c: * Cycle all the iclogbuf locks to make sure all log IO completion
fs/xfs/xfs_log.c:xlog_wait_iclog_completion(struct xlog *log)
fs/xfs/xfs_log.c: * log force state machine. Waiting on ic_force_wait ensures iclog completions
fs/xfs/xfs_log.c:	xlog_wait_iclog_completion(mp->m_log);
fs/xfs/xfs_log.c:	 * completion during unmount.  We might be processing a shutdown
fs/xfs/xfs_log.c:		 * with the I/O completion path.
fs/xfs/xfs_log.c:	 * write on I/O completion and shutdown the fs. The subsequent mount
fs/xfs/xfs_log.c:	 * Destroy the CIL after waiting for iclog IO completion because an
fs/xfs/xfs_log.c:		 * for another completion to process.
fs/xfs/xfs_log.c: * Loop running iclog completion callbacks until there are no more iclogs in a
fs/xfs/xfs_log.c: * If completion has already occurred, tell the caller so that it can avoid an
fs/xfs/xfs_log.c:	 * will have been rewritten by completion
fs/xfs/xfs_log.c:		 * We just need to wait for completion if necessary.
fs/xfs/xfs_log_cil.c:	 * not wait on log force completion because they may be holding locks
fs/xfs/xfs_log_cil.c:	 * same iclog order their IO completion callbacks in the same order that
fs/xfs/xfs_log_cil.c:	 * that we process items during log IO completion in the correct order.
fs/xfs/xfs_log_cil.c:	 * completion.
fs/xfs/xfs_log_cil.c:	 * past or future iclog awaiting IO or ordered IO completion to be run.
fs/xfs/xfs_log_cil.c:			 * Waiting on ic_force_wait orders the completion of
fs/xfs/xfs_log_cil.c: * to checkpoint completion, and then unlock all the items in the transaction.
fs/xfs/xfs_log_cil.c:	 * we can run checkpoint completion before we've updated and unlocked
fs/xfs/xfs_log_priv.h:	struct workqueue_struct	*l_ioend_workqueue; /* for I/O completions */
fs/xfs/xfs_log_recover.c: * On error or completion, trans is freed.
fs/xfs/xfs_pwork.c: * Wait for the work to finish by polling completion status and touch the soft
fs/xfs/xfs_reflink.c: * succeeded.  IO completion in this case is the process of removing the old
fs/xfs/xfs_reflink.c:	 * If we're being called as part of directio write completion, the dio
fs/xfs/xfs_sysfs.h:	init_completion(&kobj->complete);
fs/xfs/xfs_sysfs.h:	wait_for_completion(&kobj->complete);
fs/xfs/xfs_trans.c: * finished, either by abort or commit completion.
fs/zonefs/file.c:		 * Note that we may be seeing completions out of order,
fs/zonefs/file.c:	 * For a failed IO or partial completion, trigger error recovery
fs/zonefs/super.c:	 *    completions. Other possibilities are (a) an external corruption,
fs/zonefs/sysfs.c:	init_completion(&sbi->s_kobj_unregister);
fs/zonefs/sysfs.c:		wait_for_completion(&sbi->s_kobj_unregister);
fs/zonefs/sysfs.c:	wait_for_completion(&sbi->s_kobj_unregister);
fs/zonefs/zonefs.h:	 * a sequential file size on completion of direct IO writes.
fs/zonefs/zonefs.h:	struct completion	s_kobj_unregister;
include/acpi/acpi_bus.h:#include <linux/completion.h>
include/acpi/acpi_bus.h:	struct completion kobj_done;
include/acpi/actbl1.h:	u8 completion_code;
include/acpi/actbl2.h:#define ACPI_PDTT_WAIT_COMPLETION           (1<<1)
include/acpi/pcc.h:#define PCC_CMD_COMPLETION_NOTIFY	BIT(0)
include/crypto/acompress.h:					      crypto_completion_t cmpl,
include/crypto/aead.h:					     crypto_completion_t compl,
include/crypto/akcipher.h:						 crypto_completion_t cmpl,
include/crypto/hash.h:					      crypto_completion_t compl,
include/crypto/if_alg.h:#include <linux/completion.h>
include/crypto/if_alg.h: * @completion:		Work queue for synchronous operation
include/crypto/kpp.h:					    crypto_completion_t cmpl,
include/crypto/skcipher.h: * cipher request returns immediately before the completion of the operation.
include/crypto/skcipher.h: * the kernel crypto API to inform the caller about the completion of a cipher
include/crypto/skcipher.h: * have, because when calling the callback function upon completion of the
include/crypto/skcipher.h:						 crypto_completion_t compl,
include/drm/bridge/samsung-dsim.h:	struct completion completed;
include/drm/bridge/samsung-dsim.h:	struct completion completed;
include/drm/display/drm_dp_helper.h: * @reply: upon completion, contains the reply type of the transaction
include/drm/drm_atomic.h: *	...					send completion irq
include/drm/drm_atomic.h:	 * completions without the risk of the completion disappearing
include/drm/drm_atomic.h:	 * Completion of this stage is signalled implicitly by calling
include/drm/drm_atomic.h:	struct completion flip_done;
include/drm/drm_atomic.h:	 * completion of this stage.
include/drm/drm_atomic.h:	struct completion hw_done;
include/drm/drm_atomic.h:	 * a vblank wait completed it might be a bit later. This completion is
include/drm/drm_atomic.h:	 * completion of this stage.
include/drm/drm_atomic.h:	struct completion cleanup_done;
include/drm/drm_atomic.h:	 * @abort_completion:
include/drm/drm_atomic.h:	 * second reference for the completion of $drm_crtc_state.event. It's
include/drm/drm_atomic.h:	bool abort_completion;
include/drm/drm_atomic.h:	 * file descriptor. Used by writeback connectors to signal completion of
include/drm/drm_audio_component.h:#include <linux/completion.h>
include/drm/drm_audio_component.h:	 * @master_bind_complete: completion held during component master binding
include/drm/drm_audio_component.h:	struct completion master_bind_complete;
include/drm/drm_connector.h:	 * the writeback completion may be asynchronous to the normal commit
include/drm/drm_connector.h:	 * drm_writeback_signal_completion()
include/drm/drm_crtc.h:	 * Optional pointer to a DRM event to signal upon completion of the
include/drm/drm_crtc.h:	 * which the driver should call on the provided event upon completion of
include/drm/drm_crtc.h:	 * If the device can't notify of flip completion in a race-free way
include/drm/drm_crtc.h:	 * the provided event upon completion of the flip. Note that if
include/drm/drm_file.h:#include <linux/completion.h>
include/drm/drm_file.h: * This represents a DRM event. Drivers can use this as a generic completion
include/drm/drm_file.h: * mechanism, which supports kernel-internal &struct completion, &struct dma_fence
include/drm/drm_file.h:	 * @completion:
include/drm/drm_file.h:	 * Optional pointer to a kernel internal completion signalled when
include/drm/drm_file.h:	struct completion *completion;
include/drm/drm_file.h:	 * @completion_release:
include/drm/drm_file.h:	 * to clean up the reference count for the structure @completion is
include/drm/drm_file.h:	void (*completion_release)(struct completion *completion);
include/drm/drm_file.h:	 * also used to signal kernel internal threads with @completion or DMA
include/drm/drm_writeback.h:	 * drm_writeback_signal_completion()
include/drm/drm_writeback.h:	 * Used to allow drm_writeback_signal_completion to defer dropping the
include/drm/drm_writeback.h:drm_writeback_signal_completion(struct drm_writeback_connector *wb_connector,
include/drm/gpu_scheduler.h:#include <linux/completion.h>
include/drm/gpu_scheduler.h:	struct completion		entity_idle;
include/kunit/platform_device.h:						 struct completion *x);
include/linux/amba/pl022.h: * @autosuspend_delay: delay in ms following transfer completion before the
include/linux/async_tx.h: * struct async_submit_ctl - async_tx submission/completion modifiers
include/linux/async_tx.h: * @cb_fn: callback routine to run at operation completion
include/linux/avf/virtchnl.h: * until reset completion is indicated. The admin queue must be reinitialized
include/linux/backing-dev-defs.h:struct wb_completion {
include/linux/backing-dev-defs.h:#define __WB_COMPLETION_INIT(_waitq)	\
include/linux/backing-dev-defs.h:	(struct wb_completion){ .cnt = ATOMIC_INIT(1), .waitq = (_waitq) }
include/linux/backing-dev-defs.h: * ->done should be set to a wb_completion defined using the following
include/linux/backing-dev-defs.h: * can wait for the completion of all using wb_wait_for_completion().  Work
include/linux/backing-dev-defs.h: * items which are waited upon aren't freed automatically on completion.
include/linux/backing-dev-defs.h:#define WB_COMPLETION_INIT(bdi)		__WB_COMPLETION_INIT(&(bdi)->wb_waitq)
include/linux/backing-dev-defs.h:#define DEFINE_WB_COMPLETION(cmpl, bdi)	\
include/linux/backing-dev-defs.h:	struct wb_completion cmpl = WB_COMPLETION_INIT(bdi)
include/linux/backing-dev-defs.h:	struct fprop_local_percpu completions;
include/linux/backing-dev-defs.h:	struct fprop_local_percpu memcg_completions;
include/linux/backing-dev.h:void wb_wait_for_completion(struct wb_completion *done);
include/linux/bio-integrity.h:	struct work_struct	bip_work;	/* I/O completion */
include/linux/bio.h: * We cannot block waiting for requests on polled IO, as those completions
include/linux/blk-mq.h:	/* track IO completion time */
include/linux/blk-mq.h:	/* request completion needs to be signaled to zone write plugging. */
include/linux/blk-mq.h:	 * by completion.
include/linux/blk-mq.h:	 * to queue the request for softirq completion, which is long
include/linux/blk-mq.h:	 * completion callback.
include/linux/blk-mq.h:	 * @poll: Called to poll for completion of a specific tag.
include/linux/blk-mq.h: * Batched completions only work when there is no I/O error and no special
include/linux/blk-mq.h: * Request completion related functions.
include/linux/blk_types.h: * resource upon completion.
include/linux/blk_types.h: * rely on request completions freeing these resources, as IO may not be in
include/linux/blk_types.h: * BLK_STS_ZONE_OPEN_RESOURCE is returned from the driver in the completion
include/linux/blk_types.h: * BLK_STS_ZONE_ACTIVE_RESOURCE is returned from the driver in the completion
include/linux/blk_types.h:	BIO_TRACE_COMPLETION,	/* bio_endio() should trace the final completion
include/linux/blk_types.h:	__REQ_POLLED,		/* caller polls for completion using bio_poll */
include/linux/blkdev.h:	QUEUE_FLAG_STATS,		/* track IO start and completion times */
include/linux/blkdev.h:/* only poll the hardware once, don't continue until a completion was found */
include/linux/blkdev.h: * completion handler when the device returned an indicator that the respective
include/linux/blkdev.h:	 * If we're polling, the task itself is doing the completions. For
include/linux/bsg-lib.h:	 * Upon completion : the message handler must set reply_len
include/linux/buffer_head.h:	BH_Defer_Completion, /* Defer AIO completion to workqueue */
include/linux/buffer_head.h:	bh_end_io_t *b_end_io;		/* I/O completion */
include/linux/buffer_head.h:					 * serialise IO completion of other
include/linux/buffer_head.h:BUFFER_FNS(Defer_Completion, defer_completion)
include/linux/ccp.h: * called to notify the caller of completion (if the cmd was not
include/linux/ccp.h: * The iv variable is used as both input and output. On completion of the
include/linux/ccp.h: * The iv variable is used as both input and output. On completion of the
include/linux/ccp.h: * The ctx variable is used as both input and output. On completion of the
include/linux/ccp.h: * The iv variable is used as both input and output. On completion of the
include/linux/ccp.h: * @callback: operation completion callback function
include/linux/ccp.h:	/* Completion callback support */
include/linux/ceph/libceph.h:#include <linux/completion.h>
include/linux/ceph/mon_client.h:#include <linux/completion.h>
include/linux/ceph/mon_client.h:	struct completion completion;
include/linux/ceph/osd_client.h:#include <linux/completion.h>
include/linux/ceph/osd_client.h: * completion callback for async writepages
include/linux/ceph/osd_client.h:	struct completion r_completion;       /* private to osd_client.c */
include/linux/ceph/osd_client.h:	struct completion reg_commit_wait;
include/linux/ceph/osd_client.h:	struct completion notify_finish_wait;
include/linux/ceph/osd_client.h:	struct workqueue_struct	*completion_wq;
include/linux/completion.h:#ifndef __LINUX_COMPLETION_H
include/linux/completion.h:#define __LINUX_COMPLETION_H
include/linux/completion.h: * Atomic wait-for-completion handler data structures.
include/linux/completion.h: * See kernel/sched/completion.c for details.
include/linux/completion.h: * struct completion - structure used to maintain state for a "completion"
include/linux/completion.h: * This is the opaque structure used to maintain the state for a "completion".
include/linux/completion.h: * Completions currently use a FIFO to queue threads that have to wait for
include/linux/completion.h: * the "completion" event.
include/linux/completion.h: * See also:  complete(), wait_for_completion() (and friends _timeout,
include/linux/completion.h: * _interruptible, _interruptible_timeout, and _killable), init_completion(),
include/linux/completion.h: * reinit_completion(), and macros DECLARE_COMPLETION(),
include/linux/completion.h: * DECLARE_COMPLETION_ONSTACK().
include/linux/completion.h:struct completion {
include/linux/completion.h:#define init_completion_map(x, m) init_completion(x)
include/linux/completion.h:static inline void complete_acquire(struct completion *x) {}
include/linux/completion.h:static inline void complete_release(struct completion *x) {}
include/linux/completion.h:#define COMPLETION_INITIALIZER(work) \
include/linux/completion.h:#define COMPLETION_INITIALIZER_ONSTACK_MAP(work, map) \
include/linux/completion.h:	(*({ init_completion_map(&(work), &(map)); &(work); }))
include/linux/completion.h:#define COMPLETION_INITIALIZER_ONSTACK(work) \
include/linux/completion.h:	(*({ init_completion(&work); &work; }))
include/linux/completion.h: * DECLARE_COMPLETION - declare and initialize a completion structure
include/linux/completion.h: * @work:  identifier for the completion structure
include/linux/completion.h: * This macro declares and initializes a completion structure. Generally used
include/linux/completion.h:#define DECLARE_COMPLETION(work) \
include/linux/completion.h:	struct completion work = COMPLETION_INITIALIZER(work)
include/linux/completion.h: * completions - so we use the _ONSTACK() variant for those that
include/linux/completion.h: * DECLARE_COMPLETION_ONSTACK - declare and initialize a completion structure
include/linux/completion.h: * @work:  identifier for the completion structure
include/linux/completion.h: * This macro declares and initializes a completion structure on the kernel
include/linux/completion.h:# define DECLARE_COMPLETION_ONSTACK(work) \
include/linux/completion.h:	struct completion work = COMPLETION_INITIALIZER_ONSTACK(work)
include/linux/completion.h:# define DECLARE_COMPLETION_ONSTACK_MAP(work, map) \
include/linux/completion.h:	struct completion work = COMPLETION_INITIALIZER_ONSTACK_MAP(work, map)
include/linux/completion.h:# define DECLARE_COMPLETION_ONSTACK(work) DECLARE_COMPLETION(work)
include/linux/completion.h:# define DECLARE_COMPLETION_ONSTACK_MAP(work, map) DECLARE_COMPLETION(work)
include/linux/completion.h: * init_completion - Initialize a dynamically allocated completion
include/linux/completion.h: * @x:  pointer to completion structure that is to be initialized
include/linux/completion.h: * This inline function will initialize a dynamically created completion
include/linux/completion.h:static inline void init_completion(struct completion *x)
include/linux/completion.h: * reinit_completion - reinitialize a completion structure
include/linux/completion.h: * @x:  pointer to completion structure that is to be reinitialized
include/linux/completion.h: * This inline function should be used to reinitialize a completion structure so it can
include/linux/completion.h:static inline void reinit_completion(struct completion *x)
include/linux/completion.h:extern void wait_for_completion(struct completion *);
include/linux/completion.h:extern void wait_for_completion_io(struct completion *);
include/linux/completion.h:extern int wait_for_completion_interruptible(struct completion *x);
include/linux/completion.h:extern int wait_for_completion_killable(struct completion *x);
include/linux/completion.h:extern int wait_for_completion_state(struct completion *x, unsigned int state);
include/linux/completion.h:extern unsigned long wait_for_completion_timeout(struct completion *x,
include/linux/completion.h:extern unsigned long wait_for_completion_io_timeout(struct completion *x,
include/linux/completion.h:extern long wait_for_completion_interruptible_timeout(
include/linux/completion.h:	struct completion *x, unsigned long timeout);
include/linux/completion.h:extern long wait_for_completion_killable_timeout(
include/linux/completion.h:	struct completion *x, unsigned long timeout);
include/linux/completion.h:extern bool try_wait_for_completion(struct completion *x);
include/linux/completion.h:extern bool completion_done(struct completion *x);
include/linux/completion.h:extern void complete(struct completion *);
include/linux/completion.h:extern void complete_on_current_cpu(struct completion *x);
include/linux/completion.h:extern void complete_all(struct completion *);
include/linux/cpufreq.h:#include <linux/completion.h>
include/linux/cpufreq.h:	struct completion	kobj_unregister;
include/linux/crypto.h:#include <linux/completion.h>
include/linux/crypto.h:typedef void (*crypto_completion_t)(void *req, int err);
include/linux/crypto.h:	crypto_completion_t complete;
include/linux/crypto.h: * A helper struct for waiting for completion of async crypto ops
include/linux/crypto.h:	struct completion completion;
include/linux/crypto.h:		COMPLETION_INITIALIZER_ONSTACK((_wait).completion), 0 }
include/linux/crypto.h: * Async ops completion helper functioons
include/linux/crypto.h:		wait_for_completion(&wait->completion);
include/linux/crypto.h:		reinit_completion(&wait->completion);
include/linux/crypto.h:	init_completion(&wait->completion);
include/linux/damon.h:	struct completion kdamond_started;
include/linux/delayacct.h:	u64 blkio_delay;	/* wait for sync block io completion */
include/linux/dim.h: * @comps: Completion counter
include/linux/dim.h: * @comp_ctr: Current completion counter
include/linux/dim.h: * @cpms: Completions per msec
include/linux/dim.h: * @cpe_ratio: Ratio of completions to events
include/linux/dim.h:	int cpms; /* completions per msec */
include/linux/dim.h:	int cpe_ratio; /* ratio of completions to events */
include/linux/dim.h: *	values including the completion parameter
include/linux/dim.h: *	@comps: number of completions to set
include/linux/dim.h: * @completions: The number of completions collected in this round.
include/linux/dim.h: * Each call to rdma_dim takes the latest amount of completions that
include/linux/dim.h:void rdma_dim(struct dim *dim, u64 completions);
include/linux/dlm.h: * astarg: the arg used with the completion ast for the unlock
include/linux/dm-bufio.h: * Initiate writing of dirty buffers, without waiting for completion.
include/linux/dm-kcopyd.h: * or with an asynchronous completion notification.
include/linux/dma-fence.h: * dma_fence_get_status_locked - returns the status upon completion
include/linux/dma-fence.h: * dma_fence_timestamp - helper to get the completion timestamp of a fence
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_EVENT_SIZE_COMPLETION:	When TR is complete and all status for
include/linux/dma/ti-cppi5.h:	CPPI5_TR_EVENT_SIZE_COMPLETION,
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_NONE:		No error, completion: completed
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_TRANSFER_ERR:	Transfer Error, completion: none
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_ABORTED_ERR:	Aborted Error, completion: none
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_SUBMISSION_ERR:	Submission Error, completion:
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_UNSUPPORTED_ERR:	Unsupported Error, completion:
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS_TRANSFER_EXCEPTION: Transfer Exception, completion:
include/linux/dma/ti-cppi5.h: * @CPPI5_TR_RESPONSE_STATUS__TEARDOWN_FLUSH:	Teardown Flush, completion: none
include/linux/dma/ti-cppi5.h: * @wait: Wait for TR completion before allow the next TR to start
include/linux/dmaengine.h:	DMA_COMPLETION_NO_ORDER,
include/linux/dmaengine.h: *  control completion, and communicate status.
include/linux/dmaengine.h: * @DMA_PREP_INTERRUPT - trigger an interrupt (callback) upon completion of
include/linux/dmaengine.h: *  transfer has been completed (valid up to the point when the completion
include/linux/dmaengine.h: *   3. on transfer completion, use dmaengine_desc_get_metadata_ptr() to get the
include/linux/dmaengine.h: * @flags: flags to augment operation preparation, control completion, and
include/linux/dmaengine.h: * @next: at completion submit this descriptor
include/linux/dmaengine.h: * @descriptor_reuse: a submitted transfer can be resubmitted after completion
include/linux/dmaengine.h: * @device_tx_status: poll for transaction completion, the optional
include/linux/dmaengine.h: * freeing any resources accessed from within the completion callback of any
include/linux/dmaengine.h: * dma_async_is_tx_complete - poll for transaction completion
include/linux/dynamic_queue_limits.h: *   2) Periodically a completion process executes which retires consumed
include/linux/dynamic_queue_limits.h: *      actually been consumed, but completion processing has not yet run
include/linux/dynamic_queue_limits.h: *    dql_completed - called at completion time to indicate how many objects
include/linux/dynamic_queue_limits.h:	/* Fields accessed only by completion path (dql_completed) */
include/linux/edac.h:#include <linux/completion.h>
include/linux/edac.h:	struct completion complete;
include/linux/efi.h: * @efi_rts_comp:	Struct used for handling completions
include/linux/efi.h:	struct completion	efi_rts_comp;
include/linux/errno.h:#define EIOCBQUEUED	529	/* iocb queued, will get completion event */
include/linux/ethtool.h: * @cqe_size: Size of TX/RX completion queue event
include/linux/firewire.h:#include <linux/completion.h>
include/linux/firewire.h:	struct completion done;
include/linux/firewire.h: * @callback_data:	data to be passed to the transaction completion callback
include/linux/firewire.h: * @callback_data:	data to be passed to the transaction completion callback
include/linux/firewire.h:int fw_iso_context_flush_completions(struct fw_iso_context *ctx);
include/linux/firewire.h: * fw_iso_context_schedule_flush_completions() - schedule work item to process isochronous context.
include/linux/firewire.h: * is required to process the context in the current context, fw_iso_context_flush_completions() is
include/linux/firewire.h:static inline void fw_iso_context_schedule_flush_completions(struct fw_iso_context *ctx)
include/linux/firmware.h: * @poll_complete:	  Required: Check for the completion of the
include/linux/firmware.h: *			  function and is called at the completion
include/linux/fs.h: * iocb completion can be passed back to the owner for execution from a safe
include/linux/fs.h: * flag is set, the bio completion handling may set iocb->dio_complete to a
include/linux/fs.h: * used on the completion side for non-IO generating completions. It's fine to
include/linux/fs.h:		 * Can be used for O_DIRECT IO, where the completion handling
include/linux/fs.h:	/* AIO completions deferred from interrupt context */
include/linux/fs.h: * Two bits are used for locking and completion notification, I_NEW and I_SYNC.
include/linux/fs.h: * I_NEW		Serves as both a mutex and completion notification.
include/linux/fscache.h: * @term_func: The function to call upon completion
include/linux/fscache.h: * @term_func: The function to call upon completion
include/linux/fscache.h: * @term_func: The function to call upon completion
include/linux/fscache.h: * If given, @term_func will be called upon completion and supplied with
include/linux/fsl/mc.h:/* Command completion flag */
include/linux/fsl_ifc.h: * NAND Flash Page Read Completion Event Status Register
include/linux/greybus/interface.h:	struct completion mode_switch_completion;
include/linux/greybus/operation.h:#include <linux/completion.h>
include/linux/greybus/operation.h:	struct completion	completion;
include/linux/hid-sensor-hub.h: * @ready:		Completion synchronization data.
include/linux/hid-sensor-hub.h:	struct completion ready;
include/linux/host1x.h:	/* Completion fence for job tracking */
include/linux/hsi/hsi.h: * @complete: Transfer completion callback
include/linux/hsi/hsi.h: * @actual_len: Actual length of data transferred on completion
include/linux/hw_random.h:#include <linux/completion.h>
include/linux/hw_random.h:	struct completion cleanup_done;
include/linux/hw_random.h:	struct completion dying;
include/linux/hyperv.h:#include <linux/completion.h>
include/linux/hyperv.h:#define VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED	1
include/linux/hyperv.h:	struct completion  waitevent;
include/linux/hyperv.h:	struct completion rescind_event;
include/linux/i2c-algo-pca.h:	int  (*wait_for_completion)	(void *data);
include/linux/i2c.h:#include <linux/sched.h>	/* for completion */
include/linux/i2c.h:	struct completion dev_released;
include/linux/i3c/master.h:	struct completion all_ibis_handled;
include/linux/ieee80211.h: * @tsf_completion: TSF Completion
include/linux/ieee80211.h:	__le32 tsf_completion;
include/linux/iio/adc/ad_sigma_delta.h:	struct completion	completion;
include/linux/io_uring/cmd.h:	/* callback to defer completions to task context */
include/linux/io_uring/cmd.h: * Polled completions must ensure they are coming from a poll queue, and
include/linux/io_uring_types.h:	 * Number of completion events lost because the queue was full;
include/linux/io_uring_types.h:	 * the completion queue.
include/linux/io_uring_types.h:	 * As completion events come in out of order this counter is not
include/linux/io_uring_types.h:	 * Ring buffer of completion events.
include/linux/io_uring_types.h:	 * The kernel writes completion events fresh every time they are
include/linux/io_uring_types.h:	/* inline/task_work completion list, under ->uring_lock */
include/linux/io_uring_types.h:	/* batch completion logic */
include/linux/io_uring_types.h:	spinlock_t		completion_lock;
include/linux/io_uring_types.h:	struct completion		ref_comp;
include/linux/io_uring_types.h:	/* protected by ->completion_lock */
include/linux/io_uring_types.h:	/* doesn't sever on completion < 0 */
include/linux/io_uring_types.h:	/* fd initially, then cflags for completion */
include/linux/io_uring_types.h:		/* used by request caches, completion batching and iopoll */
include/linux/iomap.h: * completion, such as file size updates from direct IO.
include/linux/iomap.h: * Structure for writeback I/O completions.
include/linux/iov_iter.h: * processed and the value of @len means processes to completion).
include/linux/iov_iter.h: * processed and the value of @len means processes to completion).
include/linux/ipmi.h:	 * been set up to handle run to completion.
include/linux/ipmi_smi.h: * And responses, similarly, with an completion code added (NetFn must
include/linux/ipmi_smi.h: * response with an error code in the completion code location. When
include/linux/ipmi_smi.h:	 * completion" mode.  If this call sets the value to true, the
include/linux/ipmi_smi.h:	 * to completion immediately.
include/linux/ipmi_smi.h:	void (*set_run_to_completion)(void *send_info, bool run_to_completion);
include/linux/jbd2.h:	 * Wait queue to wait for completion of async fast commits.
include/linux/kernel.h:struct completion;
include/linux/kernel.h: * sleeping memory allocation, the oom reaper is now blocked on completion of
include/linux/kernfs.h: * completion time of these sysfs operations on each CPU.
include/linux/key.h: * completion of keys undergoing construction with a non-interruptible wait.
include/linux/kthread.h:void kthread_complete_and_exit(struct completion *, long) __noreturn;
include/linux/kvm_host.h:void kvm_clear_async_pf_completion_queue(struct kvm_vcpu *vcpu);
include/linux/kvm_host.h:void kvm_check_async_pf_completion(struct kvm_vcpu *vcpu);
include/linux/kvm_host.h:	/* Used to wait for completion of MMU notifiers.  */
include/linux/libata.h:	ATA_QCFLAG_CLEAR_EXCL	= (1 << 5), /* clear excl_link on completion */
include/linux/libata.h:enum ata_completion_errors {
include/linux/libata.h:	 * to 0xD (successful completion with sense data available bit set).
include/linux/libata.h:	struct completion	park_req_pending;
include/linux/libata.h:	enum ata_completion_errors (*qc_prep)(struct ata_queued_cmd *qc);
include/linux/libata.h:	/* init result_tf such that it indicates normal completion */
include/linux/libata.h:extern enum ata_completion_errors ata_bmdma_qc_prep(struct ata_queued_cmd *qc);
include/linux/libata.h:extern enum ata_completion_errors ata_bmdma_dumb_qc_prep(struct ata_queued_cmd *qc);
include/linux/libps2.h: * @wait: a waitqueue used to signal completion from the serio interrupt handler
include/linux/livepatch.h:#include <linux/completion.h>
include/linux/livepatch.h:	struct completion finish;
include/linux/mISDNif.h:#include <linux/completion.h>
include/linux/mISDNif.h:	struct completion	*notify;
include/linux/mailbox_controller.h:#include <linux/completion.h>
include/linux/mailbox_controller.h: * @tx_complete:	Transmission completion
include/linux/mailbox_controller.h:	struct completion tx_complete;
include/linux/memcontrol.h:	struct wb_completion done;	/* tracks in-flight foreign writebacks */
include/linux/memremap.h: * @done: completion for @ref
include/linux/memremap.h:	struct completion done;
include/linux/memstick.h:	struct completion        mrq_complete;
include/linux/mfd/altera-a10sr.h:#include <linux/completion.h>
include/linux/mfd/cs42l43.h:#include <linux/completion.h>
include/linux/mfd/cs42l43.h:	struct completion device_attach;
include/linux/mfd/cs42l43.h:	struct completion device_detach;
include/linux/mfd/cs42l43.h:	struct completion firmware_download;
include/linux/mfd/da9052/da9052.h:#include <linux/completion.h>
include/linux/mfd/da9052/da9052.h:	struct completion done;
include/linux/mfd/ipaq-micro.h:#include <linux/completion.h>
include/linux/mfd/ipaq-micro.h: * @ack: a completion that will be completed when RX is complete
include/linux/mfd/ipaq-micro.h:	struct completion ack;
include/linux/mfd/ipaq-micro.h:	init_completion(&msg->ack);
include/linux/mfd/ipaq-micro.h:	wait_for_completion(&msg->ack);
include/linux/mfd/ipaq-micro.h:	init_completion(&msg->ack);
include/linux/mfd/iqs62x.h:	struct completion ati_done;
include/linux/mfd/iqs62x.h:	struct completion fw_done;
include/linux/mfd/si476x-core.h: * completion.
include/linux/mfd/stm32-timers.h: * @completion:		end of DMA transfer completion
include/linux/mfd/stm32-timers.h:	struct completion completion;
include/linux/mfd/twl6040.h:	struct completion ready;
include/linux/mfd/wm831x/core.h:#include <linux/completion.h>
include/linux/mfd/wm8350/core.h:#include <linux/completion.h>
include/linux/mfd/wm8350/core.h:	struct completion auxadc_done;
include/linux/mhi_ep.h: * @code: Transfer completion code
include/linux/mhi_ep.h: * @cb: Callback to be executed by controller drivers after transfer completion (async)
include/linux/mlx4/cmd.h:void mlx4_cmd_wake_completions(struct mlx4_dev *dev);
include/linux/mlx4/device.h:#include <linux/completion.h>
include/linux/mlx4/device.h:	struct completion	free;
include/linux/mlx4/device.h:	struct completion	free;
include/linux/mlx4/device.h:	struct completion	free;
include/linux/mlx4/qp.h:/* Which firmware version adds support for NEC (NoErrorCompletion) bit */
include/linux/mlx4/qp.h:	 * [3:2] C (generate completion queue entry)
include/linux/mlx5/cq.h:	struct completion	free;
include/linux/mlx5/driver.h:#include <linux/completion.h>
include/linux/mlx5/driver.h:	struct completion	free;
include/linux/mlx5/driver.h:	struct completion	handling;
include/linux/mlx5/driver.h:	struct completion	slotted;
include/linux/mlx5/driver.h:	struct completion	done;
include/linux/mlx5/driver.h:	struct completion inflight_done;
include/linux/mlx5/mlx5_ifc.h:	MLX5_EVENT_TYPE_CODING_COMPLETION_EVENTS                   = 0x0,
include/linux/mlx5/mlx5_ifc.h:	MLX5_EVENT_TYPE_CODING_COMMAND_INTERFACE_COMPLETION        = 0xa,
include/linux/mlx5/mlx5_ifc.h:	u8         command_completion_vector[0x20];
include/linux/mlx5/qp.h:	struct completion	drained;
include/linux/mm_inline.h:	 * not order against TLB invalidate completion, which is what we need.
include/linux/mm_types.h:#include <linux/completion.h>
include/linux/mmc/core.h:#include <linux/completion.h>
include/linux/mmc/core.h:	struct completion	completion;
include/linux/mmc/core.h:	struct completion	cmd_completion;
include/linux/mmc/core.h:	void			(*done)(struct mmc_request *);/* completion function */
include/linux/module.h:	struct completion *kobj_completion;
include/linux/most.h: * @context: context for core completion handler
include/linux/most.h: * @complete: (in) completion routine
include/linux/most.h: * the transfer procedure by calling the completion routine.
include/linux/most.h: *   be returned back to the MostCore using completion routine.
include/linux/most.h: *   all enqueued for this channel MBOs using the completion routine.
include/linux/most.h: * @rx_completion: completion handler for received packets
include/linux/most.h: * @tx_completion: completion handler for transmitted packets
include/linux/most.h:	int (*rx_completion)(struct mbo *mbo);
include/linux/most.h:	int (*tx_completion)(struct most_interface *iface, int channel_idx);
include/linux/mtd/onenand.h:#include <linux/completion.h>
include/linux/mtd/onenand.h:	struct completion	complete;
include/linux/mtd/sh_flctl.h:#include <linux/completion.h>
include/linux/mtd/sh_flctl.h:	struct completion	dma_complete;
include/linux/netdevice.h: *	@rx_cpu_rmap:	CPU reverse-mapping for RX completion interrupts,
include/linux/netdevice.h:	struct sk_buff		*completion_queue;
include/linux/netdevice.h: * BQL enabled drivers might use this helper in their TX completion path,
include/linux/netdevice.h: *	Report the number of bytes queued for sending/completion to the network
include/linux/netdevice.h: *	Report the number of bytes queued for sending/completion to the network
include/linux/netdevice.h: *	netdev_tx_completed_queue - report number of packets/bytes at TX completion.
include/linux/netdevice.h: *	Must be called at most once per TX completion round (and not per
include/linux/netdevice.h: *  Typically used in place of consume_skb(skb) in TX completion path
include/linux/netdevice.h: * the interface. After completion, of the test, the interface state
include/linux/netfs.h:	struct kiocb		*iocb;		/* AIO completion vector */
include/linux/netfs.h:#define NETFS_RREQ_NO_UNLOCK_FOLIO	2	/* Don't unlock no_unlock_folio on completion */
include/linux/netfs.h:#define NETFS_RREQ_DONT_UNLOCK_FOLIOS	3	/* Don't unlock the folios on completion */
include/linux/nfs_fs.h:	struct completion	completion;
include/linux/nfs_page.h:	const struct nfs_pgio_completion_ops *pg_completion_ops;
include/linux/nfs_page.h:	struct nfs_io_completion *pg_io_completion;
include/linux/nfs_page.h:			     const struct nfs_pgio_completion_ops *compl_ops,
include/linux/nfs_xdr.h:struct nfs_io_completion;
include/linux/nfs_xdr.h:	const struct nfs_pgio_completion_ops *completion_ops;
include/linux/nfs_xdr.h:	struct nfs_io_completion *io_completion;
include/linux/nfs_xdr.h:struct nfs_commit_completion_ops {
include/linux/nfs_xdr.h:	void (*completion) (struct nfs_commit_data *data);
include/linux/nfs_xdr.h:	const struct nfs_commit_completion_ops *completion_ops;
include/linux/nfs_xdr.h:	const struct nfs_commit_completion_ops *completion_ops;
include/linux/nfs_xdr.h:struct nfs_pgio_completion_ops {
include/linux/nfs_xdr.h:	void	(*completion)(struct nfs_pgio_header *hdr);
include/linux/ntb.h:#include <linux/completion.h>
include/linux/ntb.h:	struct completion		released;
include/linux/ntb.h: * The drivers may wish to ring the peer doorbell at the completion of memory
include/linux/nvme-fc-driver.h: * @done:     The callback routine the LLDD is to invoke upon completion of
include/linux/nvme-fc-driver.h: * Upon completion of the LS response transmit, the LLDD will pass the
include/linux/nvme-fc-driver.h: * allowing the transport release dma resources. Upon completion of
include/linux/nvme-fc-driver.h: *     to be called upon completion of the transmit.  The transport layer
include/linux/nvme-fc-driver.h: * @done:     The callback routine the LLDD is to invoke upon completion of
include/linux/nvme-fc-driver.h: * @done:      The callback routine the LLDD is to invoke upon completion of
include/linux/nvme-fc-driver.h: * Values set by the LLDD indicating completion status of the FCP operation.
include/linux/nvme-fc-driver.h: * @status:    Completion status of the FCP operation. must be 0 upon success,
include/linux/nvme-fc-driver.h: *             NOT a reflection of the NVME CQE completion status. Only the
include/linux/nvme-fc-driver.h: *       asynchronous. This routine is called upon the completion of the
include/linux/nvme-fc-driver.h: *       asynchronous. This routine is called upon the completion of the
include/linux/nvme-fc-driver.h: * @poll_queue:  Called to poll for the completion of an io on a blk queue.
include/linux/nvme-fc-driver.h: *       non-zero errno status), and upon completion of the transmit, call
include/linux/nvme-fc-driver.h: *       itself). Upon the completion of the done routine, the LLDD shall
include/linux/nvme-fc-driver.h: * FCP I/O, and any FC exchange context.  Upon completion of the FCP target
include/linux/nvme-fc-driver.h: * Upon completion of the done() routine for either RSP or ABORT ops, no
include/linux/nvme-fc-driver.h: * @done:     The callback routine the LLDD is to invoke upon completion of
include/linux/nvme-fc-driver.h: * Values set by the LLDD indicating completion status of the FCP operation.
include/linux/nvme-fc-driver.h: *       asynchronous. This routine is called upon the completion of the
include/linux/nvme-fc-driver.h: *       non-zero errno status), and upon completion of the transmit, call
include/linux/nvme-fc-driver.h: *       itself). Upon the completion of the done() routine, the LLDD shall
include/linux/nvme-fc-driver.h: *       This may be due to the command completing or upon completion of
include/linux/nvme-fc.h:	struct nvme_completion	cqe;
include/linux/nvme-tcp.h: * @cqe:           nvme completion queue entry
include/linux/nvme-tcp.h:	struct nvme_completion	cqe;
include/linux/nvme.h: * Submission and Completion Queue Entry Sizes for the NVM command set.
include/linux/nvme.h:struct nvme_completion {
include/linux/pds/pds_adminq.h:	PDS_AQ_FLAG_FASTPOLL	= BIT(1),	/* completion poll at 1ms */
include/linux/pds/pds_adminq.h: * struct pds_core_client_reg_comp - Client registration completion
include/linux/pds/pds_adminq.h: * @comp_index: Index in the descriptor ring for which this is the completion
include/linux/pds/pds_adminq.h: * This uses the generic completion.
include/linux/pds/pds_adminq.h: * This uses the generic completion.
include/linux/pds/pds_adminq.h: * struct pds_core_lif_identify_comp - LIF identify command completion
include/linux/pds/pds_adminq.h: * struct pds_core_lif_init_comp - LIF init command completion
include/linux/pds/pds_adminq.h: * struct pds_core_lif_setattr_comp - LIF set attr command completion
include/linux/pds/pds_adminq.h: * @comp_index: Index in the descriptor ring for which this is the completion
include/linux/pds/pds_adminq.h: * struct pds_core_lif_getattr_comp - LIF get attr command completion
include/linux/pds/pds_adminq.h: * @comp_index: Index in the descriptor ring for which this is the completion
include/linux/pds/pds_adminq.h: * @comp_sz:	Completion descriptor size
include/linux/pds/pds_adminq.h:#define PDS_CORE_QIDENT_F_CQ	0x01	/* queue has completion ring */
include/linux/pds/pds_adminq.h: * struct pds_core_q_identify_comp - queue identify command completion
include/linux/pds/pds_adminq.h: * @comp_index:	Index in the descriptor ring for which this is the completion
include/linux/pds/pds_adminq.h: *    IRQ:	  Interrupt requested on completion
include/linux/pds/pds_adminq.h: * @cq_ring_base: Completion queue ring base address
include/linux/pds/pds_adminq.h:#define PDS_CORE_QINIT_F_IRQ	0x01	/* Request interrupt on completion */
include/linux/pds/pds_adminq.h: * struct pds_core_q_init_comp - Queue init command completion
include/linux/pds/pds_adminq.h: * @comp_index:	Index in the descriptor ring for which this is the completion
include/linux/pds/pds_adminq.h: * block after reading the answer.  If the completion status is 0, then there
include/linux/pds/pds_adminq.h: * struct pds_vdpa_vq_init_comp - queue init completion
include/linux/pds/pds_adminq.h: * struct pds_vdpa_vq_reset_comp - queue reset completion
include/linux/pds/pds_adminq.h: * struct pds_lm_state_size_comp - STATE_SIZE command completion
include/linux/pds/pds_adminq.h: * @comp_index:		Index in the desc ring for which this is the completion
include/linux/pds/pds_adminq.h: * completion) of struct pds_lm_dirty_region_info will be written to
include/linux/pds/pds_adminq.h: * case, the completion will only report the maximum number of regions
include/linux/pds/pds_adminq.h: * struct pds_lm_dirty_status_comp - STATUS command completion
include/linux/pds/pds_adminq.h: * @comp_index:		Index in the desc ring for which this is the completion
include/linux/pds/pds_adminq.h: * This completion descriptor is used for STATUS, ENABLE, and DISABLE.
include/linux/pds/pds_adminq.h: * the information on successful completion, such as by size-aligning the
include/linux/pds/pds_adminq.h: * This command uses struct pds_lm_dirty_status_comp for its completion.
include/linux/pds/pds_adminq.h: * This command uses struct pds_lm_dirty_status_comp for its completion.  On
include/linux/pds/pds_adminq.h:/* The color bit is a 'done' bit for the completion descriptors
include/linux/pds/pds_adminq.h: * passes through the completion descriptor ring.
include/linux/pds/pds_core_if.h: * struct pds_core_dev_identify_comp - Device identify command completion
include/linux/pds/pds_core_if.h: * struct pds_core_dev_reset_comp - Reset command completion
include/linux/pds/pds_core_if.h: * struct pds_core_dev_init_comp - Core init completion
include/linux/pds/pds_core_if.h: * struct pds_core_fw_download_comp - Firmware download completion
include/linux/pds/pds_core_if.h: * struct pds_core_vf_ctrl_comp - VF_CTRL command completion.
include/linux/pds/pds_core_if.h: * union pds_core_dev_comp - Overlay of core device completion structures
include/linux/pds/pds_core_if.h: * @done:	Command completed indicator, poll for completion
include/linux/percpu-refcount.h: * Completion of percpu_ref_kill() in itself doesn't guarantee that this
include/linux/phylink.h: * negotiation completion state in @state->an_complete, and link up state
include/linux/pipe_fs_i.h:	 * to a file system, we may need to wait for IO completion in this
include/linux/pktcdvd.h:#include <linux/completion.h>
include/linux/platform_data/edma.h: *		also manually or by "chaining" from DMA completions.
include/linux/platform_data/mlxcpld.h: * @completion_notify: callback to notify when all the adapters are created
include/linux/platform_data/mlxcpld.h:	int (*completion_notify)(void *handle, struct i2c_adapter *parent,
include/linux/platform_data/mlxreg.h: * @completion_notify: callback to notify when platform driver probing is done;
include/linux/platform_data/mlxreg.h:	int (*completion_notify)(void *handle, int id);
include/linux/pm.h:#include <linux/completion.h>
include/linux/pm.h:	struct completion	completion;
include/linux/ptrace.h: * System call handlers that, upon successful completion, need to return a
include/linux/qed/common_hsi.h:/* Completion types */
include/linux/qed/common_hsi.h:#define DB_RDMA_24B_ICID_DPM_PARAMS_COMPLETION_FLG_MASK 0x1
include/linux/qed/common_hsi.h:#define DB_RDMA_24B_ICID_DPM_PARAMS_COMPLETION_FLG_SHIFT        28
include/linux/qed/common_hsi.h:#define DB_RDMA_DPM_PARAMS_COMPLETION_FLG_MASK		0x1
include/linux/qed/common_hsi.h:#define DB_RDMA_DPM_PARAMS_COMPLETION_FLG_SHIFT		30
include/linux/qed/fcoe_common.h:enum fcoe_completion_status {
include/linux/qed/fcoe_common.h:	FCOE_COMPLETION_STATUS_SUCCESS,
include/linux/qed/fcoe_common.h:	FCOE_COMPLETION_STATUS_FCOE_VER_ERR,
include/linux/qed/fcoe_common.h:	FCOE_COMPLETION_STATUS_SRC_MAC_ADD_ARR_ERR,
include/linux/qed/fcoe_common.h:	MAX_FCOE_COMPLETION_STATUS
include/linux/qed/iscsi_common.h:/* iSCSI kernel completion queue IDs */
include/linux/qed/iscsi_common.h:/* iSCSI EQE and CQE completion status */
include/linux/qed/iscsi_common.h:	ISCSI_CONN_ERROR_LOCAL_COMPLETION_ERROR,
include/linux/qed/qed_eth_if.h:	int (*eth_cqe_completion)(struct qed_dev *cdev,
include/linux/qed/qed_if.h: * drain(): drains chip in case Tx completions fail to arrive due to pause.
include/linux/rcupdate_wait.h:#include <linux/completion.h>
include/linux/rcupdate_wait.h:	struct completion completion;
include/linux/regset.h: * @immediate:	zero if writeback at completion of next context switch is OK
include/linux/remoteproc.h:#include <linux/completion.h>
include/linux/rmi.h: * @post_delay_us - the delay after the completion of an SPI transaction.  This
include/linux/rmi.h: * and post_delay_us after completion of the SPI transfer(s) before calling it
include/linux/rndis.h:#define RNDIS_MSG_COMPLETION	0x80000000
include/linux/rndis.h:#define RNDIS_MSG_INIT_C	(RNDIS_MSG_INIT|RNDIS_MSG_COMPLETION)
include/linux/rndis.h:#define RNDIS_MSG_QUERY_C	(RNDIS_MSG_QUERY|RNDIS_MSG_COMPLETION)
include/linux/rndis.h:#define RNDIS_MSG_SET_C		(RNDIS_MSG_SET|RNDIS_MSG_COMPLETION)
include/linux/rndis.h:#define RNDIS_MSG_RESET_C	(RNDIS_MSG_RESET|RNDIS_MSG_COMPLETION)
include/linux/rndis.h:#define RNDIS_MSG_KEEPALIVE_C	(RNDIS_MSG_KEEPALIVE|RNDIS_MSG_COMPLETION)
include/linux/rndis.h:/* codes for "status" field of completion messages */
include/linux/rtsx_pci.h:	struct completion		*done;
include/linux/rtsx_pci.h:	struct completion		*finish_me;
include/linux/rwsem.h: *   proper abstraction for this case is completions. ]
include/linux/sbitmap.h:	 * @completion_cnt: Number of bits cleared passed to the
include/linux/sbitmap.h:	atomic_t completion_cnt;
include/linux/sched.h:	struct completion		*vfork_done;
include/linux/sched/signal.h:	struct completion startup;
include/linux/serdev.h: * @write_comp	Completion used by serdev_device_write() internally
include/linux/serdev.h:	struct completion write_comp;
include/linux/shrinker.h:#include <linux/completion.h>
include/linux/shrinker.h:	struct completion done;	/* use to wait for refcount to reach 0 */
include/linux/skbuff.h:/* Preserve some data across TX submission and completion.
include/linux/skbuff.h: * called before TX completion of this packet can trigger.  Otherwise
include/linux/slimbus.h:#include <linux/completion.h>
include/linux/slimbus.h: * @comp: completion for asynchronous operations, valid only if TID is
include/linux/slimbus.h:	struct	completion	*comp;
include/linux/soc/apple/rtkit.h:			     struct completion *completion, bool atomic);
include/linux/soc/qcom/qmi.h:#include <linux/completion.h>
include/linux/soc/qcom/qmi.h: * @completion:	completion object as the transaction receives a response
include/linux/soc/qcom/qmi.h:	struct completion completion;
include/linux/soundwire/sdw.h: * @port_ready: Port ready completion flag for each Slave port
include/linux/soundwire/sdw.h: * @enumeration_complete: completion utility to control potential races
include/linux/soundwire/sdw.h: * @initialization_complete: completion utility to control potential races
include/linux/soundwire/sdw.h:	struct completion port_ready[SDW_MAX_PORTS];
include/linux/soundwire/sdw.h:	struct completion enumeration_complete;
include/linux/soundwire/sdw.h:	struct completion initialization_complete;
include/linux/soundwire/sdw.h: * @complete: message completion
include/linux/soundwire/sdw.h:	struct completion complete;
include/linux/spi/spi.h:#include <linux/completion.h>
include/linux/spi/spi.h: * @cur_msg_completion: a completion for the current in-flight message
include/linux/spi/spi.h: *	the @cur_msg_completion. This flag is used to check if the driver has
include/linux/spi/spi.h: * @cur_msg_need_completion: Flag used internally to opportunistically skip
include/linux/spi/spi.h: *	the @cur_msg_completion. This flag is used to signal the context that
include/linux/spi/spi.h: * @xfer_completion: used by core transfer_one_message()
include/linux/spi/spi.h: * message's completion function when the transaction completes.
include/linux/spi/spi.h:	struct completion               cur_msg_completion;
include/linux/spi/spi.h:	bool				cur_msg_need_completion;
include/linux/spi/spi.h:	struct completion               xfer_completion;
include/linux/spi/spi.h: * and its transfers, ignore them until its completion callback.
include/linux/spi/spi.h: * @complete: called to report transaction completions
include/linux/spi/spi.h: * and its transfers, ignore them until its completion callback.
include/linux/spi/spi.h:	/* Completion is reported through a callback */
include/linux/srcutree.h:#include <linux/completion.h>
include/linux/srcutree.h:	struct completion srcu_barrier_completion;
include/linux/sunrpc/rpc_rdma.h:	RDMA_DONE = 3,		/* Client signals reply completion */
include/linux/sunrpc/rpc_rdma_cid.h: * The rpc_rdma_cid struct records completion ID information. A
include/linux/sunrpc/rpc_rdma_cid.h: * completion ID matches an incoming Send or Receive completion
include/linux/sunrpc/rpc_rdma_cid.h: * to a Completion Queue and to a previous ib_post_*(). The ID
include/linux/sunrpc/rpc_rdma_cid.h:	int			ci_completion_id;
include/linux/sunrpc/sched.h:int		rpc_wait_for_completion_task(struct rpc_task *task);
include/linux/sunrpc/svc_rdma.h:	atomic_t	     sc_completion_ids;
include/linux/sunrpc/svc_rdma.h: * svc_rdma_send_cid_init - Initialize a Receive Queue completion ID
include/linux/sunrpc/svc_rdma.h: * @cid: completion ID to initialize
include/linux/sunrpc/svc_rdma.h:	cid->ci_completion_id = atomic_inc_return(&rdma->sc_completion_ids);
include/linux/sunrpc/svc_rdma.h: * svc_rdma_send_cid_init - Initialize a Send Queue completion ID
include/linux/sunrpc/svc_rdma.h: * @cid: completion ID to initialize
include/linux/sunrpc/svc_rdma.h:	cid->ci_completion_id = atomic_inc_return(&rdma->sc_completion_ids);
include/linux/sunrpc/svcsock.h:	struct completion	sk_handshake_done;
include/linux/sunrpc/xprtsock.h:	struct completion	handshake_done;
include/linux/surface_aggregator/controller.h:#include <linux/completion.h>
include/linux/surface_aggregator/controller.h: * @comp:   Completion used to signal full completion of the request. After the
include/linux/surface_aggregator/controller.h: *          deallocated after the completion has been signaled.
include/linux/surface_aggregator/controller.h:	struct completion comp;
include/linux/surface_aggregator/controller.h: * ssam_request_sync_wait - Wait for completion of a synchronous request.
include/linux/surface_aggregator/controller.h: * Wait for completion and release of a synchronous request. After this
include/linux/surface_aggregator/controller.h: * fails in that case, due to the completion never triggering.
include/linux/surface_aggregator/controller.h: * Return: Returns the status of the given request, which is set on completion
include/linux/surface_aggregator/controller.h:	wait_for_completion(&rqst->comp);
include/linux/surface_aggregator/controller.h: * and finally waits for its completion before returning its status. This
include/linux/swap.h:	struct completion comp;		/* seldom referenced */
include/linux/sysctl.h:struct completion;
include/linux/sysctl.h:	struct completion *unregistering;
include/linux/tee_core.h: * @c_no_user:	completion used when unregistering the device
include/linux/tee_core.h:	struct completion c_no_users;
include/linux/thunderbolt.h: * %RING_DESC_INTERRUPT: Request an interrupt on completion
include/linux/ti_wilink_st.h: * @kim_rcvd: completion handler to notify when data was received,
include/linux/ti_wilink_st.h: * @ldisc_installed: completion handler to notify that the UIM accepted
include/linux/ti_wilink_st.h:	struct completion kim_rcvd, ldisc_installed;
include/linux/tifm.h:	struct completion   *finish_me;
include/linux/timer.h: * it's safe to wait for the completion of the running instance from
include/linux/torture.h:#include <linux/completion.h>
include/linux/umh.h:	struct completion *complete;
include/linux/usb.h:#include <linux/completion.h>	/* for struct completion */
include/linux/usb.h: * URB support, for asynchronous request completions
include/linux/usb.h: * @status: This is read in non-iso completion functions to get the
include/linux/usb.h: * @actual_length: This is read in non-iso completion functions, and
include/linux/usb.h: * @context: For use in completion functions.  This normally points to
include/linux/usb.h: * @complete: Completion handler. This URB is passed as the parameter to the
include/linux/usb.h: *	completion function.  The completion function may then do what
include/linux/usb.h: * breaking the queue's synchronization.  Upon URB completion, the
include/linux/usb.h: * in completion handlers, so
include/linux/usb.h: * Completion Callbacks:
include/linux/usb.h: * The completion callback is made in_interrupt(), and one of the first
include/linux/usb.h: * things that a completion handler should do is check the status field.
include/linux/usb.h: * be examined before the URB is returned to the completion handler.
include/linux/usb.h: * When the completion callback is invoked for non-isochronous URBs, the
include/linux/usb.h: * error_count.  Completion callbacks for ISO transfers will normally
include/linux/usb.h: * usb_submit_urb() till the entry into the completion routine.
include/linux/usb.h:	void *context;			/* (in) context for completion */
include/linux/usb.h:	usb_complete_t complete;	/* (in) completion routine */
include/linux/usb.h: * After an error completion, drivers may need to clear a halt condition
include/linux/usb.h:	struct completion	complete;
include/linux/usb/ehci_def.h:#define STS_ERR		(1<<1)		/* "error" completion (overflow, ...) */
include/linux/usb/ehci_def.h:#define STS_INT		(1<<0)		/* "normal" completion (short, ...) */
include/linux/usb/gadget.h: * @no_interrupt: If true, hints that no completion irq is needed.
include/linux/usb/gadget.h: *	until the completion function returns, so that any transfers
include/linux/usb/gadget.h: * @context: For use by the completion callback
include/linux/usb/gadget.h: * @status: Reports completion code, zero or a negative errno.
include/linux/usb/gadget.h: *	the completion callback returns.
include/linux/usb/gadget.h: *	Code "-ESHUTDOWN" indicates completion caused by device disconnect,
include/linux/usb/gadget.h: *	even when status otherwise indicates successful completion.
include/linux/usb/hcd.h:		/* CLEAR_TT_BUFFER completion callback */
include/linux/usb/hcd.h:static inline bool hcd_periodic_completion_in_progress(struct usb_hcd *hcd,
include/linux/vfio.h:	struct completion comp;
include/linux/virtio.h:#include <linux/completion.h>
include/linux/virtio.h:	struct completion completion;
include/linux/wkup_m3_ipc.h:	struct completion sync_complete;
include/linux/workqueue.h:		lockdep_init_map(&(_work)->lockdep_map, "(work_completion)"#_work, (_key), 0); \
include/linux/writeback.h:	 * on page writeback completions [end_page_writeback()]. Those
include/linux/writeback.h:	 * We use page writeout completions because we are interested in
include/linux/writeback.h:	 * of this period itself is measured in page writeback completions.
include/linux/writeback.h:	struct fprop_global completions;
include/linux/writeback.h:	struct timer_list period_timer;	/* timer for aging of completions */
include/linux/writeback.h:			   enum wb_reason reason, struct wb_completion *done);
include/linux/writeback.h:void laptop_io_completion(struct backing_dev_info *info);
include/linux/writeback.h:void laptop_sync_completion(void);
include/media/cec.h:	struct completion c;
include/media/cec.h: * @config_completion:	used to signal completion of the config kthread
include/media/cec.h:	struct completion config_completion;
include/media/vsp1.h: * @callback: frame completion callback function (optional). When a callback
include/media/vsp1.h: * @callback_data: data to be passed to the frame completion callback
include/net/cfg80211.h: * or aborted. This must be called to notify the completion of a CAC process,
include/net/cfg80211.h: * cfg80211_color_change_notify - notify color change completion
include/net/genetlink.h: * @done: completion callback for dumps
include/net/genetlink.h: * @done: completion callback for dumps
include/net/inet_frag.h:#include <linux/completion.h>
include/net/inet_frag.h:	struct completion	completion;
include/net/libeth/tx.h:/* Tx buffer completion */
include/net/libeth/tx.h: * enum libeth_sqe_type - type of &libeth_sqe to act on Tx completion
include/net/libeth/tx.h: * struct libeth_cq_pp - completion queue poll params
include/net/libeth/tx.h: * libeth_tx_complete - perform Tx completion for one SQE
include/net/libeth/types.h: * struct libeth_sq_napi_stats - "hot" counters to update in Tx completion loop
include/net/mac80211.h: *	completion of the channel switch.
include/net/mana/gdma.h:	GDMA_EQE_COMPLETION		= 3,
include/net/mana/gdma.h:	struct completion	eq_test_event;
include/net/mana/hw_channel.h:	struct completion comp_event;
include/net/mana/hw_channel.h:	struct completion hwc_init_eqe_comp;
include/net/mana/mana.h:#define MANA_CQE_COMPLETION 1
include/net/mana/mana.h:/* Receive completion OOB */
include/net/mana/mana.h:	struct completion fence_event;
include/net/nfc/nci_core.h:	struct completion	req_completion;
include/net/nfc/nci_core.h:	struct completion	req_completion;
include/net/nfc/nci_core.h:		 struct completion *write_handshake_completion,
include/net/xdp_sock.h: *     received a completion. The hook needs to return the actual HW timestamp.
include/net/xdp_sock.h: *  to perform tx completion in the future.
include/net/xdp_sock.h: *  and passed to xsk_tx_metadata_complete upon TX completion.
include/net/xdp_sock.h:		compl->tx_timestamp = &meta->completion.tx_timestamp;
include/net/xdp_sock.h: *  xsk_tx_metadata_complete - Evaluate AF_XDP TX metadata at completion
include/net/xdp_sock.h: *  @compl: pointer to completion metadata produced from xsk_tx_metadata_to_compl
include/net/xdp_sock.h: *  AF_XDP egress completion.
include/net/xsk_buff_pool.h:	/* Mutual exclusion of the completion ring in the SKB mode. Two cases to protect:
include/pcmcia/ss.h:#include <linux/sched.h>	/* task_struct, completion */
include/pcmcia/ss.h:	struct completion		socket_released;
include/pcmcia/ss.h:	struct completion		thread_done;
include/ras/ras_event.h:	{PCI_ERR_UNC_COMP_TIME,	"Completion Timeout"},		\
include/ras/ras_event.h:	{PCI_ERR_UNC_UNX_COMP,	"Unexpected Completion"},	\
include/rdma/ib_mad.h: *   using RMPP, this applies per window.  On completion, returns the number
include/rdma/ib_mad.h: * @mad_send_wc: Send work completion information on the sent MAD.
include/rdma/ib_mad.h: * @mad_recv_wc: Received work completion information on the received MAD.
include/rdma/ib_mad.h: * ib_mad_send_wc - MAD send completion information.
include/rdma/ib_mad.h: * @status: Completion status.
include/rdma/ib_mad.h: * @wc: Completion information for the received data.
include/rdma/ib_mad.h: * @send_handler: The completion callback routine invoked after a send
include/rdma/ib_mad.h: * @recv_handler: The completion callback routine invoked for a received
include/rdma/ib_mad.h: * @mad_recv_wc: Work completion information for a received MAD.
include/rdma/ib_mad.h: * routine to return the work completion buffers to the access layer.
include/rdma/ib_sa.h:#include <linux/completion.h>
include/rdma/ib_sa.h:	struct completion comp;
include/rdma/ib_verbs.h: * Set value of IB_WC_RECV so consumers can test if a completion is a
include/rdma/ib_verbs.h:	IB_POLL_DIRECT,		   /* caller context, no hw completions */
include/rdma/ib_verbs.h:	 * completion is supported.
include/rdma/ib_verbs.h:	struct completion	error_complete;
include/rdma/ib_verbs.h:	struct completion	srq_completion;
include/rdma/ib_verbs.h:	struct completion unreg_completion;
include/rdma/ib_verbs.h:	struct completion uses_zero;
include/rdma/ib_verbs.h: *   work completion.
include/rdma/ib_verbs.h: *   work completion.
include/rdma/ib_verbs.h: * @wc: Work completion associated with the received message.
include/rdma/ib_verbs.h: *   ignored unless the work completion indicates that the GRH is valid.
include/rdma/ib_verbs.h: *   sender of the specified work completion.
include/rdma/ib_verbs.h: * @wc: Work completion information associated with a received message.
include/rdma/ib_verbs.h: *   ignored unless the work completion indicates that the GRH is valid.
include/rdma/ib_verbs.h: *   completion event occurs on the CQ.
include/rdma/ib_verbs.h: *   asynchronous event not associated with a completion occurs on the CQ.
include/rdma/ib_verbs.h: *   the associated completion and event handlers.
include/rdma/ib_verbs.h: * ib_poll_cq - poll a CQ for completion(s)
include/rdma/ib_verbs.h: * @num_entries:maximum number of completions to return
include/rdma/ib_verbs.h: * @wc:array of at least @num_entries &struct ib_wc where completions
include/rdma/ib_verbs.h: * Poll a CQ for (possibly multiple) completions.  If the return value
include/rdma/ib_verbs.h: * number of completions returned.  If the return value is
include/rdma/ib_verbs.h: * ib_req_notify_cq - Request completion notification on a CQ.
include/rdma/ib_verbs.h: *   completion at any type, respectively. %IB_CQ_REPORT_MISSED_EVENTS
include/rdma/ib_verbs.h: *        this case is it guaranteed that any work completions added
include/rdma/ib_verbs.h: *        to the CQ since the last CQ poll will trigger a completion
include/rdma/ib_verbs.h: *        (but not guaranteed) that a work completion has been added
include/rdma/ib_verbs.h: *        completion notification event.
include/rdma/ib_verbs.h: * ib_get_vector_affinity - Get the affinity mappings of a given completion
include/rdma/ib_verbs.h: * @comp_vector:    index of completion vector
include/rdma/ib_verbs.h: * completion vector (returns all-cpus map if the device driver doesn't
include/rdma/rdmavt_cq.h: * and completion queue entries as a single memory allocation so
include/rdma/rdmavt_cq.h: * The completion queue structure.
include/rdma/rdmavt_mr.h:	struct completion comp; /* complete when refcount goes to zero */
include/rdma/rdmavt_qp.h: * RVT_S_SIGNAL_REQ_WR - set if QP send WRs contain completion signaled
include/rdma/rdmavt_qp.h: *                  next send completion entry not via send DMA
include/rdma/rdmavt_qp.h:#define RVT_SEND_COMPLETION_ONLY	(IB_SEND_RESERVED_START << 1)
include/rdma/rdmavt_qp.h: * rvt_recv_cq - add a new entry to completion queue
include/rdma/rdmavt_qp.h: * @wc: work completion entry to add
include/rdma/rdmavt_qp.h: * rvt_send_cq - add a new entry to completion queue
include/rdma/rdmavt_qp.h: * @wc: work completion entry to add
include/rdma/rdmavt_qp.h: * rvt_qp_complete_swqe - insert send completion
include/rdma/rdmavt_qp.h: * @status - completion status
include/rdma/rdmavt_qp.h: * completion into the completion
include/rdma/rdmavt_qp.h: * See IBTA 10.7.3.1 for info on completion
include/rdma/rdmavt_qp.h:	bool need_completion;
include/rdma/rdmavt_qp.h:	need_completion =
include/rdma/rdmavt_qp.h:	if (need_completion) {
include/rdma/rdmavt_qp.h:	if (need_completion) {
include/rdma/restrack.h:#include <linux/completion.h>
include/rdma/restrack.h:	 * @RDMA_RESTRACK_CQ: Completion queue (CQ)
include/rdma/restrack.h:	struct completion	comp;
include/rdma/uverbs_types.h:	 * completion_channel), we use fops, name and flags for fd creation.
include/scsi/fc/fc_fcp.h:#define	FCP_SPPF_CONF_COMPL	0x0080	/* confirmed completion allowed */
include/scsi/libfc.h: * @RPORT_ST_FLOGI:   Waiting for FLOGI completion for point-to-multipoint
include/scsi/libfc.h: * @RPORT_ST_PLOGI:   Waiting for PLOGI completion
include/scsi/libfc.h: * @RPORT_ST_PRLI:    Waiting for PRLI completion
include/scsi/libfc.h: * @RPORT_ST_RTV:     Waiting for RTV completion
include/scsi/libfc.h: * @tm_done:         Completion indicator
include/scsi/libfc.h: * @wait_for_comp:   Indicator to wait for completion of the I/O (in jiffies)
include/scsi/libfc.h: * @scsi_comp_flags: Completion flags (bit 3 Underrun bit 2: overrun)
include/scsi/libfc.h:	struct completion tm_done;
include/scsi/libfc.h:#define FC_EX_RST_CLEANUP	(1 << 1) /* reset is forcing completion */
include/scsi/libsas.h:	struct completion     completion;
include/scsi/scsi_bsg_iscsi.h:	 * The completion result. Result exists in two forms:
include/scsi/scsi_cmnd.h:	unsigned long state;	/* Command completion state */
include/scsi/scsi_host.h:struct completion;
include/scsi/scsi_host.h: * @SCSI_EH_RESET_TIMER: Reset the timer and continue waiting for completion.
include/scsi/scsi_host.h:	 * SCSI interface of blk_poll - poll for IO completions.
include/scsi/scsi_host.h:	struct completion     * eh_action; /* Wait for specific actions on the
include/scsi/scsi_host.h:	struct completion	tagset_freed;
include/scsi/scsi_transport_iscsi.h:	 * completion
include/soc/fsl/qe/ucc_fast.h:#define T_I	0x10000000	/* interrupt on completion */
include/soc/fsl/qe/ucc_fast.h:#define T_I_S	0x1000	/* interrupt on completion */
include/soc/fsl/qe/ucc_slow.h:#define T_I	0x10000000	/* interrupt on completion */
include/soc/fsl/qman.h: * Active state), the completion will be via the message ring as a FQRN - but
include/soc/fsl/qman.h: * the FINISH flag, completion can be determined either by detecting the
include/soc/qcom/tcs.h: *                       (There's no request completion callback)
include/soc/tegra/bpmp.h:	struct completion completion;
include/sound/core.h:struct completion;
include/sound/core.h:	struct completion *release_completion;
include/sound/hda_register.h:#define SD_INT_COMPLETE		0x04	/* completion interrupt */
include/sound/soc-topology.h:	/* completion - called at completion of firmware loading */
include/target/iscsi/iscsi_target_core.h:	struct completion	conn_post_wait_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	conn_wait_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	conn_wait_rcfr_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	conn_waiting_on_uc_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	conn_logout_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	tx_half_close_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	rx_half_close_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	rx_login_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	async_msg_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	reinstatement_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	session_wait_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	session_waiting_on_uc_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	np_restart_comp;
include/target/iscsi/iscsi_target_core.h:	struct completion	tpg_np_comp;
include/target/target_core_base.h:#include <linux/completion.h>
include/target/target_core_base.h:	struct completion	*free_compl;
include/target/target_core_base.h:	struct completion	*abrt_compl;
include/target/target_core_base.h:	struct completion	t_transport_stop_comp;
include/target/target_core_base.h:	struct completion	acl_free_comp;
include/target/target_core_base.h:	struct completion	stop_done;
include/target/target_core_base.h:	struct completion	pr_comp;
include/target/target_core_base.h:	struct completion	lun_shutdown_comp;
include/target/target_core_base.h:	/* Use se_cmd's cpuid for completion */
include/trace/events/block.h:DECLARE_EVENT_CLASS(block_rq_completion,
include/trace/events/block.h:DEFINE_EVENT(block_rq_completion, block_rq_complete,
include/trace/events/block.h:DEFINE_EVENT(block_rq_completion, block_rq_error,
include/trace/events/firewire.h:DECLARE_EVENT_CLASS(isoc_flush_completions_template,
include/trace/events/firewire.h:DEFINE_EVENT_CONDITION(isoc_flush_completions_template, isoc_outbound_flush_completions,
include/trace/events/firewire.h:DEFINE_EVENT_CONDITION(isoc_flush_completions_template, isoc_inbound_single_flush_completions,
include/trace/events/firewire.h:DEFINE_EVENT_CONDITION(isoc_flush_completions_template, isoc_inbound_multiple_flush_completions,
include/trace/events/firewire.h:enum fw_iso_context_completions_cause {
include/trace/events/firewire.h:	FW_ISO_CONTEXT_COMPLETIONS_CAUSE_FLUSH = 0,
include/trace/events/firewire.h:	FW_ISO_CONTEXT_COMPLETIONS_CAUSE_INTERRUPT,
include/trace/events/firewire.h:	FW_ISO_CONTEXT_COMPLETIONS_CAUSE_HEADER_OVERFLOW,
include/trace/events/firewire.h:		{ FW_ISO_CONTEXT_COMPLETIONS_CAUSE_FLUSH, "FLUSH" },			\
include/trace/events/firewire.h:		{ FW_ISO_CONTEXT_COMPLETIONS_CAUSE_INTERRUPT, "INTERRUPT" },		\
include/trace/events/firewire.h:		{ FW_ISO_CONTEXT_COMPLETIONS_CAUSE_HEADER_OVERFLOW, "HEADER_OVERFLOW" }	\
include/trace/events/firewire.h:DECLARE_EVENT_CLASS(isoc_single_completions_template,
include/trace/events/firewire.h:	TP_PROTO(const struct fw_iso_context *ctx, u16 timestamp, enum fw_iso_context_completions_cause cause, const u32 *header, unsigned int header_length),
include/trace/events/firewire.h:DEFINE_EVENT_CONDITION(isoc_single_completions_template, isoc_outbound_completions,
include/trace/events/firewire.h:	TP_PROTO(const struct fw_iso_context *ctx, u16 timestamp, enum fw_iso_context_completions_cause cause, const u32 *header, unsigned int header_length),
include/trace/events/firewire.h:DEFINE_EVENT_CONDITION(isoc_single_completions_template, isoc_inbound_single_completions,
include/trace/events/firewire.h:	TP_PROTO(const struct fw_iso_context *ctx, u16 timestamp, enum fw_iso_context_completions_cause cause, const u32 *header, unsigned int header_length),
include/trace/events/firewire.h:TRACE_EVENT(isoc_inbound_multiple_completions,
include/trace/events/firewire.h:	TP_PROTO(const struct fw_iso_context *ctx, unsigned int completed, enum fw_iso_context_completions_cause cause),
include/trace/events/firewire_ohci.h:		"card_index=%u is_error=%s generation_at_bus_reset=%u generation_at_completion=%u timestamp=0x%04x packet_data=%s",
include/trace/events/io_uring.h: * @cflags:		completion flags
include/trace/events/ksm.h: * Allows to trace the completion of a ksm scan.
include/trace/events/rdma_core.h: ** Completion Queue events
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id
include/trace/events/rpcrdma.h:DECLARE_EVENT_CLASS(rpcrdma_completion_class,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:#define DEFINE_COMPLETION_EVENT(name)					\
include/trace/events/rpcrdma.h:		DEFINE_EVENT(rpcrdma_completion_class, name,		\
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:DECLARE_EVENT_CLASS(rpcrdma_mr_completion_class,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:#define DEFINE_MR_COMPLETION_EVENT(name)				\
include/trace/events/rpcrdma.h:		DEFINE_EVENT(rpcrdma_mr_completion_class, name,		\
include/trace/events/rpcrdma.h:DECLARE_EVENT_CLASS(rpcrdma_receive_completion_class,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:#define DEFINE_RECEIVE_COMPLETION_EVENT(name)				\
include/trace/events/rpcrdma.h:		DEFINE_EVENT(rpcrdma_receive_completion_class, name,	\
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = sc->sc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h: ** Completion events
include/trace/events/rpcrdma.h:DEFINE_RECEIVE_COMPLETION_EVENT(xprtrdma_wc_receive);
include/trace/events/rpcrdma.h:DEFINE_COMPLETION_EVENT(xprtrdma_wc_send);
include/trace/events/rpcrdma.h:DEFINE_MR_COMPLETION_EVENT(xprtrdma_wc_fastreg);
include/trace/events/rpcrdma.h:DEFINE_MR_COMPLETION_EVENT(xprtrdma_wc_li);
include/trace/events/rpcrdma.h:DEFINE_MR_COMPLETION_EVENT(xprtrdma_wc_li_wake);
include/trace/events/rpcrdma.h:DEFINE_MR_COMPLETION_EVENT(xprtrdma_wc_li_done);
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->rc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->rc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->rc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->sc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->sc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = ctxt->sc_cid.ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:		__field(int, completion_id)
include/trace/events/rpcrdma.h:		__entry->completion_id = cid->ci_completion_id;
include/trace/events/rpcrdma.h:		__entry->cq_id, __entry->completion_id,
include/trace/events/rpcrdma.h:DEFINE_CLIENT_DEVICE_EVENT(rpcrdma_client_completion);
include/trace/events/rxrpc.h:#define rxrpc_completions \
include/trace/events/rxrpc.h:		    __field(enum rxrpc_call_completion,	compl)
include/trace/events/rxrpc.h:		    __entry->compl = call->completion;
include/trace/events/rxrpc.h:		      __print_symbolic(__entry->compl, rxrpc_completions),
include/uapi/asm-generic/siginfo.h:#define SI_ASYNCIO	-4		/* sent by AIO completion */
include/uapi/asm-generic/siginfo.h:#define SI_ASYNCNL	-60		/* sent by glibc async name lookup completion */
include/uapi/drm/drm.h: * DRM_EVENT_FLIP_COMPLETE - page-flip completion event
include/uapi/drm/habanalabs_accel.h:	 * will sync with this engine and with all NICs before completion.
include/uapi/drm/habanalabs_accel.h:				/* User address for completion comparison.
include/uapi/drm/habanalabs_accel.h:			/* Target value for completion comparison */
include/uapi/drm/habanalabs_accel.h:	 * for wait_cs: timestamp of CS completion
include/uapi/drm/habanalabs_accel.h:	 * for wait_multi_cs: timestamp of FIRST CS completion
include/uapi/drm/habanalabs_accel.h:	/* multi CS completion bitmap */
include/uapi/drm/habanalabs_accel.h:	__u32 cs_completion_map;
include/uapi/drm/habanalabs_accel.h: * internal. The driver will get completion notifications from the device only
include/uapi/drm/habanalabs_accel.h: * The driver will get completion notifications from the device for all queues.
include/uapi/drm/i915_drm.h: *	detection, and a 0 upon reset completion, signifying no more error
include/uapi/drm/i915_drm.h: * The returned output fence will be signaled after the completion of the
include/uapi/drm/i915_drm.h:	 * Return request completion fence as output
include/uapi/drm/i915_drm.h:	 * signaled completion for all pending requests that reference the
include/uapi/drm/i915_drm.h: * completion. Persistence allows fire-and-forget clients to queue up a
include/uapi/drm/ivpu_accel.h: * User space may wait on job completion using %DRM_IVPU_BO_WAIT ioctl.
include/uapi/drm/panfrost_drm.h:	/** An optional sync object to place the completion fence in. */
include/uapi/drm/panfrost_drm.h: * completion of the last DRM_PANFROST_SUBMIT on a BO.
include/uapi/drm/pvr_drm.h:	 * The End of Tile PDS task runs at completion of a tile during a fragment job, and is
include/uapi/drm/tegra_drm.h:	 * successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * successful completion of the IOCTL. This context needs to be passed
include/uapi/drm/tegra_drm.h:	 * completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * by the kernel upon successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * has been completed. Set by the kernel upon successful completion of
include/uapi/drm/tegra_drm.h:	 * the kernel upon successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * Set by the kernel upon successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * kernel upon successful completion of the IOCTL.
include/uapi/drm/tegra_drm.h:	 * the job's completion fence. Ignored if zero.
include/uapi/drm/tegra_drm.h:	 * Value of the syncpoint upon wait completion.
include/uapi/drm/v3d_drm.h:	/** An optional sync object to place the completion fence in. */
include/uapi/drm/v3d_drm.h: * completion of the last DRM_V3D_SUBMIT_CL on a BO.
include/uapi/drm/vc4_drm.h:	 * will be replaced with a fence that signals upon completion of this
include/uapi/drm/vc4_drm.h: * DRM_VC4_SUBMIT_CL completion using its returned seqno.
include/uapi/drm/vc4_drm.h: * completion of the last DRM_VC4_SUBMIT_CL on a BO.
include/uapi/drm/vmwgfx_drm.h: * for the host. Does not wait for host completion.
include/uapi/drm/vmwgfx_drm.h: * Does not wait for host completion. The context ID can be used directly
include/uapi/drm/vmwgfx_drm.h: * for the host. Does not wait for host completion. The surface ID can be
include/uapi/drm/vmwgfx_drm.h: * Does not wait for completion.
include/uapi/drm/vmwgfx_drm.h: * The following actions should be take on completion:
include/uapi/drm/vmwgfx_drm.h: * @shader_handle: On successful completion contains a handle that
include/uapi/drm/vmwgfx_drm.h: * for the host. Does not wait for host completion.
include/uapi/drm/xe_drm.h: * Returns to user on user fence completion or timeout.
include/uapi/linux/acrn.h: * @completion_polling:	Polling flag. Hypervisor will poll completion of the
include/uapi/linux/acrn.h:	__u32	completion_polling;
include/uapi/linux/acrn.h: * struct acrn_ioreq_notify - The structure of ioreq completion notification
include/uapi/linux/blktrace_api.h:	BLK_TC_COMPLETE	= 1 << 7,	/* completions */
include/uapi/linux/blktrace_api.h:	__u16 error;		/* completion error */
include/uapi/linux/bsg.h:	__u32 device_status;	/* [o] {SCSI: command completion status} */
include/uapi/linux/can/isotp.h:#define CAN_ISOTP_WAIT_TX_DONE	0x0400	/* wait for tx completion */
include/uapi/linux/ethtool.h: *	(usecs > 0 && time_since_first_completion >= usecs) ||
include/uapi/linux/ethtool.h: * condition time_since_first_completion >= usecs
include/uapi/linux/ethtool.h: * counting completions should validate that max_frames == !rx_usecs.
include/uapi/linux/fd.h:				    * completion */
include/uapi/linux/genwqe/genwqe_card.h:	__u64 cmplt_ts;			/* completion time stamp */
include/uapi/linux/idxd.h:/* Completion record status */
include/uapi/linux/idxd.h:enum dsa_completion_status {
include/uapi/linux/idxd.h:enum iax_completion_status {
include/uapi/linux/idxd.h:	uint64_t	completion_addr;
include/uapi/linux/idxd.h:	uint64_t        completion_addr;
include/uapi/linux/idxd.h:struct dsa_completion_record {
include/uapi/linux/idxd.h:struct dsa_raw_completion_record {
include/uapi/linux/idxd.h:struct iax_completion_record {
include/uapi/linux/idxd.h:struct iax_raw_completion_record {
include/uapi/linux/if_xdp.h:	struct xdp_ring_offset cr; /* Completion */
include/uapi/linux/if_xdp.h:#define XDP_UMEM_COMPLETION_RING	6
include/uapi/linux/if_xdp.h:#define XDP_UMEM_PGOFF_COMPLETION_RING	0x180000000ULL
include/uapi/linux/if_xdp.h:/* Request transmit timestamp. Upon completion, put it into tx_timestamp
include/uapi/linux/if_xdp.h: * when the packet is being transmitted. 'completion' union member is
include/uapi/linux/if_xdp.h: * filled by the driver when the transmit completion arrives.
include/uapi/linux/if_xdp.h:		} completion;
include/uapi/linux/io_uring.h:	__u64	user_data;	/* data to be passed back at completion time */
include/uapi/linux/io_uring.h: *				group ID given and send them all. The completion
include/uapi/linux/io_uring.h: * IO completion data structure (Completion Queue Entry)
include/uapi/linux/io_uring.h: * IORING_CQE_F_BUF_MORE If set, the buffer ID set in the completion will get
include/uapi/linux/io_uring.h: *			more completions. In other words, the buffer is being
include/uapi/linux/io_uring.h: *			more completions. This is only set for buffers used via
include/uapi/linux/io_uring.h: *			other provided buffer type, all completions with a
include/uapi/linux/ipmi.h: * commands and responses.  The completion code is always the first
include/uapi/linux/ipmi.h:#define IPMI_INVALID_CMD_COMPLETION_CODE	0xC1
include/uapi/linux/ipmi.h:#define IPMI_TIMEOUT_COMPLETION_CODE		0xC3
include/uapi/linux/ipmi.h:#define IPMI_UNKNOWN_ERR_COMPLETION_CODE	0xff
include/uapi/linux/ipmi.h:/* Note that async events and received commands do not have a completion
include/uapi/linux/nl80211.h: *	as an event on the "mlme" multicast group indicating completion of the
include/uapi/linux/nl80211.h: *	handshake offload should send this event on successful completion of
include/uapi/linux/pci_regs.h:#define  PCI_VPD_ADDR_F		0x8000	/* Write 0, 1 indicates completion */
include/uapi/linux/pci_regs.h:#define  PCI_X_STATUS_SPL_DISC	0x00040000	/* Split Completion Discarded */
include/uapi/linux/pci_regs.h:#define  PCI_X_STATUS_UNX_SPL	0x00080000	/* Unexpected Split Completion */
include/uapi/linux/pci_regs.h:#define  PCI_X_STATUS_SPL_ERR	0x20000000	/* Rcvd Split Completion Error Msg */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_LNKCTL_RCB	0x0008	/* Read Completion Boundary */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCAP2_COMP_TMOUT_DIS	0x00000010 /* Completion Timeout Disable supported */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCAP2_ATOMIC_COMP32	0x00000080 /* 32b AtomicOp completion */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCAP2_ATOMIC_COMP64	0x00000100 /* 64b AtomicOp completion */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCAP2_ATOMIC_COMP128	0x00000200 /* 128b AtomicOp completion */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCTL2_COMP_TIMEOUT	0x000f	/* Completion Timeout Value */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCTL2_COMP_TMOUT_DIS	0x0010	/* Completion Timeout Disable */
include/uapi/linux/pci_regs.h:#define  PCI_EXP_DEVCTL2_IDO_CMP_EN	0x0200	/* Allow IDO for completions */
include/uapi/linux/pci_regs.h:#define  PCI_ERR_UNC_COMP_TIME	0x00004000	/* Completion Timeout */
include/uapi/linux/pci_regs.h:#define  PCI_ERR_UNC_UNX_COMP	0x00010000	/* Unexpected Completion */
include/uapi/linux/pci_regs.h:#define  PCI_ACS_CR		0x0008	/* P2P Completion Redirect */
include/uapi/linux/ptrace.h: * On the successful completion, iov.len will be updated by the kernel,
include/uapi/linux/rds.h:#define	RDS_CMSG_ZCOPY_COMPLETION	13
include/uapi/linux/rio_mport_cdev.h: * access and has its own completion code.
include/uapi/linux/rio_mport_cdev.h:	__u32 completion_code;	/* Completion code for this transfer */
include/uapi/linux/target_core_user.h:#define TCMU_MAILBOX_FLAG_CAP_OOOC (1 << 0) /* Out-of-order completions */
include/uapi/linux/target_core_user.h:#define TCMU_MAILBOX_FLAG_CAP_KEEP_BUF (1<<3) /* Keep buf after cmd completion */
include/uapi/linux/usbdevice_fs.h:	unsigned int signr;	/* signal to be sent on completion,
include/uapi/linux/vboxguest.h:	 * Input: How long to wait (milliseconds) for completion before
include/uapi/linux/vfio.h: * completion to the root bus with supported widths provided via flags.
include/uapi/linux/virtio_scsi.h:	__u8 status;		/* Command completion status */
include/uapi/linux/xdp_diag.h:	XDP_DIAG_UMEM_COMPLETION_RING,
include/uapi/rdma/efa-abi.h:	EFA_CREATE_CQ_WITH_COMPLETION_CHANNEL = 1 << 0,
include/uapi/rdma/hfi/hfi1_ioctl.h:	/* base address of SDMA completion ring */
include/uapi/rdma/hfi/hfi1_user.h: * SDMA completion ring entry
include/uapi/rdma/hfi/hfi1_user.h:	 * Index of the slot in the SDMA completion ring
include/uapi/rdma/ib_user_verbs.h:	IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION = 1 << 0,
include/uapi/rdma/rdma_user_rxe.h: * completion queues shared between user space and kernel space.
include/uapi/rdma/rvt-abi.h: * and completion queue entries as a single memory allocation so
include/uapi/rdma/siw-abi.h:	SIW_NOTIFY_NEXT_COMPLETION = (1 << 1),
include/uapi/rdma/siw-abi.h:	SIW_NOTIFY_ALL = SIW_NOTIFY_SOLICITED | SIW_NOTIFY_NEXT_COMPLETION |
include/uapi/rdma/vmw_pvrdma-abi.h:/* Completion queue element. */
include/uapi/scsi/scsi_bsg_fc.h: * with the transport upon completion of the login.
include/uapi/scsi/scsi_bsg_fc.h:	 * The completion result. Result exists in two forms:
include/uapi/scsi/scsi_bsg_mpi3mr.h:	__le32	nvme_completion_entry[4];
include/uapi/scsi/scsi_bsg_ufs.h:	 * The completion result. Result exists in two forms:
include/ufs/ufshcd.h: * @done: UIC command completion
include/ufs/ufshcd.h:	struct completion done;
include/ufs/ufshcd.h: * @complete: internal commands completion
include/ufs/ufshcd.h:	struct completion *complete;
include/ufs/ufshcd.h: * @get_outstanding_cqs: called to get outstanding completion queues
include/ufs/ufshcd.h: * completion before gating clocks.
include/ufs/ufshcd.h: *		Clear after the first successful command completion.
include/ufs/ufshcd.h: * @uic_async_done: completion used during UIC processing
include/ufs/ufshcd.h:	struct completion *uic_async_done;
include/ufs/ufshcd.h: * @mcq_cq_head: base address of completion queue head pointer
include/ufs/ufshcd.h: * @mcq_cq_tail: base address of completion queue tail pointer
include/ufs/ufshcd.h: * @cqe_base_addr: completion queue base address
include/ufs/ufshcd.h: * @cqe_dma_addr: completion queue dma address
include/ufs/ufshci.h:/* MCQ Completion Queue Entry */
include/video/imx-ipu-image-convert.h: * @status:	completion status of this run
include/video/imx-ipu-image-convert.h: * @complete:	run completion callback
include/video/imx-ipu-image-convert.h: * @complete_context:	a context pointer for the completion callback
include/video/imx-ipu-image-convert.h: * to this context are returned via the completion callback with an
include/video/imx-ipu-image-convert.h: * completion callback. The caller is responsible for freeing the run
include/video/imx-ipu-image-convert.h: * returned via the completion callback with an error run status.
include/video/imx-ipu-image-convert.h: * @complete:	run completion callback
include/video/imx-ipu-image-convert.h: * @complete_context:	a context pointer for the completion callback
include/video/pm3fb.h:#define PM3WaitForCompletion					0x80b8
include/video/uvesafb.h:	struct completion *done;
include/xen/xenbus.h:#include <linux/completion.h>
include/xen/xenbus.h:	struct completion down;
init/Kconfig:	  resources like cpu, synchronous block I/O completion and swapping
init/Kconfig:	  completion rings that are shared between the kernel and application.
init/main.c:static __initdata DECLARE_COMPLETION(kthreadd_done);
init/main.c:	 * already, but it's stuck on the kthreadd_done completion.
init/main.c:	wait_for_completion(&kthreadd_done);
io_uring/cancel.c:	spin_lock(&ctx->completion_lock);
io_uring/cancel.c:	spin_unlock(&ctx->completion_lock);
io_uring/eventfd.c:	spin_lock(&ctx->completion_lock);
io_uring/eventfd.c:	spin_unlock(&ctx->completion_lock);
io_uring/eventfd.c:	spin_lock(&ctx->completion_lock);
io_uring/eventfd.c:	spin_unlock(&ctx->completion_lock);
io_uring/fdinfo.c:	spin_lock(&ctx->completion_lock);
io_uring/fdinfo.c:	spin_unlock(&ctx->completion_lock);
io_uring/futex.c:	 * let that side do the completion. Note that
io_uring/io-wq.c:	struct completion ref_done;
io_uring/io-wq.c:	struct completion worker_done;
io_uring/io-wq.c:	wait_for_completion(&worker->ref_done);
io_uring/io-wq.c:		 * can't make progress, any work completion or insertion will
io_uring/io-wq.c:	init_completion(&worker->ref_done);
io_uring/io-wq.c:	 * no completion will be posted for it.
io_uring/io-wq.c:	 * completion will run normally in this case.
io_uring/io-wq.c:	init_completion(&wq->worker_done);
io_uring/io-wq.c:	wait_for_completion(&wq->worker_done);
io_uring/io_uring.c: * Shared application/kernel submission and completion ring pairs, for
io_uring/io_uring.c:	io_submit_flush_completions(ctx);
io_uring/io_uring.c:	init_completion(&ctx->ref_comp);
io_uring/io_uring.c:	spin_lock_init(&ctx->completion_lock);
io_uring/io_uring.c:		spin_lock(&req->ctx->completion_lock);
io_uring/io_uring.c:		spin_unlock(&req->ctx->completion_lock);
io_uring/io_uring.c:		spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:		spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:		spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:	__acquires(ctx->completion_lock)
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:			spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	__releases(ctx->completion_lock)
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	lockdep_assert_held(&ctx->completion_lock);
io_uring/io_uring.c:	 * Force overflow the completion.
io_uring/io_uring.c:		spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:		spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	 * All execution paths but io-wq use the deferred completions by
io_uring/io_uring.c: * handlers and io_issue_sqe() are done with it, e.g. inline completion path.
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	io_submit_flush_completions(ctx);
io_uring/io_uring.c:	io_submit_flush_completions(ctx);
io_uring/io_uring.c:void __io_submit_flush_completions(struct io_ring_ctx *ctx)
io_uring/io_uring.c:				spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:				spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:		spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:		spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	 * submitter task context. Final request completions are handed to the
io_uring/io_uring.c:	/* flush only after queuing links as they can generate completions */
io_uring/io_uring.c:	io_submit_flush_completions(ctx);
io_uring/io_uring.c:			spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:			spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	 * to normal sleeps. Any request completion post min_wait should wake
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	struct completion		completion;
io_uring/io_uring.c:	complete(&work->completion);
io_uring/io_uring.c:	 * submitted async (out-of-line), then completions can come in while
io_uring/io_uring.c:		 * on completions, for example if someone does a SIGSTOP on
io_uring/io_uring.c:	} while (!wait_for_completion_interruptible_timeout(&ctx->ref_comp, interval));
io_uring/io_uring.c:	init_completion(&exit.completion);
io_uring/io_uring.c:		 * wait_for_completion_interruptible_timeout() on why this
io_uring/io_uring.c:		wait_for_completion_interruptible(&exit.completion);
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_lock(&ctx->completion_lock);
io_uring/io_uring.c:	spin_unlock(&ctx->completion_lock);
io_uring/io_uring.c:		/* read completions before cancelations */
io_uring/io_uring.c:		 * If we've seen completions, retry without waiting. This
io_uring/io_uring.c:		 * avoids a race where a completion comes in before we did
io_uring/io_uring.c:	 * For SQ polling, the thread will do all submissions and completions.
io_uring/io_uring.c:	 * space applications don't need to do io completion events
io_uring/io_uring.c:	 * For DEFER_TASKRUN we require the completion task to be the same as the
io_uring/io_uring.h:void __io_submit_flush_completions(struct io_ring_ctx *ctx);
io_uring/io_uring.h:		lockdep_assert_held(&ctx->completion_lock);
io_uring/io_uring.h:static inline void io_submit_flush_completions(struct io_ring_ctx *ctx)
io_uring/io_uring.h:		__io_submit_flush_completions(ctx);
io_uring/io_uring.h: * Don't complete immediately but use deferred completion infrastructure.
io_uring/kbuf.c:	 *    ctx->completion_lock.
io_uring/kbuf.c:		spin_lock(&ctx->completion_lock);
io_uring/kbuf.c:		spin_unlock(&ctx->completion_lock);
io_uring/kbuf.c:	spin_lock(&ctx->completion_lock);
io_uring/kbuf.c:	spin_unlock(&ctx->completion_lock);
io_uring/kbuf.c:	 * Completions that don't happen inline (eg not under uring_lock) will
io_uring/kbuf.c:	 * the completion list and splice those entries first.
io_uring/kbuf.c:		spin_lock(&ctx->completion_lock);
io_uring/kbuf.c:			spin_unlock(&ctx->completion_lock);
io_uring/kbuf.c:		spin_unlock(&ctx->completion_lock);
io_uring/kbuf.c:	 * No free buffers and no completion entries either. Allocate a new
io_uring/kbuf.h:	lockdep_assert_held(&req->ctx->completion_lock);
io_uring/net.c: * For bundle completions, we need to figure out how many segments we consumed.
io_uring/net.c:		 * list, and the eventual buffer put on completion then cannot
io_uring/net.c:		 * grab the sock_error() and use that for the completion.
io_uring/rw.c:	/* IO was queued async, completion will happen later */
io_uring/rw.c: * will register a callback when the page is unlocked at IO completion. Through
io_uring/rw.c:	 * Only spin for completions if we don't have multiple devices hanging
io_uring/rw.c:	__io_submit_flush_completions(ctx);
io_uring/sqpoll.c:	wait_for_completion(&sqd->exited);
io_uring/sqpoll.c:	init_completion(&sqd->exited);
io_uring/sqpoll.h:	struct completion	exited;
io_uring/timeout.c:	/* for linked completions */
io_uring/timeout.c:	__must_hold(&req->ctx->completion_lock)
io_uring/timeout.c:	__must_hold(&req->ctx->completion_lock)
io_uring/timeout.c:	__must_hold(&req->ctx->completion_lock)
io_uring/timeout.c:	__must_hold(&ctx->completion_lock)
io_uring/timeout.c:	 * race with the completion of the linked work.
io_uring/timeout.c:		spin_lock(&ctx->completion_lock);
io_uring/timeout.c:		spin_unlock(&ctx->completion_lock);
io_uring/timeout.c:	 * This is safe because ->completion_lock is held, and submissions
io_uring/timeout.c:	 * and completions are never mixed in the same ->completion_lock section.
io_uring/timeout.c:	 * completion_lock is needed for io_match_task(). Take it before
io_uring/timeout.c:	spin_lock(&ctx->completion_lock);
io_uring/timeout.c:	spin_unlock(&ctx->completion_lock);
io_uring/uring_cmd.c:	io_submit_flush_completions(ctx);
io_uring/uring_cmd.c: * with race between io_uring canceling and normal completion.
io_uring/uring_cmd.c:	/* task_work executor checks the deffered list completion */
ipc/sem.c:	int			status;	 /* completion status of operation */
kernel/acct.c:	struct completion	done;
kernel/acct.c:	wait_for_completion(&acct->done);
kernel/acct.c:	init_completion(&acct->done);
kernel/backtracetest.c:#include <linux/completion.h>
kernel/bpf/cpumap.c:#include <linux/completion.h>
kernel/bpf/cpumap.c:	struct completion kthread_running;
kernel/bpf/cpumap.c:	init_completion(&rcpu->kthread_running);
kernel/bpf/cpumap.c:	wait_for_completion(&rcpu->kthread_running);
kernel/bpf/helpers.c:	 * are ok, since nobody would synchronously wait for their completion.
kernel/bpf/syscall.c:	 * for the completions of these programs, but considering the waiting
kernel/cgroup/cgroup.c: * returns NULL.  On completion of iteration, css_task_iter_end() must be
kernel/cpu.c: * @done_up:	Signal completion to the issuer of the task for cpu-up
kernel/cpu.c: * @done_down:	Signal completion to the issuer of the task for cpu-down
kernel/cpu.c:	struct completion	done_up;
kernel/cpu.c:	struct completion	done_down;
kernel/cpu.c:	struct completion *done = bringup ? &st->done_up : &st->done_down;
kernel/cpu.c:	wait_for_completion(done);
kernel/cpu.c:	struct completion *done = bringup ? &st->done_up : &st->done_down;
kernel/cpu.c: * When complete or on error, should_run is cleared and the completion is fired.
kernel/cpu.c:		init_completion(&st->done_up);
kernel/cpu.c:		init_completion(&st->done_down);
kernel/cpu.c:	 * waiting for its completion.
kernel/debug/kdb/kdb_support.c: *	starts with this prefix (tab completion).
kernel/dma/map_benchmark.c:	/* wait for the completion of all started benchmark threads */
kernel/events/uprobes.c: * non-fatal signals until completion of singlestep.  When xol insn itself
kernel/events/uprobes.c: * mechanism. Set TIF_UPROBE flag and indicate completion of singlestep.
kernel/exit.c:#include <linux/completion.h>
kernel/fork.c:#include <linux/completion.h>
kernel/fork.c:	struct completion *vfork;
kernel/fork.c:				struct completion *vfork)
kernel/fork.c:	killed = wait_for_completion_state(vfork, state);
kernel/fork.c:	 * Also kthread_stop() uses this completion for synchronization.
kernel/fork.c:	struct completion vfork;
kernel/fork.c:		init_completion(&vfork);
kernel/futex/waitwake.c:	 * futex_queue() calls spin_unlock() upon completion, both serializing
kernel/irq/manage.c: *	disable_irq - disable an irq and wait for completion
kernel/irq/manage.c: *	disable_hardirq - disables an irq and waits for hardirq completion
kernel/irq/resend.c: * Especially on x86 this can cause a premature completion of an interrupt
kernel/kcsan/kcsan_test.c:		 * completion or failure.
kernel/kprobes.c:	/* Wait for unoptimizing completion. */
kernel/kthread.c:#include <linux/completion.h>
kernel/kthread.c:	struct completion *done;
kernel/kthread.c:	struct completion parked;
kernel/kthread.c:	struct completion exited;
kernel/kthread.c:	init_completion(&kthread->exited);
kernel/kthread.c:	init_completion(&kthread->parked);
kernel/kthread.c: * @comp: Completion to complete
kernel/kthread.c: * A kernel thread whose module may be removed after the completion of
kernel/kthread.c:void __noreturn kthread_complete_and_exit(struct completion *comp, long code)
kernel/kthread.c:	struct completion *done;
kernel/kthread.c:		struct completion *done = xchg(&create->done, NULL);
kernel/kthread.c:	DECLARE_COMPLETION_ONSTACK(done);
kernel/kthread.c:	 * Wait for completion in killable state, for I might be chosen by
kernel/kthread.c:	if (unlikely(wait_for_completion_killable(&done))) {
kernel/kthread.c:		wait_for_completion(&done);
kernel/kthread.c:		wait_for_completion(&kthread->parked);
kernel/kthread.c:	wait_for_completion(&kthread->exited);
kernel/kthread.c:	struct completion	done;
kernel/kthread.c:		COMPLETION_INITIALIZER_ONSTACK(fwork.done),
kernel/kthread.c:		wait_for_completion(&fwork.done);
kernel/kthread.c:		COMPLETION_INITIALIZER_ONSTACK(fwork.done),
kernel/kthread.c:	wait_for_completion(&fwork.done);
kernel/livepatch/core.c:#include <linux/completion.h>
kernel/livepatch/core.c:	wait_for_completion(&patch->finish);
kernel/livepatch/core.c:	init_completion(&patch->finish);
kernel/locking/test-ww_mutex.c:#include <linux/completion.h>
kernel/locking/test-ww_mutex.c:	struct completion ready, go, done;
kernel/locking/test-ww_mutex.c:	wait_for_completion(&mtx->go);
kernel/locking/test-ww_mutex.c:	init_completion(&mtx.ready);
kernel/locking/test-ww_mutex.c:	init_completion(&mtx.go);
kernel/locking/test-ww_mutex.c:	init_completion(&mtx.done);
kernel/locking/test-ww_mutex.c:	wait_for_completion(&mtx.ready);
kernel/locking/test-ww_mutex.c:			if (completion_done(&mtx.done)) {
kernel/locking/test-ww_mutex.c:		ret = wait_for_completion_timeout(&mtx.done, TIMEOUT);
kernel/locking/test-ww_mutex.c:	struct completion a_ready;
kernel/locking/test-ww_mutex.c:	struct completion b_ready;
kernel/locking/test-ww_mutex.c:	wait_for_completion(&abba->a_ready);
kernel/locking/test-ww_mutex.c:	init_completion(&abba.a_ready);
kernel/locking/test-ww_mutex.c:	init_completion(&abba.b_ready);
kernel/locking/test-ww_mutex.c:	wait_for_completion(&abba.b_ready);
kernel/locking/test-ww_mutex.c:	struct completion *a_signal;
kernel/locking/test-ww_mutex.c:	struct completion b_signal;
kernel/locking/test-ww_mutex.c:	wait_for_completion(&cycle->b_signal);
kernel/locking/test-ww_mutex.c:		init_completion(&cycle->b_signal);
kernel/module/dups.c:#include <linux/completion.h>
kernel/module/dups.c:	struct completion first_req_done;
kernel/module/dups.c:	init_completion(&new_kmod_req->first_req_done);
kernel/module/dups.c:	ret = wait_for_completion_state(&kmod_req->first_req_done,
kernel/module/dups.c:	 * with a slight delay here. So queueue up the completion
kernel/module/kmod.c:#include <linux/completion.h>
kernel/module/main.c:	struct completion complete;
kernel/module/main.c:	init_completion(&u->complete);
kernel/module/main.c: * the idempotent list, and the completion may still come in.
kernel/module/main.c: * the wait_for_completion and the cleanup.
kernel/module/main.c:static int idempotent_wait_for_completion(struct idempotent *u)
kernel/module/main.c:	if (wait_for_completion_interruptible(&u->complete)) {
kernel/module/main.c:	return idempotent_wait_for_completion(&idem);
kernel/module/sysfs.c:	DECLARE_COMPLETION_ONSTACK(c);
kernel/module/sysfs.c:	mod->mkobj.kobj_completion = &c;
kernel/module/sysfs.c:	wait_for_completion(&c);
kernel/padata.c:#include <linux/completion.h>
kernel/padata.c:	struct completion	completion;
kernel/padata.c:		complete(&ps->completion);
kernel/padata.c:	init_completion(&ps.completion);
kernel/padata.c:	wait_for_completion(&ps.completion);
kernel/params.c:	complete(mk->kobj_completion);
kernel/power/swap.c: *	@hb:		bio completion batch
kernel/rcu/rcu_segcblist.c: * will be fully ordered after the completion of the callback function,
kernel/rcu/rcu_segcblist.c:	 * whose ->gp_seq[] completion is at or after that passed in via
kernel/rcu/rcu_segcblist.c:	 * as their ->gp_seq[] grace-period completion sequence number.
kernel/rcu/rcu_segcblist.c:	 * ->gp_seq[] completion is at or after that passed in via "seq",
kernel/rcu/rcuscale.c:#include <linux/completion.h>
kernel/rcu/rcutorture.c:#include <linux/completion.h>
kernel/rcu/refscale.c:#include <linux/completion.h>
kernel/rcu/srcutiny.c: * synchronize_srcu - wait for prior SRCU read-side critical-section completion
kernel/rcu/srcutiny.c:	init_completion(&rs.completion);
kernel/rcu/srcutiny.c:	wait_for_completion(&rs.completion);
kernel/rcu/srcutree.c:	init_completion(&rcu.completion);
kernel/rcu/srcutree.c:	wait_for_completion(&rcu.completion);
kernel/rcu/srcutree.c: * synchronize_srcu - wait for prior SRCU read-side critical-section completion
kernel/rcu/srcutree.c:		complete(&ssp->srcu_sup->srcu_barrier_completion);
kernel/rcu/srcutree.c:	init_completion(&ssp->srcu_sup->srcu_barrier_completion);
kernel/rcu/srcutree.c:		complete(&ssp->srcu_sup->srcu_barrier_completion);
kernel/rcu/srcutree.c:	wait_for_completion(&ssp->srcu_sup->srcu_barrier_completion);
kernel/rcu/srcutree.c: * @ssp: srcu_struct on which to report batch completion.
kernel/rcu/tasks.h: * @barrier_q_completion: Barrier wait/wakeup mechanism.
kernel/rcu/tasks.h:	struct completion barrier_q_completion;
kernel/rcu/tasks.h:		complete(&rtp->barrier_q_completion);
kernel/rcu/tasks.h:	init_completion(&rtp->barrier_q_completion);
kernel/rcu/tasks.h:		complete(&rtp->barrier_q_completion);
kernel/rcu/tasks.h:	wait_for_completion(&rtp->barrier_q_completion);
kernel/rcu/tiny.c:#include <linux/completion.h>
kernel/rcu/tree.c:#include <linux/completion.h>
kernel/rcu/tree.c: * c. GP completion:
kernel/rcu/tree.c: * e. GP2 completion:
kernel/rcu/tree.c:	complete(&rs->completion);
kernel/rcu/tree.c:	 * completion (materialized by rnp->gp_seq update) thanks to the
kernel/rcu/tree.c:		 * new GP completion. If not(means nothing to detach), we are done
kernel/rcu/tree.c:		 * per-cpu flush_rcu_work() waits its completion(see last step).
kernel/rcu/tree.c:		 * directly. Wait its completion if running or pending.
kernel/rcu/tree.c:	init_completion(&rs.completion);
kernel/rcu/tree.c:	wait_for_completion(&rs.completion);
kernel/rcu/tree.c:		complete(&rcu_state.barrier_completion);
kernel/rcu/tree.c:	init_completion(&rcu_state.barrier_completion);
kernel/rcu/tree.c:		complete(&rcu_state.barrier_completion);
kernel/rcu/tree.c:	wait_for_completion(&rcu_state.barrier_completion);
kernel/rcu/tree.h:	struct completion barrier_completion;	/* Wake at barrier end. */
kernel/rcu/tree_exp.h:		 * Order GP completion with preceding accesses. Order also GP
kernel/rcu/tree_exp.h:		 * completion with post GP update side accesses. Pairs with
kernel/rcu/update.c:	complete(&rcu->completion);
kernel/rcu/update.c:			init_completion(&rs_array[i].completion);
kernel/rcu/update.c:			wait_for_completion_state(&rs_array[i].completion, state);
kernel/scftorture.c:#include <linux/completion.h>
kernel/scftorture.c:	struct completion scfc_completion;
kernel/scftorture.c:			complete(&scfcp->scfc_completion);
kernel/scftorture.c:		init_completion(&scfcp->scfc_completion);
kernel/scftorture.c:			wait_for_completion(&scfcp->scfc_completion);
kernel/sched/build_utility.c:#include "completion.c"
kernel/sched/completion.c: * Generic wait-for-completion handler;
kernel/sched/completion.c: * wait_for_completion default blocks whereas semaphore default non-block. The
kernel/sched/completion.c: * Waiting for completion is a typically sync point, but not an exclusion point.
kernel/sched/completion.c:static void complete_with_flags(struct completion *x, int wake_flags)
kernel/sched/completion.c:void complete_on_current_cpu(struct completion *x)
kernel/sched/completion.c: * complete: - signals a single thread waiting on this completion
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This will wake up a single thread waiting on this completion. Threads will be
kernel/sched/completion.c: * See also complete_all(), wait_for_completion() and related routines.
kernel/sched/completion.c:void complete(struct completion *x)
kernel/sched/completion.c: * complete_all: - signals all threads waiting on this completion
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This will wake up all threads waiting on this particular completion event.
kernel/sched/completion.c: * Since complete_all() sets the completion of @x permanently to done
kernel/sched/completion.c: * to allow multiple waiters to finish, a call to reinit_completion()
kernel/sched/completion.c: * @x. Also note that the function completion_done() can not be used
kernel/sched/completion.c:void complete_all(struct completion *x)
kernel/sched/completion.c:do_wait_for_common(struct completion *x,
kernel/sched/completion.c:__wait_for_common(struct completion *x,
kernel/sched/completion.c:wait_for_common(struct completion *x, long timeout, int state)
kernel/sched/completion.c:wait_for_common_io(struct completion *x, long timeout, int state)
kernel/sched/completion.c: * wait_for_completion: - waits for completion of a task
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits to be signaled for completion of a specific task. It is NOT
kernel/sched/completion.c: * See also similar routines (i.e. wait_for_completion_timeout()) with timeout
kernel/sched/completion.c:void __sched wait_for_completion(struct completion *x)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion);
kernel/sched/completion.c: * wait_for_completion_timeout: - waits for completion of a task (w/timeout)
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits for either a completion of a specific task to be signaled or for a
kernel/sched/completion.c:wait_for_completion_timeout(struct completion *x, unsigned long timeout)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_timeout);
kernel/sched/completion.c: * wait_for_completion_io: - waits for completion of a task
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits to be signaled for completion of a specific task. It is NOT
kernel/sched/completion.c:void __sched wait_for_completion_io(struct completion *x)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_io);
kernel/sched/completion.c: * wait_for_completion_io_timeout: - waits for completion of a task (w/timeout)
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits for either a completion of a specific task to be signaled or for a
kernel/sched/completion.c:wait_for_completion_io_timeout(struct completion *x, unsigned long timeout)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_io_timeout);
kernel/sched/completion.c: * wait_for_completion_interruptible: - waits for completion of a task (w/intr)
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits for completion of a specific task to be signaled. It is
kernel/sched/completion.c:int __sched wait_for_completion_interruptible(struct completion *x)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_interruptible);
kernel/sched/completion.c: * wait_for_completion_interruptible_timeout: - waits for completion (w/(to,intr))
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits for either a completion of a specific task to be signaled or for a
kernel/sched/completion.c:wait_for_completion_interruptible_timeout(struct completion *x,
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_interruptible_timeout);
kernel/sched/completion.c: * wait_for_completion_killable: - waits for completion of a task (killable)
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits to be signaled for completion of a specific task. It can be
kernel/sched/completion.c:int __sched wait_for_completion_killable(struct completion *x)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_killable);
kernel/sched/completion.c:int __sched wait_for_completion_state(struct completion *x, unsigned int state)
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_state);
kernel/sched/completion.c: * wait_for_completion_killable_timeout: - waits for completion of a task (w/(to,killable))
kernel/sched/completion.c: * @x:  holds the state of this particular completion
kernel/sched/completion.c: * This waits for either a completion of a specific task to be
kernel/sched/completion.c:wait_for_completion_killable_timeout(struct completion *x,
kernel/sched/completion.c:EXPORT_SYMBOL(wait_for_completion_killable_timeout);
kernel/sched/completion.c: *	try_wait_for_completion - try to decrement a completion without blocking
kernel/sched/completion.c: *	@x:	completion structure
kernel/sched/completion.c: *	If a completion is being used as a counting completion,
kernel/sched/completion.c: *	enables us to avoid waiting if the resource the completion
kernel/sched/completion.c:bool try_wait_for_completion(struct completion *x)
kernel/sched/completion.c:EXPORT_SYMBOL(try_wait_for_completion);
kernel/sched/completion.c: *	completion_done - Test to see if a completion has any waiters
kernel/sched/completion.c: *	@x:	completion structure
kernel/sched/completion.c: *	Return: 0 if there are waiters (wait_for_completion() in progress)
kernel/sched/completion.c:bool completion_done(struct completion *x)
kernel/sched/completion.c:	 * otherwise we can end up freeing the completion before complete()
kernel/sched/completion.c:EXPORT_SYMBOL(completion_done);
kernel/sched/core.c: * @refs: number of wait_for_completion()
kernel/sched/core.c:	struct completion	done;
kernel/sched/core.c: *                         `--> <woken on migration completion>
kernel/sched/core.c: * a completion signaled at the tail of the CPU stopper callback (1), triggered
kernel/sched/core.c: * (1) In the cases covered above. There is one more where the completion is
kernel/sched/core.c: *                                                         <signal completion>
kernel/sched/core.c: * pending affinity completion is preceded by an uninstallation of
kernel/sched/core.c:			init_completion(&my_pending.done);
kernel/sched/core.c:			 * we risk a completion of the pending despite having a
kernel/sched/core.c:	 *   pending completion.
kernel/sched/core.c:	wait_for_completion(&pending->done);
kernel/sched/core.c:	 * have seen the completion and decremented the refcount
kernel/sched/cpufreq_schedutil.c: * utilization boosted to speed up the completion of those IO operations.
kernel/sched/fair.c:	 * throttled-list.  rq->lock protects completion.
kernel/sched/fair.c:	 * pattern is IO completions.
kernel/sched/swait.c: * completions and not for general usage.
kernel/seccomp.c:	struct completion ready;
kernel/seccomp.c: * @completion: Indicates that the installing process has completed fd
kernel/seccomp.c:	struct completion completion;
kernel/seccomp.c:	complete(&addfd->completion);
kernel/seccomp.c:	init_completion(&n.ready);
kernel/seccomp.c:			err = wait_for_completion_killable(&n.ready);
kernel/seccomp.c:			err = wait_for_completion_interruptible(&n.ready);
kernel/seccomp.c:		complete(&addfd->completion);
kernel/seccomp.c:	init_completion(&kaddfd.completion);
kernel/seccomp.c:	ret = wait_for_completion_interruptible(&kaddfd.completion);
kernel/seccomp.c:		 * We had a successful completion. The other side has already
kernel/seccomp.c:		 * wait_for_completion_interruptible has a memory barrier upon
kernel/seccomp.c:	 * completion, a completion may have happened in the mean time.
kernel/signal.c: * %true if group stop completion should be notified to the parent, %false
kernel/signal.c:	 * Tell the caller to notify completion iff we are entering into a
kernel/signal.c: * see the address it was expecting for it's completions.
kernel/signal.c: * expirations or I/O completions".  In the case of POSIX Timers
kernel/signal.c:	 * interested in the completion of group stop.  The states
kernel/signal.c:		 * Notify the parent of the group stop completion.  Because
kernel/smp.c: * @done: &completion to signal
kernel/smp.c:	struct completion	done;
kernel/smp.c:		.done = COMPLETION_INITIALIZER_ONSTACK(sscs.done),
kernel/smp.c:	wait_for_completion(&sscs.done);
kernel/stop_machine.c:#include <linux/completion.h>
kernel/stop_machine.c: * Structure to determine completion condition and record errors.  May
kernel/stop_machine.c:	struct completion	completion;	/* fired if nr_todo reaches 0 */
kernel/stop_machine.c:	init_completion(&done->completion);
kernel/stop_machine.c:/* signal completion unless @done is NULL */
kernel/stop_machine.c:		complete(&done->completion);
kernel/stop_machine.c:	wait_for_completion(&done.completion);
kernel/stop_machine.c:	wait_for_completion(&done.completion);
kernel/stop_machine.c: * stop_one_cpu_nowait - stop a cpu but don't wait for completion
kernel/stop_machine.c: * Similar to stop_one_cpu() but doesn't wait for completion.  The
kernel/stop_machine.c:	wait_for_completion(&done.completion);
kernel/stop_machine.c:	/* Busy wait for completion. */
kernel/stop_machine.c:	while (!completion_done(&done.completion))
kernel/time/timer.c: * not hold locks which would prevent completion of the timer's callback
kernel/torture.c:#include <linux/completion.h>
kernel/trace/preemptirq_delay_test.c:#include <linux/completion.h>
kernel/trace/preemptirq_delay_test.c:static struct completion done;
kernel/trace/preemptirq_delay_test.c:	init_completion(&done);
kernel/trace/preemptirq_delay_test.c:		wait_for_completion(&done);
kernel/trace/ring_buffer.c:	struct completion		update_done;
kernel/trace/ring_buffer.c:	init_completion(&cpu_buffer->update_done);
kernel/trace/ring_buffer.c:				wait_for_completion(&cpu_buffer->update_done);
kernel/trace/ring_buffer.c:				wait_for_completion(&cpu_buffer->update_done);
kernel/trace/ring_buffer_benchmark.c:#include <linux/completion.h>
kernel/trace/ring_buffer_benchmark.c:static DECLARE_COMPLETION(read_start);
kernel/trace/ring_buffer_benchmark.c:static DECLARE_COMPLETION(read_done);
kernel/trace/ring_buffer_benchmark.c:	 * and is ready for the completion.
kernel/trace/ring_buffer_benchmark.c:		/* Init both completions here to avoid races */
kernel/trace/ring_buffer_benchmark.c:		init_completion(&read_start);
kernel/trace/ring_buffer_benchmark.c:		init_completion(&read_done);
kernel/trace/ring_buffer_benchmark.c:		/* the completions must be visible before the finish var */
kernel/trace/ring_buffer_benchmark.c:		wait_for_completion(&read_done);
kernel/trace/ring_buffer_benchmark.c:			wait_for_completion(&read_start);
kernel/trace/trace_selftest.c:	struct completion	is_ready;
kernel/trace/trace_selftest.c:	init_completion(&data.is_ready);
kernel/trace/trace_selftest.c:	wait_for_completion(&data.is_ready);
kernel/trace/trace_selftest.c:	init_completion(&data.is_ready);
kernel/trace/trace_selftest.c:	wait_for_completion(&data.is_ready);
kernel/umh.c:#include <linux/completion.h>
kernel/umh.c:	struct completion *comp = xchg(&sub_info->complete, NULL);
kernel/umh.c:	DECLARE_COMPLETION_ONSTACK(done);
kernel/umh.c:	 * Set the completion pointer only if there is a waiter.
kernel/umh.c:		retval = wait_for_completion_state(&done, state | TASK_KILLABLE);
kernel/umh.c:		 * wait_for_completion_state(). Since umh_complete() shall call
kernel/umh.c:		 * uninterruptible wait_for_completion_state() will not block
kernel/umh.c:	wait_for_completion_state(&done, state);
kernel/vhost_task.c:#include <linux/completion.h>
kernel/vhost_task.c:	struct completion exited;
kernel/vhost_task.c:	wait_for_completion(&vtsk->exited);
kernel/vhost_task.c:	init_completion(&vtsk->exited);
kernel/watchdog.c:static DEFINE_PER_CPU(struct completion, softlockup_completion);
kernel/watchdog.c:	complete(this_cpu_ptr(&softlockup_completion));
kernel/watchdog.c:	if (completion_done(this_cpu_ptr(&softlockup_completion))) {
kernel/watchdog.c:		reinit_completion(this_cpu_ptr(&softlockup_completion));
kernel/watchdog.c:	struct completion *done = this_cpu_ptr(&softlockup_completion);
kernel/watchdog.c:	init_completion(done);
kernel/watchdog.c:	wait_for_completion(this_cpu_ptr(&softlockup_completion));
kernel/workqueue.c:#include <linux/completion.h>
kernel/workqueue.c:	struct completion	done;		/* flush completion */
kernel/workqueue.c:	 * @worker is waiting on a completion in kthread() and will trigger hung
kernel/workqueue.c:	struct completion	done;
kernel/workqueue.c:		init_completion(&dead_work.done);
kernel/workqueue.c:		wait_for_completion(&dead_work.done);
kernel/workqueue.c:	struct completion	done;
kernel/workqueue.c:	init_completion_map(&barr->done, &target->lockdep_map);
kernel/workqueue.c: * __flush_workqueue - ensure that any scheduled work has run to completion.
kernel/workqueue.c:		.done = COMPLETION_INITIALIZER_ONSTACK_MAP(this_flusher.done, (*wq->lockdep_map)),
kernel/workqueue.c:		 * The next flush completion will assign us
kernel/workqueue.c:	wait_for_completion(&this_flusher.done);
kernel/workqueue.c:			while (!try_wait_for_completion(&barr.done)) {
kernel/workqueue.c:	wait_for_completion(&barr.done);
kernel/workqueue.c:	lock_name = kasprintf(GFP_KERNEL, "%s%s", "(wq_completion)", wq->name);
lib/asn1_decoder.c:			pr_err("ASN.1 decoder error: Stacks not empty at completion (%u, %u)\n",
lib/assoc_array.c: * array will be empty and ready to use again upon completion.  This function
lib/cpumask.c: * Return: >= nr_cpu_ids on completion
lib/dim/rdma_dim.c:void rdma_dim(struct dim *dim, u64 completions)
lib/dim/rdma_dim.c:				     curr_sample->comp_ctr + completions,
lib/dynamic_queue_limits.c:		 * jiffies without any Tx completions, but during first half
lib/dynamic_queue_limits.c:		/* Newest sample we should have already seen a completion for */
lib/dynamic_queue_limits.c:		 *     may have becomes starved between completion processing
lib/dynamic_queue_limits.c:		 * completion routine.
lib/irq_poll.c: * @weight:   The default weight (or command completion budget)
lib/kunit/platform-test.c:	DECLARE_COMPLETION_ONSTACK(comp);
lib/kunit/platform-test.c:	KUNIT_EXPECT_NE(test, 0, wait_for_completion_timeout(&comp, 3 * HZ));
lib/kunit/platform-test.c: * Test that kunit_platform_device_prepare_wait_for_probe() completes the completion
lib/kunit/platform-test.c:	DECLARE_COMPLETION_ONSTACK(comp);
lib/kunit/platform-test.c:	KUNIT_ASSERT_NE(test, 0, wait_for_completion_timeout(&comp, 3 * HZ));
lib/kunit/platform-test.c:	reinit_completion(&comp);
lib/kunit/platform-test.c:	KUNIT_EXPECT_NE(test, 0, wait_for_completion_timeout(&comp, HZ));
lib/kunit/platform.c:#include <linux/completion.h>
lib/kunit/platform.c:	struct completion *x;
lib/kunit/platform.c: * kunit_platform_device_prepare_wait_for_probe() - Prepare a completion
lib/kunit/platform.c: * @x: completion variable completed when @dev has probed
lib/kunit/platform.c: * Prepare a completion variable @x to wait for @pdev to probe. Waiting on the
lib/kunit/platform.c: * completion forces a preemption, allowing the platform driver to probe.
lib/kunit/platform.c: *		DECLARE_COMPLETION_ONSTACK(comp);
lib/kunit/platform.c: *		KUNIT_EXPECT_NE(test, 0, wait_for_completion_timeout(&comp, 3 * HZ));
lib/kunit/platform.c:						 struct completion *x)
lib/kunit/try-catch.c:#include <linux/completion.h>
lib/kunit/try-catch.c:	struct completion *task_done;
lib/kunit/try-catch.c:	time_remaining = wait_for_completion_timeout(task_done,
lib/maple_tree.c: * Upon completion, check the left-most node and rebalance against the node to
lib/percpu-refcount.c:	 * its completion.  If the caller ensures that ATOMIC switching
lib/percpu-refcount.c: * be collected to the main atomic counter.  On completion, when all CPUs
lib/sbitmap.c:	atomic_set(&sbq->completion_cnt, 0);
lib/sbitmap.c:	atomic_add(nr, &sbq->completion_cnt);
lib/sbitmap.c:		if (atomic_read(&sbq->completion_cnt) - wakeups < wake_batch)
lib/test_firmware.c:#include <linux/completion.h>
lib/test_firmware.c:	struct completion completion;
lib/test_firmware.c:static DECLARE_COMPLETION(async_fw_done);
lib/test_firmware.c:	wait_for_completion(&async_fw_done);
lib/test_firmware.c:	wait_for_completion(&async_fw_done);
lib/test_firmware.c:	complete(&req->completion);
lib/test_firmware.c:		init_completion(&req->completion);
lib/test_firmware.c:			wait_for_completion(&req->completion);
lib/test_firmware.c:	complete(&req->completion);
lib/test_firmware.c:		init_completion(&req->completion);
lib/test_firmware.c:			wait_for_completion(&req->completion);
lib/test_kmod.c: * @kthreads_done: completion used to signal when all work is done
lib/test_kmod.c:	struct completion kthreads_done;
lib/test_kmod.c:		wait_for_completion(&test_dev->kthreads_done);
lib/test_kmod.c:	init_completion(&test_dev->kthreads_done);
lib/test_objpool.c:#include <linux/completion.h>
lib/test_objpool.c:	struct completion wait;
lib/test_objpool.c:	struct completion rcu;
lib/test_objpool.c:	init_completion(&data->wait);
lib/test_objpool.c:	init_completion(&data->rcu);
lib/test_objpool.c:	wait_for_completion(&test->data.wait);
lib/test_objpool.c:	wait_for_completion(&test->data.wait);
lib/test_objpool.c:	wait_for_completion(&test->data.rcu);
lib/test_vmalloc.c:#include <linux/completion.h>
lib/test_vmalloc.c: * Completion tracking for worker threads.
lib/test_vmalloc.c:static DECLARE_COMPLETION(test_all_done_comp);
lib/test_vmalloc.c:	 * why we go with completion_timeout and HZ value.
lib/test_vmalloc.c:		ret = wait_for_completion_timeout(&test_all_done_comp, HZ);
lib/vdso/getrandom.c:	 * its completion before returning execution.
lib/zlib_dfltcc/dfltcc.c:        return NULL; /* Successful completion */
mm/backing-dev.c:	err = fprop_local_init_percpu(&wb->completions, gfp);
mm/backing-dev.c:		fprop_local_destroy_percpu(&wb->completions);
mm/backing-dev.c:	fprop_local_destroy_percpu(&wb->completions);
mm/backing-dev.c:	fprop_local_destroy_percpu(&wb->memcg_completions);
mm/backing-dev.c:	ret = fprop_local_init_percpu(&wb->memcg_completions, gfp);
mm/backing-dev.c:	fprop_local_destroy_percpu(&wb->memcg_completions);
mm/damon/core.c:	init_completion(&ctx->kdamond_started);
mm/damon/core.c:		reinit_completion(&ctx->kdamond_started);
mm/damon/core.c:			wait_for_completion(&ctx->kdamond_started);
mm/madvise.c: * Schedule all required I/O operations.  Do not wait for completion.
mm/memcontrol.c:			__WB_COMPLETION_INIT(&memcg_cgwb_frn_waitq);
mm/memcontrol.c:		wb_wait_for_completion(&memcg->cgwb_frn[i].done);
mm/memory-failure.c:	 * the folio lock. We need to wait for writeback completion for this
mm/memory.c:	/* Incomplete faults will be accounted upon completion. */
mm/memremap.c:	wait_for_completion(&pgmap->done);
mm/memremap.c:	init_completion(&pgmap->done);
mm/migrate.c: * This function doesn't wait the completion of hugepage I/O
mm/mm_init.c:/* Completion tracking for deferred_init_memmap() threads */
mm/mm_init.c:static __initdata DECLARE_COMPLETION(pgdat_init_all_done_comp);
mm/mm_init.c:	wait_for_completion(&pgdat_init_all_done_comp);
mm/mmu_gather.c: * IRQs delays the completion of the TLB flush we can never observe an already
mm/page-writeback.c:	struct fprop_local_percpu *wb_completions;
mm/page-writeback.c:#define VM_COMPLETIONS_PERIOD_LEN (3*HZ)
mm/page-writeback.c:				.wb_completions = &(__wb)->completions
mm/page-writeback.c:				.wb_completions = &(__wb)->memcg_completions, \
mm/page-writeback.c:static struct fprop_local_percpu *wb_memcg_completions(struct bdi_writeback *wb)
mm/page-writeback.c:	return &wb->memcg_completions;
mm/page-writeback.c:				.wb_completions = &(__wb)->completions
mm/page-writeback.c:static struct fprop_local_percpu *wb_memcg_completions(struct bdi_writeback *wb)
mm/page-writeback.c:	cur_time += VM_COMPLETIONS_PERIOD_LEN;
mm/page-writeback.c:				   struct fprop_local_percpu *completions,
mm/page-writeback.c:	__fprop_add_percpu_max(&dom->completions, completions,
mm/page-writeback.c: * Increment @wb's writeout completion count and the global writeout
mm/page-writeback.c: * completion count. Called from __folio_end_writeback().
mm/page-writeback.c:	wb_domain_writeout_add(&global_wb_domain, &wb->completions,
mm/page-writeback.c:		wb_domain_writeout_add(cgdom, wb_memcg_completions(wb),
mm/page-writeback.c:						 VM_COMPLETIONS_PERIOD_LEN;
mm/page-writeback.c:	if (fprop_new_period(&dom->completions, miss_periods + 1)) {
mm/page-writeback.c:				miss_periods * VM_COMPLETIONS_PERIOD_LEN);
mm/page-writeback.c:	return fprop_global_init(&dom->completions, gfp);
mm/page-writeback.c:	fprop_global_destroy(&dom->completions);
mm/page-writeback.c:	fprop_fraction_percpu(&dom->completions, dtc->wb_completions,
mm/page-writeback.c:	 * IO completion doesn't do it at all (to make sure written pages are
mm/page-writeback.c:void laptop_io_completion(struct backing_dev_info *info)
mm/page-writeback.c: * caused another writeback to be scheduled by laptop_io_completion.
mm/page-writeback.c:void laptop_sync_completion(void)
mm/page_alloc.c:			 * from IRQ or SoftIRQ context after an IO completion.
mm/shmem.c: * standard mutex or completion: but we cannot take i_rwsem in fault,
mm/shrinker.c:	init_completion(&shrinker->done);
mm/shrinker.c:		wait_for_completion(&shrinker->done);
mm/swapfile.c:#include <linux/completion.h>
mm/swapfile.c:	wait_for_completion(&p->comp);
mm/swapfile.c:	init_completion(&p->comp);
mm/vmscan.c:	 * Stall direct reclaim for IO completions if the lruvec is
mm/zswap.c:	 * then wait for its completion synchronously. This makes the process look
net/8021q/vlan.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/9p/trans_rdma.c: * @cq: Completion Queue pointer
net/9p/trans_rdma.c: * @cm_done: Completion event for connection management tracking
net/9p/trans_rdma.c:	struct completion cm_done;
net/9p/trans_rdma.c: * @cqe: completion queue entry
net/9p/trans_rdma.c:	init_completion(&rdma->cm_done);
net/9p/trans_rdma.c:	err = wait_for_completion_interruptible(&rdma->cm_done);
net/9p/trans_rdma.c:	err = wait_for_completion_interruptible(&rdma->cm_done);
net/9p/trans_rdma.c:	/* Create the Completion Queue */
net/9p/trans_rdma.c:	err = wait_for_completion_interruptible(&rdma->cm_done);
net/bluetooth/coredump.c: *              can signal the completion using hci_devcd_complete(). A
net/bluetooth/coredump.c: *              devcoredump is generated indicating the completion event and
net/bluetooth/hci_event.c:	 * request completion callbacks used for connecting.
net/bluetooth/hci_event.c:	 * request completion callbacks used for connecting.
net/bluetooth/hci_event.c:		 * progress, then change discovery state to indicate completion.
net/bluetooth/hci_event.c:		 * state to indicate completion.
net/bluetooth/hci_event.c:		 * progress, then change discovery state to indicate completion.
net/bluetooth/hci_event.c:		 * state to indicate completion.
net/bluetooth/hci_event.c:	/* Indicate request completion if the command failed. Also, if
net/bluetooth/hci_event.c:	 * request completion callbacks used for connecting.
net/bluetooth/mgmt.c:	/* Report any errors here, but don't report completion */
net/bridge/br.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/can/af_can.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/can/gw.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/can/j1939/transport.c:/* session completion functions */
net/ceph/mon_client.c:	init_completion(&req->completion);
net/ceph/mon_client.c:		complete_all(&req->completion);
net/ceph/mon_client.c:	ret = wait_for_completion_interruptible(&req->completion);
net/ceph/osd_client.c:	init_completion(&req->r_completion);
net/ceph/osd_client.c:	complete_all(&req->r_completion);
net/ceph/osd_client.c:	queue_work(req->r_osdc->completion_wq, &req->r_complete_work);
net/ceph/osd_client.c:	complete_all(&req->r_completion);
net/ceph/osd_client.c:	init_completion(&lreq->reg_commit_wait);
net/ceph/osd_client.c:	init_completion(&lreq->notify_finish_wait);
net/ceph/osd_client.c:	if (!completion_done(&lreq->reg_commit_wait)) {
net/ceph/osd_client.c:	ret = wait_for_completion_killable(&lreq->reg_commit_wait);
net/ceph/osd_client.c:	left = wait_for_completion_killable_timeout(&lreq->notify_finish_wait,
net/ceph/osd_client.c:		} else if (!completion_done(&lreq->notify_finish_wait)) {
net/ceph/osd_client.c:	left = wait_for_completion_killable_timeout(&req->r_completion,
net/ceph/osd_client.c:			wait_for_completion(&req->r_completion);
net/ceph/osd_client.c:	osdc->completion_wq = create_singlethread_workqueue("ceph-completion");
net/ceph/osd_client.c:	if (!osdc->completion_wq)
net/ceph/osd_client.c:	destroy_workqueue(osdc->completion_wq);
net/core/dev.c:	skb->next = __this_cpu_read(softnet_data.completion_queue);
net/core/dev.c:	__this_cpu_write(softnet_data.completion_queue, skb);
net/core/dev.c:	if (sd->completion_queue) {
net/core/dev.c:		clist = sd->completion_queue;
net/core/dev.c:		sd->completion_queue = NULL;
net/core/dev.c:	/* Find end of our completion_queue. */
net/core/dev.c:	list_skb = &sd->completion_queue;
net/core/dev.c:	/* Append completion queue from offline CPU. */
net/core/dev.c:	*list_skb = oldsd->completion_queue;
net/core/dev.c:	oldsd->completion_queue = NULL;
net/core/netpoll.c:static void zap_completion_queue(void);
net/core/netpoll.c:	zap_completion_queue();
net/core/netpoll.c:static void zap_completion_queue(void)
net/core/netpoll.c:	if (sd->completion_queue) {
net/core/netpoll.c:		clist = sd->completion_queue;
net/core/netpoll.c:		sd->completion_queue = NULL;
net/core/netpoll.c:	zap_completion_queue();
net/core/page_pool.c: * completion loop for the XDP_REDIRECT use case.
net/core/pktgen.c:	struct completion start_done;
net/core/pktgen.c:	init_completion(&t->start_done);
net/core/pktgen.c:	wait_for_completion(&t->start_done);
net/core/selftests.c:	struct completion comp;
net/core/selftests.c:	init_completion(&tpriv->comp);
net/core/selftests.c:	wait_for_completion_timeout(&tpriv->comp, attr->timeout);
net/core/skbuff.c:		/* We usually free the clone (TX completion) before original skb
net/core/skbuff.c:	 * so do not queue a completion notification
net/dccp/output.c:		 * See 8.1.5 - Handshake Completion.
net/dsa/dsa.c: * blocking that operation from completion, due to the dev_hold taken inside
net/ethtool/cmis.h: * @max_completion_time:  Maximum CDB command completion time in msec.
net/ethtool/cmis.h:	u16     max_completion_time;
net/ethtool/cmis.h:#define CDB_F_COMPLETION_VALID		BIT(0)
net/ethtool/cmis.h: * @max_duration: Maximum duration time for command completion in msec.
net/ethtool/cmis.h:void ethtool_cmis_cdb_check_completion_flag(u8 cmis_rev, u8 *flags);
net/ethtool/cmis_cdb.c:				      CDB_F_COMPLETION_VALID | CDB_F_STATUS_VALID);
net/ethtool/cmis_cdb.c:/* Some CDB commands asserts the CDB completion flag only from CMIS
net/ethtool/cmis_cdb.c:void ethtool_cmis_cdb_check_completion_flag(u8 cmis_rev, u8 *flags)
net/ethtool/cmis_cdb.c:	*flags |= cmis_rev >= 5 ? CDB_F_COMPLETION_VALID : 0;
net/ethtool/cmis_cdb.c:	__be16	max_completion_time;
net/ethtool/cmis_cdb.c:cmis_cdb_module_features_completion_time(struct cmis_cdb_module_features_rpl *rpl)
net/ethtool/cmis_cdb.c:	return be16_to_cpu(rpl->max_completion_time);
net/ethtool/cmis_cdb.c:	ethtool_cmis_cdb_check_completion_flag(cdb->cmis_rev, &flags);
net/ethtool/cmis_cdb.c:	cdb->max_completion_time =
net/ethtool/cmis_cdb.c:		cmis_cdb_module_features_completion_time(rpl);
net/ethtool/cmis_cdb.c:#define CMIS_CDB_COMPLETION_FLAG_OFFSET	0x08
net/ethtool/cmis_cdb.c:static int cmis_cdb_wait_for_completion(struct net_device *dev,
net/ethtool/cmis_cdb.c:	/* Some vendors demand waiting time before checking completion flag
net/ethtool/cmis_cdb.c:					 CDB_F_COMPLETION_VALID,
net/ethtool/cmis_cdb.c:					 CMIS_CDB_COMPLETION_FLAG_OFFSET,
net/ethtool/cmis_cdb.c:		args->err_msg = "Completion Flag did not set on time";
net/ethtool/cmis_cdb.c:	err = cmis_cdb_wait_for_completion(dev, args);
net/ethtool/cmis_fw_update.c:	ethtool_cmis_cdb_check_completion_flag(cdb->cmis_rev, &flags);
net/ethtool/cmis_fw_update.c:				      NULL, 0, cdb->max_completion_time,
net/ethtool/cmis_fw_update.c:				      CDB_F_COMPLETION_VALID | CDB_F_STATUS_VALID);
net/ethtool/cmis_fw_update.c:					      CDB_F_COMPLETION_VALID | CDB_F_STATUS_VALID);
net/ethtool/cmis_fw_update.c:				      CDB_F_COMPLETION_VALID | CDB_F_STATUS_VALID);
net/ethtool/cmis_fw_update.c:				      cdb->max_completion_time,
net/ethtool/cmis_fw_update.c:				      NULL, 0, cdb->max_completion_time,
net/ethtool/cmis_fw_update.c:				      CDB_F_COMPLETION_VALID | CDB_F_STATUS_VALID);
net/handshake/handshake-test.c:	 * completion before checking the result.
net/handshake/request.c: * exactly one subsequent completion callback is guaranteed.
net/handshake/request.c: * no completion callback will be done and that @req has been
net/handshake/request.c: * Request cancellation races with request completion. To determine
net/handshake/tlshd.c: * Request cancellation races with request completion. To determine
net/ipv4/inet_fragment.c:	init_completion(&f->completion);
net/ipv4/inet_fragment.c:		complete(&f->completion);
net/ipv4/inet_fragment.c:	wait_for_completion(&f->completion);
net/ipv4/inet_fragment.c:			complete(&f->completion);
net/ipv4/tcp.c: *		A.N.Kuznetsov	:	Don't time wait on completion of tidy
net/ipv4/tcp.c: * Because TX completion will happen shortly, it gives a chance
net/ipv4/tcp.c: * or if TX completion was delayed after we processed ACK packet.
net/ipv4/tcp.c:		/* It is possible TX completion already happened
net/ipv4/tcp_offload.c:	 * is freed at TX completion, and not right now when gso_skb
net/ipv4/tcp_output.c:	 *    Delays in TX completion can defeat the test
net/ipv4/tcp_output.c:		 * No need to wait for TX completion to call us back,
net/ipv4/tcp_output.c:		 * This helps when TX completions are delayed too much.
net/ipv4/tcp_output.c:		/* It is possible TX completion already happened
net/ipv4/tcp_vegas.c: * Instead we must wait until the completion of an RTT during
net/ipv4/udp.c: * Otherwise, csum completion requires checksumming packet body,
net/ipv6/sit.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/iucv/af_iucv.c:	/* increment and save iucv message tag for msg_completion cbk */
net/iucv/iucv.c:	 *	0x20 - Flag to allow nonpriority message completion interrupts
net/iucv/iucv.c:	 *	0x10 - Flag to allow priority message completion interrupts
net/mac80211/agg-tx.c: * setup completion.
net/mac80211/agg-tx.c: * the peer, the driver is notified of the completion of the
net/mac80211/main.c:	 * for local reasons (longer buffers, longer completion time, or
net/mac80211/scan.c:	 * We have a scan running and the driver already reported completion,
net/mac80211/util.c:	/* It's possible that we don't handle the scan completion in
net/mac802154/ieee802154_i.h:	struct completion assoc_done;
net/mac802154/llsec.c:#include <linux/completion.h>
net/mac802154/main.c:	init_completion(&local->assoc_done);
net/mac802154/scan.c:/* mac802154_scan_cleanup_locked() must be called upon scan completion or abort.
net/mac802154/scan.c: * - Completions are asynchronous, not locked by the rtnl and decided by the
net/mac802154/scan.c:	reinit_completion(&local->assoc_done);
net/mac802154/scan.c:	ret = wait_for_completion_killable_timeout(&local->assoc_done, 10 * HZ);
net/mptcp/fastopen.c:	 * completion, if needed
net/netfilter/ipvs/ip_vs_sed.c: * completion. The expected delay that the job will experience is
net/netfilter/ipvs/ip_vs_sed.c: * minimize its expected delay of completion.
net/netfilter/ipvs/ip_vs_sync.c:#include <linux/completion.h>
net/netfilter/nf_conntrack_proto_dccp.c: *   8.1.5. Handshake Completion
net/netfilter/nfnetlink_queue.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/nfc/hci/command.c: * HCI command execution completion callback.
net/nfc/hci/core.c:		  msecs_to_jiffies(hdev->cmd_pending_msg->completion_delay));
net/nfc/hci/core.c:static void __nfc_hci_cmd_completion(struct nfc_hci_dev *hdev, int err,
net/nfc/hci/core.c:	__nfc_hci_cmd_completion(hdev, nfc_hci_result_to_errno(result), skb);
net/nfc/hci/core.c:	__nfc_hci_cmd_completion(hdev, err, NULL);
net/nfc/hci/hci.h:	unsigned long completion_delay;
net/nfc/hci/hci.h:			   unsigned long completion_delay);
net/nfc/hci/hcp.c: * Guarantees that cb will be called upon completion or timeout delay
net/nfc/hci/hcp.c:			   unsigned long completion_delay)
net/nfc/hci/hcp.c:	cmd->completion_delay = completion_delay;
net/nfc/nci/core.c:#include <linux/completion.h>
net/nfc/nci/core.c:		complete(&ndev->req_completion);
net/nfc/nci/core.c:		complete(&ndev->req_completion);
net/nfc/nci/core.c:/* Execute request and wait for completion. */
net/nfc/nci/core.c:	long completion_rc;
net/nfc/nci/core.c:	reinit_completion(&ndev->req_completion);
net/nfc/nci/core.c:	completion_rc =
net/nfc/nci/core.c:		wait_for_completion_interruptible_timeout(&ndev->req_completion,
net/nfc/nci/core.c:	pr_debug("wait_for_completion return %ld\n", completion_rc);
net/nfc/nci/core.c:	if (completion_rc > 0) {
net/nfc/nci/core.c:		pr_err("wait_for_completion_interruptible_timeout failed %ld\n",
net/nfc/nci/core.c:		       completion_rc);
net/nfc/nci/core.c:		rc = ((completion_rc == 0) ? (-ETIMEDOUT) : (completion_rc));
net/nfc/nci/core.c:	init_completion(&ndev->req_completion);
net/nfc/nci/spi.c:		 struct completion *write_handshake_completion,
net/nfc/nci/spi.c:	long completion_rc;
net/nfc/nci/spi.c:	if (write_handshake_completion)	{
net/nfc/nci/spi.c:		if (wait_for_completion_timeout(write_handshake_completion,
net/nfc/nci/spi.c:	reinit_completion(&nspi->req_completion);
net/nfc/nci/spi.c:	completion_rc =	wait_for_completion_interruptible_timeout(
net/nfc/nci/spi.c:							&nspi->req_completion,
net/nfc/nci/spi.c:	if (completion_rc <= 0 || nspi->req_result == ACKNOWLEDGE_NACK)
net/nfc/nci/spi.c:	init_completion(&nspi->req_completion);
net/nfc/nci/spi.c:		 * unblock completion of latest frame sent.
net/nfc/nci/spi.c:			complete(&nspi->req_completion);
net/packet/af_packet.c:		complete(&po->skb_completion);
net/packet/af_packet.c:	reinit_completion(&po->skb_completion);
net/packet/af_packet.c:				timeo = wait_for_completion_interruptible_timeout(&po->skb_completion, timeo);
net/packet/af_packet.c:	init_completion(&po->skb_completion);
net/packet/internal.h:	struct completion	skb_completion;
net/rds/af_rds.c: *	update, or a RDMA completion, or a MSG_ZEROCOPY completion).
net/rds/ib.h:	/* Batched completions */
net/rds/ib_cm.c:	 * completion queue and send queue. This extra space is used for FRWR
net/rds/ib_cm.c:		 * We want to wait for tx and rx completion to finish
net/rds/ib_frmr.c:					  "frmr completion <%pI4,%pI4> status %u(%s), vendor_err 0x%x, disconnecting and reconnecting\n",
net/rds/ib_recv.c: * room for it beyond the ring size.  Send completion notices its special
net/rds/ib_recv.c: *  1.	We call rds_ib_attempt_ack from the recv completion handler
net/rds/ib_recv.c: *	send queue completion handler, and check whether there's
net/rds/ib_recv.c: * We get here from the send completion handler, when the
net/rds/ib_recv.c:	 * to get a recv completion _before_ the rdmacm ESTABLISHED
net/rds/ib_recv.c:			rds_ib_conn_error(conn, "recv completion on <%pI6c,%pI6c, %d> had status %u (%s), vendor err 0x%x, disconnecting and reconnecting\n",
net/rds/ib_ring.c: * the CQ completion handlers to wake it up after freeing some
net/rds/ib_send.c: * completion handler.
net/rds/ib_send.c:	/* If the user asked for a completion notification on this
net/rds/ib_send.c:	 *  2.	Notify when the IB stack gives us the completion event for
net/rds/ib_send.c:	 *  3.	Notify when the IB stack gives us the completion event for
net/rds/ib_send.c:	 * ib_dma_sync_sg_for_cpu - the completion for the RDMA
net/rds/ib_send.c:		rds_ib_conn_error(conn, "send completion on <%pI6c,%pI6c,%d> had status %u (%s), vendor err 0x%x, disconnecting and reconnecting\n",
net/rds/ib_send.c:	 * We want to delay signaling completions just enough to get
net/rds/ib_send.c: * in order so we pass ownership of the message to the completion handler
net/rds/ib_send.c:	/* if we finished the message then send completion owns it */
net/rds/rdma.c:		 * we don't want to do that in the completion handler. We
net/rds/rdma.c:		 * we don't want to do that in the completion handler. We
net/rds/recv.c:	if (put_cmsg(msg, SOL_RDS, RDS_CMSG_ZCOPY_COMPLETION, sizeof(*done),
net/rds/send.c:	 * completion handler.
net/rds/send.c: * the IB send completion on the RDMA op and the accompanying
net/rxrpc/af_rxrpc.c:	if (call->completion != RXRPC_CALL_SUCCEEDED)
net/rxrpc/ar-internal.h:	struct completion	io_thread_ready; /* Indication that the I/O thread started */
net/rxrpc/ar-internal.h: * Call completion condition (state == RXRPC_CALL_COMPLETE).
net/rxrpc/ar-internal.h:enum rxrpc_call_completion {
net/rxrpc/ar-internal.h:	NR__RXRPC_CALL_COMPLETIONS
net/rxrpc/ar-internal.h:	enum rxrpc_call_completion completion;	/* Completion condition */
net/rxrpc/ar-internal.h:	enum rxrpc_call_completion completion;	/* Call completion condition */
net/rxrpc/ar-internal.h:extern const char *const rxrpc_call_completions[];
net/rxrpc/ar-internal.h:bool rxrpc_set_call_completion(struct rxrpc_call *call,
net/rxrpc/ar-internal.h:			       enum rxrpc_call_completion compl,
net/rxrpc/ar-internal.h:void rxrpc_prefail_call(struct rxrpc_call *call, enum rxrpc_call_completion compl,
net/rxrpc/ar-internal.h:	/* Order write of completion info before write of ->state. */
net/rxrpc/ar-internal.h:	/* Order read ->state before read of completion info. */
net/rxrpc/ar-internal.h:	return rxrpc_call_is_complete(call) && call->completion != RXRPC_CALL_SUCCEEDED;
net/rxrpc/call_object.c:const char *const rxrpc_call_completions[NR__RXRPC_CALL_COMPLETIONS] = {
net/rxrpc/call_object.c:	 * completion notifies the socket.  Return 0 from sys_sendmsg() and
net/rxrpc/call_object.c:	rxrpc_set_call_completion(call, RXRPC_CALL_LOCAL_ERROR, 0, ret);
net/rxrpc/call_object.c:		rxrpc_set_call_completion(call, conn->completion,
net/rxrpc/call_state.c:bool rxrpc_set_call_completion(struct rxrpc_call *call,
net/rxrpc/call_state.c:				 enum rxrpc_call_completion compl,
net/rxrpc/call_state.c:	call->completion = compl;
net/rxrpc/call_state.c:	/* Allow reader of completion state to operate locklessly */
net/rxrpc/call_state.c:	return rxrpc_set_call_completion(call, RXRPC_CALL_SUCCEEDED, 0, 0);
net/rxrpc/call_state.c:	if (!rxrpc_set_call_completion(call, RXRPC_CALL_LOCALLY_ABORTED,
net/rxrpc/call_state.c:void rxrpc_prefail_call(struct rxrpc_call *call, enum rxrpc_call_completion compl,
net/rxrpc/call_state.c:	call->completion	= compl;
net/rxrpc/conn_client.c:	if (call->completion == RXRPC_CALL_SUCCEEDED &&
net/rxrpc/conn_event.c: * Set the completion state on an aborted connection.
net/rxrpc/conn_event.c:				   enum rxrpc_call_completion compl)
net/rxrpc/conn_event.c:			conn->completion = compl;
net/rxrpc/conn_event.c:			rxrpc_set_call_completion(call,
net/rxrpc/conn_event.c:						  conn->completion,
net/rxrpc/conn_event.c:			if (conn->completion == RXRPC_CALL_LOCALLY_ABORTED)
net/rxrpc/conn_object.c:		switch (call->completion) {
net/rxrpc/input.c:		rxrpc_set_call_completion(call, RXRPC_CALL_REMOTELY_ABORTED,
net/rxrpc/input.c:		rxrpc_set_call_completion(call, RXRPC_CALL_REMOTELY_ABORTED,
net/rxrpc/input.c:	rxrpc_set_call_completion(call, RXRPC_CALL_REMOTELY_ABORTED,
net/rxrpc/local_object.c:		init_completion(&local->io_thread_ready);
net/rxrpc/local_object.c:	wait_for_completion(&local->io_thread_ready);
net/rxrpc/output.c:			rxrpc_set_call_completion(call, RXRPC_CALL_LOCAL_ERROR,
net/rxrpc/output.c:			rxrpc_set_call_completion(call, RXRPC_CALL_LOCAL_ERROR,
net/rxrpc/peer_event.c:				   enum rxrpc_call_completion, int);
net/rxrpc/peer_event.c:	enum rxrpc_call_completion compl = RXRPC_CALL_NETWORK_ERROR;
net/rxrpc/peer_event.c:				   enum rxrpc_call_completion compl, int err)
net/rxrpc/peer_event.c:		rxrpc_set_call_completion(call, compl, 0, -err);
net/rxrpc/proc.c:		rxrpc_call_completions[conn->completion] :
net/rxrpc/recvmsg.c:	switch (call->completion) {
net/rxrpc/recvmsg.c:		pr_err("Invalid terminal call state %u\n", call->completion);
net/rxrpc/recvmsg.c:	if (call->completion == RXRPC_CALL_SUCCEEDED) {
net/rxrpc/rxperf.c:			pr_debug("premature completion %d", call->error);
net/sched/sch_netem.c:	 * place at TX completion time, so _before_ the link transit delay)
net/sctp/protocol.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/smc/smc_cdc.c:/* handler for send/transmission completion of a CDC msg */
net/smc/smc_core.h:	struct completion	*wr_tx_compl;	/* WR send CQE completion */
net/smc/smc_core.h:	struct completion	tx_ref_comp;
net/smc/smc_core.h:	struct completion	reg_ref_comp;
net/smc/smc_core.h:	struct completion	llc_testlink_resp; /* wait for rx of testlink */
net/smc/smc_ib.c:#define SMC_MAX_CQE 32766	/* max. # of completion queue elements */
net/smc/smc_ib.h:	struct ib_cq		*roce_cq_send;	/* send completion queue */
net/smc/smc_ib.h:	struct ib_cq		*roce_cq_recv;	/* recv completion queue */
net/smc/smc_llc.c:/* handler for send/transmission completion of an LLC msg */
net/smc/smc_llc.c: * and wait for send completion notification.
net/smc/smc_llc.c: * waiting for send completion
net/smc/smc_llc.c:	reinit_completion(&link->llc_testlink_resp);
net/smc/smc_llc.c:	rc = wait_for_completion_interruptible_timeout(&link->llc_testlink_resp,
net/smc/smc_llc.c:	init_completion(&link->llc_testlink_resp);
net/smc/smc_tx.c: *     message's completion
net/smc/smc_tx.c:		 * sendmsg() call or push on tx completion
net/smc/smc_wr.c: * While an SQ WR/WQE is pending, we track it until transmission completion.
net/smc/smc_wr.c: * Through a send or receive completion queue (CQ) respectively,
net/smc/smc_wr.c: * we get completion queue entries (CQEs) [aka work completions (WCs)].
net/smc/smc_wr.c:/*------------------------------- completion --------------------------------*/
net/smc/smc_wr.c: * @handler:		Send completion handler function pointer.
net/smc/smc_wr.c:/* Send prepared WR slot via ib_post_send and wait for send completion
net/smc/smc_wr.c:	init_completion(&link->wr_tx_compl[pnd_idx]);
net/smc/smc_wr.c:	/* wait for completion by smc_wr_tx_process_cqe() */
net/smc/smc_wr.c:	rc = wait_for_completion_interruptible_timeout(
net/smc/smc_wr.c:	wait_for_completion(&lnk->reg_ref_comp);
net/smc/smc_wr.c:	wait_for_completion(&lnk->tx_ref_comp);
net/smc/smc_wr.c:	init_completion(&lnk->tx_ref_comp);
net/smc/smc_wr.c:	init_completion(&lnk->reg_ref_comp);
net/sunrpc/auth_gss/auth_gss.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/sunrpc/cache.c:	struct completion completion;
net/sunrpc/cache.c:	complete(&dr->completion);
net/sunrpc/cache.c:	sleeper.completion = COMPLETION_INITIALIZER_ONSTACK(sleeper.completion);
net/sunrpc/cache.c:	    wait_for_completion_interruptible_timeout(
net/sunrpc/cache.c:		    &sleeper.completion, req->thread_wait) <= 0) {
net/sunrpc/cache.c:		/* The completion wasn't completed, so we need
net/sunrpc/cache.c:			wait_for_completion(&sleeper.completion);
net/sunrpc/sched.c: * Allow callers to wait for completion of an RPC call
net/sunrpc/sched.c:int rpc_wait_for_completion_task(struct rpc_task *task)
net/sunrpc/sched.c:EXPORT_SYMBOL_GPL(rpc_wait_for_completion_task);
net/sunrpc/sched.c:		/* Wake up anyone who may be waiting for task completion */
net/sunrpc/sunrpc_syms.c:	rcu_barrier(); /* Wait for completion of call_rcu()'s */
net/sunrpc/svcsock.c: * svc_tcp_handshake_done - Handshake completion handler
net/sunrpc/svcsock.c:	init_completion(&svsk->sk_handshake_done);
net/sunrpc/svcsock.c:	ret = wait_for_completion_interruptible_timeout(&svsk->sk_handshake_done,
net/sunrpc/svcsock.c:	 * completion downcall.
net/sunrpc/xprtrdma/frwr_ops.c: * closed, the Receive completion queue is drained before the allowing
net/sunrpc/xprtrdma/frwr_ops.c:	cid->ci_completion_id = mr->mr_ibmr->res.id;
net/sunrpc/xprtrdma/frwr_ops.c:	init_completion(&mr->mr_linv_done);
net/sunrpc/xprtrdma/frwr_ops.c: * @cq: completion queue
net/sunrpc/xprtrdma/frwr_ops.c: * @cq: completion queue
net/sunrpc/xprtrdma/frwr_ops.c: * @cq: completion queue
net/sunrpc/xprtrdma/frwr_ops.c:	reinit_completion(&mr->mr_linv_done);
net/sunrpc/xprtrdma/frwr_ops.c:		wait_for_completion(&mr->mr_linv_done);
net/sunrpc/xprtrdma/frwr_ops.c: * @cq:	completion queue
net/sunrpc/xprtrdma/frwr_ops.c:	 * are complete. The last completion will wake up the
net/sunrpc/xprtrdma/ib_client.c:#include <linux/completion.h>
net/sunrpc/xprtrdma/ib_client.c:	struct completion	rd_done;
net/sunrpc/xprtrdma/ib_client.c:	trace_rpcrdma_client_completion(rd->rd_device);
net/sunrpc/xprtrdma/ib_client.c:	init_completion(&rd->rd_done);
net/sunrpc/xprtrdma/ib_client.c:		wait_for_completion(&rd->rd_done);
net/sunrpc/xprtrdma/rpc_rdma.c:		/* LocalInv completion will complete the RPC */
net/sunrpc/xprtrdma/svc_rdma_backchannel.c:	/* Bump page refcnt so Send completion doesn't release
net/sunrpc/xprtrdma/svc_rdma_recvfrom.c: * @cq: Completion Queue context
net/sunrpc/xprtrdma/svc_rdma_recvfrom.c: * @wc: Work Completion object
net/sunrpc/xprtrdma/svc_rdma_rw.c:	if (unlikely(!cid->ci_completion_id))
net/sunrpc/xprtrdma/svc_rdma_rw.c: * svc_rdma_reply_done - Reply chunk Write completion handler
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @cq: controlling Completion Queue
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @wc: Work Completion report
net/sunrpc/xprtrdma/svc_rdma_rw.c: * Pages under I/O are released by a subsequent Send completion.
net/sunrpc/xprtrdma/svc_rdma_rw.c: * svc_rdma_write_done - Write chunk completion
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @cq: controlling Completion Queue
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @wc: Work Completion
net/sunrpc/xprtrdma/svc_rdma_rw.c: * Pages under I/O are freed by a subsequent Send completion.
net/sunrpc/xprtrdma/svc_rdma_rw.c: * svc_rdma_wc_read_done - Handle completion of an RDMA Read ctx
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @cq: controlling Completion Queue
net/sunrpc/xprtrdma/svc_rdma_rw.c: * @wc: Work Completion
net/sunrpc/xprtrdma/svc_rdma_rw.c: * - If ib_post_send() succeeds, only one completion is expected,
net/sunrpc/xprtrdma/svc_rdma_rw.c:	/* If even one was posted, there will be a completion. */
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * The logic here depends on Send Queue and completion ordering. Since
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * svc_rdma_rw_ctxt, allowing the Write completion handler to find and
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * completion handler does not release any pages.
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * Send completion handler finally releases the Reply's pages.
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * This mechanism also assumes that completions on the transport's Send
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * Completion Queue do not run in parallel. Otherwise a Write completion
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * and Send completion running at the same time could release pages that
net/sunrpc/xprtrdma/svc_rdma_sendto.c: *   successfully, or get flushed. Either way, the Send completion
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * @cq: Completion Queue context
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * @wc: Work Completion object
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * the Send completion handler could be running.
net/sunrpc/xprtrdma/svc_rdma_sendto.c:			 * completions to wake us. The XPT_CLOSE test
net/sunrpc/xprtrdma/svc_rdma_sendto.c:			 * Send completion that bumps sc_sq_avail.
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * so they are released by the Send completion handler.
net/sunrpc/xprtrdma/svc_rdma_sendto.c:	 * page array. Completion handling releases these pages.
net/sunrpc/xprtrdma/svc_rdma_sendto.c: * Send completion, or by this function on error.
net/sunrpc/xprtrdma/svc_rdma_sendto.c:	/* Send completion releases payload pages that were part
net/sunrpc/xprtrdma/svc_rdma_transport.c:	/* This blocks until the Completion Queues are empty */
net/sunrpc/xprtrdma/transport.c:	 * that the Send completion has fired, so that memory
net/sunrpc/xprtrdma/verbs.c:		wait_for_completion(&ep->re_done);
net/sunrpc/xprtrdma/verbs.c: * rpcrdma_flush_disconnect - Disconnect on flushed completion
net/sunrpc/xprtrdma/verbs.c: * @wc: work completion entry
net/sunrpc/xprtrdma/verbs.c: * @cq:	completion queue
net/sunrpc/xprtrdma/verbs.c: * @cq:	completion queue
net/sunrpc/xprtrdma/verbs.c:	init_completion(&ep->re_done);
net/sunrpc/xprtrdma/verbs.c:	rc = wait_for_completion_interruptible_timeout(&ep->re_done, wtimeout);
net/sunrpc/xprtrdma/verbs.c:	rc = wait_for_completion_interruptible_timeout(&ep->re_done, wtimeout);
net/sunrpc/xprtrdma/verbs.c:	reinit_completion(&ep->re_done);
net/sunrpc/xprtrdma/verbs.c: * Producer is the code path that handles Send completions. This path
net/sunrpc/xprtrdma/verbs.c:	sc->sc_cid.ci_completion_id =
net/sunrpc/xprtrdma/verbs.c:		atomic_inc_return(&ep->re_completion_ids);
net/sunrpc/xprtrdma/verbs.c: * Returns pointer to a free send completion context; or NULL if
net/sunrpc/xprtrdma/verbs.c:	 * completions recently. This is a sign the Send Queue is
net/sunrpc/xprtrdma/verbs.c: * Usage: Called from Send completion to return a sendctxt
net/sunrpc/xprtrdma/verbs.c:	 * req->rl_registered list unless a successful completion
net/sunrpc/xprtrdma/verbs.c:	rep->rr_cid.ci_completion_id =
net/sunrpc/xprtrdma/verbs.c:		atomic_inc_return(&r_xprt->rx_ep->re_completion_ids);
net/sunrpc/xprtrdma/verbs.c: * - No more Send or Receive completions can occur
net/sunrpc/xprtrdma/xprt_rdma.h:#include <linux/sunrpc/rpc_rdma_cid.h> 	/* completion IDs */
net/sunrpc/xprtrdma/xprt_rdma.h:	struct completion	re_done;
net/sunrpc/xprtrdma/xprt_rdma.h:	atomic_t		re_completion_ids;
net/sunrpc/xprtrdma/xprt_rdma.h:	struct completion	mr_linv_done;
net/sunrpc/xprtsock.c: * xs_tls_handshake_done - TLS handshake completion handler
net/sunrpc/xprtsock.c:	init_completion(&lower_transport->handshake_done);
net/sunrpc/xprtsock.c:	rc = wait_for_completion_interruptible_timeout(&lower_transport->handshake_done,
net/tls/tls_sw.c:		complete(&ctx->async_wait.completion);
net/tls/tls_sw.c:		/* all completions have run, we're not doing async anymore */
net/tls/tls_sw.c:		complete(&ctx->async_wait.completion);
net/vmw_vsock/virtio_transport_common.c:		 * completion for the current syscall.
net/wireless/debugfs.c:	struct completion completion;
net/wireless/debugfs.c:	complete(&w->completion);
net/wireless/debugfs.c:	complete(&w->completion);
net/wireless/debugfs.c:		.completion = COMPLETION_INITIALIZER_ONSTACK(work.completion),
net/wireless/debugfs.c:	wait_for_completion(&work.completion);
net/wireless/debugfs.c:	struct completion completion;
net/wireless/debugfs.c:	complete(&w->completion);
net/wireless/debugfs.c:	complete(&w->completion);
net/wireless/debugfs.c:		.completion = COMPLETION_INITIALIZER_ONSTACK(work.completion),
net/wireless/debugfs.c:	wait_for_completion(&work.completion);
net/xdp/xsk.c:		 * Reserve space in the completion queue and only proceed
net/xdp/xsk.c:	 * reserve space in the completion queue for all packets, but
net/xdp/xsk.c:		/* sw completion timestamp, not a real one */
net/xdp/xsk.c:		 * Reserve space in the completion queue and only proceed
net/xdp/xsk.c:	case XDP_UMEM_COMPLETION_RING:
net/xdp/xsk.c:		else if (offset == XDP_UMEM_PGOFF_COMPLETION_RING)
net/xdp/xsk_buff_pool.c:	/* One fill and completion ring required for each queue id. */
net/xdp/xsk_diag.c:					XDP_DIAG_UMEM_COMPLETION_RING, nlskb);
net/xdp/xsk_queue.h:/* Used for the fill and completion queues for buffers */
net/xdp/xsk_queue.h: * completion ring, the kernel is the producer and user space is the
rust/kernel/block/mq.rs://! completions from hardware with the correct `Request` instance. The `TagSet`
rust/kernel/error.rs:    declare_err!(EIOCBQUEUED, "iocb queued, will get completion event.");
samples/qmi/qmi_sample_client.c:#include <linux/completion.h>
samples/qmi/qmi_sample_client.c:	complete(&txn->completion);
scripts/checkpatch.pl:			WARN("CONSIDER_COMPLETION",
scripts/checkpatch.pl:			     "consider using a completion\n" . $herecurr);
scripts/kconfig/confdata.c:	 * completion of the previous steps.
scripts/spelling.txt:competion||completion
scripts/spelling.txt:completition||completion
scripts/tags.sh:	'/\<DECLARE_\(RWSEM\|COMPLETION\)([[:space:]]*\([[:alnum:]_]\+\)/\2/v/'
security/integrity/ima/ima_crypto.c:			 * read/request, wait for the completion of the
security/integrity/ima/ima_crypto.c:			 * read/request, wait for the completion of the
security/integrity/ima/ima_main.c:	 * firmware being accessible to the device prior to the completion
security/keys/request_key.c: * completion of keys undergoing construction with a non-interruptible wait.
security/keys/request_key.c: * completion of keys undergoing construction with a non-interruptible wait.
sound/aoa/soundbus/i2sbus/i2sbus.h:#include <linux/completion.h>
sound/aoa/soundbus/i2sbus/i2sbus.h:	struct completion *stop_completion;
sound/aoa/soundbus/i2sbus/pcm.c:	DECLARE_COMPLETION_ONSTACK(done);
sound/aoa/soundbus/i2sbus/pcm.c:		pi->stop_completion = &done;
sound/aoa/soundbus/i2sbus/pcm.c:		time_left = wait_for_completion_timeout(&done, HZ);
sound/aoa/soundbus/i2sbus/pcm.c:		pi->stop_completion = NULL;
sound/aoa/soundbus/i2sbus/pcm.c:		if (pi->stop_completion)
sound/aoa/soundbus/i2sbus/pcm.c:			complete(pi->stop_completion);
sound/arm/pxa2xx-ac97-regs.h:#define GSR_RDCS	(1 << 15)	/* Read Completion Status */
sound/core/compress_offload.c:	 * It is expected that driver will notify the drain completion and then
sound/core/init.c:#include <linux/completion.h>
sound/core/init.c:	if (card->release_completion)
sound/core/init.c:		complete(card->release_completion);
sound/core/init.c:	DECLARE_COMPLETION_ONSTACK(released);
sound/core/init.c:	card->release_completion = &released;
sound/core/init.c:	wait_for_completion(&released);
sound/drivers/opl4/opl4_synth.c:	/* wait for completion of loading */
sound/firewire/amdtp-stream.c:		//         snd_pcm_elapsed()           fw_iso_context_flush_completions()
sound/firewire/amdtp-stream.c:			fw_iso_context_flush_completions(s->context);
sound/firewire/amdtp-stream.c:			fw_iso_context_flush_completions(irq_target->context);
sound/firewire/amdtp-stream.c:		fw_iso_context_flush_completions(irq_target->context);
sound/firewire/dice/dice-stream.c:	if (completion_done(&dice->clock_accepted))
sound/firewire/dice/dice-stream.c:		reinit_completion(&dice->clock_accepted);
sound/firewire/dice/dice-stream.c:	if (wait_for_completion_timeout(&dice->clock_accepted,
sound/firewire/dice/dice.c:	init_completion(&dice->clock_accepted);
sound/firewire/dice/dice.h:#include <linux/completion.h>
sound/firewire/dice/dice.h:	struct completion clock_accepted;
sound/firewire/fcp.c:			 * on command completion once an INTERIM response has
sound/firewire/lib.c: * snd_fw_transaction - send a request and wait for its completion
sound/hda/hdac_component.c:	init_completion(&acomp->master_bind_complete);
sound/pci/asihpi/hpi.h:is useful for checking completion of all stream operations across the adapter
sound/pci/hda/hda_intel.c:#include <linux/completion.h>
sound/pci/hda/hda_intel.c:	wait_for_completion(&hda->probe_wait);
sound/pci/hda/hda_intel.c:	wait_for_completion(&hda->probe_wait);
sound/pci/hda/hda_intel.c:	init_completion(&hda->probe_wait);
sound/pci/hda/hda_intel.h:	struct completion probe_wait;
sound/pci/hda/hda_tegra.c:#include <linux/completion.h>
sound/pci/hda/patch_cs8409.c:	 * any i2c transaction, so the disable function will run to completion immediately
sound/pci/intel8x0.c:#define ICH_BCIS			0x08	/* buffer completion interrupt status */
sound/pci/intel8x0.c:#define ICH_LVBCI			0x04	/* last valid buffer completion interrupt */
sound/pci/intel8x0.c:#define ICH_IOCE			0x10	/* interrupt on completion enable */
sound/pci/intel8x0.c:#define   ICH_RCS		0x00008000	/* read completion status */
sound/pci/intel8x0.c:			bdbar[idx + 1] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/intel8x0.c:			bdbar[idx + 3] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/intel8x0.c:			bdbar[idx + 1] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/intel8x0m.c:#define ICH_BCIS			0x08	/* buffer completion interrupt status */
sound/pci/intel8x0m.c:#define ICH_LVBCI			0x04	/* last valid buffer completion interrupt */
sound/pci/intel8x0m.c:#define ICH_IOCE			0x10	/* interrupt on completion enable */
sound/pci/intel8x0m.c:#define   ICH_RCS		0x00008000	/* read completion status */
sound/pci/intel8x0m.c:			bdbar[idx + 1] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/intel8x0m.c:			bdbar[idx + 3] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/intel8x0m.c:			bdbar[idx + 1] = cpu_to_le32(0x80000000 | /* interrupt on completion */
sound/pci/lola/lola.h:#define LOLA_DSD_CTL_IOCE	0x04	/* interrupt on completion enable */
sound/pci/lola/lola.h:#define LOLA_DSD_STS_BCIS	0x04	/* buffer completion interrupt status */
sound/pci/oxygen/oxygen_io.c: * where the controller indicates completion aren't guaranteed to have actually
sound/ppc/snd_ps3_reg.h:/* S/PDIF Output Channel One Block Transfer Completion Interrupt Enables */
sound/sh/aica.c:		dma_wait_for_completion(AICA_DMA_CHANNEL);
sound/soc/amd/acp-pcm-dma.c:	 * interrupt on completion of the dma transfer
sound/soc/amd/acp/acp-sdw-sof-mach.c:		 * based on wait_for_completion(), tag them as 'nonatomic'.
sound/soc/atmel/mchp-spdifrx.c: * @done: completion to signal channel status bits acquisition done
sound/soc/atmel/mchp-spdifrx.c:	struct completion done;
sound/soc/atmel/mchp-spdifrx.c: * @done: completion to signal user data bits acquisition done
sound/soc/atmel/mchp-spdifrx.c:	struct completion done;
sound/soc/atmel/mchp-spdifrx.c:	 * still disabled. To void waiting for completion and return with
sound/soc/atmel/mchp-spdifrx.c:		reinit_completion(&ch_stat->done);
sound/soc/atmel/mchp-spdifrx.c:		ret = wait_for_completion_interruptible_timeout(&ch_stat->done,
sound/soc/atmel/mchp-spdifrx.c:	 * still disabled. To void waiting for completion to just timeout we
sound/soc/atmel/mchp-spdifrx.c:		reinit_completion(&user_data->done);
sound/soc/atmel/mchp-spdifrx.c:		ret = wait_for_completion_interruptible_timeout(&user_data->done,
sound/soc/atmel/mchp-spdifrx.c:		init_completion(&ctrl->ch_stat[ch].done);
sound/soc/atmel/mchp-spdifrx.c:		init_completion(&ctrl->user_data[ch].done);
sound/soc/codecs/arizona.h:#include <linux/completion.h>
sound/soc/codecs/cs35l35.c:#include <linux/completion.h>
sound/soc/codecs/cs35l35.c:	reinit_completion(&cs35l35->pdn_done);
sound/soc/codecs/cs35l35.c:	ret = wait_for_completion_timeout(&cs35l35->pdn_done,
sound/soc/codecs/cs35l35.c:	init_completion(&cs35l35->pdn_done);
sound/soc/codecs/cs35l35.h:	struct completion pdn_done;
sound/soc/codecs/cs35l36.c:#include <linux/completion.h>
sound/soc/codecs/cs35l56-sdw.c:		if (!wait_for_completion_timeout(&peripheral->initialization_complete,
sound/soc/codecs/cs35l56.c:#include <linux/completion.h>
sound/soc/codecs/cs35l56.c:	reinit_completion(&cs35l56->init_completion);
sound/soc/codecs/cs35l56.c:		if (!wait_for_completion_timeout(&cs35l56->init_completion,
sound/soc/codecs/cs35l56.c:			dev_err(cs35l56->base.dev, "%s: init_completion timed out (SDW)\n",
sound/soc/codecs/cs35l56.c:	if (!wait_for_completion_timeout(&cs35l56->init_completion,
sound/soc/codecs/cs35l56.c:		dev_err(cs35l56->base.dev, "%s: init_completion timed out\n", __func__);
sound/soc/codecs/cs35l56.c:	init_completion(&cs35l56->init_completion);
sound/soc/codecs/cs35l56.c:	complete(&cs35l56->init_completion);
sound/soc/codecs/cs35l56.h:#include <linux/completion.h>
sound/soc/codecs/cs35l56.h:	struct completion init_completion;
sound/soc/codecs/cs4234.c:#include <linux/completion.h>
sound/soc/codecs/cs4234.c:	struct completion vq_ramp_complete;
sound/soc/codecs/cs4234.c:			wait_for_completion(&cs4234->vq_ramp_complete);
sound/soc/codecs/cs4234.c:	reinit_completion(&cs4234->vq_ramp_complete);
sound/soc/codecs/cs4234.c:	init_completion(&cs4234->vq_ramp_complete);
sound/soc/codecs/cs42l42-sdw.c:	/* Poll for delayed read completion */
sound/soc/codecs/cs42l42-sdw.c:	if (!wait_for_completion_timeout(&peripheral->initialization_complete,
sound/soc/codecs/cs42l42.h:	struct completion pdn_done;
sound/soc/codecs/cs42l43-jack.c:#include <linux/completion.h>
sound/soc/codecs/cs42l43-jack.c:		reinit_completion(&priv->hp_shutdown);
sound/soc/codecs/cs42l43-jack.c:		time_left = wait_for_completion_timeout(&priv->hp_shutdown,
sound/soc/codecs/cs42l43-jack.c:		reinit_completion(&priv->hp_startup);
sound/soc/codecs/cs42l43-jack.c:		time_left = wait_for_completion_timeout(&priv->hp_startup,
sound/soc/codecs/cs42l43-jack.c:	reinit_completion(&priv->load_detect);
sound/soc/codecs/cs42l43-jack.c:	time_left = wait_for_completion_timeout(&priv->load_detect,
sound/soc/codecs/cs42l43-jack.c:	reinit_completion(&priv->type_detect);
sound/soc/codecs/cs42l43-jack.c:	time_left = wait_for_completion_timeout(&priv->type_detect,
sound/soc/codecs/cs42l43.c:		reinit_completion(&priv->hp_startup);
sound/soc/codecs/cs42l43.c:		time_left = wait_for_completion_timeout(&priv->hp_startup,
sound/soc/codecs/cs42l43.c:	reinit_completion(&priv->pll_ready);
sound/soc/codecs/cs42l43.c:	time_left = wait_for_completion_timeout(&priv->pll_ready,
sound/soc/codecs/cs42l43.c:static int cs42l43_dapm_wait_completion(struct completion *pmu, struct completion *pmd,
sound/soc/codecs/cs42l43.c:		reinit_completion(pmu);
sound/soc/codecs/cs42l43.c:		reinit_completion(pmd);
sound/soc/codecs/cs42l43.c:		time_left = wait_for_completion_timeout(pmu, msecs_to_jiffies(timeout_ms));
sound/soc/codecs/cs42l43.c:		time_left = wait_for_completion_timeout(pmd, msecs_to_jiffies(timeout_ms));
sound/soc/codecs/cs42l43.c:	return cs42l43_dapm_wait_completion(&priv->spkr_startup,
sound/soc/codecs/cs42l43.c:	return cs42l43_dapm_wait_completion(&priv->spkl_startup,
sound/soc/codecs/cs42l43.c:		ret = cs42l43_dapm_wait_completion(&priv->hp_startup,
sound/soc/codecs/cs42l43.c:		ret = cs42l43_dapm_wait_completion(&priv->hp_startup,
sound/soc/codecs/cs42l43.c:	init_completion(&priv->hp_startup);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->hp_shutdown);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->spkr_shutdown);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->spkl_shutdown);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->spkr_startup);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->spkl_startup);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->pll_ready);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->type_detect);
sound/soc/codecs/cs42l43.c:	init_completion(&priv->load_detect);
sound/soc/codecs/cs42l43.h:#include <linux/completion.h>
sound/soc/codecs/cs42l43.h:	struct completion pll_ready;
sound/soc/codecs/cs42l43.h:	struct completion hp_startup;
sound/soc/codecs/cs42l43.h:	struct completion hp_shutdown;
sound/soc/codecs/cs42l43.h:	struct completion spkr_shutdown;
sound/soc/codecs/cs42l43.h:	struct completion spkl_shutdown;
sound/soc/codecs/cs42l43.h:	struct completion spkr_startup;
sound/soc/codecs/cs42l43.h:	struct completion spkl_startup;
sound/soc/codecs/cs42l43.h:	struct completion type_detect;
sound/soc/codecs/cs42l43.h:	struct completion load_detect;
sound/soc/codecs/cs43130.c:#include <linux/completion.h>
sound/soc/codecs/cs43130.c:static int cs43130_wait_for_completion(struct cs43130_private *cs43130, struct completion *to_poll,
sound/soc/codecs/cs43130.c:		ret = wait_for_completion_timeout(to_poll, msecs_to_jiffies(time));
sound/soc/codecs/cs43130.c:			reinit_completion(&cs43130->xtal_rdy);
sound/soc/codecs/cs43130.c:			ret = cs43130_wait_for_completion(cs43130, &cs43130->xtal_rdy, 100);
sound/soc/codecs/cs43130.c:			reinit_completion(&cs43130->xtal_rdy);
sound/soc/codecs/cs43130.c:			ret = cs43130_wait_for_completion(cs43130, &cs43130->xtal_rdy, 100);
sound/soc/codecs/cs43130.c:		reinit_completion(&cs43130->pll_rdy);
sound/soc/codecs/cs43130.c:		ret = cs43130_wait_for_completion(cs43130, &cs43130->pll_rdy, 100);
sound/soc/codecs/cs43130.c:	reinit_completion(&cs43130->hpload_evt);
sound/soc/codecs/cs43130.c:	ret = wait_for_completion_timeout(&cs43130->hpload_evt,
sound/soc/codecs/cs43130.c:	init_completion(&cs43130->xtal_rdy);
sound/soc/codecs/cs43130.c:	init_completion(&cs43130->pll_rdy);
sound/soc/codecs/cs43130.c:	init_completion(&cs43130->hpload_evt);
sound/soc/codecs/cs43130.h:	struct completion		xtal_rdy;
sound/soc/codecs/cs43130.h:	struct completion		pll_rdy;
sound/soc/codecs/cs43130.h:	struct completion		hpload_evt;
sound/soc/codecs/da7213.c:	/* Begin auto calibration and wait for completion */
sound/soc/codecs/madera.h:#include <linux/completion.h>
sound/soc/codecs/max98363.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/max98373-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/nau8825.c:	} else if (active_irq & NAU8825_HEADSET_COMPLETION_IRQ) {
sound/soc/codecs/nau8825.c:			dev_warn(nau8825->dev, "Headset completion IRQ fired but no headset connected\n");
sound/soc/codecs/nau8825.c:		clear_irq = NAU8825_HEADSET_COMPLETION_IRQ;
sound/soc/codecs/nau8825.h:#define NAU8825_HEADSET_COMPLETION_IRQ	(1 << 10)
sound/soc/codecs/rt1017-sdca-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt1308-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt1316-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt1318-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt1320-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt5682-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt5682.c:		time = wait_for_completion_timeout(
sound/soc/codecs/rt700-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt711-sdca-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt711-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt712-sdca-dmic.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt712-sdca-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt715-sdca-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt715-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/rt722-sdca-sdw.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/codecs/wcd937x.c:	time_left = wait_for_completion_timeout(&tx_sdw_dev->initialization_complete,
sound/soc/codecs/wcd938x.c:	time_left = wait_for_completion_timeout(&tx_sdw_dev->initialization_complete,
sound/soc/codecs/wcd939x.c:	time_left = wait_for_completion_timeout(&tx_sdw_dev->initialization_complete,
sound/soc/codecs/wm0010.c:	struct completion boot_completion;
sound/soc/codecs/wm0010.c:	struct completion *done;
sound/soc/codecs/wm0010.c:	DECLARE_COMPLETION_ONSTACK(done);
sound/soc/codecs/wm0010.c:	wait_for_completion(&done);
sound/soc/codecs/wm0010.c:	if (!wait_for_completion_timeout(&wm0010->boot_completion,
sound/soc/codecs/wm0010.c:	if (!wait_for_completion_timeout(&wm0010->boot_completion,
sound/soc/codecs/wm0010.c:		complete(&wm0010->boot_completion);
sound/soc/codecs/wm0010.c:	init_completion(&wm0010->boot_completion);
sound/soc/codecs/wm2200.c:	struct completion fll_lock;
sound/soc/codecs/wm2200.c:	/* Clear any pending completions */
sound/soc/codecs/wm2200.c:	try_wait_for_completion(&wm2200->fll_lock);
sound/soc/codecs/wm2200.c:			time_left = wait_for_completion_timeout(
sound/soc/codecs/wm2200.c:	init_completion(&wm2200->fll_lock);
sound/soc/codecs/wm5100.c:	struct completion lock;
sound/soc/codecs/wm5100.c:	/* Clear any pending completions */
sound/soc/codecs/wm5100.c:	try_wait_for_completion(&fll->lock);
sound/soc/codecs/wm5100.c:			time_left = wait_for_completion_timeout(&fll->lock,
sound/soc/codecs/wm5100.c:		init_completion(&wm5100->fll[i].lock);
sound/soc/codecs/wm8350.c:	 * wait for its completion */
sound/soc/codecs/wm8903.c:#include <linux/completion.h>
sound/soc/codecs/wm8962.c:	struct completion fll_lock;
sound/soc/codecs/wm8962.c:	reinit_completion(&wm8962->fll_lock);
sound/soc/codecs/wm8962.c:	time_left = wait_for_completion_timeout(&wm8962->fll_lock,
sound/soc/codecs/wm8962.c:	init_completion(&wm8962->fll_lock);
sound/soc/codecs/wm8993.c:	struct completion fll_lock;
sound/soc/codecs/wm8993.c:	try_wait_for_completion(&wm8993->fll_lock);
sound/soc/codecs/wm8993.c:	time_left = wait_for_completion_timeout(&wm8993->fll_lock, time_left);
sound/soc/codecs/wm8993.c:	init_completion(&wm8993->fll_lock);
sound/soc/codecs/wm8994.c:	/* Clear any pending completion from a previous failure */
sound/soc/codecs/wm8994.c:	try_wait_for_completion(&wm8994->fll_locked[id]);
sound/soc/codecs/wm8994.c:			time_left = wait_for_completion_timeout(&wm8994->fll_locked[id],
sound/soc/codecs/wm8994.c:	struct completion *completion = data;
sound/soc/codecs/wm8994.c:	complete(completion);
sound/soc/codecs/wm8994.c:		init_completion(&wm8994->fll_locked[i]);
sound/soc/codecs/wm8994.h:#include <linux/completion.h>
sound/soc/codecs/wm8994.h:	struct completion fll_locked[2];
sound/soc/codecs/wm8996.c:#include <linux/completion.h>
sound/soc/codecs/wm8996.c:	struct completion fll_lock;
sound/soc/codecs/wm8996.c:	struct completion dcs_done;
sound/soc/codecs/wm8996.c:			time_left = wait_for_completion_timeout(&wm8996->dcs_done,
sound/soc/codecs/wm8996.c:	/* Clear any pending completions (eg, from failed startups) */
sound/soc/codecs/wm8996.c:	try_wait_for_completion(&wm8996->fll_lock);
sound/soc/codecs/wm8996.c:		time_left = wait_for_completion_timeout(&wm8996->fll_lock,
sound/soc/codecs/wm8996.c:	init_completion(&wm8996->dcs_done);
sound/soc/codecs/wm8996.c:	init_completion(&wm8996->fll_lock);
sound/soc/codecs/wm_hubs.c:			wait_for_completion_timeout(&hubs->dcs_done,
sound/soc/codecs/wm_hubs.c:	init_completion(&hubs->dcs_done);
sound/soc/codecs/wm_hubs.h:#include <linux/completion.h>
sound/soc/codecs/wm_hubs.h:	struct completion dcs_done;
sound/soc/codecs/wsa881x.c:	time = wait_for_completion_timeout(&slave->initialization_complete,
sound/soc/fsl/imx-pcm-rpmsg.c:		reinit_completion(&info->cmd_complete);
sound/soc/fsl/imx-pcm-rpmsg.c:	ret = wait_for_completion_timeout(&info->cmd_complete,
sound/soc/fsl/imx-pcm-rpmsg.c:	init_completion(&info->cmd_complete);
sound/soc/fsl/imx-pcm-rpmsg.h:	struct completion        cmd_complete;
sound/soc/intel/avs/avs.h:	struct completion fw_ready;
sound/soc/intel/avs/avs.h: * @done_completion: DONE-part of IPC i.e. ROM and ACKs from FW
sound/soc/intel/avs/avs.h: * @busy_completion: BUSY-part of IPC i.e. receiving responses from FW
sound/soc/intel/avs/avs.h:	struct completion done_completion;
sound/soc/intel/avs/avs.h:	struct completion busy_completion;
sound/soc/intel/avs/cldma.c:	struct completion completion;
sound/soc/intel/avs/cldma.c:	.completion	= COMPLETION_INITIALIZER(code_loader.completion),
sound/soc/intel/avs/cldma.c:		ret = wait_for_completion_timeout(&cl->completion,
sound/soc/intel/avs/cldma.c:		reinit_completion(&cl->completion);
sound/soc/intel/avs/cldma.c:	reinit_completion(&cl->completion);
sound/soc/intel/avs/cldma.c:	complete(&cl->completion);
sound/soc/intel/avs/cnl.c:		complete(&adev->ipc->done_completion);
sound/soc/intel/avs/core.c:	init_completion(&adev->fw_ready);
sound/soc/intel/avs/ipc.c:	/* Re-enabled on recovery completion. */
sound/soc/intel/avs/ipc.c:	complete(&ipc->busy_completion);
sound/soc/intel/avs/ipc.c:static int avs_ipc_wait_busy_completion(struct avs_ipc *ipc, int timeout)
sound/soc/intel/avs/ipc.c:	ret = wait_for_completion_timeout(&ipc->busy_completion, msecs_to_jiffies(timeout));
sound/soc/intel/avs/ipc.c:		wait_for_completion_killable(&ipc->busy_completion);
sound/soc/intel/avs/ipc.c:			reinit_completion(&ipc->busy_completion);
sound/soc/intel/avs/ipc.c:	reinit_completion(&ipc->done_completion);
sound/soc/intel/avs/ipc.c:	reinit_completion(&ipc->busy_completion);
sound/soc/intel/avs/ipc.c:	ret = avs_ipc_wait_busy_completion(ipc, timeout);
sound/soc/intel/avs/ipc.c:		ret = wait_for_completion_timeout(&ipc->done_completion, msecs_to_jiffies(timeout));
sound/soc/intel/avs/ipc.c:	init_completion(&ipc->done_completion);
sound/soc/intel/avs/ipc.c:	init_completion(&ipc->busy_completion);
sound/soc/intel/avs/loader.c:	reinit_completion(&adev->fw_ready);
sound/soc/intel/avs/loader.c:	reinit_completion(&adev->fw_ready);
sound/soc/intel/avs/loader.c:	ret = wait_for_completion_timeout(&adev->fw_ready,
sound/soc/intel/avs/loader.c:	ret = wait_for_completion_timeout(&adev->fw_ready,
sound/soc/intel/avs/skl.c:		complete(&adev->ipc->done_completion);
sound/soc/intel/boards/sof_sdw.c:		 * based on wait_for_completion(), tag them as 'nonatomic'.
sound/soc/intel/catpt/core.h:	struct completion done_completion;
sound/soc/intel/catpt/core.h:	struct completion busy_completion;
sound/soc/intel/catpt/core.h:	struct completion fw_ready;
sound/soc/intel/catpt/device.c:	init_completion(&cdev->fw_ready);
sound/soc/intel/catpt/ipc.c:	init_completion(&ipc->done_completion);
sound/soc/intel/catpt/ipc.c:	init_completion(&ipc->busy_completion);
sound/soc/intel/catpt/ipc.c:	reinit_completion(&ipc->done_completion);
sound/soc/intel/catpt/ipc.c:	reinit_completion(&ipc->busy_completion);
sound/soc/intel/catpt/ipc.c:static int catpt_wait_msg_completion(struct catpt_dev *cdev, int timeout)
sound/soc/intel/catpt/ipc.c:	ret = wait_for_completion_timeout(&ipc->done_completion,
sound/soc/intel/catpt/ipc.c:	ret = wait_for_completion_timeout(&ipc->busy_completion,
sound/soc/intel/catpt/ipc.c:	ret = catpt_wait_msg_completion(cdev, timeout);
sound/soc/intel/catpt/ipc.c:			/* signal completion of delayed reply */
sound/soc/intel/catpt/ipc.c:			complete(&ipc->busy_completion);
sound/soc/intel/catpt/ipc.c:		complete(&cdev->ipc.done_completion);
sound/soc/intel/catpt/loader.c:	reinit_completion(&cdev->fw_ready);
sound/soc/intel/catpt/loader.c:	ret = wait_for_completion_timeout(&cdev->fw_ready,
sound/soc/intel/common/sst-ipc.c:	/* wait for DSP completion (in all cases atm inc pending) */
sound/soc/intel/common/sst-ipc.c:		 * completion irq
sound/soc/qcom/qdsp6/q6dsp-errno.h:/* Operation is pending completion. */
sound/soc/sof/intel/hda-loader-skl.c:/* Interrupt On Completion Enable */
sound/soc/sof/intel/hda-loader-skl.c:	/* Disable the Interrupt On Completion, FIFO Error Interrupt,
sound/soc/sof/intel/hda-loader-skl.c:	/* Set the Interrupt On Completion, FIFO Error Interrupt,
sound/soc/sof/intel/hda-loader.c:		reinit_completion(&hda_stream->ioc);
sound/soc/sof/intel/hda-loader.c:		/* Wait for completion of transfer */
sound/soc/sof/intel/hda-loader.c:		time_left = wait_for_completion_timeout(&hda_stream->ioc,
sound/soc/sof/intel/hda-stream.c:				 * or data transfers which can rely on wait_for_completion()
sound/soc/sof/intel/hda-stream.c:		init_completion(&hda_stream->ioc);
sound/soc/sof/intel/hda.h:#include <linux/completion.h>
sound/soc/sof/intel/hda.h:/* Buffer completion interrupt */
sound/soc/sof/intel/hda.h:	struct completion ioc;
sound/soc/sof/ipc3.c:	/* wait for DSP IPC completion */
sound/soc/sof/ipc3.c:	/* now wait for completion */
sound/soc/sof/ipc3.c:		/* check for FW boot completion */
sound/soc/sof/ipc4.c:	/* wait for DSP IPC completion */
sound/soc/sof/ipc4.c:	/* now wait for completion */
sound/soc/sof/ipc4.c:		/* check for FW boot completion */
sound/soc/sof/sof-client-ipc-flood-test.c:#include <linux/completion.h>
sound/soc/sof/sof-client-ipc-flood-test.c:	/* test completion criterion */
sound/soc/sof/sof-client-ipc-msg-injector.c:#include <linux/completion.h>
sound/soc/sof/topology.c:/* completion - called at completion of firmware loading */
sound/soc/sof/topology.c:	/* completion - called at completion of firmware loading */
sound/soc/stm/stm32_spdifrx.c:#include <linux/completion.h>
sound/soc/stm/stm32_spdifrx.c: * @cs_completion: channel status retrieving completion
sound/soc/stm/stm32_spdifrx.c:	struct completion cs_completion;
sound/soc/stm/stm32_spdifrx.c:	complete(&spdifrx->cs_completion);
sound/soc/stm/stm32_spdifrx.c:	if (wait_for_completion_interruptible_timeout(&spdifrx->cs_completion,
sound/soc/stm/stm32_spdifrx.c:	init_completion(&spdifrx->cs_completion);
sound/sparc/dbri.c:CPU interrupt to signal completion.
sound/usb/line6/driver.c:	Notification of completion of asynchronous request transmission.
sound/usb/line6/midi.c:	Notification of completion of MIDI transmission.
sound/usb/midi.c: * Error handling for URB completion functions.
sound/usb/midi.c:	 * an URB's completion handler may start the timer and
sound/usb/midi2.c:/* URB completion for output; re-filling and re-submit */
sound/usb/midi2.c:/* URB completion for input; copy into rawmidi buffer and resubmit */
sound/usb/mixer_scarlett2.c:	struct completion cmd_done;
sound/usb/mixer_scarlett2.c:	if (!wait_for_completion_timeout(&private->cmd_done,
sound/usb/mixer_scarlett2.c:	init_completion(&private->cmd_done);
sound/virtio/virtio_card.c:MODULE_PARM_DESC(msg_timeout_ms, "Message completion timeout in milliseconds");
sound/virtio/virtio_card.h:/* Message completion timeout in milliseconds (module parameter). */
sound/virtio/virtio_ctl_msg.c:	struct completion notify;
sound/virtio/virtio_ctl_msg.c:	init_completion(&msg->notify);
sound/virtio/virtio_ctl_msg.c: * @nowait: Flag indicating whether to wait for completion.
sound/virtio/virtio_ctl_msg.c:	rc = wait_for_completion_interruptible_timeout(&msg->notify, js);
sound/virtio/virtio_ctl_msg.h: * The msg_timeout_ms module parameter defines the message completion timeout.
sound/virtio/virtio_pcm_msg.c: * Completion of the message means the elapsed period. If transmission is
sound/virtio/virtio_pcm_msg.c:	 * in the virtqueue. Therefore, on each completion of an I/O message,
sound/xen/xen_snd_front.c:	reinit_completion(&evtchnl->u.req.completion);
sound/xen/xen_snd_front.c:	if (wait_for_completion_timeout(&evtchnl->u.req.completion,
sound/xen/xen_snd_front_evtchnl.c:			complete(&channel->u.req.completion);
sound/xen/xen_snd_front_evtchnl.c:			complete(&channel->u.req.completion);
sound/xen/xen_snd_front_evtchnl.c:		complete_all(&channel->u.req.completion);
sound/xen/xen_snd_front_evtchnl.c:		init_completion(&channel->u.req.completion);
sound/xen/xen_snd_front_evtchnl.h:			struct completion completion;
tools/arch/x86/include/asm/amd-ibs.h:		__u64	comp_to_ret_ctr:16,	/* 0-15: op completion to retire count */
tools/bpf/bpf_dbg.c:static char **shell_completion(const char *buf, int start, int end)
tools/bpf/bpf_dbg.c:		matches = rl_completion_matches(buf, shell_comp_gen);
tools/bpf/bpf_dbg.c:	rl_attempted_completion_function = shell_completion;
tools/bpf/bpftool/Makefile:bash_compdir ?= /usr/share/bash-completion/completions
tools/bpf/bpftool/Makefile:	$(Q)$(INSTALL) -m 0644 bash-completion/bpftool $(DESTDIR)$(bash_compdir)
tools/bpf/bpftool/bash-completion/bpftool:# bpftool(8) bash completion                               -*- shell-script -*-
tools/bpf/bpftool/bash-completion/bpftool:    _init_completion -- "$@" || return
tools/bpf/bpftool/bash-completion/bpftool:    # Remove all options so completions don't have to deal with them.
tools/bpf/bpftool/bash-completion/bpftool:    # Completion depends on object and command in use
tools/hv/vmbus_bufring.h:#define VMBUS_CHANPKT_FLAG_RC		0x0001  /* report completion */
tools/include/uapi/drm/drm.h: * DRM_EVENT_FLIP_COMPLETE - page-flip completion event
tools/include/uapi/drm/i915_drm.h: *	detection, and a 0 upon reset completion, signifying no more error
tools/include/uapi/drm/i915_drm.h: * The returned output fence will be signaled after the completion of the
tools/include/uapi/drm/i915_drm.h:	 * Return request completion fence as output
tools/include/uapi/drm/i915_drm.h:	 * signaled completion for all pending requests that reference the
tools/include/uapi/drm/i915_drm.h: * completion. Persistence allows fire-and-forget clients to queue up a
tools/include/uapi/linux/if_xdp.h:	struct xdp_ring_offset cr; /* Completion */
tools/include/uapi/linux/if_xdp.h:#define XDP_UMEM_COMPLETION_RING	6
tools/include/uapi/linux/if_xdp.h:#define XDP_UMEM_PGOFF_COMPLETION_RING	0x180000000ULL
tools/include/uapi/linux/if_xdp.h:/* Request transmit timestamp. Upon completion, put it into tx_timestamp
tools/include/uapi/linux/if_xdp.h: * when the packet is being transmitted. 'completion' union member is
tools/include/uapi/linux/if_xdp.h: * filled by the driver when the transmit completion arrives.
tools/include/uapi/linux/if_xdp.h:		} completion;
tools/include/uapi/linux/io_uring.h:	__u64	user_data;	/* data to be passed back at completion time */
tools/include/uapi/linux/io_uring.h: * IO completion data structure (Completion Queue Entry)
tools/memory-model/Documentation/explanation.txt:completion, and real code generally doesn't bother to copy values into
tools/perf/Documentation/perf-record.txt:send control command completion ('ack\n') to ack-fd descriptor to synchronize with the
tools/perf/Documentation/perf-stat.txt:--delay=-1 option. Optionally send control command completion ('ack\n') to ack-fd descriptor
tools/perf/Makefile.perf:	$(call QUIET_INSTALL, perf_completion-script) \
tools/perf/Makefile.perf:		$(INSTALL) -d -m 755 '$(DESTDIR_SQ)$(sysconfdir_SQ)/bash_completion.d'; \
tools/perf/Makefile.perf:		$(INSTALL) perf-completion.sh -m 644 '$(DESTDIR_SQ)$(sysconfdir_SQ)/bash_completion.d/perf'
tools/perf/builtin-record.c:		 * after started aio request completion or at record__aio_push()
tools/perf/builtin-record.c:		     "\t\t\t  Optionally send control command completion ('ack\\n') to ack-fd descriptor.\n"
tools/perf/builtin-stat.c:			"\t\t\t  Optionally send control command completion ('ack\\n') to ack-fd descriptor.\n"
tools/perf/perf-completion.sh:# perf bash and zsh completion
tools/perf/perf-completion.sh:# Taken from git.git's completion script.
tools/perf/perf-completion.sh:	# List of word completion separators has shrunk;
tools/perf/perf-completion.sh:# Define preload__ltrim_colon_completions="false", if the function
tools/perf/perf-completion.sh:# __perf__ltrim_colon_completions() is required instead.
tools/perf/perf-completion.sh:preload__ltrim_colon_completions="true"
tools/perf/perf-completion.sh:if [ $preload__ltrim_colon_completions = "true" ]; then
tools/perf/perf-completion.sh:	type __ltrim_colon_completions &>/dev/null ||
tools/perf/perf-completion.sh:	preload__ltrim_colon_completions="false"
tools/perf/perf-completion.sh:[ $preload__ltrim_colon_completions = "true" ] ||
tools/perf/perf-completion.sh:__perf__ltrim_colon_completions()
tools/perf/perf-completion.sh:	if [ $preload__ltrim_colon_completions = "true" ]; then
tools/perf/perf-completion.sh:		__ltrim_colon_completions $cur
tools/perf/perf-completion.sh:		__perf__ltrim_colon_completions $cur
tools/perf/pmu-events/arch/powerpc/power10/frontend.json:    "EventName": "PM_FLUSH_COMPLETION",
tools/perf/pmu-events/arch/powerpc/power10/marked.json:    "BriefDescription": "Cycles from L2 RC dispatch to L2 RC completion."
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "EXCEPTION_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "MEM_ECC_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "STCX_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "LWSYNC_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "HWSYNC_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "BriefDescription": "Average cycles per completed instruction when the NTC instruction required special handling before completion",
tools/perf/pmu-events/arch/powerpc/power10/metrics.json:        "MetricName": "SPECIAL_COMPLETION_STALL_CPI"
tools/perf/pmu-events/arch/powerpc/power10/others.json:    "BriefDescription": "Isync completion count per thread."
tools/perf/pmu-events/arch/powerpc/power10/pipeline.json:    "BriefDescription": "Cycles in which both instructions in the ICT entry pair show as finished. These are the cycles between finish and completion for the oldest pair of instructions in the pipeline."
tools/perf/pmu-events/arch/powerpc/power10/pipeline.json:    "BriefDescription": "Cycles in which the oldest instruction in the pipeline completed without an ntf_type pulse. The ntf_pulse was missed by the ISU because the next-to-finish (NTF) instruction finishes and completions came too close together."
tools/perf/pmu-events/arch/powerpc/power10/pipeline.json:    "BriefDescription": "Non-speculative instruction cache miss, counted at completion."
tools/perf/pmu-events/arch/powerpc/power8/marked.json:    "BriefDescription": "Marked Group completion Stall",
tools/perf/pmu-events/arch/powerpc/power8/marked.json:    "PublicDescription": "Marked Group Completion Stall cycles (use edge detect to count #)"
tools/perf/pmu-events/arch/powerpc/power8/marked.json:    "BriefDescription": "cycles from L2 rc disp to l2 rc completion",
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "MetricName": "completion_cpi"
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "BriefDescription": "Completion Stall Cycles",
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "BriefDescription": "Instruction dispatch-to-completion ratio",
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "BriefDescription": "Base Completion Cycles",
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "MetricName": "base_completion_cpi"
tools/perf/pmu-events/arch/powerpc/power8/metrics.json:        "BriefDescription": "Marked store latency, from core completion to L2 RC machine completion",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) OR if_pc_br0_br_pred(1)",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) AND if_pc_br0_pred_type",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(1)='1'",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0) AND (not if_pc_br0_pred_type)",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred(0)='1'",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion Time Event. This event can also be calculated from the direct bus as follows: if_pc_br0_br_pred=00 AND if_pc_br0_completed",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to IFU",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to CO q full",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "completion stall due to flush by own thread",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to mem ECC delay",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to nop",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to ntcg flush",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "PublicDescription": "Completion stall due to reject (load hit store)"
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to LSU reject",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to reject (load hit store)",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to LSU reject LMQ full",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to VSU scalar instruction",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to VSU scalar long latency instruction",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall by stores this includes store agen finishes in pipe LS0/LS1 and store data finishes in LS2/LS3",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to VSU vector instruction",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to VSU vector long instruction",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion stall due to VSU instruction",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion time nested tend",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion time outer tbegin",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion time outer tend",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Completion time tabortnoncd, tabortcd, treclaim",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "Cycles group completed on both completion slots by any thread",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "TEXAS fail reason @ completion",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "TEXAS fail reason @ completion",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "TEXAS fail reason @ completion",
tools/perf/pmu-events/arch/powerpc/power8/other.json:    "BriefDescription": "TEXAS fail reason @ completion",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to a Branch Unit",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall by Dcache miss",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3)",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall by Dcache miss which resolved in L2/L3",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to cache miss that resolves in the L2 or L3 with a conflict",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "PublicDescription": "Completion stall due to cache miss resolving in core's L2/L3 with a conflict"
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to cache miss resolving missed the L3",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to cache miss that resolves in local memory",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "PublicDescription": "Completion stall due to cache miss resolving in core's Local Memory"
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall by Dcache miss which resolved from remote chip (cache or memory)",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "PublicDescription": "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3)"
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to LSU reject ERAT miss",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to a long latency fixed point instruction",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to FXU",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "completion stall due to hwsync",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to a Load finish",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall by LSU instruction",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "completion stall due to isync/lwsync",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion stall due to store forward",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion Stalled due to thread conflict. Group ready to complete but it was another thread's turn",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "PublicDescription": "Completion stall due to thread conflict"
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "EventName": "PM_FLUSH_COMPLETION",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Completion Flush",
tools/perf/pmu-events/arch/powerpc/power8/pipeline.json:    "BriefDescription": "Store completion count",
tools/perf/pmu-events/arch/powerpc/power9/cache.json:    "BriefDescription": "Cycles in which the NTC instruction is not allowed to complete because any of the 4 threads in the same core suffered a flush, which blocks completion"
tools/perf/pmu-events/arch/powerpc/power9/cache.json:    "BriefDescription": "Completion stall due to a long latency scalar fixed point instruction (division, square root)"
tools/perf/pmu-events/arch/powerpc/power9/cache.json:    "BriefDescription": "Completion stall by Dcache miss which resolved in L2/L3"
tools/perf/pmu-events/arch/powerpc/power9/cache.json:    "BriefDescription": "Completion stall due to cache miss that resolves in the L2 or L3 with a conflict"
tools/perf/pmu-events/arch/powerpc/power9/floating-point.json:    "EventName": "PM_FLUSH_COMPLETION",
tools/perf/pmu-events/arch/powerpc/power9/frontend.json:    "BriefDescription": "Completion stall of one cycle because the LSU requested to flush the next iop in the sequence. It takes 1 cycle for the ISU to process this request before the LSU instruction is allowed to complete"
tools/perf/pmu-events/arch/powerpc/power9/frontend.json:    "BriefDescription": "Completion stall by LSU instruction"
tools/perf/pmu-events/arch/powerpc/power9/frontend.json:    "BriefDescription": "Completion stall because the ISU is updating the register and notifying the Effective Address Table (EAT)"
tools/perf/pmu-events/arch/powerpc/power9/frontend.json:    "BriefDescription": "Completion stall due to store forward"
tools/perf/pmu-events/arch/powerpc/power9/marked.json:    "BriefDescription": "Completion stall by Dcache miss which resolved from remote chip (cache or memory)"
tools/perf/pmu-events/arch/powerpc/power9/marked.json:    "BriefDescription": "Completion stall due to ntc flush"
tools/perf/pmu-events/arch/powerpc/power9/marked.json:    "BriefDescription": "cycles from L2 rc disp to l2 rc completion"
tools/perf/pmu-events/arch/powerpc/power9/marked.json:    "BriefDescription": "Completion stall because the ISU is updating the TEXASR to keep track of the nested tend and decrement the TEXASR nested level. This is a short delay"
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to a Branch Unit",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by Dcache miss which resolved off node memory/cache",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to cache miss that resolves in the L2 or L3 with a conflict",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to cache miss that resolves in the L2 or L3 without conflict",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by Dcache miss which resolved in L2/L3",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to cache miss resolving missed the L3",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to cache miss that resolves in local memory",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by Dcache miss which resolved outside of local memory",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by Dcache miss which resolved from remote chip (cache or memory)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to execution units for other reasons.",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to execution units (FXU/VSU/CRU)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Cycles in which the NTC instruction is not allowed to complete because any of the 4 threads in the same core suffered a flush, which blocks completion",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to a long latency scalar fixed point instruction (division, square root)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to branch mispred",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to Icache Miss and branch mispred",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table other stalls",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to dispatch holds because the History Buffer was full. Could be GPR/VSR/VMR/FPR/CR/XVF",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to dispatch hold on this thread due to Issue q full, BRQ full, XVCF Full, Count cache, Link, Tar full",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to icache misses that were sourced from the local L3",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to icache misses that were sourced from beyond the local L3. The source could be local/remote/distant memory or another core's cache",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction Completion Table empty for this thread due to Icache Miss",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall of one cycle because the LSU requested to flush the next iop in the sequence. It takes 1 cycle for the ISU to process this request before the LSU instruction is allowed to complete",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion LSU stall for other reasons",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall by LSU instruction",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall because the ISU is updating the register and notifying the Effective Address Table (EAT)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall because the ISU is updating the TEXASR to keep track of the nested tbegin. This is a short delay, and it includes ROT",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall because the ISU is updating the TEXASR to keep track of the nested tend and decrement the TEXASR nested level. This is a short delay",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Number of cycles the Instruction Completion Table has no itags assigned to this thread",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to ntc flush",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "MetricExpr": "run_cpi - completion_cpi - thread_block_stall_cpi - stall_cpi - nothing_dispatched_cpi",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall for other reasons",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to store forward",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Nothing completed and Instruction Completion Table not empty",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion Stalled because the thread was blocked",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall due to a long latency vector fixed point instruction (division, square root)",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Instruction dispatch-to-completion ratio",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "MetricName": "completion_cpi"
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Cycles in which the oldest instruction is finished and ready to complete for waiting to get through the completion pipe",
tools/perf/pmu-events/arch/powerpc/power9/metrics.json:        "BriefDescription": "Completion stall because a different thread was using the completion pipe",
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion Stalled because the thread was blocked"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Counts the number of cycles the LRQF is full.  LRQF is the queue that holds loads between finish and completion.  If it fills up, instructions stay in LRQ until completion, potentially backing up the LRQ"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion stall due to cache miss resolving missed the L3"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion time outer tend"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion Tm nested tbegin"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion time nested tend"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Counts the number of cycles the LRQF is full.  LRQF is the queue that holds loads between finish and completion.  If it fills up, instructions stay in LRQ until completion, potentially backing up the LRQ"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "The TAGE overrode BHT direction prediction and it was correct.  Counted at completion for taken branches only"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion time outer tbegin"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Isync completion count per thread"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion stall because the ISU is updating the TEXASR to keep track of the nested tbegin. This is a short delay, and it includes ROT"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "The TAGE overrode BHT direction prediction but it was incorrect.  Counted at completion for taken branches only"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion time tabortnoncd, tabortcd, treclaim"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Conditional Branch Completed in which the HW correctly predicted the direction as taken.  Counted at completion time"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion stall due to cache miss that resolves in local memory"
tools/perf/pmu-events/arch/powerpc/power9/other.json:    "BriefDescription": "Completion stall due to execution units (FXU/VSU/CRU)"
tools/perf/pmu-events/arch/powerpc/power9/pipeline.json:    "BriefDescription": "Completion stall by Dcache miss which resolved on chip ( excluding local L2/L3)"
tools/perf/pmu-events/arch/powerpc/power9/pipeline.json:    "BriefDescription": "Non-speculative icache miss, counted at completion"
tools/perf/pmu-events/arch/powerpc/power9/pmc.json:    "BriefDescription": "Completion stall due to a Branch Unit"
tools/perf/pmu-events/arch/powerpc/power9/translation.json:    "BriefDescription": "Cycles during which the marked instruction is next to complete (completion is held up because the marked instruction hasn't completed yet)"
tools/perf/pmu-events/arch/powerpc/power9/translation.json:    "BriefDescription": "Completion stall due to a long latency vector fixed point instruction (division, square root)"
tools/perf/pmu-events/arch/s390/cf_z13/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode not using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z13/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z14/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode not using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z14/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z15/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode not using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z15/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z16/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode using special completion logic",
tools/perf/pmu-events/arch/s390/cf_z16/extended.json:		"EventName": "NNPA_COMPLETIONS",
tools/perf/pmu-events/arch/s390/cf_z16/extended.json:		"BriefDescription": "NNPA Total completions",
tools/perf/pmu-events/arch/s390/cf_zec12/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode not using special completion logic",
tools/perf/pmu-events/arch/s390/cf_zec12/extended.json:		"BriefDescription": "Aborted transactions in constrained TX mode using special completion logic",
tools/perf/pmu-events/arch/x86/alderlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/alderlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/alderlake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/alderlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.\nNote: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/broadwell/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.\nNote: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/broadwellde/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellde/uncore-cache.json:        "PublicDescription": "Counts the number of outbound transactions on the AD ring.  This can be filtered by the NDR and SNP message classes.  See the filter descriptions for more details.; Filter for outbound NDR transactions sent on the AD ring.  NDR stands for non-data response and is generally used for completions that do not include data.  AD NDR is used for transactions to remote sockets.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The Offcore outstanding state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.\nNote: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/broadwellx/cache.json:        "PublicDescription": "This event counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-cache.json:        "PublicDescription": "Counts the number of outbound transactions on the AD ring.  This can be filtered by the NDR and SNP message classes.  See the filter descriptions for more details.; Filter for outbound NDR transactions sent on the AD ring.  NDR stands for non-data response and is generally used for completions that do not include data.  AD NDR is used for transactions to remote sockets.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a DRS VN0 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN0 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a VN1 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN1 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/broadwellx/uncore-interconnect.json:        "PublicDescription": "Number of attempted VNA credit acquisitions that were rejected because the VNA credit pool was full (or almost full).  It is possible to filter this event by message class.  Some packets use more than one flit buffer, and therefore must acquire multiple credits.  Therefore, one could get a reject even if the VNA credits were not fully used up.  The VNA pool is generally used to provide the bulk of the QPI bandwidth (as opposed to the VN0 pool which is used to guarantee forward progress).  VNA credits can run out if the flit buffer on the receiving side starts to queue up substantially.  This can happen if the rest of the uncore is unable to drain the requests fast enough.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.Note: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/cascadelakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/cascadelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "BriefDescription": "P2P Transactions; P2P completions",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message requested but lost arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message requested but lost arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message requested but lost arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message requested but lost arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN0 packets lost the contest for Flit Slot 0.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN0 packets lost the contest for Flit Slot 0.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN1 packets lost the contest for Flit Slot 0.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN1 packets lost the contest for Flit Slot 0.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "D2K completion fifo credit occupancy (credits in use), accumulated across all cycles",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "count of bl messages in pump-1-pending state, in completion fifo only",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "pump-1-pending logic is at capacity (pending table plus completion fifo at limit)",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "pump-1-pending completion fifo is full",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN0 Credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN0 Credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN1 Credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN1 Credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-3",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 0",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 1",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 2",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 3",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 0-3",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses; FM read completions",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses; FM write completions",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses; NM read completions",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses; NM write completions",
tools/perf/pmu-events/arch/x86/cascadelakex/uncore-memory.json:        "PublicDescription": "Counts the number of entries in the Write Pending Queue (WPQ) at each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule writes out to the memory controller and to track the requests.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC (memory controller).  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have 'posted' to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the 'not posted' filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The 'posted' filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/emeraldrapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/emeraldrapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/emeraldrapids/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/emeraldrapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on AD : VN0 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on BL : VN0 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on AD : VN1 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on BL : VN1 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on AD : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on BL : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on AD : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on BL : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on AD : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on BL : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on AD : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on BL : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : D2K Credits : D2K completion fifo credit occupancy (credits in use), accumulated across all cycles",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : count of bl messages in pump-1-pending state, in completion fifo only",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on AD : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on BL : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending logic is at capacity (pending table plus completion fifo at limit)",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending completion fifo is full",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on AD : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on BL : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on AD : Number of Cycles there were no VN0 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on BL : Number of Cycles there were no VN0 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on AD : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on BL : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on AD : Number of Cycles there were no VN1 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on BL : Number of Cycles there were no VN1 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 4",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 5",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 6",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 1",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 2",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 3",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 4",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 5",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 6",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy: Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to memory.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy: Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to memory.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM read completions",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM write completions",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM read completions",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM write completions",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/emeraldrapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/grandridge/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/graniterapids/cache.json:        "PublicDescription": "Counts the number of off-core outstanding read-for-ownership (RFO) store transactions every cycle. An RFO transaction is considered to be in the Off-core outstanding state between L2 cache miss and transaction completion.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/graniterapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/graniterapids/uncore-io.json:        "BriefDescription": "Occupancy of outbound request queue : To device : Counts number of outbound requests/completions IIO is currently processing",
tools/perf/pmu-events/arch/x86/haswellx/uncore-cache.json:        "PublicDescription": "Counts the number of outbound transactions on the AD ring.  This can be filtered by the NDR and SNP message classes.  See the filter descriptions for more details.; Filter for outbound NDR transactions sent on the AD ring.  NDR stands for non-data response and is generally used for completions that do not include data.  AD NDR is used for transactions to remote sockets.",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a DRS VN0 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN0 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a VN1 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN1 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/haswellx/uncore-interconnect.json:        "PublicDescription": "Number of attempted VNA credit acquisitions that were rejected because the VNA credit pool was full (or almost full).  It is possible to filter this event by message class.  Some packets use more than one flit buffer, and therefore must acquire multiple credits.  Therefore, one could get a reject even if the VNA credits were not fully used up.  The VNA pool is generally used to provide the bulk of the QPI bandwidth (as opposed to the VN0 pool which is used to guarantee forward progress).  VNA credits can run out if the flit buffer on the receiving side starts to queue up substantially.  This can happen if the rest of the uncore is unable to drain the requests fast enough.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding data read requests pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelake/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding data read request is pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelake/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding Demand RFO request is pending.   RFOs are initiated by a core as part of a data store operation.  Demand RFO requests include RFOs, locks, and ItoM transactions.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelake/cache.json:        "PublicDescription": "Counts the number of off-core outstanding read-for-ownership (RFO) store transactions every cycle. An RFO transaction is considered to be in the Off-core outstanding state between L2 cache miss and transaction completion.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/icelake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding data read requests pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding data read request is pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "Cycles with outstanding code read requests pending.  Code Read requests include both cacheable and non-cacheable Code Reads.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding Demand RFO request is pending.   RFOs are initiated by a core as part of a data store operation.  Demand RFO requests include RFOs, locks, and ItoM transactions.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding code read requests pending.  Code Read requests include both cacheable and non-cacheable Code Reads.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/icelakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "BriefDescription": "P2P Transactions : P2P completions",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on AD : VN0 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on BL : VN0 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on AD : VN1 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on BL : VN1 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on AD : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on BL : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on AD : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on BL : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on AD : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on BL : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on AD : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on BL : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : D2K Credits : D2K completion fifo credit occupancy (credits in use), accumulated across all cycles",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : count of bl messages in pump-1-pending state, in completion fifo only",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on AD : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on BL : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Cycles Not Empty : RSP on AD : Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Cycles Not Empty : RSP on BL : Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending logic is at capacity (pending table plus completion fifo at limit)",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending completion fifo is full",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Inserts : RSP on AD : Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Inserts : RSP on BL : Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Inserts : RSP on AD : Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Inserts : RSP on BL : Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Occupancy : RSP on AD : Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Occupancy : RSP on BL : Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Occupancy : RSP on AD : Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Ingress (from CMS) Queue - Occupancy : RSP on BL : Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on AD : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on BL : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on AD : Number of Cycles there were no VN0 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on BL : Number of Cycles there were no VN0 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on AD : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on BL : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on AD : Number of Cycles there were no VN1 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on BL : Number of Cycles there were no VN1 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts : All Ports",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0-7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 3 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 4 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 5 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 6 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 7 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Occupancy of outbound request queue : To device : Counts number of outbound requests/completions IIO is currently processing",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number requests sent to PCIe from main die : Completion allocations",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/icelakex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM read completions",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM write completions",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM read completions",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM write completions",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/icelakex/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-cache.json:        "PublicDescription": "Counts the number of outbound transactions on the AD ring.  This can be filtered by the NDR and SNP message classes.  See the filter descriptions for more details.; Filter for outbound NDR transactions sent on the AD ring.  NDR stands for non-data response and is generally used for completions that do not include data.  AD NDR is used for transactions to remote sockets.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits received from the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits received over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets to the local socket which use the AK ring.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Counts the number of flits transmitted across the QPI Link.  This is one of three groups that allow us to track flits.  It includes filters for NDR, NCB, and NCS message classes.  Each flit is made up of 80 bits of information (in addition to some ECC data).  In full-width (L0) mode, flits are made up of four fits, each of which contains 20 bits of data (along with some additional ECC data).   In half-width (L0p) mode, the fits are only 10 bits, and therefore it takes twice as many fits to transmit a flit.  When one talks about QPI speed (for example, 8.0 GT/s), the transfers here refer to fits.  Therefore, in L0, the system will transfer 1 flit at the rate of 1/4th the QPI speed.  One can calculate the bandwidth of the link by taking: flits*80b/time.  Note that this is not the same as data bandwidth.  For example, when we are transferring a 64B cacheline across QPI, we will break it into 9 flits -- 1 with header information and 8 with 64 bits of actual data and an additional 16 bits of other information.  To calculate data bandwidth, one should therefore do: data flits * 8B / time.; Counts the total number of flits transmitted over the NDR (Non-Data Response) channel.  This channel is used to send a variety of protocol flits including grants and completions.  This is only for NDR packets destined for Route-thru to a remote socket.",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a DRS VN0 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN0 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Number of times a request failed to acquire a VN1 credit.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This therefore counts the number of times when a request failed to acquire either a VNA or VN1 credit and is delayed.  This should generally be a rare situation.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the DRS message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/ivytown/uncore-interconnect.json:        "PublicDescription": "Number of attempted VNA credit acquisitions that were rejected because the VNA credit pool was full (or almost full).  It is possible to filter this event by message class.  Some packets use more than one flit buffer, and therefore must acquire multiple credits.  Therefore, one could get a reject even if the VNA credits were not fully used up.  The VNA pool is generally used to provide the bulk of the QPI bandwidth (as opposed to the VN0 pool which is used to guarantee forward progress).  VNA credits can run out if the flit buffer on the receiving side starts to queue up substantially.  This can happen if the rest of the uncore is unable to drain the requests fast enough.; NDR packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/jaketown/uncore-cache.json:        "PublicDescription": "Counts the number of outbound NDR transactions sent on the AK ring.  NDR stands for 'non-data response' and is generally used for completions that do not include data.  AK NDR is used for messages to the local socket.",
tools/perf/pmu-events/arch/x86/jaketown/uncore-memory.json:        "PublicDescription": "Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have 'posted' to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the 'not posted' filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The 'posted' filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/lunarlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/meteorlake/cache.json:        "PublicDescription": "Counts the number of off-core outstanding read-for-ownership (RFO) store transactions every cycle. An RFO transaction is considered to be in the Off-core outstanding state between L2 cache miss and transaction completion.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 2048 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/meteorlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding data read requests pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/rocketlake/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding data read request is pending.  Data read requests include cacheable demand reads and L2 prefetches, but do not include RFOs, code reads or prefetches to the L3.  Reads due to page walks resulting from any request type will also be counted.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/rocketlake/cache.json:        "PublicDescription": "Cycles where at least 1 outstanding Demand RFO request is pending.   RFOs are initiated by a core as part of a data store operation.  Demand RFO requests include RFOs, locks, and ItoM transactions.  Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/rocketlake/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/rocketlake/cache.json:        "PublicDescription": "Counts the number of off-core outstanding read-for-ownership (RFO) store transactions every cycle. An RFO transaction is considered to be in the Off-core outstanding state between L2 cache miss and transaction completion.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/rocketlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/sapphirerapids/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/sapphirerapids/cache.json:        "PublicDescription": "For every cycle, increments by the number of outstanding demand data read requests pending.   Requests are considered outstanding from the time they miss the core's L2 cache until the transaction completion message is sent to the requestor.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 1024 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/sapphirerapids/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on AD : VN0 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN0 : RSP on BL : VN0 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on AD : VN1 message requested but lost arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Lost Arb for VN1 : RSP on BL : VN1 message requested but lost arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on AD : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN0 : RSP on BL : VN0 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on AD : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "No Credits to Arb for VN1 : RSP on BL : VN1 message is blocked from requesting arbitration due to lack of remote UPI credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on AD : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN0 : RSP on BL : VN0 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on AD : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Can't Arb for VN1 : RSP on BL : VN1 message was not able to request arbitration while some other message won arbitration : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : D2K Credits : D2K completion fifo credit occupancy (credits in use), accumulated across all cycles",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Credit Occupancy : count of bl messages in pump-1-pending state, in completion fifo only",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on AD : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 Ingress (from CMS) Queue - Cycles Not Empty : RSP on BL : Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending logic is at capacity (pending table plus completion fifo at limit)",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "Generating BL Data Flit Sequence : pump-1-pending completion fifo is full",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on AD : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 message can't slot into flit : RSP on BL : Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on AD : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 Credit Used : RSP on BL : Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on AD : Number of Cycles there were no VN0 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN0 No Credits : RSP on BL : Number of Cycles there were no VN0 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on AD : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 Credit Used : RSP on BL : Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers. : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on AD : Number of Cycles there were no VN1 Credits : Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-interconnect.json:        "PublicDescription": "VN1 No Credits : RSP on BL : Number of Cycles there were no VN1 Credits : Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 4",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 5",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 6",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 1",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 2",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 3",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 4",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 5",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 6",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy : Part 7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy: Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to memory.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy: Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to memory.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM read completions",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : FM write completions",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM read completions",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "BriefDescription": "Scoreboard Accesses : NM write completions",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/sapphirerapids/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "PCIE Completion Buffer Inserts.  Counts once per 64 byte read issued from this PCIE device.",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Count of allocations in the completion buffer",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/sierraforest/uncore-io.json:        "BriefDescription": "Occupancy of outbound request queue : To device : Counts number of outbound requests/completions IIO is currently processing",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.Note: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/skylake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/skylake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.Note: A prefetch promoted to Demand is counted from the promotion point.",
tools/perf/pmu-events/arch/x86/skylakex/cache.json:        "PublicDescription": "Counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/skylakex/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "BriefDescription": "P2P Transactions; P2P completions",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message requested but lost arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message requested but lost arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message requested but lost arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message requested but lost arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message was not able to request arbitration while some other message won arbitration; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN0 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "VN1 message is blocked from requesting arbitration due to lack of remote UPI credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN0 packets lost the contest for Flit Slot 0.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN0 packets lost the contest for Flit Slot 0.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN1 packets lost the contest for Flit Slot 0.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress VN1 packets lost the contest for Flit Slot 0.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "D2K completion fifo credit occupancy (credits in use), accumulated across all cycles",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "count of bl messages in pump-1-pending state, in completion fifo only",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of cycles when the UPI Ingress is not empty.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue occupancy.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "pump-1-pending logic is at capacity (pending table plus completion fifo at limit)",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "pump-1-pending completion fifo is full",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Counts the number of allocations into the UPI VN1  Ingress.  This tracks one of the three rings that are used by the UPI agent.  This can be used in conjunction with the UPI VN1  Ingress Occupancy Accumulator event in order to calculate average queue latency.  Multiple ingress buffers can be tracked at a given time using multiple counters.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Accumulates the occupancy of a given UPI VN1  Ingress queue in each cycle.  This tracks one of the three ring Ingress buffers.  This can be used with the UPI VN1  Ingress Not Empty event to calculate average occupancy or the UPI VN1  Ingress Allocations event in order to calculate average queuing latency.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Count cases where Ingress has packets to send but did not have time to pack into flit before sending to Agent so slot was left NULL which could have been used.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN0 credit was used on the DRS message channel.  In order for a request to be transferred across UPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN0.  VNA is a shared pool used to achieve high performance.  The VN0 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN0 if they fail.  This counts the number of times a VN0 credit was used.  Note that a single VN0 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN0 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN0 Credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN0 Credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of times a VN1 credit was used on the WB message channel.  In order for a request to be transferred across QPI, it must be guaranteed to have a flit buffer on the remote socket to sink into.  There are two credit pools, VNA and VN1.  VNA is a shared pool used to achieve high performance.  The VN1 pool has reserved entries for each message class and is used to prevent deadlock.  Requests first attempt to acquire a VNA credit, and then fall back to VN1 if they fail.  This counts the number of times a VN1 credit was used.  Note that a single VN1 credit holds access to potentially multiple flit buffers.  For example, a transfer that uses VNA could use 9 flit buffers and in that case uses 9 credits.  A transfer on VN1 will only count a single credit even though it may use multiple buffers.; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN1 Credits; Response (RSP) messages on AD.  RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-interconnect.json:        "PublicDescription": "Number of Cycles there were no VN1 Credits; Response (RSP) messages on BL. RSP packets are used to transmit a variety of protocol flits including grants and completions (CMP).",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-3",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 0",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 1",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 2",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts; Port 3",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 0-3",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer occupancy of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Data requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU; Completion of atomic requests targeting DRAM",
tools/perf/pmu-events/arch/x86/skylakex/uncore-memory.json:        "PublicDescription": "Counts the number of entries in the Write Pending Queue (WPQ) at each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule writes out to the memory controller and to track the requests.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC (memory controller).  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have 'posted' to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the 'not posted' filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The 'posted' filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-interconnect.json:        "BriefDescription": "P2P Transactions : P2P completions",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts : All Ports",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Inserts of completions with data: Part 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Inserts of completions with data : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0-7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 0 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 1 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 2 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 3 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 4 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 5 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 6 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "PCIe Completion Buffer Occupancy of completions with data : Part 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "PCIe Completion Buffer Occupancy : Part 7 : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested by the CPU : Core reporting completion of Card read from Core DRAM : Number of DWs (4 bytes) requested by the main die.  Includes all requests initiated by the main die, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Data requested of the CPU : CmpD - device sending completion to CPU request : Number of DWs (4 bytes) the card requests of the main die.    Includes all requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Occupancy of outbound request queue : To device : Counts number of outbound requests/completions IIO is currently processing",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number requests sent to PCIe from main die : Completion allocations",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : IOMMU - Type 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : IOMMU - Type 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 0/1/2/3, Or x8 card plugged in to Lane 0/1, Or x4 card is plugged in to slot 0",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 1",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 2/3, Or x4 card is plugged in to slot 2",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 3",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x16 card plugged in to Lane 4/5/6/7, Or x8 card plugged in to Lane 4/5, Or x4 card is plugged in to slot 4",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 5",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x8 card plugged in to Lane 6/7, Or x4 card is plugged in to slot 6",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "BriefDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-io.json:        "PublicDescription": "Number Transactions requested of the CPU : CmpD - device sending completion to CPU request : Also known as Inbound.  Number of 64B cache line requests initiated by the Card, including reads and writes. : x4 card is plugged in to slot 7",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/snowridgex/uncore-memory.json:        "PublicDescription": "Write Pending Queue Occupancy : Accumulates the occupancies of the Write Pending Queue each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule write out to the memory controller and to track the writes.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the HA to the iMC.  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have posted to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the not posted filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The posted filter, on the other hand, provides information about how much queueing is actually happening in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts.",
tools/perf/pmu-events/arch/x86/tigerlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/tigerlake/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/tigerlake/cache.json:        "PublicDescription": "Counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).",
tools/perf/pmu-events/arch/x86/tigerlake/cache.json:        "PublicDescription": "Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The 'Offcore outstanding' state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.",
tools/perf/pmu-events/arch/x86/tigerlake/cache.json:        "PublicDescription": "Counts the number of off-core outstanding read-for-ownership (RFO) store transactions every cycle. An RFO transaction is considered to be in the Off-core outstanding state between L2 cache miss and transaction completion.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "BriefDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.",
tools/perf/pmu-events/arch/x86/tigerlake/memory.json:        "PublicDescription": "Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.",
tools/perf/tests/builtin-test.c:/* Don't fork the tests in parallel and wait for their completion. */
tools/perf/tests/make:installed_files_bin += etc/bash_completion.d/perf
tools/perf/trace/beauty/include/uapi/linux/usbdevice_fs.h:	unsigned int signr;	/* signal to be sent on completion,
tools/power/cpupower/Makefile:bash_completion_dir ?= /usr/share/bash-completion/completions
tools/power/cpupower/Makefile:#bash completion scripts get sourced and so they should be rw only.
tools/power/cpupower/Makefile:	$(INSTALL) -d $(DESTDIR)${bash_completion_dir}
tools/power/cpupower/Makefile:	$(INSTALL_SCRIPT) cpupower-completion.sh '$(DESTDIR)${bash_completion_dir}/cpupower'
tools/power/cpupower/Makefile:	@echo  '                    "cpupower-completion.sh" script from the src dir to the'
tools/power/cpupower/cpupower-completion.sh:# bash completion script for cpupower
tools/power/cpupower/cpupower-completion.sh:# Taken from git.git's completion script.
tools/power/cpupower/man/cpupower-monitor.1:statistics are printed upon its completion, or statistics are printed periodically.
tools/power/pm-graph/README: On completion, the output folder contains a series of folders for the
tools/power/x86/turbostat/turbostat.8:in one-shot upon its completion.
tools/testing/nvdimm/test/iomap.c:	wait_for_completion(&pgmap->done);
tools/testing/nvdimm/test/iomap.c:	init_completion(&pgmap->done);
tools/testing/radix-tree/regression1.c: * This test should run to completion in a few seconds. The above bug would
tools/testing/radix-tree/regression2.c: * This test should run to completion immediately. The above bug would cause it
tools/testing/radix-tree/regression3.c: * This test should run to completion immediately. The above bug would
tools/testing/selftests/arm64/signal/test_signals.h:	 * signum considered as a successful test completion.
tools/testing/selftests/arm64/signal/test_signals.h:	/* a timeout in second for test completion */
tools/testing/selftests/arm64/signal/test_signals_utils.h:	 *   that the registered SIGTRAP handler has been run to completion
tools/testing/selftests/bpf/prog_tests/xdp_metadata.c:	 * to the completion queue index.
tools/testing/selftests/bpf/prog_tests/xdp_metadata.c:		ASSERT_NEQ(meta->completion.tx_timestamp, 0, "tx_timestamp");
tools/testing/selftests/bpf/test_bpftool_synctypes.py:    os.path.join(BPFTOOL_DIR, 'bash-completion'))
tools/testing/selftests/bpf/test_bpftool_synctypes.py:        completion file, for example:
tools/testing/selftests/bpf/test_bpftool_synctypes.py:    An extractor for bpftool's bash completion file.
tools/testing/selftests/bpf/test_bpftool_synctypes.py:    completion are all in sync on program types, map types, attach types, and
tools/testing/selftests/bpf/xdp_hw_metadata.c: * - TX HW timestamp is requested and reported back upon completion
tools/testing/selftests/bpf/xdp_hw_metadata.c:	 * to the completion queue index.
tools/testing/selftests/bpf/xdp_hw_metadata.c:	if (meta->completion.tx_timestamp) {
tools/testing/selftests/bpf/xdp_hw_metadata.c:				   meta->completion.tx_timestamp, ref_tstamp);
tools/testing/selftests/bpf/xdp_hw_metadata.c:				   last_hw_rx_timestamp, meta->completion.tx_timestamp);
tools/testing/selftests/bpf/xsk.c:	err = setsockopt(fd, SOL_XDP, XDP_UMEM_COMPLETION_RING,
tools/testing/selftests/bpf/xsk.c:		   XDP_UMEM_PGOFF_COMPLETION_RING);
tools/testing/selftests/bpf/xskxceiver.c: *    a. nopoll - soft-irq processing in run-to-completion mode
tools/testing/selftests/bpf/xskxceiver.c: *       completion rings on each socket, tx/rx in both directions. Only nopoll
tools/testing/selftests/bpf/xskxceiver.c:			ksft_print_msg("Last completion address: %llx\n",
tools/testing/selftests/bpf/xskxceiver.c:static int wait_for_tx_completion(struct xsk_socket_info *xsk)
tools/testing/selftests/bpf/xskxceiver.c:			ret = wait_for_tx_completion(&ifobject->xsk_arr[i]);
tools/testing/selftests/kvm/arch_timer.c:	/* Currently, any exit from guest is an indication of completion */
tools/testing/selftests/livepatch/test_modules/test_klp_callbacks_busy.c:static DECLARE_COMPLETION(busymod_work_started);
tools/testing/selftests/livepatch/test_modules/test_klp_callbacks_busy.c:	wait_for_completion(&busymod_work_started);
tools/testing/selftests/mm/hugetlb_dio.c: * should be properly unpinned upon completion. This patch verifies that the
tools/testing/selftests/mm/hugetlb_dio.c: * kernel correctly unpins the buffer at DIO completion for both aligned and
tools/testing/selftests/net/mptcp/simult_flows.sh:	# completion (see mptcp_connect): 200ms on each side, add some slack
tools/testing/selftests/net/msg_zerocopy.c: * the kernel queues completions on the error queue for all zerocopy
tools/testing/selftests/net/msg_zerocopy.c:static long packets, bytes, completions, expected_completions;
tools/testing/selftests/net/msg_zerocopy.c:static uint32_t next_completion;
tools/testing/selftests/net/msg_zerocopy.c:			expected_completions++;
tools/testing/selftests/net/msg_zerocopy.c:static bool do_recvmsg_completion(int fd)
tools/testing/selftests/net/msg_zerocopy.c:		    cmsg->cmsg_type == RDS_CMSG_ZCOPY_COMPLETION) {
tools/testing/selftests/net/msg_zerocopy.c:			completions += do_process_zerocopy_cookies(ck);
tools/testing/selftests/net/msg_zerocopy.c:static bool do_recv_completion(int fd, int domain)
tools/testing/selftests/net/msg_zerocopy.c:		return do_recvmsg_completion(fd);
tools/testing/selftests/net/msg_zerocopy.c:	if (cfg_verbose && lo != next_completion)
tools/testing/selftests/net/msg_zerocopy.c:			lo, hi, next_completion);
tools/testing/selftests/net/msg_zerocopy.c:	next_completion = hi + 1;
tools/testing/selftests/net/msg_zerocopy.c:	completions += range;
tools/testing/selftests/net/msg_zerocopy.c:static void do_recv_completions(int fd, int domain)
tools/testing/selftests/net/msg_zerocopy.c:	while (do_recv_completion(fd, domain)) {}
tools/testing/selftests/net/msg_zerocopy.c:/* Wait for all remaining completions on the errqueue */
tools/testing/selftests/net/msg_zerocopy.c:static void do_recv_remaining_completions(int fd, int domain)
tools/testing/selftests/net/msg_zerocopy.c:	while (completions < expected_completions &&
tools/testing/selftests/net/msg_zerocopy.c:			do_recv_completions(fd, domain);
tools/testing/selftests/net/msg_zerocopy.c:	if (completions < expected_completions)
tools/testing/selftests/net/msg_zerocopy.c:			completions, expected_completions);
tools/testing/selftests/net/msg_zerocopy.c:			do_recv_completions(fd, domain);
tools/testing/selftests/net/msg_zerocopy.c:				do_recv_completions(fd, domain);
tools/testing/selftests/net/msg_zerocopy.c:		do_recv_remaining_completions(fd, domain);
tools/testing/selftests/net/msg_zerocopy.c:		packets, bytes >> 20, completions,
tools/testing/selftests/net/netfilter/nft_queue.sh:	# completion, nfnetlink should do so automatically because nf_queue
tools/testing/selftests/net/udpgso_bench_tx.c:			error(1, 0, "Unexpected number of Zerocopy completions: %9lu expected %9lu received",
tools/testing/selftests/powerpc/nx-gzip/gunz_test.c: * ce:       completion extension
tools/testing/selftests/powerpc/nx-gzip/gunz_test.c:		 * CC=3 CE(1)=0 CE(0)=1 indicates partial completion
tools/testing/selftests/powerpc/nx-gzip/gunz_test.c:		    csb_ce_partial_completion(nx_ce)) {
tools/testing/selftests/powerpc/nx-gzip/gzfht_test.c: * ce:       completion extension
tools/testing/selftests/powerpc/nx-gzip/include/crb.h:/* Chapter 6.5.8 Coprocessor-Completion Block (CCB) */
tools/testing/selftests/powerpc/nx-gzip/include/crb.h:#define CCB_CM0_ALL_COMPLETIONS	(0x0)
tools/testing/selftests/powerpc/nx-gzip/include/crb.h:struct coprocessor_completion_block {
tools/testing/selftests/powerpc/nx-gzip/include/crb.h:	struct coprocessor_completion_block ccb;
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h: * ce:       completion extension
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:		/* cs completion sequence; unused */
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:		/* cc completion code; cc != 0 exception occurred */
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:		/* ce completion extension */
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:	/* Coprocessor Completion Block, Section 6.7 */
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:		 * completion interrupt RA, PSWID, and job utilization counter.
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h: * Completion extension ce(0) ce(1) ce(2).  Bits ce(3-7)
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:#define csb_ce_check_completion(X)    (!csb_ce_termination(X))
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:/* if not terminated then check full or partial completion */
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:#define csb_ce_partial_completion(X)  (!!((X) & CSB_CE_PARTIAL))
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:#define csb_ce_full_completion(X)     (!csb_ce_partial_completion(X))
tools/testing/selftests/powerpc/nx-gzip/include/nxu.h:#define csb_ce_cc3_partial(X)         csb_ce_partial_completion(X)
tools/testing/selftests/x86/lam.c:/* Init submission queue and completion queue */
tools/testing/selftests/x86/lam.c: * Get data from completion queue. the data buffer saved the file data
tools/testing/vsock/msg_zerocopy_common.c:void vsock_recv_completion(int fd, const bool *zerocopied)
tools/testing/vsock/msg_zerocopy_common.h:void vsock_recv_completion(int fd, const bool *zerocopied);
tools/testing/vsock/vsock_perf.c:			vsock_recv_completion(fd, NULL);
tools/testing/vsock/vsock_test_zerocopy.c:		vsock_recv_completion(fd, &test_data->zerocopied);
tools/virtio/ringtest/ring.c:	/* simple in-order completion: we don't need
virt/kvm/async_pf.c:	 * The apf struct may be freed by kvm_check_async_pf_completion() as
virt/kvm/async_pf.c:	 * i.e. async_pf_execute(), to run to completion.  If KVM is a module,
virt/kvm/async_pf.c:	 * is always required when the item is taken off the completion queue.
virt/kvm/async_pf.c:void kvm_clear_async_pf_completion_queue(struct kvm_vcpu *vcpu)
virt/kvm/async_pf.c:void kvm_check_async_pf_completion(struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:	struct completion init_done;
virt/kvm/kvm_main.c:	 * kthread_stop() waits on the 'exited' completion condition which is
virt/kvm/kvm_main.c:	init_completion(&init_context.init_done);
virt/kvm/kvm_main.c:	wait_for_completion(&init_context.init_done);
